{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 5.0,
  "eval_steps": 500,
  "global_step": 2360,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0211864406779661,
      "grad_norm": 19.892738342285156,
      "learning_rate": 1.6949152542372882e-06,
      "loss": 1.8912,
      "step": 10
    },
    {
      "epoch": 0.0423728813559322,
      "grad_norm": 1.2476916313171387,
      "learning_rate": 3.813559322033899e-06,
      "loss": 0.4268,
      "step": 20
    },
    {
      "epoch": 0.0635593220338983,
      "grad_norm": 0.48674246668815613,
      "learning_rate": 5.932203389830509e-06,
      "loss": 0.2087,
      "step": 30
    },
    {
      "epoch": 0.0847457627118644,
      "grad_norm": 0.49312594532966614,
      "learning_rate": 8.050847457627118e-06,
      "loss": 0.2028,
      "step": 40
    },
    {
      "epoch": 0.1059322033898305,
      "grad_norm": 0.5491188168525696,
      "learning_rate": 1.016949152542373e-05,
      "loss": 0.1958,
      "step": 50
    },
    {
      "epoch": 0.1271186440677966,
      "grad_norm": 0.3193136155605316,
      "learning_rate": 1.228813559322034e-05,
      "loss": 0.2017,
      "step": 60
    },
    {
      "epoch": 0.1483050847457627,
      "grad_norm": 0.5986990928649902,
      "learning_rate": 1.440677966101695e-05,
      "loss": 0.1867,
      "step": 70
    },
    {
      "epoch": 0.1694915254237288,
      "grad_norm": 0.6053755879402161,
      "learning_rate": 1.652542372881356e-05,
      "loss": 0.212,
      "step": 80
    },
    {
      "epoch": 0.1906779661016949,
      "grad_norm": 0.4479188323020935,
      "learning_rate": 1.864406779661017e-05,
      "loss": 0.2034,
      "step": 90
    },
    {
      "epoch": 0.211864406779661,
      "grad_norm": 0.30023130774497986,
      "learning_rate": 2.076271186440678e-05,
      "loss": 0.1905,
      "step": 100
    },
    {
      "epoch": 0.2330508474576271,
      "grad_norm": 0.5786157250404358,
      "learning_rate": 2.2881355932203392e-05,
      "loss": 0.1851,
      "step": 110
    },
    {
      "epoch": 0.2542372881355932,
      "grad_norm": 0.2949168384075165,
      "learning_rate": 2.5e-05,
      "loss": 0.2023,
      "step": 120
    },
    {
      "epoch": 0.2754237288135593,
      "grad_norm": 0.44998863339424133,
      "learning_rate": 2.711864406779661e-05,
      "loss": 0.1727,
      "step": 130
    },
    {
      "epoch": 0.2966101694915254,
      "grad_norm": 0.5503289103507996,
      "learning_rate": 2.9237288135593223e-05,
      "loss": 0.1927,
      "step": 140
    },
    {
      "epoch": 0.3177966101694915,
      "grad_norm": 0.3494255840778351,
      "learning_rate": 3.135593220338983e-05,
      "loss": 0.1909,
      "step": 150
    },
    {
      "epoch": 0.3389830508474576,
      "grad_norm": 0.40492263436317444,
      "learning_rate": 3.347457627118644e-05,
      "loss": 0.2028,
      "step": 160
    },
    {
      "epoch": 0.3601694915254237,
      "grad_norm": 0.2845303416252136,
      "learning_rate": 3.559322033898305e-05,
      "loss": 0.1966,
      "step": 170
    },
    {
      "epoch": 0.3813559322033898,
      "grad_norm": 0.5049861669540405,
      "learning_rate": 3.771186440677966e-05,
      "loss": 0.1818,
      "step": 180
    },
    {
      "epoch": 0.4025423728813559,
      "grad_norm": 0.47065168619155884,
      "learning_rate": 3.983050847457627e-05,
      "loss": 0.1625,
      "step": 190
    },
    {
      "epoch": 0.423728813559322,
      "grad_norm": 0.4790220856666565,
      "learning_rate": 4.1949152542372886e-05,
      "loss": 0.1929,
      "step": 200
    },
    {
      "epoch": 0.4449152542372881,
      "grad_norm": 0.283799409866333,
      "learning_rate": 4.4067796610169495e-05,
      "loss": 0.1749,
      "step": 210
    },
    {
      "epoch": 0.4661016949152542,
      "grad_norm": 0.6958953142166138,
      "learning_rate": 4.6186440677966104e-05,
      "loss": 0.1888,
      "step": 220
    },
    {
      "epoch": 0.4872881355932203,
      "grad_norm": 0.7441908121109009,
      "learning_rate": 4.8305084745762714e-05,
      "loss": 0.2011,
      "step": 230
    },
    {
      "epoch": 0.5084745762711864,
      "grad_norm": 0.31565579771995544,
      "learning_rate": 4.999989061433581e-05,
      "loss": 0.1855,
      "step": 240
    },
    {
      "epoch": 0.5296610169491526,
      "grad_norm": 0.5441368222236633,
      "learning_rate": 4.999606221659595e-05,
      "loss": 0.1981,
      "step": 250
    },
    {
      "epoch": 0.5508474576271186,
      "grad_norm": 0.661164402961731,
      "learning_rate": 4.998676549282661e-05,
      "loss": 0.1712,
      "step": 260
    },
    {
      "epoch": 0.5720338983050848,
      "grad_norm": 0.5017856955528259,
      "learning_rate": 4.99720024768488e-05,
      "loss": 0.1901,
      "step": 270
    },
    {
      "epoch": 0.5932203389830508,
      "grad_norm": 0.7548266053199768,
      "learning_rate": 4.995177639833062e-05,
      "loss": 0.1834,
      "step": 280
    },
    {
      "epoch": 0.614406779661017,
      "grad_norm": 0.5480944514274597,
      "learning_rate": 4.992609168208069e-05,
      "loss": 0.187,
      "step": 290
    },
    {
      "epoch": 0.635593220338983,
      "grad_norm": 0.8947196006774902,
      "learning_rate": 4.989495394708015e-05,
      "loss": 0.1924,
      "step": 300
    },
    {
      "epoch": 0.6567796610169492,
      "grad_norm": 0.7457882761955261,
      "learning_rate": 4.985837000525343e-05,
      "loss": 0.1906,
      "step": 310
    },
    {
      "epoch": 0.6779661016949152,
      "grad_norm": 0.5802835822105408,
      "learning_rate": 4.981634785997802e-05,
      "loss": 0.1927,
      "step": 320
    },
    {
      "epoch": 0.6991525423728814,
      "grad_norm": 0.29552918672561646,
      "learning_rate": 4.976889670433355e-05,
      "loss": 0.1883,
      "step": 330
    },
    {
      "epoch": 0.7203389830508474,
      "grad_norm": 0.52114337682724,
      "learning_rate": 4.9716026919090705e-05,
      "loss": 0.1882,
      "step": 340
    },
    {
      "epoch": 0.7415254237288136,
      "grad_norm": 0.9799765944480896,
      "learning_rate": 4.9657750070440196e-05,
      "loss": 0.1935,
      "step": 350
    },
    {
      "epoch": 0.7627118644067796,
      "grad_norm": 0.7654495239257812,
      "learning_rate": 4.959407890746248e-05,
      "loss": 0.1901,
      "step": 360
    },
    {
      "epoch": 0.7838983050847458,
      "grad_norm": 0.41431570053100586,
      "learning_rate": 4.9525027359338696e-05,
      "loss": 0.1826,
      "step": 370
    },
    {
      "epoch": 0.8050847457627118,
      "grad_norm": 0.6432830095291138,
      "learning_rate": 4.945061053230333e-05,
      "loss": 0.1781,
      "step": 380
    },
    {
      "epoch": 0.826271186440678,
      "grad_norm": 0.30043739080429077,
      "learning_rate": 4.9370844706339594e-05,
      "loss": 0.1774,
      "step": 390
    },
    {
      "epoch": 0.847457627118644,
      "grad_norm": 0.6730603575706482,
      "learning_rate": 4.9285747331617746e-05,
      "loss": 0.1953,
      "step": 400
    },
    {
      "epoch": 0.8686440677966102,
      "grad_norm": 0.5569420456886292,
      "learning_rate": 4.919533702467771e-05,
      "loss": 0.188,
      "step": 410
    },
    {
      "epoch": 0.8898305084745762,
      "grad_norm": 0.8221478462219238,
      "learning_rate": 4.909963356435624e-05,
      "loss": 0.1904,
      "step": 420
    },
    {
      "epoch": 0.9110169491525424,
      "grad_norm": 0.7826105356216431,
      "learning_rate": 4.899865788746005e-05,
      "loss": 0.1874,
      "step": 430
    },
    {
      "epoch": 0.9322033898305084,
      "grad_norm": 1.3296765089035034,
      "learning_rate": 4.88924320841855e-05,
      "loss": 0.1834,
      "step": 440
    },
    {
      "epoch": 0.9533898305084746,
      "grad_norm": 0.7198671102523804,
      "learning_rate": 4.878097939328596e-05,
      "loss": 0.1933,
      "step": 450
    },
    {
      "epoch": 0.9745762711864406,
      "grad_norm": 0.45594722032546997,
      "learning_rate": 4.866432419698792e-05,
      "loss": 0.1723,
      "step": 460
    },
    {
      "epoch": 0.9957627118644068,
      "grad_norm": 0.44286423921585083,
      "learning_rate": 4.854249201565701e-05,
      "loss": 0.1858,
      "step": 470
    },
    {
      "epoch": 1.0169491525423728,
      "grad_norm": 0.7107579112052917,
      "learning_rate": 4.841550950221486e-05,
      "loss": 0.1749,
      "step": 480
    },
    {
      "epoch": 1.0381355932203389,
      "grad_norm": 0.673674464225769,
      "learning_rate": 4.8283404436308464e-05,
      "loss": 0.1761,
      "step": 490
    },
    {
      "epoch": 1.0593220338983051,
      "grad_norm": 0.668224573135376,
      "learning_rate": 4.814620571823275e-05,
      "loss": 0.1761,
      "step": 500
    },
    {
      "epoch": 1.0805084745762712,
      "grad_norm": 0.5763281583786011,
      "learning_rate": 4.80039433626082e-05,
      "loss": 0.18,
      "step": 510
    },
    {
      "epoch": 1.1016949152542372,
      "grad_norm": 0.69967120885849,
      "learning_rate": 4.785664849181465e-05,
      "loss": 0.1692,
      "step": 520
    },
    {
      "epoch": 1.1228813559322033,
      "grad_norm": 0.6492807865142822,
      "learning_rate": 4.7704353329182673e-05,
      "loss": 0.1743,
      "step": 530
    },
    {
      "epoch": 1.1440677966101696,
      "grad_norm": 0.44814804196357727,
      "learning_rate": 4.7547091191944184e-05,
      "loss": 0.1678,
      "step": 540
    },
    {
      "epoch": 1.1652542372881356,
      "grad_norm": 0.4678633511066437,
      "learning_rate": 4.738489648394373e-05,
      "loss": 0.1606,
      "step": 550
    },
    {
      "epoch": 1.1864406779661016,
      "grad_norm": 0.6419798135757446,
      "learning_rate": 4.7217804688112014e-05,
      "loss": 0.1654,
      "step": 560
    },
    {
      "epoch": 1.207627118644068,
      "grad_norm": 0.6985452771186829,
      "learning_rate": 4.70458523587034e-05,
      "loss": 0.1722,
      "step": 570
    },
    {
      "epoch": 1.228813559322034,
      "grad_norm": 0.7107846736907959,
      "learning_rate": 4.686907711329903e-05,
      "loss": 0.1624,
      "step": 580
    },
    {
      "epoch": 1.25,
      "grad_norm": 0.44929197430610657,
      "learning_rate": 4.668751762457734e-05,
      "loss": 0.1544,
      "step": 590
    },
    {
      "epoch": 1.271186440677966,
      "grad_norm": 1.0398144721984863,
      "learning_rate": 4.650121361185368e-05,
      "loss": 0.1596,
      "step": 600
    },
    {
      "epoch": 1.292372881355932,
      "grad_norm": 0.8165411353111267,
      "learning_rate": 4.631020583239107e-05,
      "loss": 0.1761,
      "step": 610
    },
    {
      "epoch": 1.3135593220338984,
      "grad_norm": 0.8720623850822449,
      "learning_rate": 4.611453607248381e-05,
      "loss": 0.171,
      "step": 620
    },
    {
      "epoch": 1.3347457627118644,
      "grad_norm": 0.5372382998466492,
      "learning_rate": 4.5914247138316025e-05,
      "loss": 0.1743,
      "step": 630
    },
    {
      "epoch": 1.3559322033898304,
      "grad_norm": 0.6509917974472046,
      "learning_rate": 4.570938284659702e-05,
      "loss": 0.1654,
      "step": 640
    },
    {
      "epoch": 1.3771186440677967,
      "grad_norm": 0.5730022192001343,
      "learning_rate": 4.549998801497564e-05,
      "loss": 0.1558,
      "step": 650
    },
    {
      "epoch": 1.3983050847457628,
      "grad_norm": 0.7399634718894958,
      "learning_rate": 4.528610845223562e-05,
      "loss": 0.1817,
      "step": 660
    },
    {
      "epoch": 1.4194915254237288,
      "grad_norm": 0.5734956860542297,
      "learning_rate": 4.5067790948274094e-05,
      "loss": 0.1784,
      "step": 670
    },
    {
      "epoch": 1.4406779661016949,
      "grad_norm": 1.731848955154419,
      "learning_rate": 4.484508326386552e-05,
      "loss": 0.1874,
      "step": 680
    },
    {
      "epoch": 1.461864406779661,
      "grad_norm": 0.5764203071594238,
      "learning_rate": 4.461803412021314e-05,
      "loss": 0.1741,
      "step": 690
    },
    {
      "epoch": 1.4830508474576272,
      "grad_norm": 0.6602986454963684,
      "learning_rate": 4.4386693188290376e-05,
      "loss": 0.1721,
      "step": 700
    },
    {
      "epoch": 1.5042372881355932,
      "grad_norm": 0.6778096556663513,
      "learning_rate": 4.415111107797445e-05,
      "loss": 0.1627,
      "step": 710
    },
    {
      "epoch": 1.5254237288135593,
      "grad_norm": 0.5566237568855286,
      "learning_rate": 4.3911339326974587e-05,
      "loss": 0.1702,
      "step": 720
    },
    {
      "epoch": 1.5466101694915255,
      "grad_norm": 1.002274990081787,
      "learning_rate": 4.36674303895572e-05,
      "loss": 0.1688,
      "step": 730
    },
    {
      "epoch": 1.5677966101694916,
      "grad_norm": 0.6396938562393188,
      "learning_rate": 4.3419437625070634e-05,
      "loss": 0.1669,
      "step": 740
    },
    {
      "epoch": 1.5889830508474576,
      "grad_norm": 0.8814491033554077,
      "learning_rate": 4.3167415286271905e-05,
      "loss": 0.1724,
      "step": 750
    },
    {
      "epoch": 1.6101694915254239,
      "grad_norm": 0.5375171303749084,
      "learning_rate": 4.291141850745788e-05,
      "loss": 0.1555,
      "step": 760
    },
    {
      "epoch": 1.6313559322033897,
      "grad_norm": 0.788804829120636,
      "learning_rate": 4.265150329240376e-05,
      "loss": 0.1529,
      "step": 770
    },
    {
      "epoch": 1.652542372881356,
      "grad_norm": 0.4957978129386902,
      "learning_rate": 4.238772650211123e-05,
      "loss": 0.1614,
      "step": 780
    },
    {
      "epoch": 1.673728813559322,
      "grad_norm": 0.5169104337692261,
      "learning_rate": 4.212014584236914e-05,
      "loss": 0.158,
      "step": 790
    },
    {
      "epoch": 1.694915254237288,
      "grad_norm": 0.672309935092926,
      "learning_rate": 4.184881985112935e-05,
      "loss": 0.1692,
      "step": 800
    },
    {
      "epoch": 1.7161016949152543,
      "grad_norm": 1.0081223249435425,
      "learning_rate": 4.157380788570053e-05,
      "loss": 0.1895,
      "step": 810
    },
    {
      "epoch": 1.7372881355932204,
      "grad_norm": 0.60317063331604,
      "learning_rate": 4.1295170109762685e-05,
      "loss": 0.1801,
      "step": 820
    },
    {
      "epoch": 1.7584745762711864,
      "grad_norm": 0.9165993928909302,
      "learning_rate": 4.101296748020533e-05,
      "loss": 0.1619,
      "step": 830
    },
    {
      "epoch": 1.7796610169491527,
      "grad_norm": 0.4591347277164459,
      "learning_rate": 4.072726173379213e-05,
      "loss": 0.1717,
      "step": 840
    },
    {
      "epoch": 1.8008474576271185,
      "grad_norm": 0.5730170011520386,
      "learning_rate": 4.04381153736548e-05,
      "loss": 0.1625,
      "step": 850
    },
    {
      "epoch": 1.8220338983050848,
      "grad_norm": 0.4473676085472107,
      "learning_rate": 4.014559165561956e-05,
      "loss": 0.1548,
      "step": 860
    },
    {
      "epoch": 1.8432203389830508,
      "grad_norm": 0.5471455454826355,
      "learning_rate": 3.9849754574368766e-05,
      "loss": 0.1517,
      "step": 870
    },
    {
      "epoch": 1.8644067796610169,
      "grad_norm": 0.502757728099823,
      "learning_rate": 3.955066884944094e-05,
      "loss": 0.1745,
      "step": 880
    },
    {
      "epoch": 1.8855932203389831,
      "grad_norm": 0.2997833490371704,
      "learning_rate": 3.924839991107229e-05,
      "loss": 0.1728,
      "step": 890
    },
    {
      "epoch": 1.9067796610169492,
      "grad_norm": 0.7862922549247742,
      "learning_rate": 3.894301388588264e-05,
      "loss": 0.1663,
      "step": 900
    },
    {
      "epoch": 1.9279661016949152,
      "grad_norm": 0.9466378688812256,
      "learning_rate": 3.863457758240912e-05,
      "loss": 0.1708,
      "step": 910
    },
    {
      "epoch": 1.9491525423728815,
      "grad_norm": 0.6297903060913086,
      "learning_rate": 3.83231584764906e-05,
      "loss": 0.1529,
      "step": 920
    },
    {
      "epoch": 1.9703389830508473,
      "grad_norm": 0.6269917488098145,
      "learning_rate": 3.800882469650621e-05,
      "loss": 0.1669,
      "step": 930
    },
    {
      "epoch": 1.9915254237288136,
      "grad_norm": 0.38416263461112976,
      "learning_rate": 3.7691645008471e-05,
      "loss": 0.168,
      "step": 940
    },
    {
      "epoch": 2.01271186440678,
      "grad_norm": 0.41935214400291443,
      "learning_rate": 3.7371688800992235e-05,
      "loss": 0.1499,
      "step": 950
    },
    {
      "epoch": 2.0338983050847457,
      "grad_norm": 0.5914170742034912,
      "learning_rate": 3.704902607008938e-05,
      "loss": 0.1204,
      "step": 960
    },
    {
      "epoch": 2.055084745762712,
      "grad_norm": 1.1099097728729248,
      "learning_rate": 3.6723727403881284e-05,
      "loss": 0.0967,
      "step": 970
    },
    {
      "epoch": 2.0762711864406778,
      "grad_norm": 0.4850381314754486,
      "learning_rate": 3.639586396714374e-05,
      "loss": 0.1386,
      "step": 980
    },
    {
      "epoch": 2.097457627118644,
      "grad_norm": 0.7214577198028564,
      "learning_rate": 3.6065507485741e-05,
      "loss": 0.1115,
      "step": 990
    },
    {
      "epoch": 2.1186440677966103,
      "grad_norm": 0.7372007369995117,
      "learning_rate": 3.5732730230934466e-05,
      "loss": 0.1269,
      "step": 1000
    },
    {
      "epoch": 2.139830508474576,
      "grad_norm": 0.9480583071708679,
      "learning_rate": 3.539760500357207e-05,
      "loss": 0.1151,
      "step": 1010
    },
    {
      "epoch": 2.1610169491525424,
      "grad_norm": 0.8817967772483826,
      "learning_rate": 3.506020511816182e-05,
      "loss": 0.1237,
      "step": 1020
    },
    {
      "epoch": 2.1822033898305087,
      "grad_norm": 1.0037592649459839,
      "learning_rate": 3.472060438683302e-05,
      "loss": 0.1308,
      "step": 1030
    },
    {
      "epoch": 2.2033898305084745,
      "grad_norm": 1.3875430822372437,
      "learning_rate": 3.437887710318848e-05,
      "loss": 0.1085,
      "step": 1040
    },
    {
      "epoch": 2.2245762711864407,
      "grad_norm": 0.9858024716377258,
      "learning_rate": 3.403509802605159e-05,
      "loss": 0.1249,
      "step": 1050
    },
    {
      "epoch": 2.2457627118644066,
      "grad_norm": 1.4152709245681763,
      "learning_rate": 3.3689342363111435e-05,
      "loss": 0.127,
      "step": 1060
    },
    {
      "epoch": 2.266949152542373,
      "grad_norm": 0.657599925994873,
      "learning_rate": 3.3341685754469856e-05,
      "loss": 0.1221,
      "step": 1070
    },
    {
      "epoch": 2.288135593220339,
      "grad_norm": 1.2346174716949463,
      "learning_rate": 3.2992204256093815e-05,
      "loss": 0.1384,
      "step": 1080
    },
    {
      "epoch": 2.309322033898305,
      "grad_norm": 0.6870213747024536,
      "learning_rate": 3.2640974323176846e-05,
      "loss": 0.1088,
      "step": 1090
    },
    {
      "epoch": 2.330508474576271,
      "grad_norm": 1.3838870525360107,
      "learning_rate": 3.228807279341315e-05,
      "loss": 0.0987,
      "step": 1100
    },
    {
      "epoch": 2.3516949152542375,
      "grad_norm": 0.8917375802993774,
      "learning_rate": 3.193357687018798e-05,
      "loss": 0.1356,
      "step": 1110
    },
    {
      "epoch": 2.3728813559322033,
      "grad_norm": 0.7369246482849121,
      "learning_rate": 3.157756410568803e-05,
      "loss": 0.1164,
      "step": 1120
    },
    {
      "epoch": 2.3940677966101696,
      "grad_norm": 0.8573193550109863,
      "learning_rate": 3.122011238393562e-05,
      "loss": 0.1024,
      "step": 1130
    },
    {
      "epoch": 2.415254237288136,
      "grad_norm": 2.2017292976379395,
      "learning_rate": 3.086129990375012e-05,
      "loss": 0.1077,
      "step": 1140
    },
    {
      "epoch": 2.4364406779661016,
      "grad_norm": 0.9523153305053711,
      "learning_rate": 3.050120516164062e-05,
      "loss": 0.1002,
      "step": 1150
    },
    {
      "epoch": 2.457627118644068,
      "grad_norm": 0.9458925127983093,
      "learning_rate": 3.0139906934633443e-05,
      "loss": 0.1369,
      "step": 1160
    },
    {
      "epoch": 2.4788135593220337,
      "grad_norm": 0.6750054359436035,
      "learning_rate": 2.9777484263038306e-05,
      "loss": 0.1194,
      "step": 1170
    },
    {
      "epoch": 2.5,
      "grad_norm": 1.5663542747497559,
      "learning_rate": 2.941401643315686e-05,
      "loss": 0.1267,
      "step": 1180
    },
    {
      "epoch": 2.5211864406779663,
      "grad_norm": 0.8814593553543091,
      "learning_rate": 2.9049582959937392e-05,
      "loss": 0.1261,
      "step": 1190
    },
    {
      "epoch": 2.542372881355932,
      "grad_norm": 0.8683400750160217,
      "learning_rate": 2.8684263569579605e-05,
      "loss": 0.1179,
      "step": 1200
    },
    {
      "epoch": 2.5635593220338984,
      "grad_norm": 1.058855652809143,
      "learning_rate": 2.8318138182093052e-05,
      "loss": 0.1098,
      "step": 1210
    },
    {
      "epoch": 2.584745762711864,
      "grad_norm": 0.7650113105773926,
      "learning_rate": 2.7951286893813272e-05,
      "loss": 0.1055,
      "step": 1220
    },
    {
      "epoch": 2.6059322033898304,
      "grad_norm": 0.8259203433990479,
      "learning_rate": 2.7583789959879303e-05,
      "loss": 0.1023,
      "step": 1230
    },
    {
      "epoch": 2.6271186440677967,
      "grad_norm": 1.567091941833496,
      "learning_rate": 2.721572777667648e-05,
      "loss": 0.1043,
      "step": 1240
    },
    {
      "epoch": 2.648305084745763,
      "grad_norm": 1.21852445602417,
      "learning_rate": 2.6847180864248283e-05,
      "loss": 0.1358,
      "step": 1250
    },
    {
      "epoch": 2.669491525423729,
      "grad_norm": 0.956703245639801,
      "learning_rate": 2.647822984868122e-05,
      "loss": 0.1111,
      "step": 1260
    },
    {
      "epoch": 2.690677966101695,
      "grad_norm": 0.9401609301567078,
      "learning_rate": 2.610895544446641e-05,
      "loss": 0.1092,
      "step": 1270
    },
    {
      "epoch": 2.711864406779661,
      "grad_norm": 1.8761042356491089,
      "learning_rate": 2.573943843684192e-05,
      "loss": 0.0986,
      "step": 1280
    },
    {
      "epoch": 2.733050847457627,
      "grad_norm": 1.3215430974960327,
      "learning_rate": 2.5369759664119537e-05,
      "loss": 0.1062,
      "step": 1290
    },
    {
      "epoch": 2.7542372881355934,
      "grad_norm": 1.0375032424926758,
      "learning_rate": 2.5e-05,
      "loss": 0.1387,
      "step": 1300
    },
    {
      "epoch": 2.7754237288135593,
      "grad_norm": 0.8346896171569824,
      "learning_rate": 2.4630240335880462e-05,
      "loss": 0.1132,
      "step": 1310
    },
    {
      "epoch": 2.7966101694915255,
      "grad_norm": 0.7258110046386719,
      "learning_rate": 2.426056156315808e-05,
      "loss": 0.112,
      "step": 1320
    },
    {
      "epoch": 2.8177966101694913,
      "grad_norm": 1.0053722858428955,
      "learning_rate": 2.3891044555533588e-05,
      "loss": 0.1194,
      "step": 1330
    },
    {
      "epoch": 2.8389830508474576,
      "grad_norm": 1.4935792684555054,
      "learning_rate": 2.3521770151318787e-05,
      "loss": 0.1257,
      "step": 1340
    },
    {
      "epoch": 2.860169491525424,
      "grad_norm": 0.9414846301078796,
      "learning_rate": 2.3152819135751722e-05,
      "loss": 0.127,
      "step": 1350
    },
    {
      "epoch": 2.8813559322033897,
      "grad_norm": 1.2237597703933716,
      "learning_rate": 2.278427222332353e-05,
      "loss": 0.1248,
      "step": 1360
    },
    {
      "epoch": 2.902542372881356,
      "grad_norm": 1.0603785514831543,
      "learning_rate": 2.2416210040120703e-05,
      "loss": 0.1239,
      "step": 1370
    },
    {
      "epoch": 2.923728813559322,
      "grad_norm": 1.7570569515228271,
      "learning_rate": 2.2048713106186737e-05,
      "loss": 0.1274,
      "step": 1380
    },
    {
      "epoch": 2.944915254237288,
      "grad_norm": 0.9535859227180481,
      "learning_rate": 2.1681861817906954e-05,
      "loss": 0.1173,
      "step": 1390
    },
    {
      "epoch": 2.9661016949152543,
      "grad_norm": 1.7966513633728027,
      "learning_rate": 2.131573643042039e-05,
      "loss": 0.1175,
      "step": 1400
    },
    {
      "epoch": 2.9872881355932206,
      "grad_norm": 0.9366121292114258,
      "learning_rate": 2.095041704006261e-05,
      "loss": 0.1024,
      "step": 1410
    },
    {
      "epoch": 3.0084745762711864,
      "grad_norm": 0.48958349227905273,
      "learning_rate": 2.0585983566843145e-05,
      "loss": 0.1135,
      "step": 1420
    },
    {
      "epoch": 3.0296610169491527,
      "grad_norm": 0.5271353721618652,
      "learning_rate": 2.0222515736961696e-05,
      "loss": 0.0638,
      "step": 1430
    },
    {
      "epoch": 3.0508474576271185,
      "grad_norm": 1.0973058938980103,
      "learning_rate": 1.986009306536656e-05,
      "loss": 0.0495,
      "step": 1440
    },
    {
      "epoch": 3.0720338983050848,
      "grad_norm": 1.0155997276306152,
      "learning_rate": 1.949879483835939e-05,
      "loss": 0.0604,
      "step": 1450
    },
    {
      "epoch": 3.093220338983051,
      "grad_norm": 0.6359690427780151,
      "learning_rate": 1.9138700096249885e-05,
      "loss": 0.0668,
      "step": 1460
    },
    {
      "epoch": 3.114406779661017,
      "grad_norm": 1.7137157917022705,
      "learning_rate": 1.8779887616064383e-05,
      "loss": 0.0621,
      "step": 1470
    },
    {
      "epoch": 3.135593220338983,
      "grad_norm": 1.3690801858901978,
      "learning_rate": 1.8422435894311972e-05,
      "loss": 0.07,
      "step": 1480
    },
    {
      "epoch": 3.156779661016949,
      "grad_norm": 1.173703908920288,
      "learning_rate": 1.8066423129812027e-05,
      "loss": 0.0429,
      "step": 1490
    },
    {
      "epoch": 3.1779661016949152,
      "grad_norm": 0.30310317873954773,
      "learning_rate": 1.7711927206586853e-05,
      "loss": 0.0435,
      "step": 1500
    },
    {
      "epoch": 3.1991525423728815,
      "grad_norm": 0.7217503786087036,
      "learning_rate": 1.735902567682315e-05,
      "loss": 0.0427,
      "step": 1510
    },
    {
      "epoch": 3.2203389830508473,
      "grad_norm": 2.4097652435302734,
      "learning_rate": 1.7007795743906198e-05,
      "loss": 0.0773,
      "step": 1520
    },
    {
      "epoch": 3.2415254237288136,
      "grad_norm": 1.233010172843933,
      "learning_rate": 1.665831424553015e-05,
      "loss": 0.0641,
      "step": 1530
    },
    {
      "epoch": 3.26271186440678,
      "grad_norm": 1.4098470211029053,
      "learning_rate": 1.6310657636888574e-05,
      "loss": 0.0551,
      "step": 1540
    },
    {
      "epoch": 3.2838983050847457,
      "grad_norm": 0.659474790096283,
      "learning_rate": 1.596490197394841e-05,
      "loss": 0.0563,
      "step": 1550
    },
    {
      "epoch": 3.305084745762712,
      "grad_norm": 2.324876070022583,
      "learning_rate": 1.5621122896811524e-05,
      "loss": 0.0639,
      "step": 1560
    },
    {
      "epoch": 3.326271186440678,
      "grad_norm": 1.242828130722046,
      "learning_rate": 1.5279395613166986e-05,
      "loss": 0.0495,
      "step": 1570
    },
    {
      "epoch": 3.347457627118644,
      "grad_norm": 0.9368425607681274,
      "learning_rate": 1.4939794881838179e-05,
      "loss": 0.0646,
      "step": 1580
    },
    {
      "epoch": 3.3686440677966103,
      "grad_norm": 1.7941477298736572,
      "learning_rate": 1.4602394996427942e-05,
      "loss": 0.0441,
      "step": 1590
    },
    {
      "epoch": 3.389830508474576,
      "grad_norm": 1.0141535997390747,
      "learning_rate": 1.4267269769065538e-05,
      "loss": 0.0619,
      "step": 1600
    },
    {
      "epoch": 3.4110169491525424,
      "grad_norm": 1.9156450033187866,
      "learning_rate": 1.3934492514259003e-05,
      "loss": 0.0477,
      "step": 1610
    },
    {
      "epoch": 3.4322033898305087,
      "grad_norm": 0.6379232406616211,
      "learning_rate": 1.3604136032856268e-05,
      "loss": 0.0459,
      "step": 1620
    },
    {
      "epoch": 3.4533898305084745,
      "grad_norm": 1.3819389343261719,
      "learning_rate": 1.327627259611873e-05,
      "loss": 0.0461,
      "step": 1630
    },
    {
      "epoch": 3.4745762711864407,
      "grad_norm": 1.287648320198059,
      "learning_rate": 1.295097392991062e-05,
      "loss": 0.0392,
      "step": 1640
    },
    {
      "epoch": 3.4957627118644066,
      "grad_norm": 1.8540884256362915,
      "learning_rate": 1.2628311199007764e-05,
      "loss": 0.0537,
      "step": 1650
    },
    {
      "epoch": 3.516949152542373,
      "grad_norm": 2.250380277633667,
      "learning_rate": 1.2308354991529009e-05,
      "loss": 0.0591,
      "step": 1660
    },
    {
      "epoch": 3.538135593220339,
      "grad_norm": 0.7868553996086121,
      "learning_rate": 1.1991175303493793e-05,
      "loss": 0.0584,
      "step": 1670
    },
    {
      "epoch": 3.559322033898305,
      "grad_norm": 1.7459231615066528,
      "learning_rate": 1.16768415235094e-05,
      "loss": 0.06,
      "step": 1680
    },
    {
      "epoch": 3.580508474576271,
      "grad_norm": 1.3614205121994019,
      "learning_rate": 1.1365422417590878e-05,
      "loss": 0.0513,
      "step": 1690
    },
    {
      "epoch": 3.601694915254237,
      "grad_norm": 2.297391891479492,
      "learning_rate": 1.1056986114117369e-05,
      "loss": 0.0586,
      "step": 1700
    },
    {
      "epoch": 3.6228813559322033,
      "grad_norm": 1.0671379566192627,
      "learning_rate": 1.0751600088927713e-05,
      "loss": 0.0554,
      "step": 1710
    },
    {
      "epoch": 3.6440677966101696,
      "grad_norm": 1.2586872577667236,
      "learning_rate": 1.0449331150559064e-05,
      "loss": 0.0455,
      "step": 1720
    },
    {
      "epoch": 3.665254237288136,
      "grad_norm": 0.8296486735343933,
      "learning_rate": 1.0150245425631235e-05,
      "loss": 0.0432,
      "step": 1730
    },
    {
      "epoch": 3.6864406779661016,
      "grad_norm": 0.5818254947662354,
      "learning_rate": 9.854408344380442e-06,
      "loss": 0.0638,
      "step": 1740
    },
    {
      "epoch": 3.707627118644068,
      "grad_norm": 4.196223258972168,
      "learning_rate": 9.561884626345205e-06,
      "loss": 0.0465,
      "step": 1750
    },
    {
      "epoch": 3.7288135593220337,
      "grad_norm": 0.7394505143165588,
      "learning_rate": 9.272738266207872e-06,
      "loss": 0.057,
      "step": 1760
    },
    {
      "epoch": 3.75,
      "grad_norm": 0.7411571145057678,
      "learning_rate": 8.987032519794666e-06,
      "loss": 0.0452,
      "step": 1770
    },
    {
      "epoch": 3.7711864406779663,
      "grad_norm": 0.9729368686676025,
      "learning_rate": 8.704829890237326e-06,
      "loss": 0.0464,
      "step": 1780
    },
    {
      "epoch": 3.792372881355932,
      "grad_norm": 1.7363225221633911,
      "learning_rate": 8.426192114299484e-06,
      "loss": 0.0719,
      "step": 1790
    },
    {
      "epoch": 3.8135593220338984,
      "grad_norm": 0.8600322008132935,
      "learning_rate": 8.15118014887065e-06,
      "loss": 0.0575,
      "step": 1800
    },
    {
      "epoch": 3.834745762711864,
      "grad_norm": 1.5006006956100464,
      "learning_rate": 7.879854157630861e-06,
      "loss": 0.0684,
      "step": 1810
    },
    {
      "epoch": 3.8559322033898304,
      "grad_norm": 0.6346931457519531,
      "learning_rate": 7.6122734978887746e-06,
      "loss": 0.0627,
      "step": 1820
    },
    {
      "epoch": 3.8771186440677967,
      "grad_norm": 0.6377256512641907,
      "learning_rate": 7.348496707596242e-06,
      "loss": 0.0426,
      "step": 1830
    },
    {
      "epoch": 3.898305084745763,
      "grad_norm": 2.6485095024108887,
      "learning_rate": 7.088581492542121e-06,
      "loss": 0.0696,
      "step": 1840
    },
    {
      "epoch": 3.919491525423729,
      "grad_norm": 0.5428787469863892,
      "learning_rate": 6.832584713728101e-06,
      "loss": 0.0389,
      "step": 1850
    },
    {
      "epoch": 3.940677966101695,
      "grad_norm": 0.5070641040802002,
      "learning_rate": 6.580562374929369e-06,
      "loss": 0.0612,
      "step": 1860
    },
    {
      "epoch": 3.961864406779661,
      "grad_norm": 1.119519829750061,
      "learning_rate": 6.332569610442807e-06,
      "loss": 0.0444,
      "step": 1870
    },
    {
      "epoch": 3.983050847457627,
      "grad_norm": 2.2559099197387695,
      "learning_rate": 6.0886606730254176e-06,
      "loss": 0.0606,
      "step": 1880
    },
    {
      "epoch": 4.004237288135593,
      "grad_norm": 0.12269509583711624,
      "learning_rate": 5.848888922025553e-06,
      "loss": 0.0467,
      "step": 1890
    },
    {
      "epoch": 4.02542372881356,
      "grad_norm": 0.4471360146999359,
      "learning_rate": 5.613306811709634e-06,
      "loss": 0.0245,
      "step": 1900
    },
    {
      "epoch": 4.046610169491525,
      "grad_norm": 0.6352507472038269,
      "learning_rate": 5.381965879786868e-06,
      "loss": 0.0257,
      "step": 1910
    },
    {
      "epoch": 4.067796610169491,
      "grad_norm": 0.2947259843349457,
      "learning_rate": 5.154916736134488e-06,
      "loss": 0.0309,
      "step": 1920
    },
    {
      "epoch": 4.088983050847458,
      "grad_norm": 0.5354885458946228,
      "learning_rate": 4.932209051725914e-06,
      "loss": 0.0365,
      "step": 1930
    },
    {
      "epoch": 4.110169491525424,
      "grad_norm": 0.9982395768165588,
      "learning_rate": 4.713891547764384e-06,
      "loss": 0.0265,
      "step": 1940
    },
    {
      "epoch": 4.13135593220339,
      "grad_norm": 0.25293460488319397,
      "learning_rate": 4.500011985024363e-06,
      "loss": 0.0217,
      "step": 1950
    },
    {
      "epoch": 4.1525423728813555,
      "grad_norm": 0.4033403992652893,
      "learning_rate": 4.290617153402984e-06,
      "loss": 0.0236,
      "step": 1960
    },
    {
      "epoch": 4.173728813559322,
      "grad_norm": 0.05204563960433006,
      "learning_rate": 4.085752861683981e-06,
      "loss": 0.0205,
      "step": 1970
    },
    {
      "epoch": 4.194915254237288,
      "grad_norm": 0.4350651800632477,
      "learning_rate": 3.885463927516189e-06,
      "loss": 0.0161,
      "step": 1980
    },
    {
      "epoch": 4.216101694915254,
      "grad_norm": 1.316719889640808,
      "learning_rate": 3.689794167608937e-06,
      "loss": 0.0217,
      "step": 1990
    },
    {
      "epoch": 4.237288135593221,
      "grad_norm": 0.7061627507209778,
      "learning_rate": 3.49878638814633e-06,
      "loss": 0.0234,
      "step": 2000
    },
    {
      "epoch": 4.258474576271187,
      "grad_norm": 2.35050368309021,
      "learning_rate": 3.3124823754226624e-06,
      "loss": 0.0239,
      "step": 2010
    },
    {
      "epoch": 4.279661016949152,
      "grad_norm": 0.2896272540092468,
      "learning_rate": 3.1309228867009682e-06,
      "loss": 0.0263,
      "step": 2020
    },
    {
      "epoch": 4.3008474576271185,
      "grad_norm": 1.2943434715270996,
      "learning_rate": 2.9541476412966036e-06,
      "loss": 0.0309,
      "step": 2030
    },
    {
      "epoch": 4.322033898305085,
      "grad_norm": 1.4804879426956177,
      "learning_rate": 2.7821953118879974e-06,
      "loss": 0.0184,
      "step": 2040
    },
    {
      "epoch": 4.343220338983051,
      "grad_norm": 1.0645824670791626,
      "learning_rate": 2.615103516056275e-06,
      "loss": 0.0245,
      "step": 2050
    },
    {
      "epoch": 4.364406779661017,
      "grad_norm": 0.3815022110939026,
      "learning_rate": 2.4529088080558203e-06,
      "loss": 0.021,
      "step": 2060
    },
    {
      "epoch": 4.385593220338983,
      "grad_norm": 0.32889851927757263,
      "learning_rate": 2.2956466708173307e-06,
      "loss": 0.0212,
      "step": 2070
    },
    {
      "epoch": 4.406779661016949,
      "grad_norm": 1.5347799062728882,
      "learning_rate": 2.1433515081853596e-06,
      "loss": 0.0193,
      "step": 2080
    },
    {
      "epoch": 4.427966101694915,
      "grad_norm": 0.7512704133987427,
      "learning_rate": 1.996056637391805e-06,
      "loss": 0.0244,
      "step": 2090
    },
    {
      "epoch": 4.4491525423728815,
      "grad_norm": 0.5185315608978271,
      "learning_rate": 1.853794281767257e-06,
      "loss": 0.0331,
      "step": 2100
    },
    {
      "epoch": 4.470338983050848,
      "grad_norm": 1.5198965072631836,
      "learning_rate": 1.7165955636915392e-06,
      "loss": 0.0416,
      "step": 2110
    },
    {
      "epoch": 4.491525423728813,
      "grad_norm": 0.5802397131919861,
      "learning_rate": 1.5974709576071e-06,
      "loss": 0.0384,
      "step": 2120
    },
    {
      "epoch": 4.512711864406779,
      "grad_norm": 0.5011278390884399,
      "learning_rate": 1.469974920295289e-06,
      "loss": 0.0313,
      "step": 2130
    },
    {
      "epoch": 4.533898305084746,
      "grad_norm": 0.802888035774231,
      "learning_rate": 1.3476264877342908e-06,
      "loss": 0.0397,
      "step": 2140
    },
    {
      "epoch": 4.555084745762712,
      "grad_norm": 0.396091103553772,
      "learning_rate": 1.2304524257847672e-06,
      "loss": 0.0235,
      "step": 2150
    },
    {
      "epoch": 4.576271186440678,
      "grad_norm": 0.25315141677856445,
      "learning_rate": 1.1184783683232585e-06,
      "loss": 0.0291,
      "step": 2160
    },
    {
      "epoch": 4.597457627118644,
      "grad_norm": 0.9906273484230042,
      "learning_rate": 1.0117288116343298e-06,
      "loss": 0.0298,
      "step": 2170
    },
    {
      "epoch": 4.61864406779661,
      "grad_norm": 0.044752947986125946,
      "learning_rate": 9.102271090515784e-07,
      "loss": 0.0203,
      "step": 2180
    },
    {
      "epoch": 4.639830508474576,
      "grad_norm": 0.34093987941741943,
      "learning_rate": 8.139954658486771e-07,
      "loss": 0.0328,
      "step": 2190
    },
    {
      "epoch": 4.661016949152542,
      "grad_norm": 0.5383203625679016,
      "learning_rate": 7.230549343815813e-07,
      "loss": 0.0326,
      "step": 2200
    },
    {
      "epoch": 4.682203389830509,
      "grad_norm": 0.4042283892631531,
      "learning_rate": 6.374254094829723e-07,
      "loss": 0.0305,
      "step": 2210
    },
    {
      "epoch": 4.703389830508475,
      "grad_norm": 0.46909579634666443,
      "learning_rate": 5.571256241098943e-07,
      "loss": 0.031,
      "step": 2220
    },
    {
      "epoch": 4.72457627118644,
      "grad_norm": 0.2986241579055786,
      "learning_rate": 4.821731452456125e-07,
      "loss": 0.028,
      "step": 2230
    },
    {
      "epoch": 4.745762711864407,
      "grad_norm": 0.6103011965751648,
      "learning_rate": 4.1258437005650687e-07,
      "loss": 0.0339,
      "step": 2240
    },
    {
      "epoch": 4.766949152542373,
      "grad_norm": 0.3766309320926666,
      "learning_rate": 3.4837452230492284e-07,
      "loss": 0.022,
      "step": 2250
    },
    {
      "epoch": 4.788135593220339,
      "grad_norm": 1.0050246715545654,
      "learning_rate": 2.895576490187041e-07,
      "loss": 0.0296,
      "step": 2260
    },
    {
      "epoch": 4.809322033898305,
      "grad_norm": 0.5596596598625183,
      "learning_rate": 2.361466174181426e-07,
      "loss": 0.0357,
      "step": 2270
    },
    {
      "epoch": 4.830508474576272,
      "grad_norm": 3.0524213314056396,
      "learning_rate": 1.881531121010749e-07,
      "loss": 0.0309,
      "step": 2280
    },
    {
      "epoch": 4.851694915254237,
      "grad_norm": 0.2963694632053375,
      "learning_rate": 1.4558763248665175e-07,
      "loss": 0.0171,
      "step": 2290
    },
    {
      "epoch": 4.872881355932203,
      "grad_norm": 0.9106848239898682,
      "learning_rate": 1.0845949051841441e-07,
      "loss": 0.0234,
      "step": 2300
    },
    {
      "epoch": 4.8940677966101696,
      "grad_norm": 0.20553134381771088,
      "learning_rate": 7.677680862714365e-08,
      "loss": 0.0401,
      "step": 2310
    },
    {
      "epoch": 4.915254237288136,
      "grad_norm": 0.411693811416626,
      "learning_rate": 5.054651795393939e-08,
      "loss": 0.0287,
      "step": 2320
    },
    {
      "epoch": 4.936440677966102,
      "grad_norm": 0.07917856425046921,
      "learning_rate": 2.977435683389762e-08,
      "loss": 0.0244,
      "step": 2330
    },
    {
      "epoch": 4.9576271186440675,
      "grad_norm": 1.0203975439071655,
      "learning_rate": 1.4464869540772863e-08,
      "loss": 0.0293,
      "step": 2340
    },
    {
      "epoch": 4.978813559322034,
      "grad_norm": 1.1816728115081787,
      "learning_rate": 4.6214052928150734e-09,
      "loss": 0.0269,
      "step": 2350
    },
    {
      "epoch": 5.0,
      "grad_norm": 0.3759446442127228,
      "learning_rate": 2.4611752008907307e-10,
      "loss": 0.0242,
      "step": 2360
    },
    {
      "epoch": 5.0,
      "step": 2360,
      "total_flos": 1.2329380952932352e+17,
      "train_loss": 0.11997167797664464,
      "train_runtime": 5633.6253,
      "train_samples_per_second": 6.702,
      "train_steps_per_second": 0.419
    }
  ],
  "logging_steps": 10,
  "max_steps": 2360,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 15000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1.2329380952932352e+17,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
