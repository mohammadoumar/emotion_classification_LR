{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 1416,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0211864406779661,
      "grad_norm": 1.153412103652954,
      "learning_rate": 3.521126760563381e-06,
      "loss": 0.6784,
      "step": 10
    },
    {
      "epoch": 0.0423728813559322,
      "grad_norm": 0.5088267922401428,
      "learning_rate": 7.042253521126762e-06,
      "loss": 0.3254,
      "step": 20
    },
    {
      "epoch": 0.0635593220338983,
      "grad_norm": 0.7879047989845276,
      "learning_rate": 1.056338028169014e-05,
      "loss": 0.195,
      "step": 30
    },
    {
      "epoch": 0.0847457627118644,
      "grad_norm": 0.661981999874115,
      "learning_rate": 1.4084507042253523e-05,
      "loss": 0.206,
      "step": 40
    },
    {
      "epoch": 0.1059322033898305,
      "grad_norm": 0.6009793877601624,
      "learning_rate": 1.7605633802816902e-05,
      "loss": 0.2033,
      "step": 50
    },
    {
      "epoch": 0.1271186440677966,
      "grad_norm": 0.639899492263794,
      "learning_rate": 2.112676056338028e-05,
      "loss": 0.1971,
      "step": 60
    },
    {
      "epoch": 0.1483050847457627,
      "grad_norm": 0.6220641136169434,
      "learning_rate": 2.4647887323943664e-05,
      "loss": 0.1755,
      "step": 70
    },
    {
      "epoch": 0.1694915254237288,
      "grad_norm": 0.5058984756469727,
      "learning_rate": 2.8169014084507046e-05,
      "loss": 0.2098,
      "step": 80
    },
    {
      "epoch": 0.1906779661016949,
      "grad_norm": 0.5861968994140625,
      "learning_rate": 3.1690140845070426e-05,
      "loss": 0.2028,
      "step": 90
    },
    {
      "epoch": 0.211864406779661,
      "grad_norm": 0.5927409529685974,
      "learning_rate": 3.5211267605633805e-05,
      "loss": 0.1865,
      "step": 100
    },
    {
      "epoch": 0.2330508474576271,
      "grad_norm": 0.9124928116798401,
      "learning_rate": 3.8732394366197184e-05,
      "loss": 0.1762,
      "step": 110
    },
    {
      "epoch": 0.2542372881355932,
      "grad_norm": 1.3334684371948242,
      "learning_rate": 4.225352112676056e-05,
      "loss": 0.2059,
      "step": 120
    },
    {
      "epoch": 0.2754237288135593,
      "grad_norm": 0.8915910124778748,
      "learning_rate": 4.577464788732395e-05,
      "loss": 0.1654,
      "step": 130
    },
    {
      "epoch": 0.2966101694915254,
      "grad_norm": 0.6963643431663513,
      "learning_rate": 4.929577464788733e-05,
      "loss": 0.1959,
      "step": 140
    },
    {
      "epoch": 0.3177966101694915,
      "grad_norm": 1.2695045471191406,
      "learning_rate": 4.999513551586019e-05,
      "loss": 0.1893,
      "step": 150
    },
    {
      "epoch": 0.3389830508474576,
      "grad_norm": 1.3079980611801147,
      "learning_rate": 4.997537679344487e-05,
      "loss": 0.2041,
      "step": 160
    },
    {
      "epoch": 0.3601694915254237,
      "grad_norm": 0.37715306878089905,
      "learning_rate": 4.99404318075312e-05,
      "loss": 0.205,
      "step": 170
    },
    {
      "epoch": 0.3813559322033898,
      "grad_norm": 0.5059732794761658,
      "learning_rate": 4.9890321806397744e-05,
      "loss": 0.1877,
      "step": 180
    },
    {
      "epoch": 0.4025423728813559,
      "grad_norm": 0.4922621250152588,
      "learning_rate": 4.982507725940191e-05,
      "loss": 0.1717,
      "step": 190
    },
    {
      "epoch": 0.423728813559322,
      "grad_norm": 0.6368918418884277,
      "learning_rate": 4.974473783845297e-05,
      "loss": 0.1844,
      "step": 200
    },
    {
      "epoch": 0.4449152542372881,
      "grad_norm": 0.30676230788230896,
      "learning_rate": 4.964935239388964e-05,
      "loss": 0.174,
      "step": 210
    },
    {
      "epoch": 0.4661016949152542,
      "grad_norm": 0.6316922903060913,
      "learning_rate": 4.9538978924776634e-05,
      "loss": 0.1803,
      "step": 220
    },
    {
      "epoch": 0.4872881355932203,
      "grad_norm": 0.5601277947425842,
      "learning_rate": 4.941368454363839e-05,
      "loss": 0.1939,
      "step": 230
    },
    {
      "epoch": 0.5084745762711864,
      "grad_norm": 0.46270349621772766,
      "learning_rate": 4.92735454356513e-05,
      "loss": 0.18,
      "step": 240
    },
    {
      "epoch": 0.5296610169491526,
      "grad_norm": 0.7878515720367432,
      "learning_rate": 4.9118646812319416e-05,
      "loss": 0.1909,
      "step": 250
    },
    {
      "epoch": 0.5508474576271186,
      "grad_norm": 0.6070221066474915,
      "learning_rate": 4.8949082859661564e-05,
      "loss": 0.1671,
      "step": 260
    },
    {
      "epoch": 0.5720338983050848,
      "grad_norm": 1.1622616052627563,
      "learning_rate": 4.8764956680941676e-05,
      "loss": 0.184,
      "step": 270
    },
    {
      "epoch": 0.5932203389830508,
      "grad_norm": 0.6239575147628784,
      "learning_rate": 4.856638023397685e-05,
      "loss": 0.1787,
      "step": 280
    },
    {
      "epoch": 0.614406779661017,
      "grad_norm": 0.8472000360488892,
      "learning_rate": 4.835347426306146e-05,
      "loss": 0.1816,
      "step": 290
    },
    {
      "epoch": 0.635593220338983,
      "grad_norm": 0.6538931727409363,
      "learning_rate": 4.812636822554873e-05,
      "loss": 0.1882,
      "step": 300
    },
    {
      "epoch": 0.6567796610169492,
      "grad_norm": 0.6424533724784851,
      "learning_rate": 4.7885200213134164e-05,
      "loss": 0.1891,
      "step": 310
    },
    {
      "epoch": 0.6779661016949152,
      "grad_norm": 0.9166595339775085,
      "learning_rate": 4.763011686788904e-05,
      "loss": 0.1893,
      "step": 320
    },
    {
      "epoch": 0.6991525423728814,
      "grad_norm": 0.4034644365310669,
      "learning_rate": 4.736127329309476e-05,
      "loss": 0.1851,
      "step": 330
    },
    {
      "epoch": 0.7203389830508474,
      "grad_norm": 0.6158939599990845,
      "learning_rate": 4.70788329589324e-05,
      "loss": 0.1869,
      "step": 340
    },
    {
      "epoch": 0.7415254237288136,
      "grad_norm": 0.8196421265602112,
      "learning_rate": 4.678296760308474e-05,
      "loss": 0.1908,
      "step": 350
    },
    {
      "epoch": 0.7627118644067796,
      "grad_norm": 0.7965240478515625,
      "learning_rate": 4.647385712631127e-05,
      "loss": 0.1853,
      "step": 360
    },
    {
      "epoch": 0.7838983050847458,
      "grad_norm": 0.45136895775794983,
      "learning_rate": 4.615168948305967e-05,
      "loss": 0.1869,
      "step": 370
    },
    {
      "epoch": 0.8050847457627118,
      "grad_norm": 0.5765828490257263,
      "learning_rate": 4.581666056718016e-05,
      "loss": 0.1778,
      "step": 380
    },
    {
      "epoch": 0.826271186440678,
      "grad_norm": 0.4987826645374298,
      "learning_rate": 4.5468974092812405e-05,
      "loss": 0.1781,
      "step": 390
    },
    {
      "epoch": 0.847457627118644,
      "grad_norm": 0.8328953981399536,
      "learning_rate": 4.510884147051722e-05,
      "loss": 0.1881,
      "step": 400
    },
    {
      "epoch": 0.8686440677966102,
      "grad_norm": 1.7944073677062988,
      "learning_rate": 4.473648167872851e-05,
      "loss": 0.1874,
      "step": 410
    },
    {
      "epoch": 0.8898305084745762,
      "grad_norm": 0.7318974137306213,
      "learning_rate": 4.435212113060357e-05,
      "loss": 0.1863,
      "step": 420
    },
    {
      "epoch": 0.9110169491525424,
      "grad_norm": 0.8626957535743713,
      "learning_rate": 4.395599353635269e-05,
      "loss": 0.1854,
      "step": 430
    },
    {
      "epoch": 0.9322033898305084,
      "grad_norm": 1.3873353004455566,
      "learning_rate": 4.354833976113176e-05,
      "loss": 0.1798,
      "step": 440
    },
    {
      "epoch": 0.9533898305084746,
      "grad_norm": 1.0186281204223633,
      "learning_rate": 4.312940767858441e-05,
      "loss": 0.1905,
      "step": 450
    },
    {
      "epoch": 0.9745762711864406,
      "grad_norm": 0.6050499677658081,
      "learning_rate": 4.269945202012256e-05,
      "loss": 0.1624,
      "step": 460
    },
    {
      "epoch": 0.9957627118644068,
      "grad_norm": 0.5957658290863037,
      "learning_rate": 4.225873422003708e-05,
      "loss": 0.1854,
      "step": 470
    },
    {
      "epoch": 1.0169491525423728,
      "grad_norm": 0.585906982421875,
      "learning_rate": 4.180752225653292e-05,
      "loss": 0.1669,
      "step": 480
    },
    {
      "epoch": 1.0381355932203389,
      "grad_norm": 0.48237746953964233,
      "learning_rate": 4.134609048878504e-05,
      "loss": 0.1677,
      "step": 490
    },
    {
      "epoch": 1.0593220338983051,
      "grad_norm": 1.0175156593322754,
      "learning_rate": 4.08747194901145e-05,
      "loss": 0.1731,
      "step": 500
    },
    {
      "epoch": 1.0805084745762712,
      "grad_norm": 0.6902359127998352,
      "learning_rate": 4.0393695877385986e-05,
      "loss": 0.1745,
      "step": 510
    },
    {
      "epoch": 1.1016949152542372,
      "grad_norm": 0.5250658392906189,
      "learning_rate": 3.9903312136730634e-05,
      "loss": 0.1625,
      "step": 520
    },
    {
      "epoch": 1.1228813559322033,
      "grad_norm": 0.45949628949165344,
      "learning_rate": 3.9403866445699986e-05,
      "loss": 0.1645,
      "step": 530
    },
    {
      "epoch": 1.1440677966101696,
      "grad_norm": 0.356593519449234,
      "learning_rate": 3.889566249195928e-05,
      "loss": 0.1634,
      "step": 540
    },
    {
      "epoch": 1.1652542372881356,
      "grad_norm": 0.5513865351676941,
      "learning_rate": 3.8379009288630384e-05,
      "loss": 0.1538,
      "step": 550
    },
    {
      "epoch": 1.1864406779661016,
      "grad_norm": 0.6328163146972656,
      "learning_rate": 3.785422098639649e-05,
      "loss": 0.1504,
      "step": 560
    },
    {
      "epoch": 1.207627118644068,
      "grad_norm": 0.7420995831489563,
      "learning_rate": 3.732161668248303e-05,
      "loss": 0.1697,
      "step": 570
    },
    {
      "epoch": 1.228813559322034,
      "grad_norm": 0.47353535890579224,
      "learning_rate": 3.6781520226630734e-05,
      "loss": 0.1498,
      "step": 580
    },
    {
      "epoch": 1.25,
      "grad_norm": 0.6735658049583435,
      "learning_rate": 3.6234260024179033e-05,
      "loss": 0.1445,
      "step": 590
    },
    {
      "epoch": 1.271186440677966,
      "grad_norm": 1.0048108100891113,
      "learning_rate": 3.568016883637936e-05,
      "loss": 0.1507,
      "step": 600
    },
    {
      "epoch": 1.292372881355932,
      "grad_norm": 1.4832134246826172,
      "learning_rate": 3.5119583578059846e-05,
      "loss": 0.1634,
      "step": 610
    },
    {
      "epoch": 1.3135593220338984,
      "grad_norm": 0.936444878578186,
      "learning_rate": 3.4552845112764475e-05,
      "loss": 0.1613,
      "step": 620
    },
    {
      "epoch": 1.3347457627118644,
      "grad_norm": 0.5518351197242737,
      "learning_rate": 3.39802980454912e-05,
      "loss": 0.1632,
      "step": 630
    },
    {
      "epoch": 1.3559322033898304,
      "grad_norm": 0.5492082834243774,
      "learning_rate": 3.3402290513155046e-05,
      "loss": 0.1543,
      "step": 640
    },
    {
      "epoch": 1.3771186440677967,
      "grad_norm": 0.8070716261863708,
      "learning_rate": 3.281917397290371e-05,
      "loss": 0.1558,
      "step": 650
    },
    {
      "epoch": 1.3983050847457628,
      "grad_norm": 1.1220881938934326,
      "learning_rate": 3.2231302988414194e-05,
      "loss": 0.1717,
      "step": 660
    },
    {
      "epoch": 1.4194915254237288,
      "grad_norm": 0.5046328902244568,
      "learning_rate": 3.163903501430058e-05,
      "loss": 0.1593,
      "step": 670
    },
    {
      "epoch": 1.4406779661016949,
      "grad_norm": 1.2006089687347412,
      "learning_rate": 3.104273017876399e-05,
      "loss": 0.1744,
      "step": 680
    },
    {
      "epoch": 1.461864406779661,
      "grad_norm": 0.9932774901390076,
      "learning_rate": 3.044275106461678e-05,
      "loss": 0.168,
      "step": 690
    },
    {
      "epoch": 1.4830508474576272,
      "grad_norm": 0.9178822636604309,
      "learning_rate": 2.983946248881433e-05,
      "loss": 0.1673,
      "step": 700
    },
    {
      "epoch": 1.5042372881355932,
      "grad_norm": 0.6921550035476685,
      "learning_rate": 2.9233231280628248e-05,
      "loss": 0.1527,
      "step": 710
    },
    {
      "epoch": 1.5254237288135593,
      "grad_norm": 0.5621039271354675,
      "learning_rate": 2.8624426058596104e-05,
      "loss": 0.1554,
      "step": 720
    },
    {
      "epoch": 1.5466101694915255,
      "grad_norm": 0.7962204813957214,
      "learning_rate": 2.8013417006383076e-05,
      "loss": 0.1659,
      "step": 730
    },
    {
      "epoch": 1.5677966101694916,
      "grad_norm": 0.7598019242286682,
      "learning_rate": 2.7400575647692046e-05,
      "loss": 0.1527,
      "step": 740
    },
    {
      "epoch": 1.5889830508474576,
      "grad_norm": 0.6376874446868896,
      "learning_rate": 2.678627462035877e-05,
      "loss": 0.162,
      "step": 750
    },
    {
      "epoch": 1.6101694915254239,
      "grad_norm": 0.5869711637496948,
      "learning_rate": 2.61708874497697e-05,
      "loss": 0.1465,
      "step": 760
    },
    {
      "epoch": 1.6313559322033897,
      "grad_norm": 0.821317195892334,
      "learning_rate": 2.5554788321740053e-05,
      "loss": 0.1516,
      "step": 770
    },
    {
      "epoch": 1.652542372881356,
      "grad_norm": 0.4113291800022125,
      "learning_rate": 2.493835185499039e-05,
      "loss": 0.1545,
      "step": 780
    },
    {
      "epoch": 1.673728813559322,
      "grad_norm": 0.6721943020820618,
      "learning_rate": 2.432195287335984e-05,
      "loss": 0.153,
      "step": 790
    },
    {
      "epoch": 1.694915254237288,
      "grad_norm": 0.5024628043174744,
      "learning_rate": 2.370596617789476e-05,
      "loss": 0.1467,
      "step": 800
    },
    {
      "epoch": 1.7161016949152543,
      "grad_norm": 0.588132381439209,
      "learning_rate": 2.309076631895116e-05,
      "loss": 0.172,
      "step": 810
    },
    {
      "epoch": 1.7372881355932204,
      "grad_norm": 0.5778393149375916,
      "learning_rate": 2.2476727368449488e-05,
      "loss": 0.1603,
      "step": 820
    },
    {
      "epoch": 1.7584745762711864,
      "grad_norm": 0.7756549119949341,
      "learning_rate": 2.1864222692420554e-05,
      "loss": 0.1528,
      "step": 830
    },
    {
      "epoch": 1.7796610169491527,
      "grad_norm": 0.5646039843559265,
      "learning_rate": 2.125362472398041e-05,
      "loss": 0.1624,
      "step": 840
    },
    {
      "epoch": 1.8008474576271185,
      "grad_norm": 0.48813381791114807,
      "learning_rate": 2.0645304736872682e-05,
      "loss": 0.1549,
      "step": 850
    },
    {
      "epoch": 1.8220338983050848,
      "grad_norm": 0.5441946983337402,
      "learning_rate": 2.0039632619715726e-05,
      "loss": 0.1458,
      "step": 860
    },
    {
      "epoch": 1.8432203389830508,
      "grad_norm": 0.3878314793109894,
      "learning_rate": 1.9436976651092144e-05,
      "loss": 0.1434,
      "step": 870
    },
    {
      "epoch": 1.8644067796610169,
      "grad_norm": 0.3617471754550934,
      "learning_rate": 1.8837703275617104e-05,
      "loss": 0.1726,
      "step": 880
    },
    {
      "epoch": 1.8855932203389831,
      "grad_norm": 0.3520785868167877,
      "learning_rate": 1.8242176881122002e-05,
      "loss": 0.1608,
      "step": 890
    },
    {
      "epoch": 1.9067796610169492,
      "grad_norm": 0.38242051005363464,
      "learning_rate": 1.765075957708856e-05,
      "loss": 0.1567,
      "step": 900
    },
    {
      "epoch": 1.9279661016949152,
      "grad_norm": 0.6273261904716492,
      "learning_rate": 1.706381097446845e-05,
      "loss": 0.1559,
      "step": 910
    },
    {
      "epoch": 1.9491525423728815,
      "grad_norm": 0.45391643047332764,
      "learning_rate": 1.6481687967021974e-05,
      "loss": 0.1349,
      "step": 920
    },
    {
      "epoch": 1.9703389830508473,
      "grad_norm": 0.4453333020210266,
      "learning_rate": 1.5904744514309113e-05,
      "loss": 0.1522,
      "step": 930
    },
    {
      "epoch": 1.9915254237288136,
      "grad_norm": 0.5039411783218384,
      "learning_rate": 1.533333142646453e-05,
      "loss": 0.1601,
      "step": 940
    },
    {
      "epoch": 2.01271186440678,
      "grad_norm": 0.42858049273490906,
      "learning_rate": 1.4767796150887725e-05,
      "loss": 0.1279,
      "step": 950
    },
    {
      "epoch": 2.0338983050847457,
      "grad_norm": 0.5367924571037292,
      "learning_rate": 1.4208482560977848e-05,
      "loss": 0.1071,
      "step": 960
    },
    {
      "epoch": 2.055084745762712,
      "grad_norm": 0.6318113207817078,
      "learning_rate": 1.3655730747041606e-05,
      "loss": 0.0883,
      "step": 970
    },
    {
      "epoch": 2.0762711864406778,
      "grad_norm": 0.4291142225265503,
      "learning_rate": 1.3109876809501658e-05,
      "loss": 0.1029,
      "step": 980
    },
    {
      "epoch": 2.097457627118644,
      "grad_norm": 0.5149716734886169,
      "learning_rate": 1.2571252654530835e-05,
      "loss": 0.0906,
      "step": 990
    },
    {
      "epoch": 2.1186440677966103,
      "grad_norm": 0.6311320662498474,
      "learning_rate": 1.2040185792236874e-05,
      "loss": 0.1015,
      "step": 1000
    },
    {
      "epoch": 2.139830508474576,
      "grad_norm": 0.5396122336387634,
      "learning_rate": 1.1516999137520023e-05,
      "loss": 0.0903,
      "step": 1010
    },
    {
      "epoch": 2.1610169491525424,
      "grad_norm": 0.5841399431228638,
      "learning_rate": 1.100201081372485e-05,
      "loss": 0.0838,
      "step": 1020
    },
    {
      "epoch": 2.1822033898305087,
      "grad_norm": 0.9635390043258667,
      "learning_rate": 1.0495533959205505e-05,
      "loss": 0.0997,
      "step": 1030
    },
    {
      "epoch": 2.2033898305084745,
      "grad_norm": 0.8925768136978149,
      "learning_rate": 9.997876536922173e-06,
      "loss": 0.0854,
      "step": 1040
    },
    {
      "epoch": 2.2245762711864407,
      "grad_norm": 0.7578582763671875,
      "learning_rate": 9.509341147184305e-06,
      "loss": 0.0921,
      "step": 1050
    },
    {
      "epoch": 2.2457627118644066,
      "grad_norm": 0.7936879992485046,
      "learning_rate": 9.030224843654739e-06,
      "loss": 0.1023,
      "step": 1060
    },
    {
      "epoch": 2.266949152542373,
      "grad_norm": 0.85999596118927,
      "learning_rate": 8.560818952726329e-06,
      "loss": 0.0848,
      "step": 1070
    },
    {
      "epoch": 2.288135593220339,
      "grad_norm": 1.1586575508117676,
      "learning_rate": 8.101408896381141e-06,
      "loss": 0.1007,
      "step": 1080
    },
    {
      "epoch": 2.309322033898305,
      "grad_norm": 1.5644190311431885,
      "learning_rate": 7.65227401863979e-06,
      "loss": 0.0949,
      "step": 1090
    },
    {
      "epoch": 2.330508474576271,
      "grad_norm": 1.0290682315826416,
      "learning_rate": 7.213687415706416e-06,
      "loss": 0.0656,
      "step": 1100
    },
    {
      "epoch": 2.3516949152542375,
      "grad_norm": 0.6679172515869141,
      "learning_rate": 6.785915769912762e-06,
      "loss": 0.085,
      "step": 1110
    },
    {
      "epoch": 2.3728813559322033,
      "grad_norm": 1.0993731021881104,
      "learning_rate": 6.369219187562064e-06,
      "loss": 0.0932,
      "step": 1120
    },
    {
      "epoch": 2.3940677966101696,
      "grad_norm": 1.092672348022461,
      "learning_rate": 5.9638510407716394e-06,
      "loss": 0.085,
      "step": 1130
    },
    {
      "epoch": 2.415254237288136,
      "grad_norm": 0.9766286015510559,
      "learning_rate": 5.570057813410043e-06,
      "loss": 0.0838,
      "step": 1140
    },
    {
      "epoch": 2.4364406779661016,
      "grad_norm": 0.5563454031944275,
      "learning_rate": 5.188078951222744e-06,
      "loss": 0.0788,
      "step": 1150
    },
    {
      "epoch": 2.457627118644068,
      "grad_norm": 0.8894284963607788,
      "learning_rate": 4.818146716237248e-06,
      "loss": 0.1028,
      "step": 1160
    },
    {
      "epoch": 2.4788135593220337,
      "grad_norm": 0.7453480362892151,
      "learning_rate": 4.460486045536341e-06,
      "loss": 0.0827,
      "step": 1170
    },
    {
      "epoch": 2.5,
      "grad_norm": 1.0650755167007446,
      "learning_rate": 4.115314414485175e-06,
      "loss": 0.0776,
      "step": 1180
    },
    {
      "epoch": 2.5211864406779663,
      "grad_norm": 0.9210054874420166,
      "learning_rate": 3.782841704495546e-06,
      "loss": 0.0864,
      "step": 1190
    },
    {
      "epoch": 2.542372881355932,
      "grad_norm": 1.037765622138977,
      "learning_rate": 3.4632700754075845e-06,
      "loss": 0.0856,
      "step": 1200
    },
    {
      "epoch": 2.5635593220338984,
      "grad_norm": 0.7951952219009399,
      "learning_rate": 3.1567938425665993e-06,
      "loss": 0.0826,
      "step": 1210
    },
    {
      "epoch": 2.584745762711864,
      "grad_norm": 0.953333854675293,
      "learning_rate": 2.8635993586697553e-06,
      "loss": 0.0689,
      "step": 1220
    },
    {
      "epoch": 2.6059322033898304,
      "grad_norm": 1.0378011465072632,
      "learning_rate": 2.583864900454386e-06,
      "loss": 0.0789,
      "step": 1230
    },
    {
      "epoch": 2.6271186440677967,
      "grad_norm": 0.519031286239624,
      "learning_rate": 2.317760560296975e-06,
      "loss": 0.0774,
      "step": 1240
    },
    {
      "epoch": 2.648305084745763,
      "grad_norm": 1.2604749202728271,
      "learning_rate": 2.065448142788537e-06,
      "loss": 0.1061,
      "step": 1250
    },
    {
      "epoch": 2.669491525423729,
      "grad_norm": 0.804756224155426,
      "learning_rate": 1.827081066349459e-06,
      "loss": 0.0695,
      "step": 1260
    },
    {
      "epoch": 2.690677966101695,
      "grad_norm": 0.9663671255111694,
      "learning_rate": 1.602804269943503e-06,
      "loss": 0.0883,
      "step": 1270
    },
    {
      "epoch": 2.711864406779661,
      "grad_norm": 1.0305277109146118,
      "learning_rate": 1.3927541249477732e-06,
      "loss": 0.0763,
      "step": 1280
    },
    {
      "epoch": 2.733050847457627,
      "grad_norm": 0.7984049320220947,
      "learning_rate": 1.1970583522321472e-06,
      "loss": 0.0723,
      "step": 1290
    },
    {
      "epoch": 2.7542372881355934,
      "grad_norm": 0.9583699703216553,
      "learning_rate": 1.0158359444987053e-06,
      "loss": 0.0961,
      "step": 1300
    },
    {
      "epoch": 2.7754237288135593,
      "grad_norm": 1.0661165714263916,
      "learning_rate": 8.491970939282612e-07,
      "loss": 0.0902,
      "step": 1310
    },
    {
      "epoch": 2.7966101694915255,
      "grad_norm": 0.8597286939620972,
      "learning_rate": 6.97243125178093e-07,
      "loss": 0.0909,
      "step": 1320
    },
    {
      "epoch": 2.8177966101694913,
      "grad_norm": 0.8581476211547852,
      "learning_rate": 5.600664337715167e-07,
      "loss": 0.0909,
      "step": 1330
    },
    {
      "epoch": 2.8389830508474576,
      "grad_norm": 0.8783078193664551,
      "learning_rate": 4.377504299168694e-07,
      "loss": 0.0878,
      "step": 1340
    },
    {
      "epoch": 2.860169491525424,
      "grad_norm": 0.8948899507522583,
      "learning_rate": 3.303694877899666e-07,
      "loss": 0.0921,
      "step": 1350
    },
    {
      "epoch": 2.8813559322033897,
      "grad_norm": 1.0180553197860718,
      "learning_rate": 2.3798890031092037e-07,
      "loss": 0.0927,
      "step": 1360
    },
    {
      "epoch": 2.902542372881356,
      "grad_norm": 0.7150681018829346,
      "learning_rate": 1.606648394428284e-07,
      "loss": 0.0888,
      "step": 1370
    },
    {
      "epoch": 2.923728813559322,
      "grad_norm": 0.7666478753089905,
      "learning_rate": 9.844432203644228e-08,
      "loss": 0.0953,
      "step": 1380
    },
    {
      "epoch": 2.944915254237288,
      "grad_norm": 0.7252107858657837,
      "learning_rate": 5.136518124159162e-08,
      "loss": 0.081,
      "step": 1390
    },
    {
      "epoch": 2.9661016949152543,
      "grad_norm": 1.6152127981185913,
      "learning_rate": 1.9456043502766308e-08,
      "loss": 0.0915,
      "step": 1400
    },
    {
      "epoch": 2.9872881355932206,
      "grad_norm": 0.5373913049697876,
      "learning_rate": 2.7363111528233564e-09,
      "loss": 0.081,
      "step": 1410
    },
    {
      "epoch": 3.0,
      "step": 1416,
      "total_flos": 1.939744516818862e+17,
      "train_loss": 0.14912978845969432,
      "train_runtime": 3624.5377,
      "train_samples_per_second": 6.25,
      "train_steps_per_second": 0.391
    }
  ],
  "logging_steps": 10,
  "max_steps": 1416,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 15000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1.939744516818862e+17,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
