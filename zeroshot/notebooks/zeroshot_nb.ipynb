{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zero-Shot Comics Classification with LLaMA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from operator import itemgetter\n",
    "from sklearn.metrics import classification_report\n",
    "from transformers import AutoTokenizer, AutoModel, AutoModelForCausalLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model and Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"unsloth/llama-3-8b-Instruct-bnb-4bit\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_tokenizer = AutoTokenizer.from_pretrained(model_id, padding='left', padding_side='left')\n",
    "inference_tokenizer.pad_token = inference_tokenizer.eos_token\n",
    "terminators = [\n",
    "    inference_tokenizer.eos_token_id,\n",
    "    inference_tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unused kwargs: ['_load_in_4bit', '_load_in_8bit', 'quant_method']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.\n"
     ]
    }
   ],
   "source": [
    "generation_model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    #cache_dir = '/home/umushtaq/scratch/am_work/in_context_learning/model_downloads',\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_labels = [\"anger\", \"surprise\", \"fear\", \"disgust\", \"sadness\", \"joy\", \"neutral\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_map = {\n",
    "    'AN': 'anger',\n",
    "    'DI': 'disgust',\n",
    "    'FE': 'fear',\n",
    "    'SA': 'sadness',\n",
    "    'SU': 'surprise',\n",
    "    'JO': 'joy'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/Utilisateurs/umushtaq/emotion_analysis_comics/zeroshot/datasets/comics_data_processed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_emotions(row):\n",
    "\n",
    "    emotion_str = row.emotion\n",
    "\n",
    "    if emotion_str == 'Neutral':\n",
    "        return ['neutral']\n",
    "\n",
    "    emotions = emotion_str.split('-')\n",
    "    tags = []\n",
    "\n",
    "    for emotion in emotions:\n",
    "        abbrev = emotion[:2]  # Get the abbreviation\n",
    "        value_part = emotion[2:]  # Get the value part\n",
    "        \n",
    "        # Ensure that the value part is a valid integer and abbrev is in the emotion_map\n",
    "        if abbrev in emotion_map and value_part.isdigit():\n",
    "            value = int(value_part)\n",
    "            if value > 0:\n",
    "                tags.append(emotion_map[abbrev].lower())\n",
    "        else:\n",
    "            print(f\"Warning: Skipping invalid emotion entry: '{emotion}'\")\n",
    "    return tags  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['emotions_list'] = df.apply(lambda row: extract_emotions(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=[df.columns[0], df.columns[1]]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5282, 12)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Messages and Prompts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys_msg_l = []\n",
    "task_msg_l = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in df.iterrows():\n",
    "\n",
    "    sys_msg = {\"role\":\"system\", \"content\": \"### Task description: You are an expert sentiment analysis assistant that takes an utterance from a comic book and must classify the utterance into appropriate emotion class(s): anger, surprise, fear, disgust, sadness, joy, neutral. You must absolutely not generate any text or explanation other than the following JSON format {\\\"utterance_emotion\\\": <predicted emotion classes for the utterance (str)>}\\n\\n\"}\n",
    "    task_msg = {\"role\":\"user\", \"content\": f\"# Utterance:\\n{row[1].utterance}\\n\\n# Result:\\n\"}\n",
    "\n",
    "    sys_msg_l.append(sys_msg)\n",
    "    task_msg_l.append(task_msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5282, 5282)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sys_msg_l), len(task_msg_l)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Task description: You are an expert sentiment analysis assistant that takes an utterance from a comic book and must classify the utterance into appropriate emotion class(s): anger, surprise, fear, disgust, sadness, joy, neutral. You must absolutely not generate any text or explanation other than the following JSON format {\"utterance_emotion\": <predicted emotion classes for the utterance (str)>}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(sys_msg_l[0]['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Utterance:\n",
      "DID YOU HAVE TO ELECTROCUTE HER SO HARD?\n",
      "\n",
      "# Result:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(task_msg_l[0]['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepared_sys_task_msg_l = []\n",
    "\n",
    "for i in range(len(sys_msg_l)):\n",
    "    prepared_sys_task_msg_l.append([sys_msg_l[i], task_msg_l[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system',\n",
       "  'content': '### Task description: You are an expert sentiment analysis assistant that takes an utterance from a comic book and must classify the utterance into appropriate emotion class(s): anger, surprise, fear, disgust, sadness, joy, neutral. You must absolutely not generate any text or explanation other than the following JSON format {\"utterance_emotion\": <predicted emotion classes for the utterance (str)>}\\n\\n'},\n",
       " {'role': 'user',\n",
       "  'content': '# Utterance:\\nDID YOU HAVE TO ELECTROCUTE HER SO HARD?\\n\\n# Result:\\n'}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prepared_sys_task_msg_l[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57aa2404f07c4d6ba4de45a34e84e0b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5282 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    }
   ],
   "source": [
    "outputs_l = []\n",
    "\n",
    "for i in tqdm(range(len(prepared_sys_task_msg_l))):\n",
    "\n",
    "    messages = prepared_sys_task_msg_l[i]\n",
    "\n",
    "    input_ids = inference_tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    add_generation_prompt=True,\n",
    "    tokenize=True,\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    return_tensors=\"pt\"\n",
    ").to(generation_model.device)\n",
    "\n",
    "    outputs = generation_model.generate(\n",
    "    input_ids = input_ids,\n",
    "    max_new_tokens=1024,\n",
    "    pad_token_id=inference_tokenizer.eos_token_id,\n",
    "    eos_token_id=terminators,\n",
    "    do_sample=True,\n",
    "    temperature=0.1,\n",
    "    top_p=0.9,\n",
    "    )\n",
    "    # inference_tokenizer.decode(outputs[0][input_ids.shape[-1]:], skip_special_tokens=True)\n",
    "    outputs_l.append(inference_tokenizer.decode(outputs[0][input_ids.shape[-1]:], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5282"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(outputs_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "grounds = df.emotions_list.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = [list(ast.literal_eval(output).values()) for output in outputs_l]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5282, 5282)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(grounds), len(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def opposite(component_type):\n",
    "\n",
    "    if component_type == \"anger\":\n",
    "        return \"surprise\"\n",
    "    elif component_type == \"disgust\":\n",
    "        return \"joy\"\n",
    "    elif component_type == \"fear\":\n",
    "        return \"sadness\"\n",
    "    elif component_type == \"sadness\":\n",
    "        return \"anger\"\n",
    "    elif component_type == \"surprise\":\n",
    "        return \"disgust\"\n",
    "    elif component_type == \"joy\":\n",
    "        return \"fear\"\n",
    "    elif component_type == \"Neutral\":\n",
    "        return \"sadness\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def harmonize_preds(grounds, preds):\n",
    "\n",
    "    l1, l2 = len(preds), len(grounds)\n",
    "    if l1 < l2:\n",
    "        diff = l2 - l1\n",
    "        preds = preds + [opposite(x) for x in grounds[l1:]]\n",
    "    else:\n",
    "        preds = preds[:l2]\n",
    "        \n",
    "    return preds "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,(x,y) in enumerate(zip(grounds, preds)):\n",
    "        \n",
    "        if len(x) != len(y):\n",
    "            \n",
    "            preds[i] = harmonize_preds(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5282, 5282)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(preds), len(grounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grounds = [item for sublist in grounds for item in sublist]\n",
    "# preds = [item for sublist in preds for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5282, 5282)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(grounds), len(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def labels_to_binary_matrix(label_list, all_labels):\n",
    "    binary_matrix = np.zeros((len(label_list), len(all_labels)))\n",
    "    for i, labels in enumerate(label_list):\n",
    "        for label in labels:\n",
    "            if label in all_labels:\n",
    "                binary_matrix[i][all_labels.index(label)] = 1\n",
    "    return binary_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_matrix = labels_to_binary_matrix(grounds, all_labels)\n",
    "predicted_matrix = labels_to_binary_matrix(preds, all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger     0.5328    0.5762    0.5536      1791\n",
      "    surprise     0.4764    0.4434    0.4593      1590\n",
      "        fear     0.2095    0.0867    0.1226      1373\n",
      "     disgust     0.0592    0.1865    0.0899       311\n",
      "     sadness     0.3805    0.1761    0.2408      1238\n",
      "         joy     0.4384    0.4158    0.4268      1104\n",
      "     neutral     0.1836    0.2478    0.2109       343\n",
      "\n",
      "   micro avg     0.3797    0.3453    0.3617      7750\n",
      "   macro avg     0.3258    0.3046    0.3005      7750\n",
      "weighted avg     0.3917    0.3453    0.3561      7750\n",
      " samples avg     0.3707    0.3571    0.3619      7750\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Utilisateurs/umushtaq/.conda/envs/er_nb_env/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(true_matrix, predicted_matrix, target_names=all_labels, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
