{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b20aa00d-c84a-4970-bc99-ffd9f8ed9776",
   "metadata": {},
   "source": [
    "# Dataset prepration for Emory NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "640868d0-4cf7-4fb0-bfb3-3ed663372d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import json\n",
    "import random\n",
    "from pathlib import Path\n",
    "import pandas as pd # type: ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a0bc00",
   "metadata": {},
   "source": [
    "### Read data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f0c44be-8571-45e5-a85e-808d4990a707",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"/Utilisateurs/umushtaq/emotion_analysis_comics/emory_nlp/data_files/emorynlp_train_final.csv\")\n",
    "df_test = pd.read_csv(\"/Utilisateurs/umushtaq/emotion_analysis_comics/emory_nlp/data_files/emorynlp_test_final.csv\")\n",
    "df_dev = pd.read_csv(\"/Utilisateurs/umushtaq/emotion_analysis_comics/emory_nlp/data_files/emorynlp_dev_final.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dcf9f155-8e66-4a51-ae38-d0dd5f58006b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Utterance</th>\n",
       "      <th>Speaker</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Scene_ID</th>\n",
       "      <th>Utterance_ID</th>\n",
       "      <th>Season</th>\n",
       "      <th>Episode</th>\n",
       "      <th>Start_Time</th>\n",
       "      <th>End_Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Coffee.</td>\n",
       "      <td>['Rachel Green']</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>00:00:03.795</td>\n",
       "      <td>00:00:05.004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Thank you.</td>\n",
       "      <td>['Joey Tribbiani']</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>00:00:05.171</td>\n",
       "      <td>00:00:07.423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cappuccino.</td>\n",
       "      <td>['Rachel Green']</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>00:00:07.590</td>\n",
       "      <td>00:00:08.757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Grazie.</td>\n",
       "      <td>['Ross Geller']</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>00:00:08.925</td>\n",
       "      <td>00:00:11.677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>And a nice hot cider for Monica.</td>\n",
       "      <td>['Rachel Green']</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>00:01:27.253</td>\n",
       "      <td>00:01:33.383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949</th>\n",
       "      <td>It's better! You can't go to a museum in your ...</td>\n",
       "      <td>['Joey Tribbiani']</td>\n",
       "      <td>Joyful</td>\n",
       "      <td>29</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>21</td>\n",
       "      <td>00:21:37.379</td>\n",
       "      <td>00:21:44.135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>950</th>\n",
       "      <td>Well, You could, but... probably just the one ...</td>\n",
       "      <td>['Chandler Bing']</td>\n",
       "      <td>Joyful</td>\n",
       "      <td>29</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>21</td>\n",
       "      <td>00:21:45.220</td>\n",
       "      <td>00:21:47.555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>951</th>\n",
       "      <td>I bet we could get videos of all the sites, ge...</td>\n",
       "      <td>['Joey Tribbiani']</td>\n",
       "      <td>Joyful</td>\n",
       "      <td>29</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>21</td>\n",
       "      <td>00:21:49.641</td>\n",
       "      <td>00:21:55.604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>952</th>\n",
       "      <td>If we do that, we gotta get Die Hard.</td>\n",
       "      <td>['Chandler Bing']</td>\n",
       "      <td>Joyful</td>\n",
       "      <td>29</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>21</td>\n",
       "      <td>00:21:56.189</td>\n",
       "      <td>00:21:58.190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>953</th>\n",
       "      <td>Oh-ho! I bet the British version is gooooood!</td>\n",
       "      <td>['Joey Tribbiani']</td>\n",
       "      <td>Joyful</td>\n",
       "      <td>29</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>21</td>\n",
       "      <td>00:22:00.027</td>\n",
       "      <td>00:22:03.070</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>954 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Utterance             Speaker  \\\n",
       "0                                              Coffee.    ['Rachel Green']   \n",
       "1                                           Thank you.  ['Joey Tribbiani']   \n",
       "2                                          Cappuccino.    ['Rachel Green']   \n",
       "3                                              Grazie.     ['Ross Geller']   \n",
       "4                     And a nice hot cider for Monica.    ['Rachel Green']   \n",
       "..                                                 ...                 ...   \n",
       "949  It's better! You can't go to a museum in your ...  ['Joey Tribbiani']   \n",
       "950  Well, You could, but... probably just the one ...   ['Chandler Bing']   \n",
       "951  I bet we could get videos of all the sites, ge...  ['Joey Tribbiani']   \n",
       "952              If we do that, we gotta get Die Hard.   ['Chandler Bing']   \n",
       "953      Oh-ho! I bet the British version is gooooood!  ['Joey Tribbiani']   \n",
       "\n",
       "     Emotion  Scene_ID  Utterance_ID  Season  Episode    Start_Time  \\\n",
       "0    Neutral         1             1       1       15  00:00:03.795   \n",
       "1    Neutral         1             2       1       15  00:00:05.171   \n",
       "2    Neutral         1             3       1       15  00:00:07.590   \n",
       "3    Neutral         1             4       1       15  00:00:08.925   \n",
       "4    Neutral         1             5       1       15  00:01:27.253   \n",
       "..       ...       ...           ...     ...      ...           ...   \n",
       "949   Joyful        29             3       4       21  00:21:37.379   \n",
       "950   Joyful        29             4       4       21  00:21:45.220   \n",
       "951   Joyful        29             5       4       21  00:21:49.641   \n",
       "952   Joyful        29             6       4       21  00:21:56.189   \n",
       "953   Joyful        29             7       4       21  00:22:00.027   \n",
       "\n",
       "         End_Time  \n",
       "0    00:00:05.004  \n",
       "1    00:00:07.423  \n",
       "2    00:00:08.757  \n",
       "3    00:00:11.677  \n",
       "4    00:01:33.383  \n",
       "..            ...  \n",
       "949  00:21:44.135  \n",
       "950  00:21:47.555  \n",
       "951  00:21:55.604  \n",
       "952  00:21:58.190  \n",
       "953  00:22:03.070  \n",
       "\n",
       "[954 rows x 9 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e3d0ad38-7fc1-494b-b194-26dda0dfc415",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Emotion\n",
       "Neutral     322\n",
       "Joyful      205\n",
       "Scared      127\n",
       "Mad          97\n",
       "Peaceful     82\n",
       "Powerful     70\n",
       "Sad          51\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dev.Emotion.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78587a7c",
   "metadata": {},
   "source": [
    "### Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e8f654b2-a65e-4d91-8dc3-88980aaac27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_dir = Path.cwd()\n",
    "dataset_dir = current_dir / \"emotion_analysis_comics\" / \"emory_nlp\" / \"datasets\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "123f56a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/Utilisateurs/umushtaq/emotion_analysis_comics/emory_nlp/datasets')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f2fa22-35d5-41aa-abf1-5a9987ee0b08",
   "metadata": {},
   "source": [
    "### Prepare prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3fd57164",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Formatting Fx\n",
    "# Build questoin\n",
    "# Build answer"
   ]
  },
  {
   "cell_type": "raw",
   "id": "dd845ef4",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "Neutral     322\n",
    "Joyful      205\n",
    "Scared      127\n",
    "Mad          97\n",
    "Peaceful     82\n",
    "Powerful     70\n",
    "Sad          51"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "608f81e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def formatting_fct(instruction=\"\", input=\"\", output=\"\"):\n",
    "    \n",
    "    prompt_d ={\n",
    "            \n",
    "        \"instruction\": f\"\"\"{instruction}\"\"\",\n",
    "        \"input\": f\"\"\"{input}\"\"\",\n",
    "        \"output\": f\"\"\"{output}\"\"\"\n",
    "            \n",
    "        }\n",
    "    \n",
    "    return prompt_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b107f77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_instruction():\n",
    "\n",
    "    #results = json.dumps([\"emotion_class (str)\"] * nr_utterances)\n",
    "\n",
    "    instruction = f\"\"\"### You are an expert in Emotion Analysis. You are given an utterance from a tv show enclosed by <UT></UT> tags. Your task is to classify each utterance as one the following emotion classes: \"Mad\", \"Scared\", \"Sad\", \"Powerful\", \"Peaceful\", \"Joyful\" or \"Neutral\". You must return an emotion class in following JSON format: {{\"emotion_class\": [\"emotion_class (str)\"]}} where \"emotion_classes (str)\" is replaced by one of the following abbreviated emotion class labels: \"Mad\", \"Scared\", \"Sad\", \"Powerful\", \"Peaceful\", \"Joyful\" or \"Neutral\". \n",
    "\"\"\"    \n",
    "    return instruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "44e9dbd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_tagged_text(utterance):\n",
    "\n",
    "    # tagged_utterances_l = []\n",
    "\n",
    "    # for idx, utterance in enumerate(utterances_l):\n",
    "        \n",
    "    #     start_tag = \"<UT\" + str(idx+1) + \">\"\n",
    "    #     end_tag = \"</UT\" + str(idx+1) + \">\"\n",
    "    #     tagged_utterance = start_tag + utterance + end_tag\n",
    "    #     tagged_utterances_l.append(tagged_utterance)\n",
    "        \n",
    "    # tagged_title_text = ''.join(tagged_utterances_l)\n",
    "    \n",
    "    tagged_utterance = \"<UT>\" + utterance + \"</UT>\"\n",
    "    question = f\"\"\"### Here is the utterance from a tv show: {tagged_utterance}\"\"\"\n",
    "\n",
    "    return question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b268e896",
   "metadata": {},
   "outputs": [],
   "source": [
    "# utterance_emotions_l = []\n",
    "#     emotion_class_labels = [\"Anger\", \"Disgust\", \"Fear\", \"Sadness\", \"Surprise\", \"Joy\"]\n",
    "\n",
    "#     if utterance_emotions == 'Neutral':\n",
    "        \n",
    "#         utterance_emotions_l.append([utterance_emotions])\n",
    "    \n",
    "#     else:\n",
    "#         utterance_emotions = utterance_emotions.split(\"-\")\n",
    "       \n",
    "#         #emotion_annotation_l = []\n",
    "\n",
    "#         for idx, emotion_annotation in enumerate(utterance_emotions):\n",
    "\n",
    "#             if '0' not in emotion_annotation:\n",
    "         \n",
    "#                 #emotion_annotation_l.append(emotion_class_labels[idx])\n",
    "#                 utterance_emotions_l.append(emotion_annotation[:-1])\n",
    "            \n",
    "#         #title_emotions_l.append(emotion_annotation_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "539b6d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_answer(utterance_emotion):    \n",
    "                \n",
    "\n",
    "    return json.dumps({\"emotion_class\": [utterance_emotion]})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd67b57",
   "metadata": {},
   "source": [
    "### Build Data Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "85fd7584",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_train = df[df.split == 'TRAIN'].reset_index()\n",
    "\n",
    "data_file_train = []\n",
    "\n",
    "for index, _ in df_train.iterrows():\n",
    "    \n",
    "    i = index\n",
    "\n",
    "    instruction = build_instruction()\n",
    "    question = build_tagged_text(df_train.iloc[i].Utterance)\n",
    "    answer = build_answer(df_train.iloc[i].Emotion)\n",
    "    \n",
    "    data_file_train.append( formatting_fct(instruction, question, answer) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "181fe00c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7551"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_file_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f7a42377",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'instruction': '### You are an expert in Emotion Analysis. You are given an utterance from a tv show enclosed by <UT></UT> tags. Your task is to classify each utterance as one the following emotion classes: \"Mad\", \"Scared\", \"Sad\", \"Powerful\", \"Peaceful\", \"Joyful\" or \"Neutral\". You must return an emotion class in following JSON format: {\"emotion_class\": [\"emotion_class (str)\"]} where \"emotion_classes (str)\" is replaced by one of the following abbreviated emotion class labels: \"Mad\", \"Scared\", \"Sad\", \"Powerful\", \"Peaceful\", \"Joyful\" or \"Neutral\". \\n', 'input': \"### Here is the utterance from a tv show: <UT>What you guys don't understand is, for us, kissing is as important as any part of it.</UT>\", 'output': '{\"emotion_class\": [\"Joyful\"]}'}\n",
      "{'instruction': '### You are an expert in Emotion Analysis. You are given an utterance from a tv show enclosed by <UT></UT> tags. Your task is to classify each utterance as one the following emotion classes: \"Mad\", \"Scared\", \"Sad\", \"Powerful\", \"Peaceful\", \"Joyful\" or \"Neutral\". You must return an emotion class in following JSON format: {\"emotion_class\": [\"emotion_class (str)\"]} where \"emotion_classes (str)\" is replaced by one of the following abbreviated emotion class labels: \"Mad\", \"Scared\", \"Sad\", \"Powerful\", \"Peaceful\", \"Joyful\" or \"Neutral\". \\n', 'input': \"### Here is the utterance from a tv show: <UT>Yeah, right!.......Y'serious?</UT>\", 'output': '{\"emotion_class\": [\"Neutral\"]}'}\n",
      "{'instruction': '### You are an expert in Emotion Analysis. You are given an utterance from a tv show enclosed by <UT></UT> tags. Your task is to classify each utterance as one the following emotion classes: \"Mad\", \"Scared\", \"Sad\", \"Powerful\", \"Peaceful\", \"Joyful\" or \"Neutral\". You must return an emotion class in following JSON format: {\"emotion_class\": [\"emotion_class (str)\"]} where \"emotion_classes (str)\" is replaced by one of the following abbreviated emotion class labels: \"Mad\", \"Scared\", \"Sad\", \"Powerful\", \"Peaceful\", \"Joyful\" or \"Neutral\". \\n', 'input': '### Here is the utterance from a tv show: <UT>Oh, yeah!</UT>', 'output': '{\"emotion_class\": [\"Joyful\"]}'}\n",
      "{'instruction': '### You are an expert in Emotion Analysis. You are given an utterance from a tv show enclosed by <UT></UT> tags. Your task is to classify each utterance as one the following emotion classes: \"Mad\", \"Scared\", \"Sad\", \"Powerful\", \"Peaceful\", \"Joyful\" or \"Neutral\". You must return an emotion class in following JSON format: {\"emotion_class\": [\"emotion_class (str)\"]} where \"emotion_classes (str)\" is replaced by one of the following abbreviated emotion class labels: \"Mad\", \"Scared\", \"Sad\", \"Powerful\", \"Peaceful\", \"Joyful\" or \"Neutral\". \\n', 'input': '### Here is the utterance from a tv show: <UT>Everything you need to know is in that first kiss.</UT>', 'output': '{\"emotion_class\": [\"Powerful\"]}'}\n",
      "{'instruction': '### You are an expert in Emotion Analysis. You are given an utterance from a tv show enclosed by <UT></UT> tags. Your task is to classify each utterance as one the following emotion classes: \"Mad\", \"Scared\", \"Sad\", \"Powerful\", \"Peaceful\", \"Joyful\" or \"Neutral\". You must return an emotion class in following JSON format: {\"emotion_class\": [\"emotion_class (str)\"]} where \"emotion_classes (str)\" is replaced by one of the following abbreviated emotion class labels: \"Mad\", \"Scared\", \"Sad\", \"Powerful\", \"Peaceful\", \"Joyful\" or \"Neutral\". \\n', 'input': '### Here is the utterance from a tv show: <UT>Absolutely.</UT>', 'output': '{\"emotion_class\": [\"Powerful\"]}'}\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(data_file_train[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "91becc82",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_test = df[df.split == 'TEST'].reset_index()\n",
    "\n",
    "data_file_test = []\n",
    "\n",
    "for index, _ in df_test.iterrows():\n",
    "    \n",
    "    i = index\n",
    "\n",
    "    instruction = build_instruction()\n",
    "    question = build_tagged_text(df_test.iloc[i].Utterance)\n",
    "    answer = build_answer(df_test.iloc[i].Emotion)\n",
    "    \n",
    "    data_file_test.append( formatting_fct(instruction, question, answer) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "96669b4f-b279-48ba-8b9b-d04f91d49c67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "984"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_file_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6e2c531d-d86d-4289-8f3d-d00fd56d0051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'instruction': '### You are an expert in Emotion Analysis. You are given an utterance from a tv show enclosed by <UT></UT> tags. Your task is to classify each utterance as one the following emotion classes: \"Mad\", \"Scared\", \"Sad\", \"Powerful\", \"Peaceful\", \"Joyful\" or \"Neutral\". You must return an emotion class in following JSON format: {\"emotion_class\": [\"emotion_class (str)\"]} where \"emotion_classes (str)\" is replaced by one of the following abbreviated emotion class labels: \"Mad\", \"Scared\", \"Sad\", \"Powerful\", \"Peaceful\", \"Joyful\" or \"Neutral\". \\n', 'input': \"### Here is the utterance from a tv show: <UT>I'm supposed to attach a brackety thing to the side things, using a bunch of these little worm guys. I have no brackety thing, I see no whim guys whatsoever and- I cannot feel my legs.</UT>\", 'output': '{\"emotion_class\": [\"Mad\"]}'}\n",
      "{'instruction': '### You are an expert in Emotion Analysis. You are given an utterance from a tv show enclosed by <UT></UT> tags. Your task is to classify each utterance as one the following emotion classes: \"Mad\", \"Scared\", \"Sad\", \"Powerful\", \"Peaceful\", \"Joyful\" or \"Neutral\". You must return an emotion class in following JSON format: {\"emotion_class\": [\"emotion_class (str)\"]} where \"emotion_classes (str)\" is replaced by one of the following abbreviated emotion class labels: \"Mad\", \"Scared\", \"Sad\", \"Powerful\", \"Peaceful\", \"Joyful\" or \"Neutral\". \\n', 'input': \"### Here is the utterance from a tv show: <UT>I'm thinking we've got a bookcase here.</UT>\", 'output': '{\"emotion_class\": [\"Neutral\"]}'}\n",
      "{'instruction': '### You are an expert in Emotion Analysis. You are given an utterance from a tv show enclosed by <UT></UT> tags. Your task is to classify each utterance as one the following emotion classes: \"Mad\", \"Scared\", \"Sad\", \"Powerful\", \"Peaceful\", \"Joyful\" or \"Neutral\". You must return an emotion class in following JSON format: {\"emotion_class\": [\"emotion_class (str)\"]} where \"emotion_classes (str)\" is replaced by one of the following abbreviated emotion class labels: \"Mad\", \"Scared\", \"Sad\", \"Powerful\", \"Peaceful\", \"Joyful\" or \"Neutral\". \\n', 'input': \"### Here is the utterance from a tv show: <UT>It's a beautiful thing.</UT>\", 'output': '{\"emotion_class\": [\"Joyful\"]}'}\n",
      "{'instruction': '### You are an expert in Emotion Analysis. You are given an utterance from a tv show enclosed by <UT></UT> tags. Your task is to classify each utterance as one the following emotion classes: \"Mad\", \"Scared\", \"Sad\", \"Powerful\", \"Peaceful\", \"Joyful\" or \"Neutral\". You must return an emotion class in following JSON format: {\"emotion_class\": [\"emotion_class (str)\"]} where \"emotion_classes (str)\" is replaced by one of the following abbreviated emotion class labels: \"Mad\", \"Scared\", \"Sad\", \"Powerful\", \"Peaceful\", \"Joyful\" or \"Neutral\". \\n', 'input': \"### Here is the utterance from a tv show: <UT>What's this?</UT>\", 'output': '{\"emotion_class\": [\"Neutral\"]}'}\n",
      "{'instruction': '### You are an expert in Emotion Analysis. You are given an utterance from a tv show enclosed by <UT></UT> tags. Your task is to classify each utterance as one the following emotion classes: \"Mad\", \"Scared\", \"Sad\", \"Powerful\", \"Peaceful\", \"Joyful\" or \"Neutral\". You must return an emotion class in following JSON format: {\"emotion_class\": [\"emotion_class (str)\"]} where \"emotion_classes (str)\" is replaced by one of the following abbreviated emotion class labels: \"Mad\", \"Scared\", \"Sad\", \"Powerful\", \"Peaceful\", \"Joyful\" or \"Neutral\". \\n', 'input': '### Here is the utterance from a tv show: <UT>Which goes where?</UT>', 'output': '{\"emotion_class\": [\"Neutral\"]}'}\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(data_file_test[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "039c7960",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_test = df[df.split == 'TEST'].reset_index()\n",
    "\n",
    "data_file_dev = []\n",
    "\n",
    "for index, _ in df_dev.iterrows():\n",
    "    \n",
    "    i = index\n",
    "\n",
    "    instruction = build_instruction()\n",
    "    question = build_tagged_text(df_dev.iloc[i].Utterance)\n",
    "    answer = build_answer(df_dev.iloc[i].Emotion)\n",
    "    \n",
    "    data_file_dev.append( formatting_fct(instruction, question, answer) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e1687423",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "954"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_file_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ccca0eb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'instruction': '### You are an expert in Emotion Analysis. You are given an utterance from a tv show enclosed by <UT></UT> tags. Your task is to classify each utterance as one the following emotion classes: \"Mad\", \"Scared\", \"Sad\", \"Powerful\", \"Peaceful\", \"Joyful\" or \"Neutral\". You must return an emotion class in following JSON format: {\"emotion_class\": [\"emotion_class (str)\"]} where \"emotion_classes (str)\" is replaced by one of the following abbreviated emotion class labels: \"Mad\", \"Scared\", \"Sad\", \"Powerful\", \"Peaceful\", \"Joyful\" or \"Neutral\". \\n', 'input': '### Here is the utterance from a tv show: <UT>Coffee.</UT>', 'output': '{\"emotion_class\": [\"Neutral\"]}'}\n",
      "{'instruction': '### You are an expert in Emotion Analysis. You are given an utterance from a tv show enclosed by <UT></UT> tags. Your task is to classify each utterance as one the following emotion classes: \"Mad\", \"Scared\", \"Sad\", \"Powerful\", \"Peaceful\", \"Joyful\" or \"Neutral\". You must return an emotion class in following JSON format: {\"emotion_class\": [\"emotion_class (str)\"]} where \"emotion_classes (str)\" is replaced by one of the following abbreviated emotion class labels: \"Mad\", \"Scared\", \"Sad\", \"Powerful\", \"Peaceful\", \"Joyful\" or \"Neutral\". \\n', 'input': '### Here is the utterance from a tv show: <UT>Thank you.</UT>', 'output': '{\"emotion_class\": [\"Neutral\"]}'}\n",
      "{'instruction': '### You are an expert in Emotion Analysis. You are given an utterance from a tv show enclosed by <UT></UT> tags. Your task is to classify each utterance as one the following emotion classes: \"Mad\", \"Scared\", \"Sad\", \"Powerful\", \"Peaceful\", \"Joyful\" or \"Neutral\". You must return an emotion class in following JSON format: {\"emotion_class\": [\"emotion_class (str)\"]} where \"emotion_classes (str)\" is replaced by one of the following abbreviated emotion class labels: \"Mad\", \"Scared\", \"Sad\", \"Powerful\", \"Peaceful\", \"Joyful\" or \"Neutral\". \\n', 'input': '### Here is the utterance from a tv show: <UT>Cappuccino.</UT>', 'output': '{\"emotion_class\": [\"Neutral\"]}'}\n",
      "{'instruction': '### You are an expert in Emotion Analysis. You are given an utterance from a tv show enclosed by <UT></UT> tags. Your task is to classify each utterance as one the following emotion classes: \"Mad\", \"Scared\", \"Sad\", \"Powerful\", \"Peaceful\", \"Joyful\" or \"Neutral\". You must return an emotion class in following JSON format: {\"emotion_class\": [\"emotion_class (str)\"]} where \"emotion_classes (str)\" is replaced by one of the following abbreviated emotion class labels: \"Mad\", \"Scared\", \"Sad\", \"Powerful\", \"Peaceful\", \"Joyful\" or \"Neutral\". \\n', 'input': '### Here is the utterance from a tv show: <UT>Grazie.</UT>', 'output': '{\"emotion_class\": [\"Neutral\"]}'}\n",
      "{'instruction': '### You are an expert in Emotion Analysis. You are given an utterance from a tv show enclosed by <UT></UT> tags. Your task is to classify each utterance as one the following emotion classes: \"Mad\", \"Scared\", \"Sad\", \"Powerful\", \"Peaceful\", \"Joyful\" or \"Neutral\". You must return an emotion class in following JSON format: {\"emotion_class\": [\"emotion_class (str)\"]} where \"emotion_classes (str)\" is replaced by one of the following abbreviated emotion class labels: \"Mad\", \"Scared\", \"Sad\", \"Powerful\", \"Peaceful\", \"Joyful\" or \"Neutral\". \\n', 'input': '### Here is the utterance from a tv show: <UT>And a nice hot cider for Monica.</UT>', 'output': '{\"emotion_class\": [\"Neutral\"]}'}\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(data_file_dev[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb35781",
   "metadata": {},
   "source": [
    "### Create and save JSON files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "95f32abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "01306b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = Path(dataset_dir) / \"emorynlp_utterance_train.json\"\n",
    "\n",
    "with open(file_path, 'w') as file:\n",
    "    \n",
    "    json.dump(data_file_train, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9b6f5885",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = Path(dataset_dir) / \"emorynlp_utterance_test.json\"\n",
    "\n",
    "with open(file_path, 'w') as file:\n",
    "    \n",
    "    json.dump(data_file_test, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "21f7e522",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = Path(dataset_dir) / \"emorynlp_utterance_dev.json\"\n",
    "\n",
    "with open(file_path, 'w') as file:\n",
    "    \n",
    "    json.dump(data_file_dev, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b48dab0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
