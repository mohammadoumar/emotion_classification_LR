{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 1416,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0211864406779661,
      "grad_norm": 1.3341039419174194,
      "learning_rate": 2.8169014084507042e-06,
      "loss": 1.1554,
      "step": 10
    },
    {
      "epoch": 0.0423728813559322,
      "grad_norm": 0.5248833894729614,
      "learning_rate": 6.338028169014085e-06,
      "loss": 0.2155,
      "step": 20
    },
    {
      "epoch": 0.0635593220338983,
      "grad_norm": 0.6363644003868103,
      "learning_rate": 9.859154929577465e-06,
      "loss": 0.1914,
      "step": 30
    },
    {
      "epoch": 0.0847457627118644,
      "grad_norm": 0.68197101354599,
      "learning_rate": 1.3380281690140845e-05,
      "loss": 0.2016,
      "step": 40
    },
    {
      "epoch": 0.1059322033898305,
      "grad_norm": 0.5669451355934143,
      "learning_rate": 1.6901408450704224e-05,
      "loss": 0.2043,
      "step": 50
    },
    {
      "epoch": 0.1271186440677966,
      "grad_norm": 0.614557683467865,
      "learning_rate": 2.0422535211267607e-05,
      "loss": 0.203,
      "step": 60
    },
    {
      "epoch": 0.1483050847457627,
      "grad_norm": 0.718343198299408,
      "learning_rate": 2.3943661971830986e-05,
      "loss": 0.1842,
      "step": 70
    },
    {
      "epoch": 0.1694915254237288,
      "grad_norm": 1.2937687635421753,
      "learning_rate": 2.746478873239437e-05,
      "loss": 0.219,
      "step": 80
    },
    {
      "epoch": 0.1906779661016949,
      "grad_norm": 0.8617511987686157,
      "learning_rate": 3.0985915492957744e-05,
      "loss": 0.2047,
      "step": 90
    },
    {
      "epoch": 0.211864406779661,
      "grad_norm": 0.7472587823867798,
      "learning_rate": 3.450704225352113e-05,
      "loss": 0.1917,
      "step": 100
    },
    {
      "epoch": 0.2330508474576271,
      "grad_norm": 0.9441710710525513,
      "learning_rate": 3.802816901408451e-05,
      "loss": 0.1789,
      "step": 110
    },
    {
      "epoch": 0.2542372881355932,
      "grad_norm": 1.0292736291885376,
      "learning_rate": 4.154929577464789e-05,
      "loss": 0.2059,
      "step": 120
    },
    {
      "epoch": 0.2754237288135593,
      "grad_norm": 0.6486120223999023,
      "learning_rate": 4.507042253521127e-05,
      "loss": 0.1688,
      "step": 130
    },
    {
      "epoch": 0.2966101694915254,
      "grad_norm": 0.8385751247406006,
      "learning_rate": 4.8591549295774653e-05,
      "loss": 0.194,
      "step": 140
    },
    {
      "epoch": 0.3177966101694915,
      "grad_norm": 1.1496821641921997,
      "learning_rate": 4.999726368884718e-05,
      "loss": 0.1931,
      "step": 150
    },
    {
      "epoch": 0.3389830508474576,
      "grad_norm": 0.8920131921768188,
      "learning_rate": 4.9980543956497236e-05,
      "loss": 0.1974,
      "step": 160
    },
    {
      "epoch": 0.3601694915254237,
      "grad_norm": 0.5537172555923462,
      "learning_rate": 4.994863481875841e-05,
      "loss": 0.1994,
      "step": 170
    },
    {
      "epoch": 0.3813559322033898,
      "grad_norm": 0.7794821262359619,
      "learning_rate": 4.9901555677963565e-05,
      "loss": 0.1926,
      "step": 180
    },
    {
      "epoch": 0.4025423728813559,
      "grad_norm": 1.0286041498184204,
      "learning_rate": 4.9839335160557174e-05,
      "loss": 0.1857,
      "step": 190
    },
    {
      "epoch": 0.423728813559322,
      "grad_norm": 0.8577151894569397,
      "learning_rate": 4.976201109968908e-05,
      "loss": 0.1852,
      "step": 200
    },
    {
      "epoch": 0.4449152542372881,
      "grad_norm": 0.5208063721656799,
      "learning_rate": 4.966963051221004e-05,
      "loss": 0.1829,
      "step": 210
    },
    {
      "epoch": 0.4661016949152542,
      "grad_norm": 0.8936119675636292,
      "learning_rate": 4.956224957008313e-05,
      "loss": 0.1851,
      "step": 220
    },
    {
      "epoch": 0.4872881355932203,
      "grad_norm": 1.193176507949829,
      "learning_rate": 4.9439933566228485e-05,
      "loss": 0.2027,
      "step": 230
    },
    {
      "epoch": 0.5084745762711864,
      "grad_norm": 0.5155306458473206,
      "learning_rate": 4.930275687482191e-05,
      "loss": 0.1836,
      "step": 240
    },
    {
      "epoch": 0.5296610169491526,
      "grad_norm": 1.0558034181594849,
      "learning_rate": 4.915080290607174e-05,
      "loss": 0.1935,
      "step": 250
    },
    {
      "epoch": 0.5508474576271186,
      "grad_norm": 0.9300828576087952,
      "learning_rate": 4.8984164055501305e-05,
      "loss": 0.1668,
      "step": 260
    },
    {
      "epoch": 0.5720338983050848,
      "grad_norm": 2.2145724296569824,
      "learning_rate": 4.8802941647767856e-05,
      "loss": 0.1903,
      "step": 270
    },
    {
      "epoch": 0.5932203389830508,
      "grad_norm": 1.2274521589279175,
      "learning_rate": 4.860724587505223e-05,
      "loss": 0.1822,
      "step": 280
    },
    {
      "epoch": 0.614406779661017,
      "grad_norm": 1.752153754234314,
      "learning_rate": 4.83971957300565e-05,
      "loss": 0.1823,
      "step": 290
    },
    {
      "epoch": 0.635593220338983,
      "grad_norm": 1.5653878450393677,
      "learning_rate": 4.817291893365055e-05,
      "loss": 0.1883,
      "step": 300
    },
    {
      "epoch": 0.6567796610169492,
      "grad_norm": 1.002567172050476,
      "learning_rate": 4.793455185721147e-05,
      "loss": 0.1973,
      "step": 310
    },
    {
      "epoch": 0.6779661016949152,
      "grad_norm": 0.8082989454269409,
      "learning_rate": 4.7682239439703025e-05,
      "loss": 0.1892,
      "step": 320
    },
    {
      "epoch": 0.6991525423728814,
      "grad_norm": 0.7178853750228882,
      "learning_rate": 4.741613509954561e-05,
      "loss": 0.1851,
      "step": 330
    },
    {
      "epoch": 0.7203389830508474,
      "grad_norm": 0.8059045672416687,
      "learning_rate": 4.713640064133025e-05,
      "loss": 0.197,
      "step": 340
    },
    {
      "epoch": 0.7415254237288136,
      "grad_norm": 0.8543874621391296,
      "learning_rate": 4.684320615743341e-05,
      "loss": 0.1957,
      "step": 350
    },
    {
      "epoch": 0.7627118644067796,
      "grad_norm": 0.6532551646232605,
      "learning_rate": 4.653672992459242e-05,
      "loss": 0.1898,
      "step": 360
    },
    {
      "epoch": 0.7838983050847458,
      "grad_norm": 1.150514841079712,
      "learning_rate": 4.621715829550446e-05,
      "loss": 0.1852,
      "step": 370
    },
    {
      "epoch": 0.8050847457627118,
      "grad_norm": 1.4012730121612549,
      "learning_rate": 4.588468558551483e-05,
      "loss": 0.1815,
      "step": 380
    },
    {
      "epoch": 0.826271186440678,
      "grad_norm": 1.2810184955596924,
      "learning_rate": 4.553951395446366e-05,
      "loss": 0.1754,
      "step": 390
    },
    {
      "epoch": 0.847457627118644,
      "grad_norm": 1.4049090147018433,
      "learning_rate": 4.518185328376275e-05,
      "loss": 0.195,
      "step": 400
    },
    {
      "epoch": 0.8686440677966102,
      "grad_norm": 1.3223210573196411,
      "learning_rate": 4.481192104877726e-05,
      "loss": 0.1893,
      "step": 410
    },
    {
      "epoch": 0.8898305084745762,
      "grad_norm": 1.4047467708587646,
      "learning_rate": 4.442994218658996e-05,
      "loss": 0.1918,
      "step": 420
    },
    {
      "epoch": 0.9110169491525424,
      "grad_norm": 0.7488855123519897,
      "learning_rate": 4.4036148959228365e-05,
      "loss": 0.1855,
      "step": 430
    },
    {
      "epoch": 0.9322033898305084,
      "grad_norm": 1.6296366453170776,
      "learning_rate": 4.3630780812437934e-05,
      "loss": 0.179,
      "step": 440
    },
    {
      "epoch": 0.9533898305084746,
      "grad_norm": 1.0273923873901367,
      "learning_rate": 4.3214084230087243e-05,
      "loss": 0.1906,
      "step": 450
    },
    {
      "epoch": 0.9745762711864406,
      "grad_norm": 0.4718605875968933,
      "learning_rate": 4.2786312584293586e-05,
      "loss": 0.167,
      "step": 460
    },
    {
      "epoch": 0.9957627118644068,
      "grad_norm": 0.8241758346557617,
      "learning_rate": 4.234772598136021e-05,
      "loss": 0.1833,
      "step": 470
    },
    {
      "epoch": 1.0169491525423728,
      "grad_norm": 1.017065167427063,
      "learning_rate": 4.189859110361886e-05,
      "loss": 0.1702,
      "step": 480
    },
    {
      "epoch": 1.0381355932203389,
      "grad_norm": 1.0922402143478394,
      "learning_rate": 4.143918104727368e-05,
      "loss": 0.1726,
      "step": 490
    },
    {
      "epoch": 1.0593220338983051,
      "grad_norm": 0.7805785536766052,
      "learning_rate": 4.096977515634527e-05,
      "loss": 0.1703,
      "step": 500
    },
    {
      "epoch": 1.0805084745762712,
      "grad_norm": 0.6017960906028748,
      "learning_rate": 4.04906588528157e-05,
      "loss": 0.1707,
      "step": 510
    },
    {
      "epoch": 1.1016949152542372,
      "grad_norm": 0.7695357203483582,
      "learning_rate": 4.0002123463077836e-05,
      "loss": 0.1651,
      "step": 520
    },
    {
      "epoch": 1.1228813559322033,
      "grad_norm": 0.6001004576683044,
      "learning_rate": 3.95044660407945e-05,
      "loss": 0.1702,
      "step": 530
    },
    {
      "epoch": 1.1440677966101696,
      "grad_norm": 0.5368025302886963,
      "learning_rate": 3.899798918627516e-05,
      "loss": 0.1616,
      "step": 540
    },
    {
      "epoch": 1.1652542372881356,
      "grad_norm": 0.7918504476547241,
      "learning_rate": 3.8483000862479986e-05,
      "loss": 0.1546,
      "step": 550
    },
    {
      "epoch": 1.1864406779661016,
      "grad_norm": 0.6297299265861511,
      "learning_rate": 3.7959814207763135e-05,
      "loss": 0.1547,
      "step": 560
    },
    {
      "epoch": 1.207627118644068,
      "grad_norm": 0.7279411554336548,
      "learning_rate": 3.742874734546917e-05,
      "loss": 0.1711,
      "step": 570
    },
    {
      "epoch": 1.228813559322034,
      "grad_norm": 0.5699270367622375,
      "learning_rate": 3.689012319049835e-05,
      "loss": 0.1549,
      "step": 580
    },
    {
      "epoch": 1.25,
      "grad_norm": 0.8588083386421204,
      "learning_rate": 3.634426925295839e-05,
      "loss": 0.1466,
      "step": 590
    },
    {
      "epoch": 1.271186440677966,
      "grad_norm": 0.8673877716064453,
      "learning_rate": 3.579151743902216e-05,
      "loss": 0.1548,
      "step": 600
    },
    {
      "epoch": 1.292372881355932,
      "grad_norm": 0.943636417388916,
      "learning_rate": 3.523220384911227e-05,
      "loss": 0.1596,
      "step": 610
    },
    {
      "epoch": 1.3135593220338984,
      "grad_norm": 0.8954060077667236,
      "learning_rate": 3.466666857353547e-05,
      "loss": 0.1671,
      "step": 620
    },
    {
      "epoch": 1.3347457627118644,
      "grad_norm": 0.5863843560218811,
      "learning_rate": 3.409525548569089e-05,
      "loss": 0.1643,
      "step": 630
    },
    {
      "epoch": 1.3559322033898304,
      "grad_norm": 0.7804599404335022,
      "learning_rate": 3.351831203297803e-05,
      "loss": 0.1565,
      "step": 640
    },
    {
      "epoch": 1.3771186440677967,
      "grad_norm": 1.036096215248108,
      "learning_rate": 3.293618902553156e-05,
      "loss": 0.1511,
      "step": 650
    },
    {
      "epoch": 1.3983050847457628,
      "grad_norm": 1.2599648237228394,
      "learning_rate": 3.234924042291144e-05,
      "loss": 0.1743,
      "step": 660
    },
    {
      "epoch": 1.4194915254237288,
      "grad_norm": 0.8476629853248596,
      "learning_rate": 3.175782311887801e-05,
      "loss": 0.1634,
      "step": 670
    },
    {
      "epoch": 1.4406779661016949,
      "grad_norm": 2.2625951766967773,
      "learning_rate": 3.11622967243829e-05,
      "loss": 0.1716,
      "step": 680
    },
    {
      "epoch": 1.461864406779661,
      "grad_norm": 1.716387152671814,
      "learning_rate": 3.056302334890786e-05,
      "loss": 0.1654,
      "step": 690
    },
    {
      "epoch": 1.4830508474576272,
      "grad_norm": 1.6550018787384033,
      "learning_rate": 2.996036738028427e-05,
      "loss": 0.1669,
      "step": 700
    },
    {
      "epoch": 1.5042372881355932,
      "grad_norm": 1.3589321374893188,
      "learning_rate": 2.9354695263127324e-05,
      "loss": 0.1583,
      "step": 710
    },
    {
      "epoch": 1.5254237288135593,
      "grad_norm": 0.8523456454277039,
      "learning_rate": 2.874637527601959e-05,
      "loss": 0.1586,
      "step": 720
    },
    {
      "epoch": 1.5466101694915255,
      "grad_norm": 1.134057879447937,
      "learning_rate": 2.8135777307579452e-05,
      "loss": 0.1598,
      "step": 730
    },
    {
      "epoch": 1.5677966101694916,
      "grad_norm": 0.8331444263458252,
      "learning_rate": 2.752327263155051e-05,
      "loss": 0.1568,
      "step": 740
    },
    {
      "epoch": 1.5889830508474576,
      "grad_norm": 0.668270468711853,
      "learning_rate": 2.6909233681048845e-05,
      "loss": 0.1652,
      "step": 750
    },
    {
      "epoch": 1.6101694915254239,
      "grad_norm": 0.7656260132789612,
      "learning_rate": 2.629403382210524e-05,
      "loss": 0.1426,
      "step": 760
    },
    {
      "epoch": 1.6313559322033897,
      "grad_norm": 1.1972476243972778,
      "learning_rate": 2.5678047126640166e-05,
      "loss": 0.1472,
      "step": 770
    },
    {
      "epoch": 1.652542372881356,
      "grad_norm": 0.7298184633255005,
      "learning_rate": 2.506164814500962e-05,
      "loss": 0.1572,
      "step": 780
    },
    {
      "epoch": 1.673728813559322,
      "grad_norm": 0.7176342606544495,
      "learning_rate": 2.444521167825995e-05,
      "loss": 0.1523,
      "step": 790
    },
    {
      "epoch": 1.694915254237288,
      "grad_norm": 0.8646774888038635,
      "learning_rate": 2.38291125502303e-05,
      "loss": 0.15,
      "step": 800
    },
    {
      "epoch": 1.7161016949152543,
      "grad_norm": 0.8710426688194275,
      "learning_rate": 2.3213725379641234e-05,
      "loss": 0.173,
      "step": 810
    },
    {
      "epoch": 1.7372881355932204,
      "grad_norm": 0.73683762550354,
      "learning_rate": 2.2599424352307957e-05,
      "loss": 0.1666,
      "step": 820
    },
    {
      "epoch": 1.7584745762711864,
      "grad_norm": 0.9751697182655334,
      "learning_rate": 2.1986582993616926e-05,
      "loss": 0.1603,
      "step": 830
    },
    {
      "epoch": 1.7796610169491527,
      "grad_norm": 0.5434223413467407,
      "learning_rate": 2.13755739414039e-05,
      "loss": 0.1575,
      "step": 840
    },
    {
      "epoch": 1.8008474576271185,
      "grad_norm": 0.906471312046051,
      "learning_rate": 2.076676871937176e-05,
      "loss": 0.1527,
      "step": 850
    },
    {
      "epoch": 1.8220338983050848,
      "grad_norm": 0.6729419827461243,
      "learning_rate": 2.016053751118568e-05,
      "loss": 0.1444,
      "step": 860
    },
    {
      "epoch": 1.8432203389830508,
      "grad_norm": 0.5817322134971619,
      "learning_rate": 1.9557248935383228e-05,
      "loss": 0.1467,
      "step": 870
    },
    {
      "epoch": 1.8644067796610169,
      "grad_norm": 0.48722079396247864,
      "learning_rate": 1.8957269821236018e-05,
      "loss": 0.1676,
      "step": 880
    },
    {
      "epoch": 1.8855932203389831,
      "grad_norm": 0.4610249996185303,
      "learning_rate": 1.8360964985699424e-05,
      "loss": 0.1548,
      "step": 890
    },
    {
      "epoch": 1.9067796610169492,
      "grad_norm": 0.7209131717681885,
      "learning_rate": 1.776869701158581e-05,
      "loss": 0.1545,
      "step": 900
    },
    {
      "epoch": 1.9279661016949152,
      "grad_norm": 0.7261806130409241,
      "learning_rate": 1.718082602709629e-05,
      "loss": 0.156,
      "step": 910
    },
    {
      "epoch": 1.9491525423728815,
      "grad_norm": 0.7212953567504883,
      "learning_rate": 1.6597709486844956e-05,
      "loss": 0.1408,
      "step": 920
    },
    {
      "epoch": 1.9703389830508473,
      "grad_norm": 0.6106451153755188,
      "learning_rate": 1.6019701954508802e-05,
      "loss": 0.1511,
      "step": 930
    },
    {
      "epoch": 1.9915254237288136,
      "grad_norm": 0.6049840450286865,
      "learning_rate": 1.544715488723553e-05,
      "loss": 0.1532,
      "step": 940
    },
    {
      "epoch": 2.01271186440678,
      "grad_norm": 0.5961133241653442,
      "learning_rate": 1.4880416421940155e-05,
      "loss": 0.1279,
      "step": 950
    },
    {
      "epoch": 2.0338983050847457,
      "grad_norm": 0.6340343952178955,
      "learning_rate": 1.4319831163620646e-05,
      "loss": 0.1011,
      "step": 960
    },
    {
      "epoch": 2.055084745762712,
      "grad_norm": 1.0130592584609985,
      "learning_rate": 1.3765739975820962e-05,
      "loss": 0.0772,
      "step": 970
    },
    {
      "epoch": 2.0762711864406778,
      "grad_norm": 0.7909771800041199,
      "learning_rate": 1.3218479773369275e-05,
      "loss": 0.0974,
      "step": 980
    },
    {
      "epoch": 2.097457627118644,
      "grad_norm": 0.9886288046836853,
      "learning_rate": 1.2678383317516984e-05,
      "loss": 0.0986,
      "step": 990
    },
    {
      "epoch": 2.1186440677966103,
      "grad_norm": 0.9597740173339844,
      "learning_rate": 1.214577901360352e-05,
      "loss": 0.1014,
      "step": 1000
    },
    {
      "epoch": 2.139830508474576,
      "grad_norm": 1.0086686611175537,
      "learning_rate": 1.162099071136962e-05,
      "loss": 0.0917,
      "step": 1010
    },
    {
      "epoch": 2.1610169491525424,
      "grad_norm": 0.8420247435569763,
      "learning_rate": 1.1104337508040723e-05,
      "loss": 0.0856,
      "step": 1020
    },
    {
      "epoch": 2.1822033898305087,
      "grad_norm": 1.8472932577133179,
      "learning_rate": 1.0596133554300014e-05,
      "loss": 0.1005,
      "step": 1030
    },
    {
      "epoch": 2.2033898305084745,
      "grad_norm": 0.9658442139625549,
      "learning_rate": 1.0096687863269368e-05,
      "loss": 0.0716,
      "step": 1040
    },
    {
      "epoch": 2.2245762711864407,
      "grad_norm": 1.5018699169158936,
      "learning_rate": 9.606304122614024e-06,
      "loss": 0.0937,
      "step": 1050
    },
    {
      "epoch": 2.2457627118644066,
      "grad_norm": 1.8980906009674072,
      "learning_rate": 9.125280509885505e-06,
      "loss": 0.0976,
      "step": 1060
    },
    {
      "epoch": 2.266949152542373,
      "grad_norm": 2.2521157264709473,
      "learning_rate": 8.653909511214963e-06,
      "loss": 0.088,
      "step": 1070
    },
    {
      "epoch": 2.288135593220339,
      "grad_norm": 1.4768861532211304,
      "learning_rate": 8.192477743467078e-06,
      "loss": 0.0964,
      "step": 1080
    },
    {
      "epoch": 2.309322033898305,
      "grad_norm": 1.481583595275879,
      "learning_rate": 7.741265779962924e-06,
      "loss": 0.0822,
      "step": 1090
    },
    {
      "epoch": 2.330508474576271,
      "grad_norm": 1.0629627704620361,
      "learning_rate": 7.300547979877448e-06,
      "loss": 0.0619,
      "step": 1100
    },
    {
      "epoch": 2.3516949152542375,
      "grad_norm": 1.6527516841888428,
      "learning_rate": 6.8705923214155945e-06,
      "loss": 0.0971,
      "step": 1110
    },
    {
      "epoch": 2.3728813559322033,
      "grad_norm": 1.1250379085540771,
      "learning_rate": 6.451660238868243e-06,
      "loss": 0.0986,
      "step": 1120
    },
    {
      "epoch": 2.3940677966101696,
      "grad_norm": 1.2642375230789185,
      "learning_rate": 6.044006463647317e-06,
      "loss": 0.0836,
      "step": 1130
    },
    {
      "epoch": 2.415254237288136,
      "grad_norm": 0.8213100433349609,
      "learning_rate": 5.647878869396425e-06,
      "loss": 0.0826,
      "step": 1140
    },
    {
      "epoch": 2.4364406779661016,
      "grad_norm": 0.5140599608421326,
      "learning_rate": 5.2635183212714905e-06,
      "loss": 0.0744,
      "step": 1150
    },
    {
      "epoch": 2.457627118644068,
      "grad_norm": 1.4492483139038086,
      "learning_rate": 4.891158529482781e-06,
      "loss": 0.0898,
      "step": 1160
    },
    {
      "epoch": 2.4788135593220337,
      "grad_norm": 1.028260350227356,
      "learning_rate": 4.531025907187597e-06,
      "loss": 0.0797,
      "step": 1170
    },
    {
      "epoch": 2.5,
      "grad_norm": 1.495743751525879,
      "learning_rate": 4.183339432819844e-06,
      "loss": 0.091,
      "step": 1180
    },
    {
      "epoch": 2.5211864406779663,
      "grad_norm": 0.7676336169242859,
      "learning_rate": 3.848310516940332e-06,
      "loss": 0.0888,
      "step": 1190
    },
    {
      "epoch": 2.542372881355932,
      "grad_norm": 0.8523011803627014,
      "learning_rate": 3.5261428736887314e-06,
      "loss": 0.0875,
      "step": 1200
    },
    {
      "epoch": 2.5635593220338984,
      "grad_norm": 1.1570332050323486,
      "learning_rate": 3.217032396915265e-06,
      "loss": 0.0741,
      "step": 1210
    },
    {
      "epoch": 2.584745762711864,
      "grad_norm": 1.1925793886184692,
      "learning_rate": 2.9211670410676045e-06,
      "loss": 0.0706,
      "step": 1220
    },
    {
      "epoch": 2.6059322033898304,
      "grad_norm": 1.1205518245697021,
      "learning_rate": 2.6387267069052452e-06,
      "loss": 0.0671,
      "step": 1230
    },
    {
      "epoch": 2.6271186440677967,
      "grad_norm": 0.7525466084480286,
      "learning_rate": 2.36988313211097e-06,
      "loss": 0.068,
      "step": 1240
    },
    {
      "epoch": 2.648305084745763,
      "grad_norm": 1.7534760236740112,
      "learning_rate": 2.1147997868658425e-06,
      "loss": 0.0931,
      "step": 1250
    },
    {
      "epoch": 2.669491525423729,
      "grad_norm": 1.098527193069458,
      "learning_rate": 1.873631774451276e-06,
      "loss": 0.065,
      "step": 1260
    },
    {
      "epoch": 2.690677966101695,
      "grad_norm": 1.2180039882659912,
      "learning_rate": 1.6465257369385367e-06,
      "loss": 0.0756,
      "step": 1270
    },
    {
      "epoch": 2.711864406779661,
      "grad_norm": 1.4717885255813599,
      "learning_rate": 1.433619766023156e-06,
      "loss": 0.0737,
      "step": 1280
    },
    {
      "epoch": 2.733050847457627,
      "grad_norm": 1.4822721481323242,
      "learning_rate": 1.2350433190583266e-06,
      "loss": 0.0703,
      "step": 1290
    },
    {
      "epoch": 2.7542372881355934,
      "grad_norm": 2.4076855182647705,
      "learning_rate": 1.0509171403384393e-06,
      "loss": 0.0984,
      "step": 1300
    },
    {
      "epoch": 2.7754237288135593,
      "grad_norm": 2.0934181213378906,
      "learning_rate": 8.81353187680592e-07,
      "loss": 0.0904,
      "step": 1310
    },
    {
      "epoch": 2.7966101694915255,
      "grad_norm": 0.8829870820045471,
      "learning_rate": 7.264545643486997e-07,
      "loss": 0.083,
      "step": 1320
    },
    {
      "epoch": 2.8177966101694913,
      "grad_norm": 1.3517905473709106,
      "learning_rate": 5.863154563616136e-07,
      "loss": 0.092,
      "step": 1330
    },
    {
      "epoch": 2.8389830508474576,
      "grad_norm": 0.7979152202606201,
      "learning_rate": 4.6102107522336403e-07,
      "loss": 0.0889,
      "step": 1340
    },
    {
      "epoch": 2.860169491525424,
      "grad_norm": 1.5464028120040894,
      "learning_rate": 3.5064760611036027e-07,
      "loss": 0.0856,
      "step": 1350
    },
    {
      "epoch": 2.8813559322033897,
      "grad_norm": 1.283883810043335,
      "learning_rate": 2.552621615470291e-07,
      "loss": 0.0848,
      "step": 1360
    },
    {
      "epoch": 2.902542372881356,
      "grad_norm": 0.774642288684845,
      "learning_rate": 1.7492274059809078e-07,
      "loss": 0.0977,
      "step": 1370
    },
    {
      "epoch": 2.923728813559322,
      "grad_norm": 1.1280583143234253,
      "learning_rate": 1.0967819360225562e-07,
      "loss": 0.0875,
      "step": 1380
    },
    {
      "epoch": 2.944915254237288,
      "grad_norm": 1.6025526523590088,
      "learning_rate": 5.956819246881185e-08,
      "loss": 0.0809,
      "step": 1390
    },
    {
      "epoch": 2.9661016949152543,
      "grad_norm": 1.869663953781128,
      "learning_rate": 2.462320655513273e-08,
      "loss": 0.0846,
      "step": 1400
    },
    {
      "epoch": 2.9872881355932206,
      "grad_norm": 0.7967621088027954,
      "learning_rate": 4.864484139810444e-09,
      "loss": 0.085,
      "step": 1410
    },
    {
      "epoch": 3.0,
      "step": 1416,
      "total_flos": 1.96680929081557e+17,
      "train_loss": 0.15196986963688316,
      "train_runtime": 4133.7467,
      "train_samples_per_second": 5.48,
      "train_steps_per_second": 0.343
    }
  ],
  "logging_steps": 10,
  "max_steps": 1416,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 15000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1.96680929081557e+17,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
