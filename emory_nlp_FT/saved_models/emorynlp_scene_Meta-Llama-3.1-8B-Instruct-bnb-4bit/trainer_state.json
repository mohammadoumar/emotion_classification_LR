{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 2.9899665551839467,
  "eval_steps": 500,
  "global_step": 447,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.06688963210702341,
      "grad_norm": 0.7297838926315308,
      "learning_rate": 1.1111111111111112e-05,
      "loss": 0.4619,
      "step": 10
    },
    {
      "epoch": 0.13377926421404682,
      "grad_norm": 0.5166729688644409,
      "learning_rate": 2.2222222222222223e-05,
      "loss": 0.397,
      "step": 20
    },
    {
      "epoch": 0.20066889632107024,
      "grad_norm": 0.650364339351654,
      "learning_rate": 3.3333333333333335e-05,
      "loss": 0.3531,
      "step": 30
    },
    {
      "epoch": 0.26755852842809363,
      "grad_norm": 0.6768056154251099,
      "learning_rate": 4.4444444444444447e-05,
      "loss": 0.3889,
      "step": 40
    },
    {
      "epoch": 0.33444816053511706,
      "grad_norm": 1.7493520975112915,
      "learning_rate": 4.998091718663671e-05,
      "loss": 0.3888,
      "step": 50
    },
    {
      "epoch": 0.4013377926421405,
      "grad_norm": 1.208353877067566,
      "learning_rate": 4.982842942906386e-05,
      "loss": 0.363,
      "step": 60
    },
    {
      "epoch": 0.4682274247491639,
      "grad_norm": 1.5465160608291626,
      "learning_rate": 4.9524384725066355e-05,
      "loss": 0.3567,
      "step": 70
    },
    {
      "epoch": 0.5351170568561873,
      "grad_norm": 1.0750024318695068,
      "learning_rate": 4.907063901511141e-05,
      "loss": 0.3927,
      "step": 80
    },
    {
      "epoch": 0.6020066889632107,
      "grad_norm": 1.331190586090088,
      "learning_rate": 4.846996204000967e-05,
      "loss": 0.3388,
      "step": 90
    },
    {
      "epoch": 0.6688963210702341,
      "grad_norm": 1.0127698183059692,
      "learning_rate": 4.77260204339473e-05,
      "loss": 0.3444,
      "step": 100
    },
    {
      "epoch": 0.7357859531772575,
      "grad_norm": 1.78675377368927,
      "learning_rate": 4.693771734774578e-05,
      "loss": 0.3688,
      "step": 110
    },
    {
      "epoch": 0.802675585284281,
      "grad_norm": 2.4407732486724854,
      "learning_rate": 4.593478432952002e-05,
      "loss": 0.385,
      "step": 120
    },
    {
      "epoch": 0.8695652173913043,
      "grad_norm": 1.2626289129257202,
      "learning_rate": 4.480406183527823e-05,
      "loss": 0.3609,
      "step": 130
    },
    {
      "epoch": 0.9364548494983278,
      "grad_norm": 1.4852632284164429,
      "learning_rate": 4.355245198700003e-05,
      "loss": 0.3756,
      "step": 140
    },
    {
      "epoch": 1.0033444816053512,
      "grad_norm": 1.5118144750595093,
      "learning_rate": 4.218759482358765e-05,
      "loss": 0.3431,
      "step": 150
    },
    {
      "epoch": 1.0702341137123745,
      "grad_norm": 1.309410810470581,
      "learning_rate": 4.071782166477213e-05,
      "loss": 0.3159,
      "step": 160
    },
    {
      "epoch": 1.137123745819398,
      "grad_norm": 1.5086501836776733,
      "learning_rate": 3.915210425532383e-05,
      "loss": 0.2695,
      "step": 170
    },
    {
      "epoch": 1.2040133779264215,
      "grad_norm": 0.9719927906990051,
      "learning_rate": 3.7500000000000003e-05,
      "loss": 0.2712,
      "step": 180
    },
    {
      "epoch": 1.2709030100334449,
      "grad_norm": 1.0589085817337036,
      "learning_rate": 3.5771593623524265e-05,
      "loss": 0.2913,
      "step": 190
    },
    {
      "epoch": 1.3377926421404682,
      "grad_norm": 1.0780797004699707,
      "learning_rate": 3.397743561171562e-05,
      "loss": 0.303,
      "step": 200
    },
    {
      "epoch": 1.4046822742474916,
      "grad_norm": 1.133158564567566,
      "learning_rate": 3.2128477809532684e-05,
      "loss": 0.3326,
      "step": 210
    },
    {
      "epoch": 1.471571906354515,
      "grad_norm": 2.223900079727173,
      "learning_rate": 3.0236006569153617e-05,
      "loss": 0.2941,
      "step": 220
    },
    {
      "epoch": 1.5384615384615383,
      "grad_norm": 0.8487116694450378,
      "learning_rate": 2.83115738561672e-05,
      "loss": 0.3082,
      "step": 230
    },
    {
      "epoch": 1.605351170568562,
      "grad_norm": 0.9540719985961914,
      "learning_rate": 2.636692673441465e-05,
      "loss": 0.2933,
      "step": 240
    },
    {
      "epoch": 1.6722408026755853,
      "grad_norm": 1.082503318786621,
      "learning_rate": 2.441393565991849e-05,
      "loss": 0.2803,
      "step": 250
    },
    {
      "epoch": 1.7391304347826086,
      "grad_norm": 1.1686345338821411,
      "learning_rate": 2.246452202160471e-05,
      "loss": 0.3301,
      "step": 260
    },
    {
      "epoch": 1.8060200668896322,
      "grad_norm": 2.244590997695923,
      "learning_rate": 2.053058537112177e-05,
      "loss": 0.2621,
      "step": 270
    },
    {
      "epoch": 1.8729096989966556,
      "grad_norm": 1.2387585639953613,
      "learning_rate": 1.8623930785958092e-05,
      "loss": 0.2597,
      "step": 280
    },
    {
      "epoch": 1.939799331103679,
      "grad_norm": 1.2727487087249756,
      "learning_rate": 1.6756196809245838e-05,
      "loss": 0.2846,
      "step": 290
    },
    {
      "epoch": 2.0066889632107023,
      "grad_norm": 1.0704669952392578,
      "learning_rate": 1.493878440611866e-05,
      "loss": 0.3024,
      "step": 300
    },
    {
      "epoch": 2.0735785953177257,
      "grad_norm": 1.0220420360565186,
      "learning_rate": 1.3182787370285865e-05,
      "loss": 0.1909,
      "step": 310
    },
    {
      "epoch": 2.140468227424749,
      "grad_norm": 1.2370491027832031,
      "learning_rate": 1.1498924605633111e-05,
      "loss": 0.1661,
      "step": 320
    },
    {
      "epoch": 2.2073578595317724,
      "grad_norm": 1.1374398469924927,
      "learning_rate": 9.89747469621411e-06,
      "loss": 0.1424,
      "step": 330
    },
    {
      "epoch": 2.274247491638796,
      "grad_norm": 1.5378566980361938,
      "learning_rate": 8.38821316402946e-06,
      "loss": 0.1672,
      "step": 340
    },
    {
      "epoch": 2.3411371237458196,
      "grad_norm": 1.0240367650985718,
      "learning_rate": 6.980352797581438e-06,
      "loss": 0.1695,
      "step": 350
    },
    {
      "epoch": 2.408026755852843,
      "grad_norm": 1.157292127609253,
      "learning_rate": 5.6824874154497194e-06,
      "loss": 0.1819,
      "step": 360
    },
    {
      "epoch": 2.4749163879598663,
      "grad_norm": 1.2511242628097534,
      "learning_rate": 4.502539408164386e-06,
      "loss": 0.1735,
      "step": 370
    },
    {
      "epoch": 2.5418060200668897,
      "grad_norm": 1.1737399101257324,
      "learning_rate": 3.4477113785898407e-06,
      "loss": 0.1726,
      "step": 380
    },
    {
      "epoch": 2.608695652173913,
      "grad_norm": 0.9722040295600891,
      "learning_rate": 2.5244421760146355e-06,
      "loss": 0.1722,
      "step": 390
    },
    {
      "epoch": 2.6755852842809364,
      "grad_norm": 1.0629298686981201,
      "learning_rate": 1.738367592322837e-06,
      "loss": 0.1673,
      "step": 400
    },
    {
      "epoch": 2.74247491638796,
      "grad_norm": 1.2544035911560059,
      "learning_rate": 1.0942859601639794e-06,
      "loss": 0.1534,
      "step": 410
    },
    {
      "epoch": 2.809364548494983,
      "grad_norm": 1.5445860624313354,
      "learning_rate": 5.961288631163687e-07,
      "loss": 0.179,
      "step": 420
    },
    {
      "epoch": 2.8762541806020065,
      "grad_norm": 1.3779847621917725,
      "learning_rate": 2.4693713663372644e-07,
      "loss": 0.1716,
      "step": 430
    },
    {
      "epoch": 2.94314381270903,
      "grad_norm": 1.6003239154815674,
      "learning_rate": 4.884230626960307e-08,
      "loss": 0.1861,
      "step": 440
    },
    {
      "epoch": 2.9899665551839467,
      "step": 447,
      "total_flos": 5.287152799973376e+16,
      "train_loss": 0.2796608369622455,
      "train_runtime": 1182.6368,
      "train_samples_per_second": 1.517,
      "train_steps_per_second": 0.378
    }
  ],
  "logging_steps": 10,
  "max_steps": 447,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 15000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 5.287152799973376e+16,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
