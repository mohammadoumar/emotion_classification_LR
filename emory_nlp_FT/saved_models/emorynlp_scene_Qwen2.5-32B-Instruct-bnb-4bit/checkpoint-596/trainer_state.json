{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 3.9866220735785953,
  "eval_steps": 500,
  "global_step": 596,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.06688963210702341,
      "grad_norm": 0.7461187839508057,
      "learning_rate": 7.5e-06,
      "loss": 1.0794,
      "step": 10
    },
    {
      "epoch": 0.13377926421404682,
      "grad_norm": 0.877964198589325,
      "learning_rate": 1.5833333333333333e-05,
      "loss": 0.8108,
      "step": 20
    },
    {
      "epoch": 0.20066889632107024,
      "grad_norm": 0.47650256752967834,
      "learning_rate": 2.4166666666666667e-05,
      "loss": 0.6285,
      "step": 30
    },
    {
      "epoch": 0.26755852842809363,
      "grad_norm": 0.31594163179397583,
      "learning_rate": 3.2500000000000004e-05,
      "loss": 0.604,
      "step": 40
    },
    {
      "epoch": 0.33444816053511706,
      "grad_norm": 0.3762522041797638,
      "learning_rate": 4.0833333333333334e-05,
      "loss": 0.5423,
      "step": 50
    },
    {
      "epoch": 0.4013377926421405,
      "grad_norm": 0.30004721879959106,
      "learning_rate": 4.9166666666666665e-05,
      "loss": 0.5187,
      "step": 60
    },
    {
      "epoch": 0.4682274247491639,
      "grad_norm": 0.5168250799179077,
      "learning_rate": 4.996522521217386e-05,
      "loss": 0.5164,
      "step": 70
    },
    {
      "epoch": 0.5351170568561873,
      "grad_norm": 0.5914117097854614,
      "learning_rate": 4.9845140267045654e-05,
      "loss": 0.5437,
      "step": 80
    },
    {
      "epoch": 0.6020066889632107,
      "grad_norm": 0.4936906397342682,
      "learning_rate": 4.963972816285715e-05,
      "loss": 0.5105,
      "step": 90
    },
    {
      "epoch": 0.6688963210702341,
      "grad_norm": 0.8936177492141724,
      "learning_rate": 4.934969435874838e-05,
      "loss": 0.5523,
      "step": 100
    },
    {
      "epoch": 0.7357859531772575,
      "grad_norm": 1.040116310119629,
      "learning_rate": 4.89760349352514e-05,
      "loss": 0.5494,
      "step": 110
    },
    {
      "epoch": 0.802675585284281,
      "grad_norm": 0.7252480387687683,
      "learning_rate": 4.852003317339102e-05,
      "loss": 0.5377,
      "step": 120
    },
    {
      "epoch": 0.8695652173913043,
      "grad_norm": 0.3168526887893677,
      "learning_rate": 4.798325514743558e-05,
      "loss": 0.504,
      "step": 130
    },
    {
      "epoch": 0.9364548494983278,
      "grad_norm": 0.41981032490730286,
      "learning_rate": 4.7367544346434e-05,
      "loss": 0.5222,
      "step": 140
    },
    {
      "epoch": 1.0033444816053512,
      "grad_norm": 0.6161984205245972,
      "learning_rate": 4.667501534301043e-05,
      "loss": 0.5425,
      "step": 150
    },
    {
      "epoch": 1.0702341137123745,
      "grad_norm": 0.458354115486145,
      "learning_rate": 4.5908046531160396e-05,
      "loss": 0.493,
      "step": 160
    },
    {
      "epoch": 1.137123745819398,
      "grad_norm": 0.5075778961181641,
      "learning_rate": 4.5069271957989276e-05,
      "loss": 0.4658,
      "step": 170
    },
    {
      "epoch": 1.2040133779264215,
      "grad_norm": 0.4378686249256134,
      "learning_rate": 4.416157227744594e-05,
      "loss": 0.4552,
      "step": 180
    },
    {
      "epoch": 1.2709030100334449,
      "grad_norm": 0.5636603236198425,
      "learning_rate": 4.318806485711972e-05,
      "loss": 0.4616,
      "step": 190
    },
    {
      "epoch": 1.3377926421404682,
      "grad_norm": 0.6977821588516235,
      "learning_rate": 4.2152093072077435e-05,
      "loss": 0.4994,
      "step": 200
    },
    {
      "epoch": 1.4046822742474916,
      "grad_norm": 0.50609290599823,
      "learning_rate": 4.1057214822509394e-05,
      "loss": 0.4972,
      "step": 210
    },
    {
      "epoch": 1.471571906354515,
      "grad_norm": 0.8986217975616455,
      "learning_rate": 3.990719031461884e-05,
      "loss": 0.4745,
      "step": 220
    },
    {
      "epoch": 1.5384615384615383,
      "grad_norm": 0.5838996767997742,
      "learning_rate": 3.8705969146719686e-05,
      "loss": 0.4834,
      "step": 230
    },
    {
      "epoch": 1.605351170568562,
      "grad_norm": 0.7254647016525269,
      "learning_rate": 3.7457676744893594e-05,
      "loss": 0.4783,
      "step": 240
    },
    {
      "epoch": 1.6722408026755853,
      "grad_norm": 0.41003158688545227,
      "learning_rate": 3.61666001947911e-05,
      "loss": 0.4818,
      "step": 250
    },
    {
      "epoch": 1.7391304347826086,
      "grad_norm": 0.6477171182632446,
      "learning_rate": 3.483717351823561e-05,
      "loss": 0.4814,
      "step": 260
    },
    {
      "epoch": 1.8060200668896322,
      "grad_norm": 0.9975987076759338,
      "learning_rate": 3.3473962445195646e-05,
      "loss": 0.4486,
      "step": 270
    },
    {
      "epoch": 1.8729096989966556,
      "grad_norm": 0.6528233885765076,
      "learning_rate": 3.2081648733423893e-05,
      "loss": 0.4791,
      "step": 280
    },
    {
      "epoch": 1.939799331103679,
      "grad_norm": 0.6275165677070618,
      "learning_rate": 3.066501408961509e-05,
      "loss": 0.4781,
      "step": 290
    },
    {
      "epoch": 2.0066889632107023,
      "grad_norm": 0.41561785340309143,
      "learning_rate": 2.922892374730316e-05,
      "loss": 0.495,
      "step": 300
    },
    {
      "epoch": 2.0735785953177257,
      "grad_norm": 0.6469905972480774,
      "learning_rate": 2.7778309757897213e-05,
      "loss": 0.3723,
      "step": 310
    },
    {
      "epoch": 2.140468227424749,
      "grad_norm": 0.6779227256774902,
      "learning_rate": 2.6318154052240807e-05,
      "loss": 0.3711,
      "step": 320
    },
    {
      "epoch": 2.2073578595317724,
      "grad_norm": 0.6712534427642822,
      "learning_rate": 2.4853471330867335e-05,
      "loss": 0.3057,
      "step": 330
    },
    {
      "epoch": 2.274247491638796,
      "grad_norm": 0.6194502711296082,
      "learning_rate": 2.338929184171247e-05,
      "loss": 0.337,
      "step": 340
    },
    {
      "epoch": 2.3411371237458196,
      "grad_norm": 0.6200400590896606,
      "learning_rate": 2.1930644104431197e-05,
      "loss": 0.3458,
      "step": 350
    },
    {
      "epoch": 2.408026755852843,
      "grad_norm": 0.7186350226402283,
      "learning_rate": 2.0626731828497225e-05,
      "loss": 0.3323,
      "step": 360
    },
    {
      "epoch": 2.4749163879598663,
      "grad_norm": 0.8244103789329529,
      "learning_rate": 1.9192366084125425e-05,
      "loss": 0.334,
      "step": 370
    },
    {
      "epoch": 2.5418060200668897,
      "grad_norm": 0.6582440733909607,
      "learning_rate": 1.777794584610124e-05,
      "loss": 0.3616,
      "step": 380
    },
    {
      "epoch": 2.608695652173913,
      "grad_norm": 0.5481879711151123,
      "learning_rate": 1.638832874289168e-05,
      "loss": 0.3394,
      "step": 390
    },
    {
      "epoch": 2.6755852842809364,
      "grad_norm": 0.7271470427513123,
      "learning_rate": 1.502828722006655e-05,
      "loss": 0.3419,
      "step": 400
    },
    {
      "epoch": 2.74247491638796,
      "grad_norm": 0.6350660920143127,
      "learning_rate": 1.3702492150001659e-05,
      "loss": 0.3156,
      "step": 410
    },
    {
      "epoch": 2.809364548494983,
      "grad_norm": 0.9793906807899475,
      "learning_rate": 1.2415496790421011e-05,
      "loss": 0.3546,
      "step": 420
    },
    {
      "epoch": 2.8762541806020065,
      "grad_norm": 0.8801709413528442,
      "learning_rate": 1.1171721146870015e-05,
      "loss": 0.3646,
      "step": 430
    },
    {
      "epoch": 2.94314381270903,
      "grad_norm": 0.9973158836364746,
      "learning_rate": 9.975436792824691e-06,
      "loss": 0.3548,
      "step": 440
    },
    {
      "epoch": 3.0100334448160537,
      "grad_norm": 0.6249653697013855,
      "learning_rate": 8.830752199570033e-06,
      "loss": 0.2909,
      "step": 450
    },
    {
      "epoch": 3.076923076923077,
      "grad_norm": 0.4224885404109955,
      "learning_rate": 7.741598626230079e-06,
      "loss": 0.2494,
      "step": 460
    },
    {
      "epoch": 3.1438127090301005,
      "grad_norm": 0.5500075817108154,
      "learning_rate": 6.711716618408281e-06,
      "loss": 0.2418,
      "step": 470
    },
    {
      "epoch": 3.210702341137124,
      "grad_norm": 1.0705996751785278,
      "learning_rate": 5.74464316180689e-06,
      "loss": 0.2269,
      "step": 480
    },
    {
      "epoch": 3.277591973244147,
      "grad_norm": 0.8967825770378113,
      "learning_rate": 4.843699534944257e-06,
      "loss": 0.2508,
      "step": 490
    },
    {
      "epoch": 3.3444816053511706,
      "grad_norm": 0.6099444627761841,
      "learning_rate": 4.01197990268834e-06,
      "loss": 0.239,
      "step": 500
    },
    {
      "epoch": 3.411371237458194,
      "grad_norm": 0.2065764218568802,
      "learning_rate": 3.252340689780245e-06,
      "loss": 0.211,
      "step": 510
    },
    {
      "epoch": 3.4782608695652173,
      "grad_norm": 3.6717207431793213,
      "learning_rate": 2.5673907708429976e-06,
      "loss": 0.244,
      "step": 520
    },
    {
      "epoch": 3.5451505016722407,
      "grad_norm": 0.6278781890869141,
      "learning_rate": 1.9594825105665654e-06,
      "loss": 0.2602,
      "step": 530
    },
    {
      "epoch": 3.6120401337792645,
      "grad_norm": 0.2613961100578308,
      "learning_rate": 1.4307036848403648e-06,
      "loss": 0.2161,
      "step": 540
    },
    {
      "epoch": 3.678929765886288,
      "grad_norm": 0.8015972375869751,
      "learning_rate": 9.828703105789983e-07,
      "loss": 0.2134,
      "step": 550
    },
    {
      "epoch": 3.745819397993311,
      "grad_norm": 0.838011622428894,
      "learning_rate": 6.175204088661485e-07,
      "loss": 0.233,
      "step": 560
    },
    {
      "epoch": 3.8127090301003346,
      "grad_norm": 1.0139480829238892,
      "learning_rate": 3.3590872283633944e-07,
      "loss": 0.2297,
      "step": 570
    },
    {
      "epoch": 3.879598662207358,
      "grad_norm": 0.33052051067352295,
      "learning_rate": 1.3900240843510993e-07,
      "loss": 0.2553,
      "step": 580
    },
    {
      "epoch": 3.9464882943143813,
      "grad_norm": 0.7837225794792175,
      "learning_rate": 2.7477712857215677e-08,
      "loss": 0.2643,
      "step": 590
    }
  ],
  "logging_steps": 10,
  "max_steps": 596,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 4,
  "save_steps": 15000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 3.133618703470756e+17,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
