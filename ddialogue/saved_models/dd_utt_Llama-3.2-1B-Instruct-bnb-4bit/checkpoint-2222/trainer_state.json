{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.9986507758039127,
  "eval_steps": 500,
  "global_step": 2222,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.026984483921744996,
      "grad_norm": 0.8968830108642578,
      "learning_rate": 6.726457399103139e-06,
      "loss": 0.3616,
      "step": 30
    },
    {
      "epoch": 0.05396896784348999,
      "grad_norm": 0.6189404129981995,
      "learning_rate": 1.3452914798206278e-05,
      "loss": 0.1325,
      "step": 60
    },
    {
      "epoch": 0.080953451765235,
      "grad_norm": 0.8214097619056702,
      "learning_rate": 2.017937219730942e-05,
      "loss": 0.1075,
      "step": 90
    },
    {
      "epoch": 0.10793793568697999,
      "grad_norm": 0.36468350887298584,
      "learning_rate": 2.6905829596412556e-05,
      "loss": 0.1254,
      "step": 120
    },
    {
      "epoch": 0.13492241960872497,
      "grad_norm": 0.9331653714179993,
      "learning_rate": 3.36322869955157e-05,
      "loss": 0.1172,
      "step": 150
    },
    {
      "epoch": 0.16190690353047,
      "grad_norm": 0.38137105107307434,
      "learning_rate": 4.035874439461884e-05,
      "loss": 0.1024,
      "step": 180
    },
    {
      "epoch": 0.18889138745221498,
      "grad_norm": 0.8512039184570312,
      "learning_rate": 4.708520179372198e-05,
      "loss": 0.0943,
      "step": 210
    },
    {
      "epoch": 0.21587587137395997,
      "grad_norm": 0.9746677875518799,
      "learning_rate": 4.999107812406553e-05,
      "loss": 0.1058,
      "step": 240
    },
    {
      "epoch": 0.24286035529570496,
      "grad_norm": 0.24741923809051514,
      "learning_rate": 4.993183170686049e-05,
      "loss": 0.0948,
      "step": 270
    },
    {
      "epoch": 0.26984483921744995,
      "grad_norm": 0.5978941917419434,
      "learning_rate": 4.9817175002228896e-05,
      "loss": 0.0892,
      "step": 300
    },
    {
      "epoch": 0.29682932313919497,
      "grad_norm": 0.385812371969223,
      "learning_rate": 4.9647362831438337e-05,
      "loss": 0.081,
      "step": 330
    },
    {
      "epoch": 0.32381380706094,
      "grad_norm": 0.6554864048957825,
      "learning_rate": 4.9422772597212486e-05,
      "loss": 0.0809,
      "step": 360
    },
    {
      "epoch": 0.35079829098268495,
      "grad_norm": 0.515539288520813,
      "learning_rate": 4.9143903444964226e-05,
      "loss": 0.0797,
      "step": 390
    },
    {
      "epoch": 0.37778277490442996,
      "grad_norm": 0.6372978091239929,
      "learning_rate": 4.881137515345922e-05,
      "loss": 0.0961,
      "step": 420
    },
    {
      "epoch": 0.4047672588261749,
      "grad_norm": 0.9488064050674438,
      "learning_rate": 4.842592675737514e-05,
      "loss": 0.0881,
      "step": 450
    },
    {
      "epoch": 0.43175174274791994,
      "grad_norm": 0.39938610792160034,
      "learning_rate": 4.7988414904818166e-05,
      "loss": 0.0874,
      "step": 480
    },
    {
      "epoch": 0.45873622666966496,
      "grad_norm": 0.5610843896865845,
      "learning_rate": 4.7499811953446895e-05,
      "loss": 0.0803,
      "step": 510
    },
    {
      "epoch": 0.4857207105914099,
      "grad_norm": 0.3715599775314331,
      "learning_rate": 4.696120380943504e-05,
      "loss": 0.0813,
      "step": 540
    },
    {
      "epoch": 0.5127051945131549,
      "grad_norm": 1.1277124881744385,
      "learning_rate": 4.637378751407588e-05,
      "loss": 0.0788,
      "step": 570
    },
    {
      "epoch": 0.5396896784348999,
      "grad_norm": 1.2612636089324951,
      "learning_rate": 4.5738868583391966e-05,
      "loss": 0.0849,
      "step": 600
    },
    {
      "epoch": 0.5666741623566449,
      "grad_norm": 1.1022816896438599,
      "learning_rate": 4.505785810666289e-05,
      "loss": 0.0843,
      "step": 630
    },
    {
      "epoch": 0.5936586462783899,
      "grad_norm": 0.2205280214548111,
      "learning_rate": 4.433226961031941e-05,
      "loss": 0.0816,
      "step": 660
    },
    {
      "epoch": 0.620643130200135,
      "grad_norm": 0.6628361940383911,
      "learning_rate": 4.356371569417403e-05,
      "loss": 0.0855,
      "step": 690
    },
    {
      "epoch": 0.64762761412188,
      "grad_norm": 0.6543553471565247,
      "learning_rate": 4.275390444746373e-05,
      "loss": 0.0812,
      "step": 720
    },
    {
      "epoch": 0.6746120980436249,
      "grad_norm": 1.0228426456451416,
      "learning_rate": 4.190463565267015e-05,
      "loss": 0.0811,
      "step": 750
    },
    {
      "epoch": 0.7015965819653699,
      "grad_norm": 0.3314901292324066,
      "learning_rate": 4.101779678555422e-05,
      "loss": 0.0676,
      "step": 780
    },
    {
      "epoch": 0.7285810658871149,
      "grad_norm": 0.7169950604438782,
      "learning_rate": 4.012665884956571e-05,
      "loss": 0.069,
      "step": 810
    },
    {
      "epoch": 0.7555655498088599,
      "grad_norm": 0.4510868191719055,
      "learning_rate": 3.91717563490565e-05,
      "loss": 0.0787,
      "step": 840
    },
    {
      "epoch": 0.7825500337306049,
      "grad_norm": 0.5091550350189209,
      "learning_rate": 3.818535752281105e-05,
      "loss": 0.0707,
      "step": 870
    },
    {
      "epoch": 0.8095345176523498,
      "grad_norm": 0.7926889657974243,
      "learning_rate": 3.7169654614188054e-05,
      "loss": 0.0711,
      "step": 900
    },
    {
      "epoch": 0.8365190015740949,
      "grad_norm": 0.5789964199066162,
      "learning_rate": 3.61269049940365e-05,
      "loss": 0.0647,
      "step": 930
    },
    {
      "epoch": 0.8635034854958399,
      "grad_norm": 0.26526355743408203,
      "learning_rate": 3.505942614375309e-05,
      "loss": 0.0748,
      "step": 960
    },
    {
      "epoch": 0.8904879694175849,
      "grad_norm": 0.5995652675628662,
      "learning_rate": 3.396959050474573e-05,
      "loss": 0.0715,
      "step": 990
    },
    {
      "epoch": 0.9174724533393299,
      "grad_norm": 0.3072815239429474,
      "learning_rate": 3.285982020574987e-05,
      "loss": 0.0715,
      "step": 1020
    },
    {
      "epoch": 0.9444569372610749,
      "grad_norm": 0.49217188358306885,
      "learning_rate": 3.17325816797163e-05,
      "loss": 0.0757,
      "step": 1050
    },
    {
      "epoch": 0.9714414211828198,
      "grad_norm": 0.5809378623962402,
      "learning_rate": 3.059038018223394e-05,
      "loss": 0.0721,
      "step": 1080
    },
    {
      "epoch": 0.9984259051045649,
      "grad_norm": 0.4200283885002136,
      "learning_rate": 2.943575422367052e-05,
      "loss": 0.0651,
      "step": 1110
    },
    {
      "epoch": 1.0254103890263098,
      "grad_norm": 0.5852142572402954,
      "learning_rate": 2.8271269927405437e-05,
      "loss": 0.0549,
      "step": 1140
    },
    {
      "epoch": 1.0523948729480548,
      "grad_norm": 0.35770362615585327,
      "learning_rate": 2.7099515326693474e-05,
      "loss": 0.0513,
      "step": 1170
    },
    {
      "epoch": 1.0793793568697998,
      "grad_norm": 0.3801681101322174,
      "learning_rate": 2.5923094612834415e-05,
      "loss": 0.0545,
      "step": 1200
    },
    {
      "epoch": 1.1063638407915448,
      "grad_norm": 0.43186691403388977,
      "learning_rate": 2.4744622347431912e-05,
      "loss": 0.0614,
      "step": 1230
    },
    {
      "epoch": 1.1333483247132898,
      "grad_norm": 0.43165123462677,
      "learning_rate": 2.356671765160463e-05,
      "loss": 0.0587,
      "step": 1260
    },
    {
      "epoch": 1.1603328086350349,
      "grad_norm": 0.6558780074119568,
      "learning_rate": 2.2391998385063956e-05,
      "loss": 0.057,
      "step": 1290
    },
    {
      "epoch": 1.1873172925567799,
      "grad_norm": 0.4513818025588989,
      "learning_rate": 2.122307532799524e-05,
      "loss": 0.0637,
      "step": 1320
    },
    {
      "epoch": 1.2143017764785249,
      "grad_norm": 0.4267629086971283,
      "learning_rate": 2.006254637867299e-05,
      "loss": 0.0522,
      "step": 1350
    },
    {
      "epoch": 1.24128626040027,
      "grad_norm": 0.4409201443195343,
      "learning_rate": 1.8912990779705808e-05,
      "loss": 0.0548,
      "step": 1380
    },
    {
      "epoch": 1.268270744322015,
      "grad_norm": 0.882735013961792,
      "learning_rate": 1.7776963385742997e-05,
      "loss": 0.0526,
      "step": 1410
    },
    {
      "epoch": 1.29525522824376,
      "grad_norm": 0.5222133994102478,
      "learning_rate": 1.6656988985382664e-05,
      "loss": 0.0632,
      "step": 1440
    },
    {
      "epoch": 1.322239712165505,
      "grad_norm": 0.5239952802658081,
      "learning_rate": 1.555555668990088e-05,
      "loss": 0.058,
      "step": 1470
    },
    {
      "epoch": 1.3492241960872497,
      "grad_norm": 0.3649160861968994,
      "learning_rate": 1.4475114401272558e-05,
      "loss": 0.0547,
      "step": 1500
    },
    {
      "epoch": 1.3762086800089948,
      "grad_norm": 0.3837994337081909,
      "learning_rate": 1.3418063371778905e-05,
      "loss": 0.0591,
      "step": 1530
    },
    {
      "epoch": 1.4031931639307398,
      "grad_norm": 0.5819070935249329,
      "learning_rate": 1.2386752867292461e-05,
      "loss": 0.0526,
      "step": 1560
    },
    {
      "epoch": 1.4301776478524848,
      "grad_norm": 0.5367304086685181,
      "learning_rate": 1.1383474946100444e-05,
      "loss": 0.0589,
      "step": 1590
    },
    {
      "epoch": 1.4571621317742298,
      "grad_norm": 0.5693296194076538,
      "learning_rate": 1.04104593648704e-05,
      "loss": 0.0537,
      "step": 1620
    },
    {
      "epoch": 1.4841466156959748,
      "grad_norm": 0.7307138442993164,
      "learning_rate": 9.469868623079311e-06,
      "loss": 0.0512,
      "step": 1650
    },
    {
      "epoch": 1.5111310996177199,
      "grad_norm": 0.2594148516654968,
      "learning_rate": 8.563793156919997e-06,
      "loss": 0.0565,
      "step": 1680
    },
    {
      "epoch": 1.5381155835394646,
      "grad_norm": 0.6105325222015381,
      "learning_rate": 7.694246693366086e-06,
      "loss": 0.0565,
      "step": 1710
    },
    {
      "epoch": 1.5651000674612097,
      "grad_norm": 0.1505507379770279,
      "learning_rate": 6.86316177472103e-06,
      "loss": 0.0472,
      "step": 1740
    },
    {
      "epoch": 1.5920845513829547,
      "grad_norm": 0.35626640915870667,
      "learning_rate": 6.0723854635977935e-06,
      "loss": 0.0509,
      "step": 1770
    },
    {
      "epoch": 1.6190690353046997,
      "grad_norm": 0.5980235934257507,
      "learning_rate": 5.323675237874631e-06,
      "loss": 0.0563,
      "step": 1800
    },
    {
      "epoch": 1.6460535192264447,
      "grad_norm": 0.2964176535606384,
      "learning_rate": 4.618695084750493e-06,
      "loss": 0.055,
      "step": 1830
    },
    {
      "epoch": 1.6730380031481897,
      "grad_norm": 0.352651983499527,
      "learning_rate": 3.959011802580739e-06,
      "loss": 0.0535,
      "step": 1860
    },
    {
      "epoch": 1.7000224870699348,
      "grad_norm": 0.3046610653400421,
      "learning_rate": 3.346091518712352e-06,
      "loss": 0.0556,
      "step": 1890
    },
    {
      "epoch": 1.7270069709916798,
      "grad_norm": 0.4933980107307434,
      "learning_rate": 2.7812964310575396e-06,
      "loss": 0.0462,
      "step": 1920
    },
    {
      "epoch": 1.7539914549134248,
      "grad_norm": 0.6305911540985107,
      "learning_rate": 2.265881780647608e-06,
      "loss": 0.0466,
      "step": 1950
    },
    {
      "epoch": 1.7809759388351698,
      "grad_norm": 0.3252260982990265,
      "learning_rate": 1.8009930618954368e-06,
      "loss": 0.0573,
      "step": 1980
    },
    {
      "epoch": 1.8079604227569148,
      "grad_norm": 0.44059357047080994,
      "learning_rate": 1.3876634767666986e-06,
      "loss": 0.0531,
      "step": 2010
    },
    {
      "epoch": 1.8349449066786598,
      "grad_norm": 0.37190207839012146,
      "learning_rate": 1.0268116385178634e-06,
      "loss": 0.047,
      "step": 2040
    },
    {
      "epoch": 1.8619293906004049,
      "grad_norm": 0.6548238396644592,
      "learning_rate": 7.192395301043292e-07,
      "loss": 0.0573,
      "step": 2070
    },
    {
      "epoch": 1.8889138745221499,
      "grad_norm": 0.5580947995185852,
      "learning_rate": 4.6563072179609815e-07,
      "loss": 0.045,
      "step": 2100
    },
    {
      "epoch": 1.9158983584438949,
      "grad_norm": 0.5339930057525635,
      "learning_rate": 2.6654885196228663e-07,
      "loss": 0.0504,
      "step": 2130
    },
    {
      "epoch": 1.94288284236564,
      "grad_norm": 0.6082282662391663,
      "learning_rate": 1.2243637440085832e-07,
      "loss": 0.0511,
      "step": 2160
    },
    {
      "epoch": 1.9698673262873847,
      "grad_norm": 0.48580652475357056,
      "learning_rate": 3.361357499763462e-08,
      "loss": 0.0546,
      "step": 2190
    },
    {
      "epoch": 1.9968518102091297,
      "grad_norm": 0.7181969285011292,
      "learning_rate": 2.7785990002193727e-10,
      "loss": 0.0546,
      "step": 2220
    }
  ],
  "logging_steps": 30,
  "max_steps": 2222,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 15000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 4.82573768467415e+16,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
