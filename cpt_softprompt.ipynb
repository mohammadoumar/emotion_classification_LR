{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Dict, List, Union\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import Dataset\n",
    "from tqdm import tqdm\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    DataCollatorForLanguageModeling,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    ")\n",
    "\n",
    "from peft import CPTConfig, get_peft_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_INPUT_LENGTH = 1024\n",
    "MAX_ICL_SAMPLES = 10\n",
    "NUM_TRAINING_SAMPLES = 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_id = 'bigscience/bloom-1b7'\n",
    "model_id = 'unsloth/Llama-3.2-1B'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05597ede7ca04636a6e7065bb4522529",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/50.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f8640aa020f4367a000d3a63f579dcc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/17.2M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e682d286dadc47d094d2baa97413e008",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/459 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize the tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_id,               # The name or path of the pre-trained tokenizer (e.g., \"bert-base-uncased\").\n",
    "    cache_dir='.',          # Directory to cache the tokenizer files locally.\n",
    "    padding_side='right',   # Specifies that padding should be added to the right side of sequences.\n",
    "    trust_remote_code=True  # Allows loading tokenizer implementations from external sources.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset('glue', 'sst2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence': 'despite its dry wit and compassion , the film suffers from a philosophical emptiness and maddeningly sedate pacing . ',\n",
       " 'label': 0,\n",
       " 'idx': 1013}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][1013] # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_string_labels(example):\n",
    "    \"\"\"\n",
    "    Converts numerical labels into human-readable string labels.\n",
    "\n",
    "    Args:\n",
    "        example (dict): A single example from the dataset with a numerical 'label'.\n",
    "\n",
    "    Returns:\n",
    "        dict: The example augmented with a 'label_text' field.\n",
    "    \"\"\"\n",
    "    # Map numerical label to string label\n",
    "    example['label_text'] = \"positive\" if example['label'] == 1 else \"negative\"\n",
    "    return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_dataset = dataset['train'].select(range(MAX_ICL_SAMPLES)).map(add_string_labels)\n",
    "train_dataset = dataset['train'].select(range(MAX_ICL_SAMPLES, NUM_TRAINING_SAMPLES + MAX_ICL_SAMPLES)).map(add_string_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "quick_review = True # set to False for a comprehensive evaluation\n",
    "num_of_test_examples = 100 if quick_review else len(dataset['validation'])\n",
    "# Subset and process the validation dataset\n",
    "test_dataset = dataset['validation'].select(range(num_of_test_examples)).map(add_string_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CPTDataset(Dataset):\n",
    "    def __init__(self, samples, tokenizer, template, max_length=MAX_INPUT_LENGTH):\n",
    "        \"\"\"\n",
    "        Initialize the CPTDataset with samples, a tokenizer, and a template.\n",
    "\n",
    "        Args:\n",
    "            samples (list): List of samples containing input sentences and labels.\n",
    "            tokenizer: Tokenizer instance for encoding text.\n",
    "            template (dict): Dictionary defining input/output templates and separators.\n",
    "            max_length (int): Maximum input length for truncation.\n",
    "        \"\"\"\n",
    "        self.template = template\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "        # Storage for tokenized inputs and masks\n",
    "        self.attention_mask = []\n",
    "        self.input_ids = []\n",
    "        self.input_type_mask = []\n",
    "        self.inter_seperator_ids = self._get_input_ids(template['inter_seperator'])\n",
    "\n",
    "        # Tokenize each sample and prepare inputs\n",
    "        for sample_i in tqdm(samples):\n",
    "            input_text, label = sample_i['sentence'], sample_i['label_text']\n",
    "            input_ids, attention_mask, input_type_mask = self.preprocess_sentence(input_text, label)\n",
    "\n",
    "            self.input_ids.append(input_ids)\n",
    "            self.attention_mask.append(attention_mask)\n",
    "            self.input_type_mask.append(input_type_mask)\n",
    "\n",
    "\n",
    "    def _get_input_ids(self, text):\n",
    "        \"\"\"\n",
    "        Tokenize the given text into input IDs.\n",
    "\n",
    "        Args:\n",
    "            text (str): The text to tokenize.\n",
    "\n",
    "        Returns:\n",
    "            list: Tokenized input IDs.\n",
    "        \"\"\"\n",
    "        return self.tokenizer(text, add_special_tokens=False)[\"input_ids\"]\n",
    "\n",
    "\n",
    "    def preprocess_sentence(self, input_text, label):\n",
    "        \"\"\"\n",
    "        Preprocess a sentence and its corresponding label using templates.\n",
    "\n",
    "        Args:\n",
    "            input_text (str): The input sentence.\n",
    "            label (str): The label text (e.g., \"positive\", \"negative\").\n",
    "\n",
    "        Returns:\n",
    "            tuple: (input_ids, attention_mask, input_type_mask)\n",
    "        \"\"\"\n",
    "\n",
    "        # Split input template into parts\n",
    "        input_template_part_1_text, input_template_part_2_text = self.template['input'].split('{}')\n",
    "        input_template_tokenized_part1 = self._get_input_ids(input_template_part_1_text)\n",
    "        input_tokenized = self._get_input_ids(input_text)\n",
    "        input_template_tokenized_part2 = self._get_input_ids(input_template_part_2_text)\n",
    "\n",
    "        # Separator token\n",
    "        sep_tokenized = self._get_input_ids(self.template['intra_seperator'])\n",
    "\n",
    "        # Process the label using the template\n",
    "        label_template_part_1, label_template_part_2 = self.template['output'].split('{}')\n",
    "        label_template_part1_tokenized = self._get_input_ids(label_template_part_1)\n",
    "        label_tokenized = self._get_input_ids(label)\n",
    "        label_template_part2_tokenized = self._get_input_ids(label_template_part_2)\n",
    "\n",
    "        # End-of-sequence token\n",
    "        eos = [self.tokenizer.eos_token_id] if self.tokenizer.eos_token_id is not None else []\n",
    "\n",
    "        # Concatenate all tokenized parts\n",
    "        input_ids = input_template_tokenized_part1 + input_tokenized + input_template_tokenized_part2 + sep_tokenized + label_template_part1_tokenized + label_tokenized + label_template_part2_tokenized + eos\n",
    "\n",
    "        # Generate attention and type masks\n",
    "        attention_mask = [1] * len(input_ids)\n",
    "        input_type_mask = [1] * len(input_template_tokenized_part1) + [2] * len(input_tokenized) + [1] * len(\n",
    "            input_template_tokenized_part2) + [0] * len(sep_tokenized) + \\\n",
    "                          [3] * len(label_template_part1_tokenized) + [4] * len(label_tokenized) + [3] * len( \\\n",
    "            label_template_part2_tokenized) + [0] * len(eos)\n",
    "\n",
    "        # Ensure all masks and inputs are the same length\n",
    "        assert len(input_type_mask) == len(input_ids) == len(attention_mask)\n",
    "\n",
    "        return input_ids, attention_mask, input_type_mask\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Get the number of examples in the dataset.\n",
    "\n",
    "        Returns:\n",
    "            int: Number of examples.\n",
    "        \"\"\"\n",
    "        return len(self.input_ids)\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Get the tokenized representation for the given index.\n",
    "\n",
    "        Args:\n",
    "            idx (int): Index of the example.\n",
    "\n",
    "        Returns:\n",
    "            dict: Tokenized inputs with attention and type masks.\n",
    "        \"\"\"\n",
    "\n",
    "        return {\n",
    "            \"input_ids\": self.input_ids[idx],\n",
    "            \"attention_mask\": self.attention_mask[idx],\n",
    "            \"input_type_mask\": self.input_type_mask[idx]\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "templates = {\n",
    "    'input': 'input: {}',     # Input template with placeholder\n",
    "    'intra_seperator': ' ',   # Separator between input and output\n",
    "    'output': 'output: {}',   # Output template with placeholder\n",
    "    'inter_seperator': '\\n'   # Separator between examples\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 2196.59it/s]\n"
     ]
    }
   ],
   "source": [
    "cpt_train_dataset = CPTDataset(train_dataset, tokenizer, templates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 1045.94it/s]\n"
     ]
    }
   ],
   "source": [
    "context_ids = []                # Concatenated input IDs for all samples\n",
    "context_attention_mask = []     # Concatenated attention masks\n",
    "context_input_type_mask = []    # Concatenated input type masks\n",
    "first_type_mask = 0             # Initial offset for input type mask\n",
    "\n",
    "cpt_context_dataset = CPTDataset(context_dataset, tokenizer, templates)\n",
    "\n",
    "# Iterate through the CPT training dataset\n",
    "for i in range(len(context_dataset)):\n",
    "    # Add input IDs to the context\n",
    "    context_ids += cpt_context_dataset[i]['input_ids']\n",
    "\n",
    "    # Add attention mask to the context\n",
    "    context_attention_mask += cpt_context_dataset[i]['attention_mask']\n",
    "\n",
    "    # Adjust and add the input type mask to the context\n",
    "    context_input_type_mask += [\n",
    "        i + first_type_mask if i > 0 else 0 # Increment type indices dynamically\n",
    "        for i in cpt_context_dataset[i]['input_type_mask']\n",
    "        ]\n",
    "\n",
    "    # Increment the type mask offset after processing the sample\n",
    "    first_type_mask += 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cpt_train_dataset.input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cpt_context_dataset.input_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a12aafea0d8442d93926e8dfd19f541",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/935 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "352845e048b245eda34bd216b842e223",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/2.47G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4804298bc3af4d8caafbf10999ed525f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/230 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load a pre-trained causal language model\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    cache_dir='.',\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map='auto'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the CPT configuration\n",
    "config = CPTConfig(\n",
    "            cpt_token_ids=context_ids,\n",
    "            cpt_mask=context_attention_mask,\n",
    "            cpt_tokens_type_mask=context_input_type_mask,\n",
    "\n",
    "            opt_weighted_loss_type='decay',\n",
    "            opt_loss_decay_factor=0.95,         # we choose the exponential decay factor applied to the loss\n",
    "            opt_projection_epsilon=0.2,         # we choose the projection over the input tokens\n",
    "            opt_projection_format_epsilon=0.1,  # we choose the projection over input and output templates\n",
    "\n",
    "            tokenizer_name_or_path=model_id,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1379"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_ids[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the CPT model with PEFT\n",
    "model = get_peft_model(base_model, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CPTDataCollatorForLanguageModeling(DataCollatorForLanguageModeling):\n",
    "    def __init__(self, tokenizer, training=True, mlm=False):\n",
    "        \"\"\"\n",
    "        Custom collator for CPT-style language modeling.\n",
    "\n",
    "        Args:\n",
    "            tokenizer: The tokenizer to handle tokenization and special tokens.\n",
    "            training (bool): If True, operates in training mode; otherwise in evaluation mode.\n",
    "            mlm (bool): If True, enables masked language modeling.\n",
    "        \"\"\"\n",
    "\n",
    "        super().__init__(tokenizer, mlm=mlm) # Initialize the parent class\n",
    "        self.training = training\n",
    "\n",
    "        # Add a special padding token if not already defined\n",
    "        self.tokenizer.add_special_tokens({\"pad_token\": \"[PAD]\"})\n",
    "\n",
    "    def torch_call(self, examples: List[Union[List[int], Any, Dict[str, Any]]]) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Process a batch of examples for language modeling.\n",
    "\n",
    "        Args:\n",
    "            examples (List): A batch of examples with tokenized inputs and optional sample masks.\n",
    "\n",
    "        Returns:\n",
    "            Dict: A dictionary containing padded and tensor-converted inputs, attention masks,\n",
    "                  input type masks, and optional sample masks and labels.\n",
    "        \"\"\"\n",
    "\n",
    "        # Initialize a list to collect sample masks if provided\n",
    "        list_sample_mask = []\n",
    "        for i in range(len(examples)):\n",
    "            if \"sample_mask\" in examples[i].keys():\n",
    "                list_sample_mask.append(examples[i].pop(\"sample_mask\"))\n",
    "\n",
    "        # Define a helper function for padding sequences to the maximum length\n",
    "        max_len = max(len(ex[\"input_ids\"]) for ex in examples)\n",
    "\n",
    "        # Define a helper function for padding sequences to the maximum length\n",
    "        def pad_sequence(sequence, max_len, pad_value=0):\n",
    "            return sequence + [pad_value] * (max_len - len(sequence))\n",
    "\n",
    "        # Pad and convert `input_ids`, `attention_mask`, and `input_type_mask` to tensors\n",
    "        input_ids = torch.tensor([pad_sequence(ex[\"input_ids\"], max_len) for ex in examples])\n",
    "        attention_mask = torch.tensor([pad_sequence(ex[\"attention_mask\"], max_len) for ex in examples])\n",
    "        input_type_mask = torch.tensor([pad_sequence(ex[\"input_type_mask\"], max_len) for ex in examples])\n",
    "\n",
    "        # Create the initial batch dictionary\n",
    "        batch = {\"input_ids\": input_ids, \"attention_mask\": attention_mask, \"input_type_mask\": input_type_mask}\n",
    "\n",
    "        # Create a tensor to store sample masks\n",
    "        tensor_sample_mask = batch[\"input_ids\"].clone().long()\n",
    "        tensor_sample_mask[:, :] = 0 # Initialize with zeros\n",
    "\n",
    "        # Populate the tensor with the provided sample masks\n",
    "        for i in range(len(list_sample_mask)):\n",
    "            tensor_sample_mask[i, : len(list_sample_mask[i])] = list_sample_mask[i]\n",
    "\n",
    "        # Copy `input_ids` to use as `labels`\n",
    "        batch[\"labels\"] = batch[\"input_ids\"].clone()\n",
    "\n",
    "        # If in evaluation mode, include the `sample_mask` in the batch\n",
    "        if not self.training:\n",
    "            batch[\"sample_mask\"] = tensor_sample_mask\n",
    "\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='../.',\n",
    "    use_cpu=False,\n",
    "    auto_find_batch_size=False,\n",
    "    learning_rate=1e-4,\n",
    "    logging_steps=100,\n",
    "    per_device_train_batch_size=1,\n",
    "    save_total_limit=1,\n",
    "    remove_unused_columns=False,\n",
    "    num_train_epochs=5,\n",
    "    fp16=True,\n",
    "    save_strategy='no',\n",
    "    logging_dir=\"logs\",\n",
    "    report_to=\"none\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=cpt_train_dataset,  # Custom CPT training dataset.\n",
    "    data_collator=CPTDataCollatorForLanguageModeling(tokenizer, training=True, mlm=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='500' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [500/500 00:41, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.153800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.013000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.006700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.002700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=500, training_loss=0.03526093910261989, metrics={'train_runtime': 42.065, 'train_samples_per_second': 11.886, 'train_steps_per_second': 11.886, 'total_flos': 63497783808000.0, 'train_loss': 0.03526093910261989, 'epoch': 5.0})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence': \"it 's a charming and often affecting journey . \",\n",
       " 'label': 1,\n",
       " 'idx': 0,\n",
       " 'label_text': 'positive'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForCausalLM(\n",
       "  (base_model): LlamaForCausalLM(\n",
       "    (model): LlamaModel(\n",
       "      (embed_tokens): Embedding(128256, 2048, padding_idx=128004)\n",
       "      (layers): ModuleList(\n",
       "        (0-15): 16 x LlamaDecoderLayer(\n",
       "          (self_attn): LlamaSdpaAttention(\n",
       "            (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            (k_proj): Linear(in_features=2048, out_features=512, bias=False)\n",
       "            (v_proj): Linear(in_features=2048, out_features=512, bias=False)\n",
       "            (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            (rotary_emb): LlamaRotaryEmbedding()\n",
       "          )\n",
       "          (mlp): LlamaMLP(\n",
       "            (gate_proj): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "            (up_proj): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "            (down_proj): Linear(in_features=8192, out_features=2048, bias=False)\n",
       "            (act_fn): SiLU()\n",
       "          )\n",
       "          (input_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "          (post_attention_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "        )\n",
       "      )\n",
       "      (norm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "      (rotary_emb): LlamaRotaryEmbedding()\n",
       "    )\n",
       "    (lm_head): Linear(in_features=2048, out_features=128256, bias=False)\n",
       "  )\n",
       "  (prompt_encoder): ModuleDict(\n",
       "    (default): CPTEmbedding(\n",
       "      (embedding): Embedding(223, 2048)\n",
       "      (delta_embedding): Embedding(223, 2048)\n",
       "    )\n",
       "  )\n",
       "  (word_embeddings): Embedding(128256, 2048, padding_idx=128004)\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 1274.60it/s]\n"
     ]
    }
   ],
   "source": [
    "test_dataset = test_dataset.select_columns(['sentence', 'label_text'])\n",
    "\n",
    "# Convert the test dataset to a CPT-compatible format\n",
    "cpt_test_dataset = CPTDataset(test_dataset, tokenizer, templates)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"input: it's a charming and often affecting journey.  output: positive<|end_of_text|>\""
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(cpt_test_dataset[0]['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the device where the model is loaded (CPU or GPU)\n",
    "device = model.device\n",
    "list_bool_predictions = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]/Utilisateurs/umushtaq/.conda/envs/triton_env/lib/python3.10/site-packages/peft/peft_model.py:1889: UserWarning: Position ids are not supported for parameter efficient tuning. Ignoring position ids.\n",
      "  warnings.warn(\"Position ids are not supported for parameter efficient tuning. Ignoring position ids.\")\n",
      "  0%|          | 0/100 [00:01<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(len(test_dataset))):\n",
    "    input_ids, input_type_mask = cpt_test_dataset[i]['input_ids'], cpt_test_dataset[i]['input_type_mask']\n",
    "\n",
    "    # Pass the inputs through the model\n",
    "    outputs = model.generate(\n",
    "        input_ids=torch.Tensor(input_ids).long().to(device=device).view(1, -1),\n",
    "        #labels=torch.Tensor(input_ids).long().to(device=device).view(1, -1),\n",
    "        #return_dict_in_generate=True,\n",
    "        #input_type_mask=torch.Tensor(input_type_mask).long().to(device=device).view(1, -1)\n",
    "    )\n",
    "    break\n",
    "    #op = outputs[0][]\n",
    "#     # Shift logits to exclude the last token and match the labels\n",
    "#     shifted_logits = outputs.logits[..., :-1, :].contiguous().to(model.dtype)[0, -len(input_ids) + 1:]\n",
    "#     shift_labels = torch.Tensor(input_ids).long().to(device=device).view(1, -1)[0, 1:].contiguous().to(device)\n",
    "#     shifted_input_type_mask = torch.Tensor(input_type_mask).long().to(device=device).view(1, -1)[..., 1:].contiguous().to(device)\n",
    "\n",
    "#     # Create a mask for the type `4` tokens (label tokens)\n",
    "#     mask = torch.Tensor(shifted_input_type_mask).long().to(device=device).view(-1,) == 4\n",
    "\n",
    "#     # Extract logits and labels corresponding to the mask\n",
    "#     logit = shifted_logits[mask]\n",
    "#     label = shift_labels[mask]\n",
    "\n",
    "#     # All possible label tokens for `negative` and `positive`\n",
    "#     all_labels = torch.Tensor([tokenizer(i, add_special_tokens=False)[\"input_ids\"] for i in ['negative', 'positive']]).long().to(device).view(-1,)\n",
    "\n",
    "#     # Compare logits with label tokens and infer prediction\n",
    "#     prediction = logit[0, torch.Tensor([tokenizer(i, add_special_tokens=False)[\"input_ids\"] for i in ['negative', 'positive']]).long().to(device).view(-1,)].argmax()\n",
    "#     prediction_text = 'negative' if prediction == 0 else 'positive'\n",
    "#     print(f\"Sentence: {tokenizer.decode(input_ids)} \\n \\t The prediction is: {prediction_text}\\n \\t The GT is {tokenizer.decode(label)}\")\n",
    "#     list_bool_predictions.append(prediction_text == tokenizer.decode(label))\n",
    "\n",
    "# print(f'The model Acc is {100 * np.mean(list_bool_predictions)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp = torch.Tensor(input_ids).long().to(device=device).view(1, -1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "op = outputs[0][sp[1]:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def: is a moving and engaging film that is also a reminder of the power of the human spirit.  output: positive  1\\n4.5/5  1 vote\\n1 vote ( 0.00% )'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(op, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (triton_env2)",
   "language": "python",
   "name": "triton_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
