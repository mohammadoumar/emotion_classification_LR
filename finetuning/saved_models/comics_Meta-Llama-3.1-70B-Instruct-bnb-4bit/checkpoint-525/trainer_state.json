{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 2.995720399429387,
  "eval_steps": 500,
  "global_step": 525,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.05706134094151213,
      "grad_norm": 1.1505547761917114,
      "learning_rate": 8.49056603773585e-06,
      "loss": 1.8096,
      "step": 10
    },
    {
      "epoch": 0.11412268188302425,
      "grad_norm": 0.7201175689697266,
      "learning_rate": 1.6037735849056604e-05,
      "loss": 0.8403,
      "step": 20
    },
    {
      "epoch": 0.17118402282453637,
      "grad_norm": 0.1079355925321579,
      "learning_rate": 2.547169811320755e-05,
      "loss": 0.3015,
      "step": 30
    },
    {
      "epoch": 0.2282453637660485,
      "grad_norm": 0.38095882534980774,
      "learning_rate": 3.490566037735849e-05,
      "loss": 0.287,
      "step": 40
    },
    {
      "epoch": 0.28530670470756064,
      "grad_norm": 0.6893713474273682,
      "learning_rate": 4.433962264150944e-05,
      "loss": 0.278,
      "step": 50
    },
    {
      "epoch": 0.34236804564907275,
      "grad_norm": 0.3055873215198517,
      "learning_rate": 4.9991140278086316e-05,
      "loss": 0.225,
      "step": 60
    },
    {
      "epoch": 0.39942938659058486,
      "grad_norm": 0.3216412365436554,
      "learning_rate": 4.989154050948159e-05,
      "loss": 0.2246,
      "step": 70
    },
    {
      "epoch": 0.456490727532097,
      "grad_norm": 0.4017031788825989,
      "learning_rate": 4.9681708868033616e-05,
      "loss": 0.226,
      "step": 80
    },
    {
      "epoch": 0.5135520684736091,
      "grad_norm": 0.5922845005989075,
      "learning_rate": 4.936257459051703e-05,
      "loss": 0.1903,
      "step": 90
    },
    {
      "epoch": 0.5706134094151213,
      "grad_norm": 0.1110646054148674,
      "learning_rate": 4.893555095905014e-05,
      "loss": 0.1861,
      "step": 100
    },
    {
      "epoch": 0.6276747503566333,
      "grad_norm": 0.09433288872241974,
      "learning_rate": 4.840252904239291e-05,
      "loss": 0.1914,
      "step": 110
    },
    {
      "epoch": 0.6847360912981455,
      "grad_norm": 0.10213392972946167,
      "learning_rate": 4.7765869321372836e-05,
      "loss": 0.193,
      "step": 120
    },
    {
      "epoch": 0.7417974322396577,
      "grad_norm": 0.08030399680137634,
      "learning_rate": 4.702839123552541e-05,
      "loss": 0.1974,
      "step": 130
    },
    {
      "epoch": 0.7988587731811697,
      "grad_norm": 0.07044149935245514,
      "learning_rate": 4.619336069724177e-05,
      "loss": 0.1848,
      "step": 140
    },
    {
      "epoch": 0.8559201141226819,
      "grad_norm": 0.07485464960336685,
      "learning_rate": 4.526447562871685e-05,
      "loss": 0.1746,
      "step": 150
    },
    {
      "epoch": 0.912981455064194,
      "grad_norm": 0.06979012489318848,
      "learning_rate": 4.4245849585747654e-05,
      "loss": 0.1974,
      "step": 160
    },
    {
      "epoch": 0.9700427960057061,
      "grad_norm": 0.0758080929517746,
      "learning_rate": 4.3141993540903404e-05,
      "loss": 0.1806,
      "step": 170
    },
    {
      "epoch": 1.0271041369472182,
      "grad_norm": 0.07271190732717514,
      "learning_rate": 4.195779590674041e-05,
      "loss": 0.1793,
      "step": 180
    },
    {
      "epoch": 1.0841654778887304,
      "grad_norm": 0.08218276500701904,
      "learning_rate": 4.06985008875288e-05,
      "loss": 0.1761,
      "step": 190
    },
    {
      "epoch": 1.1412268188302426,
      "grad_norm": 0.07780362665653229,
      "learning_rate": 3.9369685255360175e-05,
      "loss": 0.1621,
      "step": 200
    },
    {
      "epoch": 1.1982881597717547,
      "grad_norm": 0.41923025250434875,
      "learning_rate": 3.797723365348277e-05,
      "loss": 0.1728,
      "step": 210
    },
    {
      "epoch": 1.2553495007132667,
      "grad_norm": 0.08786539733409882,
      "learning_rate": 3.652731253623315e-05,
      "loss": 0.1722,
      "step": 220
    },
    {
      "epoch": 1.3124108416547788,
      "grad_norm": 0.10088428854942322,
      "learning_rate": 3.502634286097104e-05,
      "loss": 0.1646,
      "step": 230
    },
    {
      "epoch": 1.369472182596291,
      "grad_norm": 0.08079518377780914,
      "learning_rate": 3.348097165295076e-05,
      "loss": 0.1683,
      "step": 240
    },
    {
      "epoch": 1.4265335235378032,
      "grad_norm": 0.07874120771884918,
      "learning_rate": 3.189804256905376e-05,
      "loss": 0.1712,
      "step": 250
    },
    {
      "epoch": 1.4835948644793153,
      "grad_norm": 0.09507238119840622,
      "learning_rate": 3.028456559074061e-05,
      "loss": 0.1732,
      "step": 260
    },
    {
      "epoch": 1.5406562054208273,
      "grad_norm": 0.08887669444084167,
      "learning_rate": 2.8647685980436546e-05,
      "loss": 0.1714,
      "step": 270
    },
    {
      "epoch": 1.5977175463623396,
      "grad_norm": 0.06973676383495331,
      "learning_rate": 2.6994652638827078e-05,
      "loss": 0.1716,
      "step": 280
    },
    {
      "epoch": 1.6547788873038516,
      "grad_norm": 0.09387003630399704,
      "learning_rate": 2.5332786003192847e-05,
      "loss": 0.1615,
      "step": 290
    },
    {
      "epoch": 1.7118402282453637,
      "grad_norm": 0.08272556960582733,
      "learning_rate": 2.3669445628945542e-05,
      "loss": 0.1506,
      "step": 300
    },
    {
      "epoch": 1.768901569186876,
      "grad_norm": 0.09986572712659836,
      "learning_rate": 2.201199759792966e-05,
      "loss": 0.16,
      "step": 310
    },
    {
      "epoch": 1.825962910128388,
      "grad_norm": 0.08365921676158905,
      "learning_rate": 2.0367781897822147e-05,
      "loss": 0.156,
      "step": 320
    },
    {
      "epoch": 1.8830242510699002,
      "grad_norm": 0.06702122092247009,
      "learning_rate": 1.874407991708957e-05,
      "loss": 0.155,
      "step": 330
    },
    {
      "epoch": 1.9400855920114122,
      "grad_norm": 0.08734013885259628,
      "learning_rate": 1.714808219945129e-05,
      "loss": 0.1811,
      "step": 340
    },
    {
      "epoch": 1.9971469329529246,
      "grad_norm": 0.093082495033741,
      "learning_rate": 1.5586856600647344e-05,
      "loss": 0.1712,
      "step": 350
    },
    {
      "epoch": 2.0542082738944365,
      "grad_norm": 0.10089126229286194,
      "learning_rate": 1.4067316988528617e-05,
      "loss": 0.1389,
      "step": 360
    },
    {
      "epoch": 2.1112696148359484,
      "grad_norm": 0.09956837445497513,
      "learning_rate": 1.2596192625080294e-05,
      "loss": 0.1343,
      "step": 370
    },
    {
      "epoch": 2.168330955777461,
      "grad_norm": 0.1341128647327423,
      "learning_rate": 1.1179998365970174e-05,
      "loss": 0.1191,
      "step": 380
    },
    {
      "epoch": 2.2253922967189728,
      "grad_norm": 0.09637553244829178,
      "learning_rate": 9.825005809592563e-06,
      "loss": 0.1196,
      "step": 390
    },
    {
      "epoch": 2.282453637660485,
      "grad_norm": 0.0970500186085701,
      "learning_rate": 8.537215523374038e-06,
      "loss": 0.1275,
      "step": 400
    },
    {
      "epoch": 2.339514978601997,
      "grad_norm": 0.12120728939771652,
      "learning_rate": 7.3223304703363135e-06,
      "loss": 0.1227,
      "step": 410
    },
    {
      "epoch": 2.3965763195435095,
      "grad_norm": 0.10020092129707336,
      "learning_rate": 6.185730753596539e-06,
      "loss": 0.1266,
      "step": 420
    },
    {
      "epoch": 2.4536376604850214,
      "grad_norm": 0.1097460463643074,
      "learning_rate": 5.132449790648561e-06,
      "loss": 0.1324,
      "step": 430
    },
    {
      "epoch": 2.5106990014265333,
      "grad_norm": 0.10414333641529083,
      "learning_rate": 4.167152022937124e-06,
      "loss": 0.1161,
      "step": 440
    },
    {
      "epoch": 2.5677603423680457,
      "grad_norm": 0.1323663741350174,
      "learning_rate": 3.2941122594378233e-06,
      "loss": 0.1269,
      "step": 450
    },
    {
      "epoch": 2.6248216833095577,
      "grad_norm": 0.12339778244495392,
      "learning_rate": 2.5171967457195216e-06,
      "loss": 0.1242,
      "step": 460
    },
    {
      "epoch": 2.68188302425107,
      "grad_norm": 0.1138586476445198,
      "learning_rate": 1.839846042324686e-06,
      "loss": 0.1188,
      "step": 470
    },
    {
      "epoch": 2.738944365192582,
      "grad_norm": 0.11134086549282074,
      "learning_rate": 1.265059788290468e-06,
      "loss": 0.1145,
      "step": 480
    },
    {
      "epoch": 2.7960057061340944,
      "grad_norm": 0.11431384086608887,
      "learning_rate": 7.953834172850865e-07,
      "loss": 0.1167,
      "step": 490
    },
    {
      "epoch": 2.8530670470756063,
      "grad_norm": 0.13286349177360535,
      "learning_rate": 4.328968851869758e-07,
      "loss": 0.1161,
      "step": 500
    },
    {
      "epoch": 2.9101283880171183,
      "grad_norm": 0.12765681743621826,
      "learning_rate": 1.7920545902646024e-07,
      "loss": 0.1198,
      "step": 510
    },
    {
      "epoch": 2.9671897289586306,
      "grad_norm": 0.12953640520572662,
      "learning_rate": 3.543260808095139e-08,
      "loss": 0.1168,
      "step": 520
    }
  ],
  "logging_steps": 10,
  "max_steps": 525,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 5000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 8.70681425643307e+17,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
