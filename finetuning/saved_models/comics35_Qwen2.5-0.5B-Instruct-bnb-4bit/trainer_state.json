{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.9977020298736117,
  "eval_steps": 500,
  "global_step": 1304,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.015319800842589047,
      "grad_norm": 2.2066116333007812,
      "learning_rate": 3.816793893129772e-06,
      "loss": 0.436,
      "step": 10
    },
    {
      "epoch": 0.030639601685178094,
      "grad_norm": 2.1498095989227295,
      "learning_rate": 7.633587786259543e-06,
      "loss": 0.2879,
      "step": 20
    },
    {
      "epoch": 0.04595940252776714,
      "grad_norm": 1.3509398698806763,
      "learning_rate": 1.1450381679389314e-05,
      "loss": 0.2788,
      "step": 30
    },
    {
      "epoch": 0.06127920337035619,
      "grad_norm": 1.0903778076171875,
      "learning_rate": 1.5267175572519086e-05,
      "loss": 0.2882,
      "step": 40
    },
    {
      "epoch": 0.07659900421294523,
      "grad_norm": 1.9011822938919067,
      "learning_rate": 1.9083969465648855e-05,
      "loss": 0.2469,
      "step": 50
    },
    {
      "epoch": 0.09191880505553428,
      "grad_norm": 2.2863104343414307,
      "learning_rate": 2.2900763358778628e-05,
      "loss": 0.2604,
      "step": 60
    },
    {
      "epoch": 0.10723860589812333,
      "grad_norm": 1.3992270231246948,
      "learning_rate": 2.6717557251908397e-05,
      "loss": 0.2588,
      "step": 70
    },
    {
      "epoch": 0.12255840674071238,
      "grad_norm": 1.4293687343597412,
      "learning_rate": 3.053435114503817e-05,
      "loss": 0.2628,
      "step": 80
    },
    {
      "epoch": 0.1378782075833014,
      "grad_norm": 0.6929889917373657,
      "learning_rate": 3.435114503816794e-05,
      "loss": 0.2781,
      "step": 90
    },
    {
      "epoch": 0.15319800842589046,
      "grad_norm": 0.5961660146713257,
      "learning_rate": 3.816793893129771e-05,
      "loss": 0.2232,
      "step": 100
    },
    {
      "epoch": 0.1685178092684795,
      "grad_norm": 1.4145915508270264,
      "learning_rate": 4.198473282442748e-05,
      "loss": 0.2453,
      "step": 110
    },
    {
      "epoch": 0.18383761011106856,
      "grad_norm": 1.2504384517669678,
      "learning_rate": 4.5801526717557256e-05,
      "loss": 0.2436,
      "step": 120
    },
    {
      "epoch": 0.1991574109536576,
      "grad_norm": 0.8963958024978638,
      "learning_rate": 4.9618320610687025e-05,
      "loss": 0.2566,
      "step": 130
    },
    {
      "epoch": 0.21447721179624665,
      "grad_norm": 0.7200674414634705,
      "learning_rate": 4.999273764080493e-05,
      "loss": 0.2601,
      "step": 140
    },
    {
      "epoch": 0.2297970126388357,
      "grad_norm": 0.9283108711242676,
      "learning_rate": 4.996763860622537e-05,
      "loss": 0.2414,
      "step": 150
    },
    {
      "epoch": 0.24511681348142475,
      "grad_norm": 0.5899554491043091,
      "learning_rate": 4.992463123579936e-05,
      "loss": 0.239,
      "step": 160
    },
    {
      "epoch": 0.26043661432401377,
      "grad_norm": 0.888896107673645,
      "learning_rate": 4.986374637707503e-05,
      "loss": 0.2337,
      "step": 170
    },
    {
      "epoch": 0.2757564151666028,
      "grad_norm": 1.6849184036254883,
      "learning_rate": 4.978502770044167e-05,
      "loss": 0.2567,
      "step": 180
    },
    {
      "epoch": 0.29107621600919187,
      "grad_norm": 0.7959105968475342,
      "learning_rate": 4.968853166780668e-05,
      "loss": 0.2333,
      "step": 190
    },
    {
      "epoch": 0.3063960168517809,
      "grad_norm": 0.821090817451477,
      "learning_rate": 4.957432749209755e-05,
      "loss": 0.2214,
      "step": 200
    },
    {
      "epoch": 0.32171581769436997,
      "grad_norm": 1.2597343921661377,
      "learning_rate": 4.944249708761804e-05,
      "loss": 0.2382,
      "step": 210
    },
    {
      "epoch": 0.337035618536959,
      "grad_norm": 1.011619210243225,
      "learning_rate": 4.929313501129427e-05,
      "loss": 0.229,
      "step": 220
    },
    {
      "epoch": 0.35235541937954806,
      "grad_norm": 0.6701900959014893,
      "learning_rate": 4.912634839485251e-05,
      "loss": 0.2297,
      "step": 230
    },
    {
      "epoch": 0.3676752202221371,
      "grad_norm": 1.0872317552566528,
      "learning_rate": 4.8942256867977775e-05,
      "loss": 0.2228,
      "step": 240
    },
    {
      "epoch": 0.38299502106472616,
      "grad_norm": 0.5026569962501526,
      "learning_rate": 4.874099247250798e-05,
      "loss": 0.2514,
      "step": 250
    },
    {
      "epoch": 0.3983148219073152,
      "grad_norm": 0.6643242835998535,
      "learning_rate": 4.8522699567725364e-05,
      "loss": 0.2255,
      "step": 260
    },
    {
      "epoch": 0.41363462274990426,
      "grad_norm": 0.7108950614929199,
      "learning_rate": 4.828753472681302e-05,
      "loss": 0.2314,
      "step": 270
    },
    {
      "epoch": 0.4289544235924933,
      "grad_norm": 0.7815048098564148,
      "learning_rate": 4.803566662455102e-05,
      "loss": 0.2134,
      "step": 280
    },
    {
      "epoch": 0.44427422443508235,
      "grad_norm": 1.032492756843567,
      "learning_rate": 4.7767275916332356e-05,
      "loss": 0.2105,
      "step": 290
    },
    {
      "epoch": 0.4595940252776714,
      "grad_norm": 1.2595208883285522,
      "learning_rate": 4.74825551085857e-05,
      "loss": 0.2126,
      "step": 300
    },
    {
      "epoch": 0.47491382612026045,
      "grad_norm": 0.7588241696357727,
      "learning_rate": 4.7181708420697925e-05,
      "loss": 0.2235,
      "step": 310
    },
    {
      "epoch": 0.4902336269628495,
      "grad_norm": 0.6167949438095093,
      "learning_rate": 4.6864951638535285e-05,
      "loss": 0.2101,
      "step": 320
    },
    {
      "epoch": 0.5055534278054385,
      "grad_norm": 0.7716192007064819,
      "learning_rate": 4.653251195966843e-05,
      "loss": 0.2159,
      "step": 330
    },
    {
      "epoch": 0.5208732286480275,
      "grad_norm": 1.0145760774612427,
      "learning_rate": 4.618462783041231e-05,
      "loss": 0.2108,
      "step": 340
    },
    {
      "epoch": 0.5361930294906166,
      "grad_norm": 0.5993781089782715,
      "learning_rate": 4.582154877479761e-05,
      "loss": 0.23,
      "step": 350
    },
    {
      "epoch": 0.5515128303332056,
      "grad_norm": 1.0606889724731445,
      "learning_rate": 4.544353521559677e-05,
      "loss": 0.2251,
      "step": 360
    },
    {
      "epoch": 0.5668326311757947,
      "grad_norm": 0.6876198649406433,
      "learning_rate": 4.505085828753258e-05,
      "loss": 0.2118,
      "step": 370
    },
    {
      "epoch": 0.5821524320183837,
      "grad_norm": 0.8924806714057922,
      "learning_rate": 4.4643799642803646e-05,
      "loss": 0.216,
      "step": 380
    },
    {
      "epoch": 0.5974722328609728,
      "grad_norm": 0.9449522495269775,
      "learning_rate": 4.422265124906593e-05,
      "loss": 0.214,
      "step": 390
    },
    {
      "epoch": 0.6127920337035618,
      "grad_norm": 1.0971394777297974,
      "learning_rate": 4.378771518001551e-05,
      "loss": 0.1949,
      "step": 400
    },
    {
      "epoch": 0.6281118345461509,
      "grad_norm": 1.1451513767242432,
      "learning_rate": 4.333930339872264e-05,
      "loss": 0.2179,
      "step": 410
    },
    {
      "epoch": 0.6434316353887399,
      "grad_norm": 1.1068897247314453,
      "learning_rate": 4.2877737533872485e-05,
      "loss": 0.2143,
      "step": 420
    },
    {
      "epoch": 0.658751436231329,
      "grad_norm": 0.5159239768981934,
      "learning_rate": 4.2403348649073174e-05,
      "loss": 0.2148,
      "step": 430
    },
    {
      "epoch": 0.674071237073918,
      "grad_norm": 1.3324896097183228,
      "learning_rate": 4.1916477005396414e-05,
      "loss": 0.2221,
      "step": 440
    },
    {
      "epoch": 0.6893910379165071,
      "grad_norm": 0.8344489336013794,
      "learning_rate": 4.141747181732128e-05,
      "loss": 0.2169,
      "step": 450
    },
    {
      "epoch": 0.7047108387590961,
      "grad_norm": 0.5655383467674255,
      "learning_rate": 4.09066910022559e-05,
      "loss": 0.2011,
      "step": 460
    },
    {
      "epoch": 0.7200306396016852,
      "grad_norm": 0.9061763286590576,
      "learning_rate": 4.038450092381697e-05,
      "loss": 0.2138,
      "step": 470
    },
    {
      "epoch": 0.7353504404442742,
      "grad_norm": 0.7112887501716614,
      "learning_rate": 3.985127612905108e-05,
      "loss": 0.2198,
      "step": 480
    },
    {
      "epoch": 0.7506702412868632,
      "grad_norm": 0.8377757668495178,
      "learning_rate": 3.93073990797864e-05,
      "loss": 0.2008,
      "step": 490
    },
    {
      "epoch": 0.7659900421294523,
      "grad_norm": 0.5566742420196533,
      "learning_rate": 3.875325987830736e-05,
      "loss": 0.2144,
      "step": 500
    },
    {
      "epoch": 0.7813098429720413,
      "grad_norm": 1.0790187120437622,
      "learning_rate": 3.818925598754918e-05,
      "loss": 0.2074,
      "step": 510
    },
    {
      "epoch": 0.7966296438146304,
      "grad_norm": 0.5041263103485107,
      "learning_rate": 3.761579194601284e-05,
      "loss": 0.213,
      "step": 520
    },
    {
      "epoch": 0.8119494446572194,
      "grad_norm": 1.1794514656066895,
      "learning_rate": 3.703327907760499e-05,
      "loss": 0.2073,
      "step": 530
    },
    {
      "epoch": 0.8272692454998085,
      "grad_norm": 0.555549681186676,
      "learning_rate": 3.644213519661103e-05,
      "loss": 0.2155,
      "step": 540
    },
    {
      "epoch": 0.8425890463423975,
      "grad_norm": 0.8579668998718262,
      "learning_rate": 3.5842784308012816e-05,
      "loss": 0.2022,
      "step": 550
    },
    {
      "epoch": 0.8579088471849866,
      "grad_norm": 0.6375381946563721,
      "learning_rate": 3.523565630336607e-05,
      "loss": 0.1914,
      "step": 560
    },
    {
      "epoch": 0.8732286480275756,
      "grad_norm": 1.4678163528442383,
      "learning_rate": 3.4621186652455515e-05,
      "loss": 0.2148,
      "step": 570
    },
    {
      "epoch": 0.8885484488701647,
      "grad_norm": 1.0542206764221191,
      "learning_rate": 3.399981609094902e-05,
      "loss": 0.2058,
      "step": 580
    },
    {
      "epoch": 0.9038682497127537,
      "grad_norm": 1.1880964040756226,
      "learning_rate": 3.3371990304274656e-05,
      "loss": 0.2301,
      "step": 590
    },
    {
      "epoch": 0.9191880505553428,
      "grad_norm": 0.7068465352058411,
      "learning_rate": 3.273815960794757e-05,
      "loss": 0.2078,
      "step": 600
    },
    {
      "epoch": 0.9345078513979318,
      "grad_norm": 0.5645698308944702,
      "learning_rate": 3.20987786245758e-05,
      "loss": 0.1949,
      "step": 610
    },
    {
      "epoch": 0.9498276522405209,
      "grad_norm": 0.8215548396110535,
      "learning_rate": 3.1454305957776794e-05,
      "loss": 0.213,
      "step": 620
    },
    {
      "epoch": 0.9651474530831099,
      "grad_norm": 0.7305980324745178,
      "learning_rate": 3.0805203863238527e-05,
      "loss": 0.2111,
      "step": 630
    },
    {
      "epoch": 0.980467253925699,
      "grad_norm": 0.8386112451553345,
      "learning_rate": 3.0151937917161088e-05,
      "loss": 0.2107,
      "step": 640
    },
    {
      "epoch": 0.995787054768288,
      "grad_norm": 0.8838352560997009,
      "learning_rate": 2.949497668231663e-05,
      "loss": 0.1993,
      "step": 650
    },
    {
      "epoch": 1.011106855610877,
      "grad_norm": 0.7780336141586304,
      "learning_rate": 2.8834791371967142e-05,
      "loss": 0.1674,
      "step": 660
    },
    {
      "epoch": 1.026426656453466,
      "grad_norm": 0.7234471440315247,
      "learning_rate": 2.8171855511881106e-05,
      "loss": 0.179,
      "step": 670
    },
    {
      "epoch": 1.041746457296055,
      "grad_norm": 1.0453705787658691,
      "learning_rate": 2.7506644600691567e-05,
      "loss": 0.1628,
      "step": 680
    },
    {
      "epoch": 1.0570662581386443,
      "grad_norm": 0.7506476044654846,
      "learning_rate": 2.6839635768839018e-05,
      "loss": 0.1598,
      "step": 690
    },
    {
      "epoch": 1.0723860589812333,
      "grad_norm": 1.0663033723831177,
      "learning_rate": 2.6171307436343917e-05,
      "loss": 0.1642,
      "step": 700
    },
    {
      "epoch": 1.0877058598238223,
      "grad_norm": 0.7960523366928101,
      "learning_rate": 2.550213896965431e-05,
      "loss": 0.1559,
      "step": 710
    },
    {
      "epoch": 1.1030256606664113,
      "grad_norm": 0.9308127164840698,
      "learning_rate": 2.483261033781444e-05,
      "loss": 0.1734,
      "step": 720
    },
    {
      "epoch": 1.1183454615090005,
      "grad_norm": 0.7173441648483276,
      "learning_rate": 2.416320176820132e-05,
      "loss": 0.1763,
      "step": 730
    },
    {
      "epoch": 1.1336652623515895,
      "grad_norm": 0.8361645936965942,
      "learning_rate": 2.3494393402075882e-05,
      "loss": 0.1514,
      "step": 740
    },
    {
      "epoch": 1.1489850631941785,
      "grad_norm": 0.7557232975959778,
      "learning_rate": 2.2893375541928446e-05,
      "loss": 0.1792,
      "step": 750
    },
    {
      "epoch": 1.1643048640367675,
      "grad_norm": 0.7394553422927856,
      "learning_rate": 2.2227028532477307e-05,
      "loss": 0.1484,
      "step": 760
    },
    {
      "epoch": 1.1796246648793565,
      "grad_norm": 1.082753300666809,
      "learning_rate": 2.1562670469803078e-05,
      "loss": 0.1883,
      "step": 770
    },
    {
      "epoch": 1.1949444657219457,
      "grad_norm": 0.7907865047454834,
      "learning_rate": 2.0900777872630512e-05,
      "loss": 0.1863,
      "step": 780
    },
    {
      "epoch": 1.2102642665645347,
      "grad_norm": 0.8035048246383667,
      "learning_rate": 2.0241825491299897e-05,
      "loss": 0.1678,
      "step": 790
    },
    {
      "epoch": 1.2255840674071237,
      "grad_norm": 0.7473676800727844,
      "learning_rate": 1.958628596724673e-05,
      "loss": 0.1566,
      "step": 800
    },
    {
      "epoch": 1.2409038682497127,
      "grad_norm": 1.0739479064941406,
      "learning_rate": 1.8934629493994005e-05,
      "loss": 0.1604,
      "step": 810
    },
    {
      "epoch": 1.2562236690923019,
      "grad_norm": 1.1032078266143799,
      "learning_rate": 1.8287323479900346e-05,
      "loss": 0.1631,
      "step": 820
    },
    {
      "epoch": 1.2715434699348909,
      "grad_norm": 2.1052772998809814,
      "learning_rate": 1.764483221290578e-05,
      "loss": 0.1723,
      "step": 830
    },
    {
      "epoch": 1.2868632707774799,
      "grad_norm": 1.1225662231445312,
      "learning_rate": 1.7007616527515694e-05,
      "loss": 0.1822,
      "step": 840
    },
    {
      "epoch": 1.3021830716200689,
      "grad_norm": 0.7789884209632874,
      "learning_rate": 1.63761334742618e-05,
      "loss": 0.1589,
      "step": 850
    },
    {
      "epoch": 1.3175028724626578,
      "grad_norm": 0.9046103954315186,
      "learning_rate": 1.5750835991877198e-05,
      "loss": 0.1657,
      "step": 860
    },
    {
      "epoch": 1.332822673305247,
      "grad_norm": 1.0882928371429443,
      "learning_rate": 1.5132172582420712e-05,
      "loss": 0.1812,
      "step": 870
    },
    {
      "epoch": 1.348142474147836,
      "grad_norm": 1.1880115270614624,
      "learning_rate": 1.4520586989583406e-05,
      "loss": 0.1749,
      "step": 880
    },
    {
      "epoch": 1.363462274990425,
      "grad_norm": 1.265795350074768,
      "learning_rate": 1.3916517880408152e-05,
      "loss": 0.1701,
      "step": 890
    },
    {
      "epoch": 1.3787820758330143,
      "grad_norm": 1.2092528343200684,
      "learning_rate": 1.332039853065055e-05,
      "loss": 0.1555,
      "step": 900
    },
    {
      "epoch": 1.3941018766756033,
      "grad_norm": 0.8062694668769836,
      "learning_rate": 1.2732656514006591e-05,
      "loss": 0.1558,
      "step": 910
    },
    {
      "epoch": 1.4094216775181923,
      "grad_norm": 1.6425164937973022,
      "learning_rate": 1.215371339543048e-05,
      "loss": 0.1746,
      "step": 920
    },
    {
      "epoch": 1.4247414783607812,
      "grad_norm": 0.7872245907783508,
      "learning_rate": 1.1583984428762077e-05,
      "loss": 0.1411,
      "step": 930
    },
    {
      "epoch": 1.4400612792033702,
      "grad_norm": 1.222949504852295,
      "learning_rate": 1.1023878258881142e-05,
      "loss": 0.1725,
      "step": 940
    },
    {
      "epoch": 1.4553810800459595,
      "grad_norm": 1.621778964996338,
      "learning_rate": 1.0473796628601982e-05,
      "loss": 0.1866,
      "step": 950
    },
    {
      "epoch": 1.4707008808885484,
      "grad_norm": 1.0579073429107666,
      "learning_rate": 9.934134090518593e-06,
      "loss": 0.1633,
      "step": 960
    },
    {
      "epoch": 1.4860206817311374,
      "grad_norm": 1.248313546180725,
      "learning_rate": 9.405277724007117e-06,
      "loss": 0.178,
      "step": 970
    },
    {
      "epoch": 1.5013404825737267,
      "grad_norm": 1.3750817775726318,
      "learning_rate": 8.887606857588585e-06,
      "loss": 0.1636,
      "step": 980
    },
    {
      "epoch": 1.5166602834163156,
      "grad_norm": 1.1793328523635864,
      "learning_rate": 8.38149279685101e-06,
      "loss": 0.1782,
      "step": 990
    },
    {
      "epoch": 1.5319800842589046,
      "grad_norm": 1.139153003692627,
      "learning_rate": 7.887298558126007e-06,
      "loss": 0.1391,
      "step": 1000
    },
    {
      "epoch": 1.5472998851014936,
      "grad_norm": 0.8669185042381287,
      "learning_rate": 7.405378608111058e-06,
      "loss": 0.1618,
      "step": 1010
    },
    {
      "epoch": 1.5626196859440826,
      "grad_norm": 0.6764294505119324,
      "learning_rate": 6.936078609624022e-06,
      "loss": 0.1689,
      "step": 1020
    },
    {
      "epoch": 1.5779394867866716,
      "grad_norm": 1.3634514808654785,
      "learning_rate": 6.479735173672388e-06,
      "loss": 0.1636,
      "step": 1030
    },
    {
      "epoch": 1.5932592876292608,
      "grad_norm": 0.7664749622344971,
      "learning_rate": 6.036675618014992e-06,
      "loss": 0.1354,
      "step": 1040
    },
    {
      "epoch": 1.6085790884718498,
      "grad_norm": 1.0639874935150146,
      "learning_rate": 5.607217732389503e-06,
      "loss": 0.1513,
      "step": 1050
    },
    {
      "epoch": 1.623898889314439,
      "grad_norm": 1.05487859249115,
      "learning_rate": 5.191669550573925e-06,
      "loss": 0.1439,
      "step": 1060
    },
    {
      "epoch": 1.639218690157028,
      "grad_norm": 0.7461987137794495,
      "learning_rate": 4.7903291294457034e-06,
      "loss": 0.1585,
      "step": 1070
    },
    {
      "epoch": 1.654538490999617,
      "grad_norm": 1.0323635339736938,
      "learning_rate": 4.4034843351969e-06,
      "loss": 0.1621,
      "step": 1080
    },
    {
      "epoch": 1.669858291842206,
      "grad_norm": 0.9431507587432861,
      "learning_rate": 4.031412636858745e-06,
      "loss": 0.1513,
      "step": 1090
    },
    {
      "epoch": 1.685178092684795,
      "grad_norm": 1.0848345756530762,
      "learning_rate": 3.674380907283631e-06,
      "loss": 0.1436,
      "step": 1100
    },
    {
      "epoch": 1.700497893527384,
      "grad_norm": 1.0576516389846802,
      "learning_rate": 3.3326452317274407e-06,
      "loss": 0.16,
      "step": 1110
    },
    {
      "epoch": 1.7158176943699732,
      "grad_norm": 0.9120290875434875,
      "learning_rate": 3.006450724169324e-06,
      "loss": 0.151,
      "step": 1120
    },
    {
      "epoch": 1.7311374952125622,
      "grad_norm": 1.5312597751617432,
      "learning_rate": 2.696031351500761e-06,
      "loss": 0.1553,
      "step": 1130
    },
    {
      "epoch": 1.7464572960551514,
      "grad_norm": 0.8575084209442139,
      "learning_rate": 2.401609765710064e-06,
      "loss": 0.1532,
      "step": 1140
    },
    {
      "epoch": 1.7617770968977404,
      "grad_norm": 0.7805230617523193,
      "learning_rate": 2.1233971441825704e-06,
      "loss": 0.1439,
      "step": 1150
    },
    {
      "epoch": 1.7770968977403294,
      "grad_norm": 1.3168511390686035,
      "learning_rate": 1.861593038231138e-06,
      "loss": 0.1749,
      "step": 1160
    },
    {
      "epoch": 1.7924166985829184,
      "grad_norm": 1.405682921409607,
      "learning_rate": 1.616385229965614e-06,
      "loss": 0.1319,
      "step": 1170
    },
    {
      "epoch": 1.8077364994255074,
      "grad_norm": 1.2837293148040771,
      "learning_rate": 1.3879495976038825e-06,
      "loss": 0.1638,
      "step": 1180
    },
    {
      "epoch": 1.8230563002680964,
      "grad_norm": 1.5698100328445435,
      "learning_rate": 1.1764499893210878e-06,
      "loss": 0.144,
      "step": 1190
    },
    {
      "epoch": 1.8383761011106856,
      "grad_norm": 0.7425130009651184,
      "learning_rate": 9.820381057276228e-07,
      "loss": 0.1667,
      "step": 1200
    },
    {
      "epoch": 1.8536959019532746,
      "grad_norm": 1.2654008865356445,
      "learning_rate": 8.048533910600425e-07,
      "loss": 0.151,
      "step": 1210
    },
    {
      "epoch": 1.8690157027958638,
      "grad_norm": 0.9280117750167847,
      "learning_rate": 6.450229331630253e-07,
      "loss": 0.1673,
      "step": 1220
    },
    {
      "epoch": 1.8843355036384528,
      "grad_norm": 1.2599910497665405,
      "learning_rate": 5.026613723340956e-07,
      "loss": 0.1553,
      "step": 1230
    },
    {
      "epoch": 1.8996553044810418,
      "grad_norm": 0.996701717376709,
      "learning_rate": 3.778708190965291e-07,
      "loss": 0.1615,
      "step": 1240
    },
    {
      "epoch": 1.9149751053236308,
      "grad_norm": 1.9720350503921509,
      "learning_rate": 2.707407809593526e-07,
      "loss": 0.1907,
      "step": 1250
    },
    {
      "epoch": 1.9302949061662198,
      "grad_norm": 1.2706235647201538,
      "learning_rate": 1.8134809821701016e-07,
      "loss": 0.1445,
      "step": 1260
    },
    {
      "epoch": 1.9456147070088088,
      "grad_norm": 0.8884113430976868,
      "learning_rate": 1.0975688883476387e-07,
      "loss": 0.1615,
      "step": 1270
    },
    {
      "epoch": 1.9609345078513978,
      "grad_norm": 0.8873377442359924,
      "learning_rate": 5.60185024593124e-08,
      "loss": 0.157,
      "step": 1280
    },
    {
      "epoch": 1.976254308693987,
      "grad_norm": 1.087651252746582,
      "learning_rate": 2.0171483587638763e-08,
      "loss": 0.1772,
      "step": 1290
    },
    {
      "epoch": 1.991574109536576,
      "grad_norm": 1.040468692779541,
      "learning_rate": 2.2415439205281108e-09,
      "loss": 0.1372,
      "step": 1300
    },
    {
      "epoch": 1.9977020298736117,
      "step": 1304,
      "total_flos": 5632742057127936.0,
      "train_loss": 0.1956337235776559,
      "train_runtime": 1411.6189,
      "train_samples_per_second": 7.399,
      "train_steps_per_second": 0.924
    }
  ],
  "logging_steps": 10,
  "max_steps": 1304,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 5000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 5632742057127936.0,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
