{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.9977020298736117,
  "eval_steps": 500,
  "global_step": 1304,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.015319800842589047,
      "grad_norm": 1.3707283735275269,
      "learning_rate": 2.2900763358778625e-06,
      "loss": 1.1322,
      "step": 10
    },
    {
      "epoch": 0.030639601685178094,
      "grad_norm": 1.4518344402313232,
      "learning_rate": 6.106870229007634e-06,
      "loss": 0.7192,
      "step": 20
    },
    {
      "epoch": 0.04595940252776714,
      "grad_norm": 0.2820800840854645,
      "learning_rate": 9.923664122137405e-06,
      "loss": 0.284,
      "step": 30
    },
    {
      "epoch": 0.06127920337035619,
      "grad_norm": 0.5014600157737732,
      "learning_rate": 1.3740458015267178e-05,
      "loss": 0.2798,
      "step": 40
    },
    {
      "epoch": 0.07659900421294523,
      "grad_norm": 0.805905818939209,
      "learning_rate": 1.7557251908396945e-05,
      "loss": 0.2179,
      "step": 50
    },
    {
      "epoch": 0.09191880505553428,
      "grad_norm": 1.0873562097549438,
      "learning_rate": 2.1374045801526718e-05,
      "loss": 0.2259,
      "step": 60
    },
    {
      "epoch": 0.10723860589812333,
      "grad_norm": 1.3955020904541016,
      "learning_rate": 2.5190839694656487e-05,
      "loss": 0.2172,
      "step": 70
    },
    {
      "epoch": 0.12255840674071238,
      "grad_norm": 0.5626788139343262,
      "learning_rate": 2.900763358778626e-05,
      "loss": 0.2013,
      "step": 80
    },
    {
      "epoch": 0.1378782075833014,
      "grad_norm": 0.3726927638053894,
      "learning_rate": 3.282442748091603e-05,
      "loss": 0.2471,
      "step": 90
    },
    {
      "epoch": 0.15319800842589046,
      "grad_norm": 0.557345449924469,
      "learning_rate": 3.66412213740458e-05,
      "loss": 0.1991,
      "step": 100
    },
    {
      "epoch": 0.1685178092684795,
      "grad_norm": 0.8481522798538208,
      "learning_rate": 4.0458015267175576e-05,
      "loss": 0.2178,
      "step": 110
    },
    {
      "epoch": 0.18383761011106856,
      "grad_norm": 0.845206081867218,
      "learning_rate": 4.4274809160305345e-05,
      "loss": 0.2225,
      "step": 120
    },
    {
      "epoch": 0.1991574109536576,
      "grad_norm": 1.7650967836380005,
      "learning_rate": 4.809160305343512e-05,
      "loss": 0.2224,
      "step": 130
    },
    {
      "epoch": 0.21447721179624665,
      "grad_norm": 0.6019611954689026,
      "learning_rate": 4.999775845607947e-05,
      "loss": 0.2279,
      "step": 140
    },
    {
      "epoch": 0.2297970126388357,
      "grad_norm": 0.9989578127861023,
      "learning_rate": 4.997982851641236e-05,
      "loss": 0.2113,
      "step": 150
    },
    {
      "epoch": 0.24511681348142475,
      "grad_norm": 0.5472817420959473,
      "learning_rate": 4.994398149754069e-05,
      "loss": 0.2049,
      "step": 160
    },
    {
      "epoch": 0.26043661432401377,
      "grad_norm": 0.9558039307594299,
      "learning_rate": 4.989024311116524e-05,
      "loss": 0.1933,
      "step": 170
    },
    {
      "epoch": 0.2757564151666028,
      "grad_norm": 1.5544533729553223,
      "learning_rate": 4.981865190178299e-05,
      "loss": 0.2318,
      "step": 180
    },
    {
      "epoch": 0.29107621600919187,
      "grad_norm": 0.8437245488166809,
      "learning_rate": 4.9729259219040646e-05,
      "loss": 0.2156,
      "step": 190
    },
    {
      "epoch": 0.3063960168517809,
      "grad_norm": 0.849517822265625,
      "learning_rate": 4.9622129180903476e-05,
      "loss": 0.2086,
      "step": 200
    },
    {
      "epoch": 0.32171581769436997,
      "grad_norm": 1.3241770267486572,
      "learning_rate": 4.9497338627665903e-05,
      "loss": 0.2238,
      "step": 210
    },
    {
      "epoch": 0.337035618536959,
      "grad_norm": 1.0810225009918213,
      "learning_rate": 4.9354977066836986e-05,
      "loss": 0.2241,
      "step": 220
    },
    {
      "epoch": 0.35235541937954806,
      "grad_norm": 0.6576372981071472,
      "learning_rate": 4.919514660893996e-05,
      "loss": 0.2061,
      "step": 230
    },
    {
      "epoch": 0.3676752202221371,
      "grad_norm": 1.5274897813796997,
      "learning_rate": 4.901796189427238e-05,
      "loss": 0.1978,
      "step": 240
    },
    {
      "epoch": 0.38299502106472616,
      "grad_norm": 0.7800741791725159,
      "learning_rate": 4.882355001067892e-05,
      "loss": 0.2367,
      "step": 250
    },
    {
      "epoch": 0.3983148219073152,
      "grad_norm": 1.0167529582977295,
      "learning_rate": 4.8612050402396125e-05,
      "loss": 0.2014,
      "step": 260
    },
    {
      "epoch": 0.41363462274990426,
      "grad_norm": 0.8375118970870972,
      "learning_rate": 4.8383614770034387e-05,
      "loss": 0.2393,
      "step": 270
    },
    {
      "epoch": 0.4289544235924933,
      "grad_norm": 0.7255662083625793,
      "learning_rate": 4.813840696176887e-05,
      "loss": 0.194,
      "step": 280
    },
    {
      "epoch": 0.44427422443508235,
      "grad_norm": 1.0419367551803589,
      "learning_rate": 4.787660285581743e-05,
      "loss": 0.2057,
      "step": 290
    },
    {
      "epoch": 0.4595940252776714,
      "grad_norm": 1.6817080974578857,
      "learning_rate": 4.759839023428994e-05,
      "loss": 0.2208,
      "step": 300
    },
    {
      "epoch": 0.47491382612026045,
      "grad_norm": 0.6808765530586243,
      "learning_rate": 4.7303968648499245e-05,
      "loss": 0.2115,
      "step": 310
    },
    {
      "epoch": 0.4902336269628495,
      "grad_norm": 0.9900599122047424,
      "learning_rate": 4.6993549275830686e-05,
      "loss": 0.1916,
      "step": 320
    },
    {
      "epoch": 0.5055534278054385,
      "grad_norm": 1.3552309274673462,
      "learning_rate": 4.6667354768272565e-05,
      "loss": 0.1966,
      "step": 330
    },
    {
      "epoch": 0.5208732286480275,
      "grad_norm": 1.1038258075714111,
      "learning_rate": 4.632561909271637e-05,
      "loss": 0.2043,
      "step": 340
    },
    {
      "epoch": 0.5361930294906166,
      "grad_norm": 0.36144116520881653,
      "learning_rate": 4.5968587363141256e-05,
      "loss": 0.208,
      "step": 350
    },
    {
      "epoch": 0.5515128303332056,
      "grad_norm": 0.8021625280380249,
      "learning_rate": 4.5596515664803096e-05,
      "loss": 0.1979,
      "step": 360
    },
    {
      "epoch": 0.5668326311757947,
      "grad_norm": 0.9666122198104858,
      "learning_rate": 4.52096708705543e-05,
      "loss": 0.1809,
      "step": 370
    },
    {
      "epoch": 0.5821524320183837,
      "grad_norm": 0.5392124056816101,
      "learning_rate": 4.480833044942608e-05,
      "loss": 0.1934,
      "step": 380
    },
    {
      "epoch": 0.5974722328609728,
      "grad_norm": 0.61661696434021,
      "learning_rate": 4.43927822676105e-05,
      "loss": 0.2033,
      "step": 390
    },
    {
      "epoch": 0.6127920337035618,
      "grad_norm": 0.5564543008804321,
      "learning_rate": 4.396332438198501e-05,
      "loss": 0.1778,
      "step": 400
    },
    {
      "epoch": 0.6281118345461509,
      "grad_norm": 0.8331151008605957,
      "learning_rate": 4.352026482632762e-05,
      "loss": 0.1915,
      "step": 410
    },
    {
      "epoch": 0.6434316353887399,
      "grad_norm": 0.9094541668891907,
      "learning_rate": 4.3063921390375974e-05,
      "loss": 0.191,
      "step": 420
    },
    {
      "epoch": 0.658751436231329,
      "grad_norm": 0.5088807940483093,
      "learning_rate": 4.2594621391888946e-05,
      "loss": 0.1958,
      "step": 430
    },
    {
      "epoch": 0.674071237073918,
      "grad_norm": 1.7789944410324097,
      "learning_rate": 4.211270144187399e-05,
      "loss": 0.2067,
      "step": 440
    },
    {
      "epoch": 0.6893910379165071,
      "grad_norm": 0.865857720375061,
      "learning_rate": 4.1618507203148994e-05,
      "loss": 0.2104,
      "step": 450
    },
    {
      "epoch": 0.7047108387590961,
      "grad_norm": 0.4896896481513977,
      "learning_rate": 4.111239314241142e-05,
      "loss": 0.1736,
      "step": 460
    },
    {
      "epoch": 0.7200306396016852,
      "grad_norm": 0.7714831829071045,
      "learning_rate": 4.0594722275992885e-05,
      "loss": 0.1865,
      "step": 470
    },
    {
      "epoch": 0.7353504404442742,
      "grad_norm": 0.9106191396713257,
      "learning_rate": 4.0065865909481417e-05,
      "loss": 0.214,
      "step": 480
    },
    {
      "epoch": 0.7506702412868632,
      "grad_norm": 1.2678934335708618,
      "learning_rate": 3.952620337139802e-05,
      "loss": 0.1928,
      "step": 490
    },
    {
      "epoch": 0.7659900421294523,
      "grad_norm": 0.4367850124835968,
      "learning_rate": 3.897612174111886e-05,
      "loss": 0.1998,
      "step": 500
    },
    {
      "epoch": 0.7813098429720413,
      "grad_norm": 1.4405373334884644,
      "learning_rate": 3.841601557123793e-05,
      "loss": 0.1915,
      "step": 510
    },
    {
      "epoch": 0.7966296438146304,
      "grad_norm": 0.8390274047851562,
      "learning_rate": 3.784628660456952e-05,
      "loss": 0.2148,
      "step": 520
    },
    {
      "epoch": 0.8119494446572194,
      "grad_norm": 0.5370776057243347,
      "learning_rate": 3.7267343485993406e-05,
      "loss": 0.1909,
      "step": 530
    },
    {
      "epoch": 0.8272692454998085,
      "grad_norm": 0.40906617045402527,
      "learning_rate": 3.6679601469349457e-05,
      "loss": 0.2123,
      "step": 540
    },
    {
      "epoch": 0.8425890463423975,
      "grad_norm": 0.4425566792488098,
      "learning_rate": 3.608348211959185e-05,
      "loss": 0.1955,
      "step": 550
    },
    {
      "epoch": 0.8579088471849866,
      "grad_norm": 0.4107154607772827,
      "learning_rate": 3.547941301041661e-05,
      "loss": 0.1822,
      "step": 560
    },
    {
      "epoch": 0.8732286480275756,
      "grad_norm": 0.7769267559051514,
      "learning_rate": 3.4867827417579293e-05,
      "loss": 0.1948,
      "step": 570
    },
    {
      "epoch": 0.8885484488701647,
      "grad_norm": 0.6768064498901367,
      "learning_rate": 3.42491640081228e-05,
      "loss": 0.1818,
      "step": 580
    },
    {
      "epoch": 0.9038682497127537,
      "grad_norm": 0.778915524482727,
      "learning_rate": 3.3623866525738214e-05,
      "loss": 0.2163,
      "step": 590
    },
    {
      "epoch": 0.9191880505553428,
      "grad_norm": 0.7471454739570618,
      "learning_rate": 3.2992383472484315e-05,
      "loss": 0.1984,
      "step": 600
    },
    {
      "epoch": 0.9345078513979318,
      "grad_norm": 0.7552757859230042,
      "learning_rate": 3.235516778709423e-05,
      "loss": 0.1835,
      "step": 610
    },
    {
      "epoch": 0.9498276522405209,
      "grad_norm": 0.6399683952331543,
      "learning_rate": 3.171267652009966e-05,
      "loss": 0.1894,
      "step": 620
    },
    {
      "epoch": 0.9651474530831099,
      "grad_norm": 0.43297815322875977,
      "learning_rate": 3.106537050600601e-05,
      "loss": 0.2014,
      "step": 630
    },
    {
      "epoch": 0.980467253925699,
      "grad_norm": 0.5157052278518677,
      "learning_rate": 3.041371403275328e-05,
      "loss": 0.1956,
      "step": 640
    },
    {
      "epoch": 0.995787054768288,
      "grad_norm": 0.6529996991157532,
      "learning_rate": 2.975817450870011e-05,
      "loss": 0.1844,
      "step": 650
    },
    {
      "epoch": 1.011106855610877,
      "grad_norm": 0.5830708146095276,
      "learning_rate": 2.9099222127369497e-05,
      "loss": 0.1679,
      "step": 660
    },
    {
      "epoch": 1.026426656453466,
      "grad_norm": 0.4055442214012146,
      "learning_rate": 2.843732953019693e-05,
      "loss": 0.1583,
      "step": 670
    },
    {
      "epoch": 1.041746457296055,
      "grad_norm": 0.7540454864501953,
      "learning_rate": 2.7772971467522706e-05,
      "loss": 0.1543,
      "step": 680
    },
    {
      "epoch": 1.0570662581386443,
      "grad_norm": 0.819521963596344,
      "learning_rate": 2.710662445807156e-05,
      "loss": 0.1681,
      "step": 690
    },
    {
      "epoch": 1.0723860589812333,
      "grad_norm": 0.5542240142822266,
      "learning_rate": 2.6438766447163992e-05,
      "loss": 0.1635,
      "step": 700
    },
    {
      "epoch": 1.0877058598238223,
      "grad_norm": 0.40370264649391174,
      "learning_rate": 2.5769876463904265e-05,
      "loss": 0.1394,
      "step": 710
    },
    {
      "epoch": 1.1030256606664113,
      "grad_norm": 0.8044038414955139,
      "learning_rate": 2.5100434277591078e-05,
      "loss": 0.1559,
      "step": 720
    },
    {
      "epoch": 1.1183454615090005,
      "grad_norm": 0.5163697004318237,
      "learning_rate": 2.4430920053597356e-05,
      "loss": 0.1639,
      "step": 730
    },
    {
      "epoch": 1.1336652623515895,
      "grad_norm": 0.5830740332603455,
      "learning_rate": 2.376181400896591e-05,
      "loss": 0.1385,
      "step": 740
    },
    {
      "epoch": 1.1489850631941785,
      "grad_norm": 1.2166178226470947,
      "learning_rate": 2.3093596067968025e-05,
      "loss": 0.167,
      "step": 750
    },
    {
      "epoch": 1.1643048640367675,
      "grad_norm": 0.5122572779655457,
      "learning_rate": 2.242674551787212e-05,
      "loss": 0.1466,
      "step": 760
    },
    {
      "epoch": 1.1796246648793565,
      "grad_norm": 0.7849571704864502,
      "learning_rate": 2.1761740665169188e-05,
      "loss": 0.1855,
      "step": 770
    },
    {
      "epoch": 1.1949444657219457,
      "grad_norm": 0.2841393053531647,
      "learning_rate": 2.1099058492501826e-05,
      "loss": 0.16,
      "step": 780
    },
    {
      "epoch": 1.2102642665645347,
      "grad_norm": 0.5255990028381348,
      "learning_rate": 2.0439174316542743e-05,
      "loss": 0.1571,
      "step": 790
    },
    {
      "epoch": 1.2255840674071237,
      "grad_norm": 0.6067772507667542,
      "learning_rate": 1.978256144706821e-05,
      "loss": 0.1552,
      "step": 800
    },
    {
      "epoch": 1.2409038682497127,
      "grad_norm": 0.6426736116409302,
      "learning_rate": 1.9129690847471e-05,
      "loss": 0.1652,
      "step": 810
    },
    {
      "epoch": 1.2562236690923019,
      "grad_norm": 0.502590537071228,
      "learning_rate": 1.8481030796956312e-05,
      "loss": 0.1628,
      "step": 820
    },
    {
      "epoch": 1.2715434699348909,
      "grad_norm": 0.7157136797904968,
      "learning_rate": 1.783704655466289e-05,
      "loss": 0.1525,
      "step": 830
    },
    {
      "epoch": 1.2868632707774799,
      "grad_norm": 0.4959349036216736,
      "learning_rate": 1.7198200025950424e-05,
      "loss": 0.1699,
      "step": 840
    },
    {
      "epoch": 1.3021830716200689,
      "grad_norm": 0.5158047080039978,
      "learning_rate": 1.6564949431092403e-05,
      "loss": 0.1647,
      "step": 850
    },
    {
      "epoch": 1.3175028724626578,
      "grad_norm": 0.40873634815216064,
      "learning_rate": 1.5937748976612176e-05,
      "loss": 0.1647,
      "step": 860
    },
    {
      "epoch": 1.332822673305247,
      "grad_norm": 0.5549647808074951,
      "learning_rate": 1.5317048529497938e-05,
      "loss": 0.1627,
      "step": 870
    },
    {
      "epoch": 1.348142474147836,
      "grad_norm": 0.5053373575210571,
      "learning_rate": 1.4703293294530247e-05,
      "loss": 0.1534,
      "step": 880
    },
    {
      "epoch": 1.363462274990425,
      "grad_norm": 0.5890669226646423,
      "learning_rate": 1.4096923494953628e-05,
      "loss": 0.1478,
      "step": 890
    },
    {
      "epoch": 1.3787820758330143,
      "grad_norm": 0.7745649814605713,
      "learning_rate": 1.3498374056721197e-05,
      "loss": 0.1513,
      "step": 900
    },
    {
      "epoch": 1.3941018766756033,
      "grad_norm": 0.4130825102329254,
      "learning_rate": 1.2908074296538864e-05,
      "loss": 0.1439,
      "step": 910
    },
    {
      "epoch": 1.4094216775181923,
      "grad_norm": 0.6907250285148621,
      "learning_rate": 1.2326447613932798e-05,
      "loss": 0.171,
      "step": 920
    },
    {
      "epoch": 1.4247414783607812,
      "grad_norm": 0.3584723472595215,
      "learning_rate": 1.1753911187561077e-05,
      "loss": 0.137,
      "step": 930
    },
    {
      "epoch": 1.4400612792033702,
      "grad_norm": 0.6103532910346985,
      "learning_rate": 1.1190875675987356e-05,
      "loss": 0.1607,
      "step": 940
    },
    {
      "epoch": 1.4553810800459595,
      "grad_norm": 0.5986139178276062,
      "learning_rate": 1.0637744923131118e-05,
      "loss": 0.1719,
      "step": 950
    },
    {
      "epoch": 1.4707008808885484,
      "grad_norm": 0.378412663936615,
      "learning_rate": 1.0094915668605787e-05,
      "loss": 0.1531,
      "step": 960
    },
    {
      "epoch": 1.4860206817311374,
      "grad_norm": 0.6538220643997192,
      "learning_rate": 9.56277726315257e-06,
      "loss": 0.1591,
      "step": 970
    },
    {
      "epoch": 1.5013404825737267,
      "grad_norm": 0.4437154531478882,
      "learning_rate": 9.04171138937398e-06,
      "loss": 0.1527,
      "step": 980
    },
    {
      "epoch": 1.5166602834163156,
      "grad_norm": 0.5479035377502441,
      "learning_rate": 8.532091787967428e-06,
      "loss": 0.1558,
      "step": 990
    },
    {
      "epoch": 1.5319800842589046,
      "grad_norm": 0.8950881958007812,
      "learning_rate": 8.034283989655305e-06,
      "loss": 0.1414,
      "step": 1000
    },
    {
      "epoch": 1.5472998851014936,
      "grad_norm": 0.4006519019603729,
      "learning_rate": 7.548645053003689e-06,
      "loss": 0.1533,
      "step": 1010
    },
    {
      "epoch": 1.5626196859440826,
      "grad_norm": 0.6018823385238647,
      "learning_rate": 7.075523308317863e-06,
      "loss": 0.1522,
      "step": 1020
    },
    {
      "epoch": 1.5779394867866716,
      "grad_norm": 0.5781965851783752,
      "learning_rate": 6.6152581077982224e-06,
      "loss": 0.1425,
      "step": 1030
    },
    {
      "epoch": 1.5932592876292608,
      "grad_norm": 0.7539018392562866,
      "learning_rate": 6.168179582135919e-06,
      "loss": 0.1295,
      "step": 1040
    },
    {
      "epoch": 1.6085790884718498,
      "grad_norm": 0.45085135102272034,
      "learning_rate": 5.734608403722674e-06,
      "loss": 0.1314,
      "step": 1050
    },
    {
      "epoch": 1.623898889314439,
      "grad_norm": 0.423740416765213,
      "learning_rate": 5.314855556644668e-06,
      "loss": 0.1447,
      "step": 1060
    },
    {
      "epoch": 1.639218690157028,
      "grad_norm": 0.4729503095149994,
      "learning_rate": 4.9092221136255444e-06,
      "loss": 0.1543,
      "step": 1070
    },
    {
      "epoch": 1.654538490999617,
      "grad_norm": 0.40739092230796814,
      "learning_rate": 4.5179990200784006e-06,
      "loss": 0.1637,
      "step": 1080
    },
    {
      "epoch": 1.669858291842206,
      "grad_norm": 0.5328815579414368,
      "learning_rate": 4.141466885421699e-06,
      "loss": 0.1474,
      "step": 1090
    },
    {
      "epoch": 1.685178092684795,
      "grad_norm": 0.44124701619148254,
      "learning_rate": 3.7798957818088816e-06,
      "loss": 0.1432,
      "step": 1100
    },
    {
      "epoch": 1.700497893527384,
      "grad_norm": 0.4120329022407532,
      "learning_rate": 3.4335450504158597e-06,
      "loss": 0.147,
      "step": 1110
    },
    {
      "epoch": 1.7158176943699732,
      "grad_norm": 0.6459934115409851,
      "learning_rate": 3.102663115425475e-06,
      "loss": 0.1409,
      "step": 1120
    },
    {
      "epoch": 1.7311374952125622,
      "grad_norm": 0.5942326784133911,
      "learning_rate": 2.7874873058423205e-06,
      "loss": 0.1414,
      "step": 1130
    },
    {
      "epoch": 1.7464572960551514,
      "grad_norm": 0.44808390736579895,
      "learning_rate": 2.488243685265676e-06,
      "loss": 0.1433,
      "step": 1140
    },
    {
      "epoch": 1.7617770968977404,
      "grad_norm": 0.592361569404602,
      "learning_rate": 2.205146889742685e-06,
      "loss": 0.1359,
      "step": 1150
    },
    {
      "epoch": 1.7770968977403294,
      "grad_norm": 0.6271960735321045,
      "learning_rate": 1.938399973818125e-06,
      "loss": 0.1684,
      "step": 1160
    },
    {
      "epoch": 1.7924166985829184,
      "grad_norm": 0.7069497108459473,
      "learning_rate": 1.6881942648911076e-06,
      "loss": 0.1256,
      "step": 1170
    },
    {
      "epoch": 1.8077364994255074,
      "grad_norm": 0.6727814674377441,
      "learning_rate": 1.454709225983214e-06,
      "loss": 0.1398,
      "step": 1180
    },
    {
      "epoch": 1.8230563002680964,
      "grad_norm": 0.5800949335098267,
      "learning_rate": 1.2381123270165245e-06,
      "loss": 0.1369,
      "step": 1190
    },
    {
      "epoch": 1.8383761011106856,
      "grad_norm": 0.4423674941062927,
      "learning_rate": 1.0385589246938193e-06,
      "loss": 0.1409,
      "step": 1200
    },
    {
      "epoch": 1.8536959019532746,
      "grad_norm": 0.714715301990509,
      "learning_rate": 8.561921510671311e-07,
      "loss": 0.1558,
      "step": 1210
    },
    {
      "epoch": 1.8690157027958638,
      "grad_norm": 0.48571544885635376,
      "learning_rate": 6.911428108745704e-07,
      "loss": 0.1529,
      "step": 1220
    },
    {
      "epoch": 1.8843355036384528,
      "grad_norm": 0.43859368562698364,
      "learning_rate": 5.435292877190995e-07,
      "loss": 0.149,
      "step": 1230
    },
    {
      "epoch": 1.8996553044810418,
      "grad_norm": 0.6761986613273621,
      "learning_rate": 4.134574591564494e-07,
      "loss": 0.1477,
      "step": 1240
    },
    {
      "epoch": 1.9149751053236308,
      "grad_norm": 0.6606113910675049,
      "learning_rate": 3.0102062075320626e-07,
      "loss": 0.1519,
      "step": 1250
    },
    {
      "epoch": 1.9302949061662198,
      "grad_norm": 0.4808497726917267,
      "learning_rate": 2.0629941916944783e-07,
      "loss": 0.1232,
      "step": 1260
    },
    {
      "epoch": 1.9456147070088088,
      "grad_norm": 0.44231149554252625,
      "learning_rate": 1.2936179431397022e-07,
      "loss": 0.1461,
      "step": 1270
    },
    {
      "epoch": 1.9609345078513978,
      "grad_norm": 0.4526403844356537,
      "learning_rate": 7.026293061357658e-08,
      "loss": 0.1419,
      "step": 1280
    },
    {
      "epoch": 1.976254308693987,
      "grad_norm": 0.36318573355674744,
      "learning_rate": 2.9045217431397655e-08,
      "loss": 0.1571,
      "step": 1290
    },
    {
      "epoch": 1.991574109536576,
      "grad_norm": 0.43221092224121094,
      "learning_rate": 5.738218662601491e-09,
      "loss": 0.1318,
      "step": 1300
    },
    {
      "epoch": 1.9977020298736117,
      "step": 1304,
      "total_flos": 1.0429894528975503e+18,
      "train_loss": 0.19008925479431094,
      "train_runtime": 10882.0889,
      "train_samples_per_second": 0.96,
      "train_steps_per_second": 0.12
    }
  ],
  "logging_steps": 10,
  "max_steps": 1304,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 5000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1.0429894528975503e+18,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
