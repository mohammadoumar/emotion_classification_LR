{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.9977020298736117,
  "eval_steps": 500,
  "global_step": 1304,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.015319800842589047,
      "grad_norm": 1.679951786994934,
      "learning_rate": 3.4351145038167944e-06,
      "loss": 0.5867,
      "step": 10
    },
    {
      "epoch": 0.030639601685178094,
      "grad_norm": 1.2645771503448486,
      "learning_rate": 7.251908396946565e-06,
      "loss": 0.3447,
      "step": 20
    },
    {
      "epoch": 0.04595940252776714,
      "grad_norm": 0.45738309621810913,
      "learning_rate": 1.1068702290076336e-05,
      "loss": 0.2554,
      "step": 30
    },
    {
      "epoch": 0.06127920337035619,
      "grad_norm": 0.5878415107727051,
      "learning_rate": 1.4885496183206107e-05,
      "loss": 0.2754,
      "step": 40
    },
    {
      "epoch": 0.07659900421294523,
      "grad_norm": 0.6044657826423645,
      "learning_rate": 1.8702290076335878e-05,
      "loss": 0.225,
      "step": 50
    },
    {
      "epoch": 0.09191880505553428,
      "grad_norm": 1.1614549160003662,
      "learning_rate": 2.2519083969465647e-05,
      "loss": 0.2293,
      "step": 60
    },
    {
      "epoch": 0.10723860589812333,
      "grad_norm": 0.6860197186470032,
      "learning_rate": 2.633587786259542e-05,
      "loss": 0.2255,
      "step": 70
    },
    {
      "epoch": 0.12255840674071238,
      "grad_norm": 0.5604127049446106,
      "learning_rate": 3.0152671755725192e-05,
      "loss": 0.2171,
      "step": 80
    },
    {
      "epoch": 0.1378782075833014,
      "grad_norm": 0.5206684470176697,
      "learning_rate": 3.3969465648854964e-05,
      "loss": 0.2731,
      "step": 90
    },
    {
      "epoch": 0.15319800842589046,
      "grad_norm": 0.4602052867412567,
      "learning_rate": 3.778625954198473e-05,
      "loss": 0.2045,
      "step": 100
    },
    {
      "epoch": 0.1685178092684795,
      "grad_norm": 0.7615395188331604,
      "learning_rate": 4.160305343511451e-05,
      "loss": 0.236,
      "step": 110
    },
    {
      "epoch": 0.18383761011106856,
      "grad_norm": 0.7804558873176575,
      "learning_rate": 4.541984732824428e-05,
      "loss": 0.2266,
      "step": 120
    },
    {
      "epoch": 0.1991574109536576,
      "grad_norm": 1.0127249956130981,
      "learning_rate": 4.923664122137405e-05,
      "loss": 0.2285,
      "step": 130
    },
    {
      "epoch": 0.21447721179624665,
      "grad_norm": 0.6374832987785339,
      "learning_rate": 4.99942617813374e-05,
      "loss": 0.2271,
      "step": 140
    },
    {
      "epoch": 0.2297970126388357,
      "grad_norm": 0.9609721899032593,
      "learning_rate": 4.9970954782568604e-05,
      "loss": 0.2302,
      "step": 150
    },
    {
      "epoch": 0.24511681348142475,
      "grad_norm": 0.9635885953903198,
      "learning_rate": 4.992973706938643e-05,
      "loss": 0.2133,
      "step": 160
    },
    {
      "epoch": 0.26043661432401377,
      "grad_norm": 0.745173990726471,
      "learning_rate": 4.9870638205686034e-05,
      "loss": 0.2243,
      "step": 170
    },
    {
      "epoch": 0.2757564151666028,
      "grad_norm": 1.7042262554168701,
      "learning_rate": 4.979370058083056e-05,
      "loss": 0.2389,
      "step": 180
    },
    {
      "epoch": 0.29107621600919187,
      "grad_norm": 1.269226312637329,
      "learning_rate": 4.96989793792468e-05,
      "loss": 0.2219,
      "step": 190
    },
    {
      "epoch": 0.3063960168517809,
      "grad_norm": 1.343726396560669,
      "learning_rate": 4.958654254084355e-05,
      "loss": 0.2128,
      "step": 200
    },
    {
      "epoch": 0.32171581769436997,
      "grad_norm": 1.024207353591919,
      "learning_rate": 4.94564707122809e-05,
      "loss": 0.221,
      "step": 210
    },
    {
      "epoch": 0.337035618536959,
      "grad_norm": 0.8098239302635193,
      "learning_rate": 4.9308857189125436e-05,
      "loss": 0.2175,
      "step": 220
    },
    {
      "epoch": 0.35235541937954806,
      "grad_norm": 0.7655194997787476,
      "learning_rate": 4.914380784893288e-05,
      "loss": 0.2095,
      "step": 230
    },
    {
      "epoch": 0.3676752202221371,
      "grad_norm": 1.1290600299835205,
      "learning_rate": 4.896144107530618e-05,
      "loss": 0.2,
      "step": 240
    },
    {
      "epoch": 0.38299502106472616,
      "grad_norm": 0.7295926809310913,
      "learning_rate": 4.8761887672983475e-05,
      "loss": 0.2348,
      "step": 250
    },
    {
      "epoch": 0.3983148219073152,
      "grad_norm": 0.8423998355865479,
      "learning_rate": 4.854529077401679e-05,
      "loss": 0.2071,
      "step": 260
    },
    {
      "epoch": 0.41363462274990426,
      "grad_norm": 0.8225303292274475,
      "learning_rate": 4.8311805735108894e-05,
      "loss": 0.2155,
      "step": 270
    },
    {
      "epoch": 0.4289544235924933,
      "grad_norm": 0.9868219494819641,
      "learning_rate": 4.806160002618188e-05,
      "loss": 0.1832,
      "step": 280
    },
    {
      "epoch": 0.44427422443508235,
      "grad_norm": 1.2097954750061035,
      "learning_rate": 4.779485311025732e-05,
      "loss": 0.2118,
      "step": 290
    },
    {
      "epoch": 0.4595940252776714,
      "grad_norm": 1.6588680744171143,
      "learning_rate": 4.751175631473433e-05,
      "loss": 0.2134,
      "step": 300
    },
    {
      "epoch": 0.47491382612026045,
      "grad_norm": 0.9164637327194214,
      "learning_rate": 4.7212512694157685e-05,
      "loss": 0.2176,
      "step": 310
    },
    {
      "epoch": 0.4902336269628495,
      "grad_norm": 0.7194947004318237,
      "learning_rate": 4.6897336884574526e-05,
      "loss": 0.2022,
      "step": 320
    },
    {
      "epoch": 0.5055534278054385,
      "grad_norm": 0.9182164669036865,
      "learning_rate": 4.656645494958415e-05,
      "loss": 0.1992,
      "step": 330
    },
    {
      "epoch": 0.5208732286480275,
      "grad_norm": 0.956055760383606,
      "learning_rate": 4.6220104218191126e-05,
      "loss": 0.1992,
      "step": 340
    },
    {
      "epoch": 0.5361930294906166,
      "grad_norm": 0.6748566031455994,
      "learning_rate": 4.585853311457831e-05,
      "loss": 0.2015,
      "step": 350
    },
    {
      "epoch": 0.5515128303332056,
      "grad_norm": 1.302582025527954,
      "learning_rate": 4.5482000979921604e-05,
      "loss": 0.1994,
      "step": 360
    },
    {
      "epoch": 0.5668326311757947,
      "grad_norm": 1.1102198362350464,
      "learning_rate": 4.509077788637446e-05,
      "loss": 0.1898,
      "step": 370
    },
    {
      "epoch": 0.5821524320183837,
      "grad_norm": 0.7776666879653931,
      "learning_rate": 4.468514444335534e-05,
      "loss": 0.2008,
      "step": 380
    },
    {
      "epoch": 0.5974722328609728,
      "grad_norm": 1.2003965377807617,
      "learning_rate": 4.426539159627733e-05,
      "loss": 0.2046,
      "step": 390
    },
    {
      "epoch": 0.6127920337035618,
      "grad_norm": 0.8310548067092896,
      "learning_rate": 4.3831820417864085e-05,
      "loss": 0.1767,
      "step": 400
    },
    {
      "epoch": 0.6281118345461509,
      "grad_norm": 0.953808605670929,
      "learning_rate": 4.338474189220178e-05,
      "loss": 0.2034,
      "step": 410
    },
    {
      "epoch": 0.6434316353887399,
      "grad_norm": 0.7623182535171509,
      "learning_rate": 4.2924476691682144e-05,
      "loss": 0.1933,
      "step": 420
    },
    {
      "epoch": 0.658751436231329,
      "grad_norm": 0.5695501565933228,
      "learning_rate": 4.245135494699631e-05,
      "loss": 0.2048,
      "step": 430
    },
    {
      "epoch": 0.674071237073918,
      "grad_norm": 1.0447826385498047,
      "learning_rate": 4.19657160103447e-05,
      "loss": 0.207,
      "step": 440
    },
    {
      "epoch": 0.6893910379165071,
      "grad_norm": 0.5755696892738342,
      "learning_rate": 4.146790821203258e-05,
      "loss": 0.2073,
      "step": 450
    },
    {
      "epoch": 0.7047108387590961,
      "grad_norm": 0.5836997032165527,
      "learning_rate": 4.095828861062603e-05,
      "loss": 0.1809,
      "step": 460
    },
    {
      "epoch": 0.7200306396016852,
      "grad_norm": 0.9583187699317932,
      "learning_rate": 4.043722273684744e-05,
      "loss": 0.2077,
      "step": 470
    },
    {
      "epoch": 0.7353504404442742,
      "grad_norm": 0.7788547873497009,
      "learning_rate": 3.9905084331394215e-05,
      "loss": 0.2048,
      "step": 480
    },
    {
      "epoch": 0.7506702412868632,
      "grad_norm": 0.7113845348358154,
      "learning_rate": 3.9362255076868895e-05,
      "loss": 0.1941,
      "step": 490
    },
    {
      "epoch": 0.7659900421294523,
      "grad_norm": 0.5732263922691345,
      "learning_rate": 3.880912432401265e-05,
      "loss": 0.2029,
      "step": 500
    },
    {
      "epoch": 0.7813098429720413,
      "grad_norm": 0.9615482687950134,
      "learning_rate": 3.824608881243893e-05,
      "loss": 0.1898,
      "step": 510
    },
    {
      "epoch": 0.7966296438146304,
      "grad_norm": 0.609192430973053,
      "learning_rate": 3.7673552386067216e-05,
      "loss": 0.2192,
      "step": 520
    },
    {
      "epoch": 0.8119494446572194,
      "grad_norm": 0.6910430192947388,
      "learning_rate": 3.709192570346114e-05,
      "loss": 0.1984,
      "step": 530
    },
    {
      "epoch": 0.8272692454998085,
      "grad_norm": 0.35179442167282104,
      "learning_rate": 3.6501625943278805e-05,
      "loss": 0.2129,
      "step": 540
    },
    {
      "epoch": 0.8425890463423975,
      "grad_norm": 0.6462786197662354,
      "learning_rate": 3.5903076505046376e-05,
      "loss": 0.1947,
      "step": 550
    },
    {
      "epoch": 0.8579088471849866,
      "grad_norm": 0.4741339683532715,
      "learning_rate": 3.5296706705469754e-05,
      "loss": 0.1853,
      "step": 560
    },
    {
      "epoch": 0.8732286480275756,
      "grad_norm": 1.0090683698654175,
      "learning_rate": 3.468295147050207e-05,
      "loss": 0.1953,
      "step": 570
    },
    {
      "epoch": 0.8885484488701647,
      "grad_norm": 1.0688704252243042,
      "learning_rate": 3.4062251023387827e-05,
      "loss": 0.1931,
      "step": 580
    },
    {
      "epoch": 0.9038682497127537,
      "grad_norm": 0.7813845872879028,
      "learning_rate": 3.34350505689076e-05,
      "loss": 0.2103,
      "step": 590
    },
    {
      "epoch": 0.9191880505553428,
      "grad_norm": 0.6599509119987488,
      "learning_rate": 3.280179997404958e-05,
      "loss": 0.2052,
      "step": 600
    },
    {
      "epoch": 0.9345078513979318,
      "grad_norm": 0.6459518671035767,
      "learning_rate": 3.2162953445337115e-05,
      "loss": 0.1903,
      "step": 610
    },
    {
      "epoch": 0.9498276522405209,
      "grad_norm": 0.7305079698562622,
      "learning_rate": 3.1518969203043694e-05,
      "loss": 0.1923,
      "step": 620
    },
    {
      "epoch": 0.9651474530831099,
      "grad_norm": 0.6279131770133972,
      "learning_rate": 3.0870309152529003e-05,
      "loss": 0.2141,
      "step": 630
    },
    {
      "epoch": 0.980467253925699,
      "grad_norm": 0.6205477714538574,
      "learning_rate": 3.02174385529318e-05,
      "loss": 0.1974,
      "step": 640
    },
    {
      "epoch": 0.995787054768288,
      "grad_norm": 0.6327049136161804,
      "learning_rate": 2.956082568345726e-05,
      "loss": 0.1861,
      "step": 650
    },
    {
      "epoch": 1.011106855610877,
      "grad_norm": 0.6574366092681885,
      "learning_rate": 2.890094150749818e-05,
      "loss": 0.1674,
      "step": 660
    },
    {
      "epoch": 1.026426656453466,
      "grad_norm": 0.6100617051124573,
      "learning_rate": 2.8238259334830818e-05,
      "loss": 0.1621,
      "step": 670
    },
    {
      "epoch": 1.041746457296055,
      "grad_norm": 1.128373622894287,
      "learning_rate": 2.757325448212788e-05,
      "loss": 0.1533,
      "step": 680
    },
    {
      "epoch": 1.0570662581386443,
      "grad_norm": 0.7852590680122375,
      "learning_rate": 2.690640393203197e-05,
      "loss": 0.1601,
      "step": 690
    },
    {
      "epoch": 1.0723860589812333,
      "grad_norm": 0.8472103476524353,
      "learning_rate": 2.6238185991034086e-05,
      "loss": 0.1575,
      "step": 700
    },
    {
      "epoch": 1.0877058598238223,
      "grad_norm": 0.5646933317184448,
      "learning_rate": 2.556907994640264e-05,
      "loss": 0.1407,
      "step": 710
    },
    {
      "epoch": 1.1030256606664113,
      "grad_norm": 1.126237154006958,
      "learning_rate": 2.4899565722408928e-05,
      "loss": 0.1609,
      "step": 720
    },
    {
      "epoch": 1.1183454615090005,
      "grad_norm": 0.7857115864753723,
      "learning_rate": 2.4230123536095748e-05,
      "loss": 0.1639,
      "step": 730
    },
    {
      "epoch": 1.1336652623515895,
      "grad_norm": 0.6585984826087952,
      "learning_rate": 2.3561233552836017e-05,
      "loss": 0.1386,
      "step": 740
    },
    {
      "epoch": 1.1489850631941785,
      "grad_norm": 0.7843055725097656,
      "learning_rate": 2.2893375541928446e-05,
      "loss": 0.1629,
      "step": 750
    },
    {
      "epoch": 1.1643048640367675,
      "grad_norm": 0.6831398606300354,
      "learning_rate": 2.2227028532477307e-05,
      "loss": 0.1429,
      "step": 760
    },
    {
      "epoch": 1.1796246648793565,
      "grad_norm": 0.8580158948898315,
      "learning_rate": 2.1562670469803078e-05,
      "loss": 0.1867,
      "step": 770
    },
    {
      "epoch": 1.1949444657219457,
      "grad_norm": 0.7103006839752197,
      "learning_rate": 2.0900777872630512e-05,
      "loss": 0.1595,
      "step": 780
    },
    {
      "epoch": 1.2102642665645347,
      "grad_norm": 0.9422827363014221,
      "learning_rate": 2.0241825491299897e-05,
      "loss": 0.1509,
      "step": 790
    },
    {
      "epoch": 1.2255840674071237,
      "grad_norm": 0.736231803894043,
      "learning_rate": 1.958628596724673e-05,
      "loss": 0.1465,
      "step": 800
    },
    {
      "epoch": 1.2409038682497127,
      "grad_norm": 1.3106803894042969,
      "learning_rate": 1.8934629493994005e-05,
      "loss": 0.1683,
      "step": 810
    },
    {
      "epoch": 1.2562236690923019,
      "grad_norm": 0.8298740386962891,
      "learning_rate": 1.8287323479900346e-05,
      "loss": 0.1616,
      "step": 820
    },
    {
      "epoch": 1.2715434699348909,
      "grad_norm": 1.142125129699707,
      "learning_rate": 1.764483221290578e-05,
      "loss": 0.1492,
      "step": 830
    },
    {
      "epoch": 1.2868632707774799,
      "grad_norm": 0.7558892965316772,
      "learning_rate": 1.7007616527515694e-05,
      "loss": 0.1691,
      "step": 840
    },
    {
      "epoch": 1.3021830716200689,
      "grad_norm": 0.8298987150192261,
      "learning_rate": 1.63761334742618e-05,
      "loss": 0.1597,
      "step": 850
    },
    {
      "epoch": 1.3175028724626578,
      "grad_norm": 0.6090266108512878,
      "learning_rate": 1.5750835991877198e-05,
      "loss": 0.1635,
      "step": 860
    },
    {
      "epoch": 1.332822673305247,
      "grad_norm": 0.8732883334159851,
      "learning_rate": 1.5132172582420712e-05,
      "loss": 0.1661,
      "step": 870
    },
    {
      "epoch": 1.348142474147836,
      "grad_norm": 0.6683341860771179,
      "learning_rate": 1.4520586989583406e-05,
      "loss": 0.1624,
      "step": 880
    },
    {
      "epoch": 1.363462274990425,
      "grad_norm": 1.0679725408554077,
      "learning_rate": 1.3916517880408152e-05,
      "loss": 0.1497,
      "step": 890
    },
    {
      "epoch": 1.3787820758330143,
      "grad_norm": 1.2812561988830566,
      "learning_rate": 1.332039853065055e-05,
      "loss": 0.1537,
      "step": 900
    },
    {
      "epoch": 1.3941018766756033,
      "grad_norm": 0.6871673464775085,
      "learning_rate": 1.2732656514006591e-05,
      "loss": 0.1529,
      "step": 910
    },
    {
      "epoch": 1.4094216775181923,
      "grad_norm": 1.2539845705032349,
      "learning_rate": 1.215371339543048e-05,
      "loss": 0.1713,
      "step": 920
    },
    {
      "epoch": 1.4247414783607812,
      "grad_norm": 0.7052391767501831,
      "learning_rate": 1.1583984428762077e-05,
      "loss": 0.1412,
      "step": 930
    },
    {
      "epoch": 1.4400612792033702,
      "grad_norm": 0.969052255153656,
      "learning_rate": 1.1023878258881142e-05,
      "loss": 0.1647,
      "step": 940
    },
    {
      "epoch": 1.4553810800459595,
      "grad_norm": 1.0292503833770752,
      "learning_rate": 1.0473796628601982e-05,
      "loss": 0.1732,
      "step": 950
    },
    {
      "epoch": 1.4707008808885484,
      "grad_norm": 0.693831741809845,
      "learning_rate": 9.934134090518593e-06,
      "loss": 0.1535,
      "step": 960
    },
    {
      "epoch": 1.4860206817311374,
      "grad_norm": 1.2244009971618652,
      "learning_rate": 9.405277724007117e-06,
      "loss": 0.1657,
      "step": 970
    },
    {
      "epoch": 1.5013404825737267,
      "grad_norm": 0.8653746843338013,
      "learning_rate": 8.887606857588585e-06,
      "loss": 0.1601,
      "step": 980
    },
    {
      "epoch": 1.5166602834163156,
      "grad_norm": 0.6809244751930237,
      "learning_rate": 8.38149279685101e-06,
      "loss": 0.1594,
      "step": 990
    },
    {
      "epoch": 1.5319800842589046,
      "grad_norm": 0.7624925374984741,
      "learning_rate": 7.887298558126007e-06,
      "loss": 0.1366,
      "step": 1000
    },
    {
      "epoch": 1.5472998851014936,
      "grad_norm": 0.5842053294181824,
      "learning_rate": 7.405378608111058e-06,
      "loss": 0.1504,
      "step": 1010
    },
    {
      "epoch": 1.5626196859440826,
      "grad_norm": 0.6974587440490723,
      "learning_rate": 6.936078609624022e-06,
      "loss": 0.1479,
      "step": 1020
    },
    {
      "epoch": 1.5779394867866716,
      "grad_norm": 1.3183828592300415,
      "learning_rate": 6.479735173672388e-06,
      "loss": 0.1362,
      "step": 1030
    },
    {
      "epoch": 1.5932592876292608,
      "grad_norm": 0.7352975606918335,
      "learning_rate": 6.036675618014992e-06,
      "loss": 0.1448,
      "step": 1040
    },
    {
      "epoch": 1.6085790884718498,
      "grad_norm": 0.6205036044120789,
      "learning_rate": 5.607217732389503e-06,
      "loss": 0.1472,
      "step": 1050
    },
    {
      "epoch": 1.623898889314439,
      "grad_norm": 0.7053846120834351,
      "learning_rate": 5.191669550573925e-06,
      "loss": 0.1439,
      "step": 1060
    },
    {
      "epoch": 1.639218690157028,
      "grad_norm": 0.9619417190551758,
      "learning_rate": 4.7903291294457034e-06,
      "loss": 0.1608,
      "step": 1070
    },
    {
      "epoch": 1.654538490999617,
      "grad_norm": 0.6850352883338928,
      "learning_rate": 4.4034843351969e-06,
      "loss": 0.1612,
      "step": 1080
    },
    {
      "epoch": 1.669858291842206,
      "grad_norm": 1.1007550954818726,
      "learning_rate": 4.031412636858745e-06,
      "loss": 0.1356,
      "step": 1090
    },
    {
      "epoch": 1.685178092684795,
      "grad_norm": 0.6824173927307129,
      "learning_rate": 3.674380907283631e-06,
      "loss": 0.1414,
      "step": 1100
    },
    {
      "epoch": 1.700497893527384,
      "grad_norm": 0.7168980240821838,
      "learning_rate": 3.3326452317274407e-06,
      "loss": 0.1474,
      "step": 1110
    },
    {
      "epoch": 1.7158176943699732,
      "grad_norm": 1.0029069185256958,
      "learning_rate": 3.006450724169324e-06,
      "loss": 0.1382,
      "step": 1120
    },
    {
      "epoch": 1.7311374952125622,
      "grad_norm": 1.1413991451263428,
      "learning_rate": 2.696031351500761e-06,
      "loss": 0.1538,
      "step": 1130
    },
    {
      "epoch": 1.7464572960551514,
      "grad_norm": 0.570212185382843,
      "learning_rate": 2.401609765710064e-06,
      "loss": 0.1554,
      "step": 1140
    },
    {
      "epoch": 1.7617770968977404,
      "grad_norm": 0.6554979085922241,
      "learning_rate": 2.1233971441825704e-06,
      "loss": 0.1431,
      "step": 1150
    },
    {
      "epoch": 1.7770968977403294,
      "grad_norm": 1.0494415760040283,
      "learning_rate": 1.861593038231138e-06,
      "loss": 0.1679,
      "step": 1160
    },
    {
      "epoch": 1.7924166985829184,
      "grad_norm": 0.973392128944397,
      "learning_rate": 1.616385229965614e-06,
      "loss": 0.122,
      "step": 1170
    },
    {
      "epoch": 1.8077364994255074,
      "grad_norm": 1.1483278274536133,
      "learning_rate": 1.3879495976038825e-06,
      "loss": 0.1446,
      "step": 1180
    },
    {
      "epoch": 1.8230563002680964,
      "grad_norm": 0.7410669326782227,
      "learning_rate": 1.1764499893210878e-06,
      "loss": 0.1328,
      "step": 1190
    },
    {
      "epoch": 1.8383761011106856,
      "grad_norm": 0.6322897672653198,
      "learning_rate": 9.820381057276228e-07,
      "loss": 0.1444,
      "step": 1200
    },
    {
      "epoch": 1.8536959019532746,
      "grad_norm": 1.1766966581344604,
      "learning_rate": 8.048533910600425e-07,
      "loss": 0.1488,
      "step": 1210
    },
    {
      "epoch": 1.8690157027958638,
      "grad_norm": 0.6873711943626404,
      "learning_rate": 6.450229331630253e-07,
      "loss": 0.1624,
      "step": 1220
    },
    {
      "epoch": 1.8843355036384528,
      "grad_norm": 0.7138863205909729,
      "learning_rate": 5.026613723340956e-07,
      "loss": 0.1586,
      "step": 1230
    },
    {
      "epoch": 1.8996553044810418,
      "grad_norm": 1.0477949380874634,
      "learning_rate": 3.778708190965291e-07,
      "loss": 0.1456,
      "step": 1240
    },
    {
      "epoch": 1.9149751053236308,
      "grad_norm": 0.9380642771720886,
      "learning_rate": 2.707407809593526e-07,
      "loss": 0.1586,
      "step": 1250
    },
    {
      "epoch": 1.9302949061662198,
      "grad_norm": 0.8919311165809631,
      "learning_rate": 1.8134809821701016e-07,
      "loss": 0.1337,
      "step": 1260
    },
    {
      "epoch": 1.9456147070088088,
      "grad_norm": 0.7403208017349243,
      "learning_rate": 1.0975688883476387e-07,
      "loss": 0.1482,
      "step": 1270
    },
    {
      "epoch": 1.9609345078513978,
      "grad_norm": 0.7523654699325562,
      "learning_rate": 5.60185024593124e-08,
      "loss": 0.1471,
      "step": 1280
    },
    {
      "epoch": 1.976254308693987,
      "grad_norm": 0.6812712550163269,
      "learning_rate": 2.0171483587638763e-08,
      "loss": 0.1554,
      "step": 1290
    },
    {
      "epoch": 1.991574109536576,
      "grad_norm": 0.705790638923645,
      "learning_rate": 2.2415439205281108e-09,
      "loss": 0.1309,
      "step": 1300
    }
  ],
  "logging_steps": 10,
  "max_steps": 1304,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 5000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 4.241845150875648e+16,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
