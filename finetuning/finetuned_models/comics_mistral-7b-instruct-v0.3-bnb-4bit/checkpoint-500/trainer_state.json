{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 2.280501710376283,
  "eval_steps": 500,
  "global_step": 500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.04561003420752566,
      "grad_norm": 5.310967922210693,
      "learning_rate": 5.303030303030304e-06,
      "loss": 0.9506,
      "step": 10
    },
    {
      "epoch": 0.09122006841505131,
      "grad_norm": 2.1282958984375,
      "learning_rate": 1.287878787878788e-05,
      "loss": 0.2465,
      "step": 20
    },
    {
      "epoch": 0.13683010262257697,
      "grad_norm": 1.611781120300293,
      "learning_rate": 2.0454545454545457e-05,
      "loss": 0.2207,
      "step": 30
    },
    {
      "epoch": 0.18244013683010263,
      "grad_norm": 1.1934083700180054,
      "learning_rate": 2.803030303030303e-05,
      "loss": 0.2148,
      "step": 40
    },
    {
      "epoch": 0.22805017103762829,
      "grad_norm": 0.8614120483398438,
      "learning_rate": 3.560606060606061e-05,
      "loss": 0.2016,
      "step": 50
    },
    {
      "epoch": 0.27366020524515394,
      "grad_norm": 0.4342690408229828,
      "learning_rate": 4.318181818181819e-05,
      "loss": 0.1916,
      "step": 60
    },
    {
      "epoch": 0.31927023945267957,
      "grad_norm": 2.592444658279419,
      "learning_rate": 4.999964678936299e-05,
      "loss": 0.191,
      "step": 70
    },
    {
      "epoch": 0.36488027366020526,
      "grad_norm": 1.3274668455123901,
      "learning_rate": 4.995727358814036e-05,
      "loss": 0.1832,
      "step": 80
    },
    {
      "epoch": 0.4104903078677309,
      "grad_norm": 0.7597790956497192,
      "learning_rate": 4.984439542929117e-05,
      "loss": 0.1962,
      "step": 90
    },
    {
      "epoch": 0.45610034207525657,
      "grad_norm": 1.5893025398254395,
      "learning_rate": 4.9661331196598085e-05,
      "loss": 0.2073,
      "step": 100
    },
    {
      "epoch": 0.5017103762827823,
      "grad_norm": 1.1281673908233643,
      "learning_rate": 4.940859805135771e-05,
      "loss": 0.194,
      "step": 110
    },
    {
      "epoch": 0.5473204104903079,
      "grad_norm": 0.6509718894958496,
      "learning_rate": 4.9086909971386305e-05,
      "loss": 0.1848,
      "step": 120
    },
    {
      "epoch": 0.5929304446978335,
      "grad_norm": 1.0859805345535278,
      "learning_rate": 4.869717573401354e-05,
      "loss": 0.1891,
      "step": 130
    },
    {
      "epoch": 0.6385404789053591,
      "grad_norm": 1.4156328439712524,
      "learning_rate": 4.824049634876253e-05,
      "loss": 0.1811,
      "step": 140
    },
    {
      "epoch": 0.6841505131128849,
      "grad_norm": 2.663027048110962,
      "learning_rate": 4.7718161946968835e-05,
      "loss": 0.176,
      "step": 150
    },
    {
      "epoch": 0.7297605473204105,
      "grad_norm": 1.7249364852905273,
      "learning_rate": 4.7131648137125316e-05,
      "loss": 0.1954,
      "step": 160
    },
    {
      "epoch": 0.7753705815279361,
      "grad_norm": 2.4650604724884033,
      "learning_rate": 4.648261183624914e-05,
      "loss": 0.1776,
      "step": 170
    },
    {
      "epoch": 0.8209806157354618,
      "grad_norm": 2.2528138160705566,
      "learning_rate": 4.577288658904741e-05,
      "loss": 0.1931,
      "step": 180
    },
    {
      "epoch": 0.8665906499429875,
      "grad_norm": 0.935441792011261,
      "learning_rate": 4.500447738810493e-05,
      "loss": 0.1801,
      "step": 190
    },
    {
      "epoch": 0.9122006841505131,
      "grad_norm": 2.151918411254883,
      "learning_rate": 4.417955500972706e-05,
      "loss": 0.189,
      "step": 200
    },
    {
      "epoch": 0.9578107183580388,
      "grad_norm": 1.9344651699066162,
      "learning_rate": 4.3300449881439375e-05,
      "loss": 0.185,
      "step": 210
    },
    {
      "epoch": 1.0034207525655645,
      "grad_norm": 1.7798781394958496,
      "learning_rate": 4.2369645498468235e-05,
      "loss": 0.1744,
      "step": 220
    },
    {
      "epoch": 1.0490307867730901,
      "grad_norm": 1.2330522537231445,
      "learning_rate": 4.138977140780114e-05,
      "loss": 0.1525,
      "step": 230
    },
    {
      "epoch": 1.0946408209806158,
      "grad_norm": 0.8659422397613525,
      "learning_rate": 4.0363595779647e-05,
      "loss": 0.1546,
      "step": 240
    },
    {
      "epoch": 1.1402508551881414,
      "grad_norm": 1.598244309425354,
      "learning_rate": 3.929401758728205e-05,
      "loss": 0.1509,
      "step": 250
    },
    {
      "epoch": 1.185860889395667,
      "grad_norm": 1.3346000909805298,
      "learning_rate": 3.818405841737381e-05,
      "loss": 0.1556,
      "step": 260
    },
    {
      "epoch": 1.2314709236031927,
      "grad_norm": 1.3494468927383423,
      "learning_rate": 3.7036853933918784e-05,
      "loss": 0.1586,
      "step": 270
    },
    {
      "epoch": 1.2770809578107183,
      "grad_norm": 1.7634214162826538,
      "learning_rate": 3.585564501990885e-05,
      "loss": 0.1459,
      "step": 280
    },
    {
      "epoch": 1.3226909920182441,
      "grad_norm": 0.9376296401023865,
      "learning_rate": 3.464376862175106e-05,
      "loss": 0.1692,
      "step": 290
    },
    {
      "epoch": 1.3683010262257698,
      "grad_norm": 0.8249356150627136,
      "learning_rate": 3.340464832230592e-05,
      "loss": 0.137,
      "step": 300
    },
    {
      "epoch": 1.4139110604332954,
      "grad_norm": 1.504684567451477,
      "learning_rate": 3.2141784669175226e-05,
      "loss": 0.1415,
      "step": 310
    },
    {
      "epoch": 1.459521094640821,
      "grad_norm": 1.4553254842758179,
      "learning_rate": 3.0858745285562596e-05,
      "loss": 0.1446,
      "step": 320
    },
    {
      "epoch": 1.5051311288483467,
      "grad_norm": 1.2197908163070679,
      "learning_rate": 2.95591547916436e-05,
      "loss": 0.1619,
      "step": 330
    },
    {
      "epoch": 1.5507411630558723,
      "grad_norm": 1.6478559970855713,
      "learning_rate": 2.8246684564917956e-05,
      "loss": 0.1394,
      "step": 340
    },
    {
      "epoch": 1.596351197263398,
      "grad_norm": 1.647627830505371,
      "learning_rate": 2.6925042368471016e-05,
      "loss": 0.1483,
      "step": 350
    },
    {
      "epoch": 1.6419612314709235,
      "grad_norm": 1.3886479139328003,
      "learning_rate": 2.5597961876445077e-05,
      "loss": 0.1497,
      "step": 360
    },
    {
      "epoch": 1.6875712656784492,
      "grad_norm": 1.195697546005249,
      "learning_rate": 2.4269192126311182e-05,
      "loss": 0.1507,
      "step": 370
    },
    {
      "epoch": 1.7331812998859748,
      "grad_norm": 1.121580719947815,
      "learning_rate": 2.2942486927739217e-05,
      "loss": 0.1234,
      "step": 380
    },
    {
      "epoch": 1.7787913340935004,
      "grad_norm": 1.0009547472000122,
      "learning_rate": 2.162159425798629e-05,
      "loss": 0.1656,
      "step": 390
    },
    {
      "epoch": 1.824401368301026,
      "grad_norm": 1.2812427282333374,
      "learning_rate": 2.0310245673761967e-05,
      "loss": 0.1463,
      "step": 400
    },
    {
      "epoch": 1.870011402508552,
      "grad_norm": 1.5760114192962646,
      "learning_rate": 1.9012145769481894e-05,
      "loss": 0.143,
      "step": 410
    },
    {
      "epoch": 1.9156214367160775,
      "grad_norm": 1.5484215021133423,
      "learning_rate": 1.7730961711690655e-05,
      "loss": 0.1516,
      "step": 420
    },
    {
      "epoch": 1.9612314709236032,
      "grad_norm": 1.021897554397583,
      "learning_rate": 1.6470312879219325e-05,
      "loss": 0.1407,
      "step": 430
    },
    {
      "epoch": 2.006841505131129,
      "grad_norm": 0.7905457615852356,
      "learning_rate": 1.523376063834461e-05,
      "loss": 0.1278,
      "step": 440
    },
    {
      "epoch": 2.0524515393386547,
      "grad_norm": 0.6724194288253784,
      "learning_rate": 1.4024798281834966e-05,
      "loss": 0.0817,
      "step": 450
    },
    {
      "epoch": 2.0980615735461803,
      "grad_norm": 1.1500585079193115,
      "learning_rate": 1.284684116030621e-05,
      "loss": 0.0707,
      "step": 460
    },
    {
      "epoch": 2.143671607753706,
      "grad_norm": 0.9571995735168457,
      "learning_rate": 1.1703217033765676e-05,
      "loss": 0.056,
      "step": 470
    },
    {
      "epoch": 2.1892816419612315,
      "grad_norm": 1.8537157773971558,
      "learning_rate": 1.0597156670602299e-05,
      "loss": 0.0689,
      "step": 480
    },
    {
      "epoch": 2.234891676168757,
      "grad_norm": 0.9335727691650391,
      "learning_rate": 9.531784720580483e-06,
      "loss": 0.0652,
      "step": 490
    },
    {
      "epoch": 2.280501710376283,
      "grad_norm": 0.9064439535140991,
      "learning_rate": 8.510110887621911e-06,
      "loss": 0.0659,
      "step": 500
    }
  ],
  "logging_steps": 10,
  "max_steps": 657,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 8.87940724073431e+16,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
