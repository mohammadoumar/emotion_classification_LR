{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 4.994298745724059,
  "eval_steps": 500,
  "global_step": 1095,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.04561003420752566,
      "grad_norm": 1.580163598060608,
      "learning_rate": 4.0909090909090915e-06,
      "loss": 1.0729,
      "step": 10
    },
    {
      "epoch": 0.09122006841505131,
      "grad_norm": 0.8702172040939331,
      "learning_rate": 8.636363636363637e-06,
      "loss": 0.3112,
      "step": 20
    },
    {
      "epoch": 0.13683010262257697,
      "grad_norm": 1.110647439956665,
      "learning_rate": 1.318181818181818e-05,
      "loss": 0.2868,
      "step": 30
    },
    {
      "epoch": 0.18244013683010263,
      "grad_norm": 0.48659709095954895,
      "learning_rate": 1.772727272727273e-05,
      "loss": 0.2538,
      "step": 40
    },
    {
      "epoch": 0.22805017103762829,
      "grad_norm": 0.530407190322876,
      "learning_rate": 2.2272727272727274e-05,
      "loss": 0.2504,
      "step": 50
    },
    {
      "epoch": 0.27366020524515394,
      "grad_norm": 0.6422861814498901,
      "learning_rate": 2.681818181818182e-05,
      "loss": 0.2407,
      "step": 60
    },
    {
      "epoch": 0.31927023945267957,
      "grad_norm": 0.961342453956604,
      "learning_rate": 3.1363636363636365e-05,
      "loss": 0.2514,
      "step": 70
    },
    {
      "epoch": 0.36488027366020526,
      "grad_norm": 0.7215344905853271,
      "learning_rate": 3.590909090909091e-05,
      "loss": 0.2433,
      "step": 80
    },
    {
      "epoch": 0.4104903078677309,
      "grad_norm": 0.6760740876197815,
      "learning_rate": 4.045454545454546e-05,
      "loss": 0.2355,
      "step": 90
    },
    {
      "epoch": 0.45610034207525657,
      "grad_norm": 1.4370101690292358,
      "learning_rate": 4.5e-05,
      "loss": 0.2433,
      "step": 100
    },
    {
      "epoch": 0.5017103762827823,
      "grad_norm": 0.694146990776062,
      "learning_rate": 4.9545454545454553e-05,
      "loss": 0.2399,
      "step": 110
    },
    {
      "epoch": 0.5473204104903079,
      "grad_norm": 0.8611969351768494,
      "learning_rate": 4.998970106077018e-05,
      "loss": 0.2353,
      "step": 120
    },
    {
      "epoch": 0.5929304446978335,
      "grad_norm": 0.9799940586090088,
      "learning_rate": 4.9954110683260805e-05,
      "loss": 0.233,
      "step": 130
    },
    {
      "epoch": 0.6385404789053591,
      "grad_norm": 0.7621191740036011,
      "learning_rate": 4.989313791265896e-05,
      "loss": 0.2272,
      "step": 140
    },
    {
      "epoch": 0.6841505131128849,
      "grad_norm": 2.0698180198669434,
      "learning_rate": 4.980684476819872e-05,
      "loss": 0.2198,
      "step": 150
    },
    {
      "epoch": 0.7297605473204105,
      "grad_norm": 1.0263961553573608,
      "learning_rate": 4.969531902405652e-05,
      "loss": 0.2481,
      "step": 160
    },
    {
      "epoch": 0.7753705815279361,
      "grad_norm": 1.1338846683502197,
      "learning_rate": 4.955867412007052e-05,
      "loss": 0.2298,
      "step": 170
    },
    {
      "epoch": 0.8209806157354618,
      "grad_norm": 0.9531588554382324,
      "learning_rate": 4.9397049046353874e-05,
      "loss": 0.2404,
      "step": 180
    },
    {
      "epoch": 0.8665906499429875,
      "grad_norm": 0.8634197115898132,
      "learning_rate": 4.921060820191908e-05,
      "loss": 0.2271,
      "step": 190
    },
    {
      "epoch": 0.9122006841505131,
      "grad_norm": 1.524478554725647,
      "learning_rate": 4.8999541227457514e-05,
      "loss": 0.2359,
      "step": 200
    },
    {
      "epoch": 0.9578107183580388,
      "grad_norm": 0.7397962212562561,
      "learning_rate": 4.8764062812443875e-05,
      "loss": 0.2331,
      "step": 210
    },
    {
      "epoch": 1.0034207525655645,
      "grad_norm": 0.6643184423446655,
      "learning_rate": 4.8504412476762105e-05,
      "loss": 0.2151,
      "step": 220
    },
    {
      "epoch": 1.0490307867730901,
      "grad_norm": 0.9598261117935181,
      "learning_rate": 4.822085432707465e-05,
      "loss": 0.2029,
      "step": 230
    },
    {
      "epoch": 1.0946408209806158,
      "grad_norm": 0.7213599681854248,
      "learning_rate": 4.791367678818299e-05,
      "loss": 0.2262,
      "step": 240
    },
    {
      "epoch": 1.1402508551881414,
      "grad_norm": 0.9227632880210876,
      "learning_rate": 4.7583192309652674e-05,
      "loss": 0.1944,
      "step": 250
    },
    {
      "epoch": 1.185860889395667,
      "grad_norm": 0.549265444278717,
      "learning_rate": 4.72297370480012e-05,
      "loss": 0.2022,
      "step": 260
    },
    {
      "epoch": 1.2314709236031927,
      "grad_norm": 0.9593155384063721,
      "learning_rate": 4.6853670524772174e-05,
      "loss": 0.2188,
      "step": 270
    },
    {
      "epoch": 1.2770809578107183,
      "grad_norm": 1.039747953414917,
      "learning_rate": 4.6455375260843316e-05,
      "loss": 0.2143,
      "step": 280
    },
    {
      "epoch": 1.3226909920182441,
      "grad_norm": 0.6327729225158691,
      "learning_rate": 4.6035256387340485e-05,
      "loss": 0.2365,
      "step": 290
    },
    {
      "epoch": 1.3683010262257698,
      "grad_norm": 0.7208497524261475,
      "learning_rate": 4.559374123355337e-05,
      "loss": 0.1965,
      "step": 300
    },
    {
      "epoch": 1.4139110604332954,
      "grad_norm": 0.8868591785430908,
      "learning_rate": 4.5131278892272e-05,
      "loss": 0.1971,
      "step": 310
    },
    {
      "epoch": 1.459521094640821,
      "grad_norm": 0.9225364327430725,
      "learning_rate": 4.4648339762986304e-05,
      "loss": 0.1936,
      "step": 320
    },
    {
      "epoch": 1.5051311288483467,
      "grad_norm": 0.6276835203170776,
      "learning_rate": 4.414541507341322e-05,
      "loss": 0.2188,
      "step": 330
    },
    {
      "epoch": 1.5507411630558723,
      "grad_norm": 1.0668315887451172,
      "learning_rate": 4.3623016379838145e-05,
      "loss": 0.1888,
      "step": 340
    },
    {
      "epoch": 1.596351197263398,
      "grad_norm": 0.8150675892829895,
      "learning_rate": 4.308167504677893e-05,
      "loss": 0.2024,
      "step": 350
    },
    {
      "epoch": 1.6419612314709235,
      "grad_norm": 0.8464752435684204,
      "learning_rate": 4.2521941706501625e-05,
      "loss": 0.2199,
      "step": 360
    },
    {
      "epoch": 1.6875712656784492,
      "grad_norm": 0.5767040252685547,
      "learning_rate": 4.194438569893784e-05,
      "loss": 0.2007,
      "step": 370
    },
    {
      "epoch": 1.7331812998859748,
      "grad_norm": 0.6820082664489746,
      "learning_rate": 4.1349594492573354e-05,
      "loss": 0.1788,
      "step": 380
    },
    {
      "epoch": 1.7787913340935004,
      "grad_norm": 0.7440627813339233,
      "learning_rate": 4.073817308689699e-05,
      "loss": 0.2122,
      "step": 390
    },
    {
      "epoch": 1.824401368301026,
      "grad_norm": 1.301208734512329,
      "learning_rate": 4.011074339701771e-05,
      "loss": 0.2071,
      "step": 400
    },
    {
      "epoch": 1.870011402508552,
      "grad_norm": 0.8337963223457336,
      "learning_rate": 3.946794362107563e-05,
      "loss": 0.1953,
      "step": 410
    },
    {
      "epoch": 1.9156214367160775,
      "grad_norm": 0.9601798057556152,
      "learning_rate": 3.881042759109064e-05,
      "loss": 0.2077,
      "step": 420
    },
    {
      "epoch": 1.9612314709236032,
      "grad_norm": 1.219799280166626,
      "learning_rate": 3.813886410790879e-05,
      "loss": 0.2102,
      "step": 430
    },
    {
      "epoch": 2.006841505131129,
      "grad_norm": 1.4213175773620605,
      "learning_rate": 3.7453936260922986e-05,
      "loss": 0.1942,
      "step": 440
    },
    {
      "epoch": 2.0524515393386547,
      "grad_norm": 1.101820468902588,
      "learning_rate": 3.675634073325981e-05,
      "loss": 0.1368,
      "step": 450
    },
    {
      "epoch": 2.0980615735461803,
      "grad_norm": 1.1719377040863037,
      "learning_rate": 3.604678709313941e-05,
      "loss": 0.1327,
      "step": 460
    },
    {
      "epoch": 2.143671607753706,
      "grad_norm": 0.943136990070343,
      "learning_rate": 3.532599707212906e-05,
      "loss": 0.126,
      "step": 470
    },
    {
      "epoch": 2.1892816419612315,
      "grad_norm": 0.9764398336410522,
      "learning_rate": 3.459470383102472e-05,
      "loss": 0.1201,
      "step": 480
    },
    {
      "epoch": 2.234891676168757,
      "grad_norm": 1.0832796096801758,
      "learning_rate": 3.385365121410706e-05,
      "loss": 0.1377,
      "step": 490
    },
    {
      "epoch": 2.280501710376283,
      "grad_norm": 0.8808876872062683,
      "learning_rate": 3.3103592992530816e-05,
      "loss": 0.1242,
      "step": 500
    },
    {
      "epoch": 2.3261117445838084,
      "grad_norm": 1.3920432329177856,
      "learning_rate": 3.234529209761676e-05,
      "loss": 0.1386,
      "step": 510
    },
    {
      "epoch": 2.371721778791334,
      "grad_norm": 0.8375263214111328,
      "learning_rate": 3.157951984482635e-05,
      "loss": 0.1321,
      "step": 520
    },
    {
      "epoch": 2.4173318129988597,
      "grad_norm": 1.0172014236450195,
      "learning_rate": 3.080705514920836e-05,
      "loss": 0.1228,
      "step": 530
    },
    {
      "epoch": 2.4629418472063853,
      "grad_norm": 1.1049469709396362,
      "learning_rate": 3.0028683733115415e-05,
      "loss": 0.1518,
      "step": 540
    },
    {
      "epoch": 2.508551881413911,
      "grad_norm": 1.1781359910964966,
      "learning_rate": 2.9245197326996515e-05,
      "loss": 0.1377,
      "step": 550
    },
    {
      "epoch": 2.5541619156214366,
      "grad_norm": 0.9393876194953918,
      "learning_rate": 2.845739286407821e-05,
      "loss": 0.1276,
      "step": 560
    },
    {
      "epoch": 2.5997719498289626,
      "grad_norm": 1.1438102722167969,
      "learning_rate": 2.7666071669753807e-05,
      "loss": 0.1339,
      "step": 570
    },
    {
      "epoch": 2.6453819840364883,
      "grad_norm": 1.2916569709777832,
      "learning_rate": 2.687203864650497e-05,
      "loss": 0.1334,
      "step": 580
    },
    {
      "epoch": 2.690992018244014,
      "grad_norm": 1.3457468748092651,
      "learning_rate": 2.6076101455184866e-05,
      "loss": 0.1484,
      "step": 590
    },
    {
      "epoch": 2.7366020524515395,
      "grad_norm": 1.4348034858703613,
      "learning_rate": 2.527906969349559e-05,
      "loss": 0.1412,
      "step": 600
    },
    {
      "epoch": 2.782212086659065,
      "grad_norm": 0.8910486102104187,
      "learning_rate": 2.44817540724955e-05,
      "loss": 0.1311,
      "step": 610
    },
    {
      "epoch": 2.827822120866591,
      "grad_norm": 1.3341463804244995,
      "learning_rate": 2.3684965591974083e-05,
      "loss": 0.1307,
      "step": 620
    },
    {
      "epoch": 2.8734321550741164,
      "grad_norm": 1.3846994638442993,
      "learning_rate": 2.2889514715533162e-05,
      "loss": 0.1437,
      "step": 630
    },
    {
      "epoch": 2.919042189281642,
      "grad_norm": 1.2517194747924805,
      "learning_rate": 2.2096210546213395e-05,
      "loss": 0.1342,
      "step": 640
    },
    {
      "epoch": 2.9646522234891677,
      "grad_norm": 1.6213784217834473,
      "learning_rate": 2.1305860003504862e-05,
      "loss": 0.1286,
      "step": 650
    },
    {
      "epoch": 3.0102622576966933,
      "grad_norm": 0.7674224376678467,
      "learning_rate": 2.051926700257852e-05,
      "loss": 0.1047,
      "step": 660
    },
    {
      "epoch": 3.055872291904219,
      "grad_norm": 0.6580281257629395,
      "learning_rate": 1.9737231636573594e-05,
      "loss": 0.0593,
      "step": 670
    },
    {
      "epoch": 3.1014823261117446,
      "grad_norm": 1.133698582649231,
      "learning_rate": 1.8960549362772617e-05,
      "loss": 0.0562,
      "step": 680
    },
    {
      "epoch": 3.14709236031927,
      "grad_norm": 1.5331412553787231,
      "learning_rate": 1.8190010193491867e-05,
      "loss": 0.0519,
      "step": 690
    },
    {
      "epoch": 3.192702394526796,
      "grad_norm": 2.159287691116333,
      "learning_rate": 1.7426397892510243e-05,
      "loss": 0.0562,
      "step": 700
    },
    {
      "epoch": 3.2383124287343215,
      "grad_norm": 2.288902759552002,
      "learning_rate": 1.6670489177853855e-05,
      "loss": 0.0479,
      "step": 710
    },
    {
      "epoch": 3.283922462941847,
      "grad_norm": 1.5178669691085815,
      "learning_rate": 1.5923052931747408e-05,
      "loss": 0.0522,
      "step": 720
    },
    {
      "epoch": 3.3295324971493727,
      "grad_norm": 1.708778738975525,
      "learning_rate": 1.5184849418535762e-05,
      "loss": 0.0401,
      "step": 730
    },
    {
      "epoch": 3.3751425313568983,
      "grad_norm": 1.1989943981170654,
      "learning_rate": 1.4456629511371345e-05,
      "loss": 0.0644,
      "step": 740
    },
    {
      "epoch": 3.420752565564424,
      "grad_norm": 0.8595945835113525,
      "learning_rate": 1.3739133928453885e-05,
      "loss": 0.0365,
      "step": 750
    },
    {
      "epoch": 3.4663625997719496,
      "grad_norm": 1.6542439460754395,
      "learning_rate": 1.3033092479599452e-05,
      "loss": 0.0604,
      "step": 760
    },
    {
      "epoch": 3.5119726339794752,
      "grad_norm": 1.1884499788284302,
      "learning_rate": 1.2339223323905025e-05,
      "loss": 0.0591,
      "step": 770
    },
    {
      "epoch": 3.557582668187001,
      "grad_norm": 1.5559431314468384,
      "learning_rate": 1.1658232239263815e-05,
      "loss": 0.0502,
      "step": 780
    },
    {
      "epoch": 3.603192702394527,
      "grad_norm": 0.6141040325164795,
      "learning_rate": 1.099081190447418e-05,
      "loss": 0.0646,
      "step": 790
    },
    {
      "epoch": 3.6488027366020526,
      "grad_norm": 1.032900094985962,
      "learning_rate": 1.0337641194672606e-05,
      "loss": 0.0547,
      "step": 800
    },
    {
      "epoch": 3.694412770809578,
      "grad_norm": 0.8023449182510376,
      "learning_rate": 9.699384490807112e-06,
      "loss": 0.0413,
      "step": 810
    },
    {
      "epoch": 3.740022805017104,
      "grad_norm": 1.4044578075408936,
      "learning_rate": 9.076691003853666e-06,
      "loss": 0.0497,
      "step": 820
    },
    {
      "epoch": 3.7856328392246295,
      "grad_norm": 1.9957215785980225,
      "learning_rate": 8.470194114462965e-06,
      "loss": 0.0425,
      "step": 830
    },
    {
      "epoch": 3.831242873432155,
      "grad_norm": 1.0574150085449219,
      "learning_rate": 7.880510728709176e-06,
      "loss": 0.0685,
      "step": 840
    },
    {
      "epoch": 3.8768529076396807,
      "grad_norm": 0.8267974257469177,
      "learning_rate": 7.30824065059603e-06,
      "loss": 0.037,
      "step": 850
    },
    {
      "epoch": 3.9224629418472063,
      "grad_norm": 2.3382482528686523,
      "learning_rate": 6.753965971958487e-06,
      "loss": 0.0748,
      "step": 860
    },
    {
      "epoch": 3.968072976054732,
      "grad_norm": 1.0347257852554321,
      "learning_rate": 6.218250480380611e-06,
      "loss": 0.0506,
      "step": 870
    },
    {
      "epoch": 4.013683010262258,
      "grad_norm": 0.42033088207244873,
      "learning_rate": 5.701639085731786e-06,
      "loss": 0.0357,
      "step": 880
    },
    {
      "epoch": 4.059293044469784,
      "grad_norm": 0.4310837388038635,
      "learning_rate": 5.204657265904664e-06,
      "loss": 0.0178,
      "step": 890
    },
    {
      "epoch": 4.104903078677309,
      "grad_norm": 0.17468658089637756,
      "learning_rate": 4.7278105323186245e-06,
      "loss": 0.0128,
      "step": 900
    },
    {
      "epoch": 4.150513112884835,
      "grad_norm": 0.9971967339515686,
      "learning_rate": 4.271583915732338e-06,
      "loss": 0.0216,
      "step": 910
    },
    {
      "epoch": 4.196123147092361,
      "grad_norm": 0.45355334877967834,
      "learning_rate": 3.836441472888541e-06,
      "loss": 0.0174,
      "step": 920
    },
    {
      "epoch": 4.241733181299886,
      "grad_norm": 0.9375960826873779,
      "learning_rate": 3.4228258144927584e-06,
      "loss": 0.0178,
      "step": 930
    },
    {
      "epoch": 4.287343215507412,
      "grad_norm": 0.18542416393756866,
      "learning_rate": 3.0311576550061864e-06,
      "loss": 0.0147,
      "step": 940
    },
    {
      "epoch": 4.3329532497149374,
      "grad_norm": 0.6789292693138123,
      "learning_rate": 2.6618353847105705e-06,
      "loss": 0.0185,
      "step": 950
    },
    {
      "epoch": 4.378563283922463,
      "grad_norm": 0.508851170539856,
      "learning_rate": 2.315234664480448e-06,
      "loss": 0.016,
      "step": 960
    },
    {
      "epoch": 4.424173318129989,
      "grad_norm": 0.35246336460113525,
      "learning_rate": 1.9917080436748616e-06,
      "loss": 0.0141,
      "step": 970
    },
    {
      "epoch": 4.469783352337514,
      "grad_norm": 2.18599534034729,
      "learning_rate": 1.6915846015372855e-06,
      "loss": 0.0198,
      "step": 980
    },
    {
      "epoch": 4.51539338654504,
      "grad_norm": 0.5568529963493347,
      "learning_rate": 1.4151696124684504e-06,
      "loss": 0.0163,
      "step": 990
    },
    {
      "epoch": 4.561003420752566,
      "grad_norm": 0.3443372845649719,
      "learning_rate": 1.1627442355125834e-06,
      "loss": 0.0129,
      "step": 1000
    },
    {
      "epoch": 4.606613454960091,
      "grad_norm": 2.0325405597686768,
      "learning_rate": 9.345652283728828e-07,
      "loss": 0.0164,
      "step": 1010
    },
    {
      "epoch": 4.652223489167617,
      "grad_norm": 0.6573944687843323,
      "learning_rate": 7.308646862471319e-07,
      "loss": 0.0111,
      "step": 1020
    },
    {
      "epoch": 4.6978335233751425,
      "grad_norm": 1.21341073513031,
      "learning_rate": 5.518498057491161e-07,
      "loss": 0.0089,
      "step": 1030
    },
    {
      "epoch": 4.743443557582668,
      "grad_norm": 0.5673666000366211,
      "learning_rate": 3.977026741559087e-07,
      "loss": 0.0107,
      "step": 1040
    },
    {
      "epoch": 4.789053591790194,
      "grad_norm": 0.22612875699996948,
      "learning_rate": 2.6858008419548e-07,
      "loss": 0.0193,
      "step": 1050
    },
    {
      "epoch": 4.834663625997719,
      "grad_norm": 0.108315609395504,
      "learning_rate": 1.6461337456297187e-07,
      "loss": 0.0128,
      "step": 1060
    },
    {
      "epoch": 4.880273660205245,
      "grad_norm": 0.663193941116333,
      "learning_rate": 8.590829632785513e-08,
      "loss": 0.0216,
      "step": 1070
    },
    {
      "epoch": 4.925883694412771,
      "grad_norm": 1.8151670694351196,
      "learning_rate": 3.2544905367876134e-08,
      "loss": 0.0137,
      "step": 1080
    },
    {
      "epoch": 4.971493728620296,
      "grad_norm": 0.8494712114334106,
      "learning_rate": 4.577480939194079e-09,
      "loss": 0.0174,
      "step": 1090
    }
  ],
  "logging_steps": 10,
  "max_steps": 1095,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 3000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1.8529743877544346e+17,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
