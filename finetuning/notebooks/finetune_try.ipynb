{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ast\n",
    "import sys\n",
    "import json\n",
    "import torch\n",
    "import pickle\n",
    "import subprocess\n",
    "\n",
    "sys.path.append('../')\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from llamafactory.chat import ChatModel\n",
    "from llamafactory.extras.misc import torch_gc\n",
    "from sklearn.metrics import classification_report\n",
    "#from utils.post_processing import post_process\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:    \n",
    "    assert torch.cuda.is_available() is True\n",
    "    \n",
    "except AssertionError:\n",
    "    \n",
    "    print(\"Please set up a GPU before using LLaMA Factory...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CURRENT_DIR = Path.cwd()\n",
    "FT_DIR = CURRENT_DIR / \"emotion_analysis_comics\" / \"finetuning\"\n",
    "DATASET_DIR = CURRENT_DIR / \"emotion_analysis_comics\" / \"finetuning\" / \"datasets\"\n",
    "\n",
    "ERC_DIR = FT_DIR.parent\n",
    "LLAMA_FACTORY_DIR = ERC_DIR / \"LLaMA-Factory\"\n",
    "\n",
    "BASE_MODEL = \"unsloth/llama-3-8b-Instruct-bnb-4bit\"\n",
    "LOGGING_DIR = FT_DIR / \"training_logs\"\n",
    "OUTPUT_DIR = FT_DIR / \"saved_models\" / f\"\"\"comics35_pg_nb_xx_{BASE_MODEL.split(\"/\")[1]}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_DIR = CURRENT_DIR / \"emotion_analysis_comics\" / \"finetuning\" / \"datasets\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_name = f\"\"\"comics35_utterance_pg_classp_train.json\"\"\"\n",
    "test_dataset_name = f\"\"\"comics35_utterance_pg_classp_test.json\"\"\"\n",
    "\n",
    "train_dataset_file = DATASET_DIR / train_dataset_name\n",
    "test_dataset_file = DATASET_DIR / test_dataset_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/Utilisateurs/umushtaq/emotion_analysis_comics/finetuning/datasets/comics35_utterance_pg_classp_train.json')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if not os.path.exists(os.path.join(FT_DIR, \"model_args\")):\n",
    "    os.mkdir(os.path.join(FT_DIR, \"model_args\"))\n",
    "\n",
    "train_file = FT_DIR / \"model_args\" / f\"\"\"{train_dataset_name.split(\".\")[0].split(\"train\")[0]}{BASE_MODEL.split(\"/\")[1]}.json\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_info_line =  {\n",
    "  \"file_name\": f\"{train_dataset_file}\",\n",
    "  \"columns\": {\n",
    "    \"prompt\": \"instruction\",\n",
    "    \"query\": \"input\",\n",
    "    \"response\": \"output\"\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(LLAMA_FACTORY_DIR, \"data/dataset_info.json\"), \"r\") as jsonFile:\n",
    "    data = json.load(jsonFile)\n",
    "\n",
    "data[\"comics\"] = dataset_info_line\n",
    "\n",
    "with open(os.path.join(LLAMA_FACTORY_DIR, \"data/dataset_info.json\"), \"w\") as jsonFile:\n",
    "    json.dump(data, jsonFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_EPOCHS = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = dict(\n",
    "    \n",
    "  stage=\"sft\",                           # do supervised fine-tuning\n",
    "  do_train=True,\n",
    "\n",
    "  model_name_or_path=BASE_MODEL,         # use bnb-4bit-quantized Llama-3-8B-Instruct model\n",
    "  num_train_epochs=NB_EPOCHS,            # the epochs of training\n",
    "  output_dir=str(OUTPUT_DIR),                 # the path to save LoRA adapters\n",
    "  overwrite_output_dir=True,             # overrides existing output contents\n",
    "\n",
    "  dataset=\"comics\",                      # dataset name\n",
    "  template=\"llama3\",                     # use llama3 prompt template\n",
    "  train_on_prompt=True,\n",
    "  val_size=0.1,\n",
    "  max_samples=10000,                       # use 500 examples in each dataset\n",
    "\n",
    "  finetuning_type=\"lora\",                # use LoRA adapters to save memory\n",
    "  lora_target=\"all\",                     # attach LoRA adapters to all linear layers\n",
    "  per_device_train_batch_size=2,         # the batch size\n",
    "  gradient_accumulation_steps=4,         # the gradient accumulation steps\n",
    "  lr_scheduler_type=\"cosine\",            # use cosine learning rate scheduler\n",
    "  loraplus_lr_ratio=16.0,                # use LoRA+ algorithm with lambda=16.0\n",
    "  #temperature=0.5,\n",
    "  \n",
    "  warmup_ratio=0.1,                      # use warmup scheduler    \n",
    "  learning_rate=5e-5,                    # the learning rate\n",
    "  max_grad_norm=1.0,                     # clip gradient norm to 1.0\n",
    "  \n",
    "  fp16=True,                             # use float16 mixed precision training\n",
    "  quantization_bit=4,                    # use 4-bit QLoRA  \n",
    "  #use_liger_kernel=True,\n",
    "  #quantization_device_map=\"auto\",\n",
    "  \n",
    "  #load_best_model_at_end=True,\n",
    "  #metric_for_best_model=\"eval_loss\",\n",
    "  #save_strategy=\"epoch\",\n",
    "  #eval_strategy=\"epoch\",\n",
    "  logging_steps=10,                      # log every 10 steps\n",
    "  save_steps=5000,                       # save checkpoint every 1000 steps    \n",
    "  logging_dir=str(LOGGING_DIR),\n",
    "  \n",
    "  #use_unsloth=True,\n",
    "  report_to=\"tensorboard\"                       # discards wandb\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(args, open(train_file, \"w\", encoding=\"utf-8\"), indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = subprocess.Popen([\"llamafactory-cli\", \"train\", train_file], cwd=LLAMA_FACTORY_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/14/2024 13:38:42 - INFO - llamafactory.cli - Initializing distributed tasks at: 127.0.0.1:27359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1114 13:38:43.527000 140616479401280 torch/distributed/run.py:779] \n",
      "W1114 13:38:43.527000 140616479401280 torch/distributed/run.py:779] *****************************************\n",
      "W1114 13:38:43.527000 140616479401280 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "W1114 13:38:43.527000 140616479401280 torch/distributed/run.py:779] *****************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/14/2024 13:38:49 - WARNING - llamafactory.hparams.parser - We recommend enable `upcast_layernorm` in quantized training.\n",
      "11/14/2024 13:38:49 - WARNING - llamafactory.hparams.parser - `ddp_find_unused_parameters` needs to be set as False for LoRA in DDP training.\n",
      "11/14/2024 13:38:49 - INFO - llamafactory.hparams.parser - Process rank: 0, device: cuda:0, n_gpu: 1, distributed training: True, compute dtype: torch.float16\n",
      "11/14/2024 13:38:49 - WARNING - llamafactory.hparams.parser - We recommend enable `upcast_layernorm` in quantized training.\n",
      "11/14/2024 13:38:49 - WARNING - llamafactory.hparams.parser - `ddp_find_unused_parameters` needs to be set as False for LoRA in DDP training.\n",
      "11/14/2024 13:38:49 - INFO - llamafactory.hparams.parser - Process rank: 1, device: cuda:1, n_gpu: 1, distributed training: True, compute dtype: torch.float16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|configuration_utils.py:672] 2024-11-14 13:38:49,277 >> loading configuration file config.json from cache at /Utilisateurs/umushtaq/.cache/huggingface/hub/models--unsloth--llama-3-8b-Instruct-bnb-4bit/snapshots/f296897830363557c84cc4a942c2cd1f91818ae4/config.json\n",
      "[INFO|configuration_utils.py:739] 2024-11-14 13:38:49,277 >> Model config LlamaConfig {\n",
      "  \"_name_or_path\": \"unsloth/llama-3-8b-Instruct-bnb-4bit\",\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 128000,\n",
      "  \"eos_token_id\": 128009,\n",
      "  \"head_dim\": 128,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 4096,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 14336,\n",
      "  \"max_position_embeddings\": 8192,\n",
      "  \"mlp_bias\": false,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"num_key_value_heads\": 8,\n",
      "  \"pad_token_id\": 128255,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"quantization_config\": {\n",
      "    \"_load_in_4bit\": true,\n",
      "    \"_load_in_8bit\": false,\n",
      "    \"bnb_4bit_compute_dtype\": \"bfloat16\",\n",
      "    \"bnb_4bit_quant_storage\": \"uint8\",\n",
      "    \"bnb_4bit_quant_type\": \"nf4\",\n",
      "    \"bnb_4bit_use_double_quant\": true,\n",
      "    \"llm_int8_enable_fp32_cpu_offload\": false,\n",
      "    \"llm_int8_has_fp16_weight\": false,\n",
      "    \"llm_int8_skip_modules\": null,\n",
      "    \"llm_int8_threshold\": 6.0,\n",
      "    \"load_in_4bit\": true,\n",
      "    \"load_in_8bit\": false,\n",
      "    \"quant_method\": \"bitsandbytes\"\n",
      "  },\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 500000.0,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.45.0\",\n",
      "  \"unsloth_version\": \"2024.9\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 128256\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:2214] 2024-11-14 13:38:49,404 >> loading file tokenizer.json from cache at /Utilisateurs/umushtaq/.cache/huggingface/hub/models--unsloth--llama-3-8b-Instruct-bnb-4bit/snapshots/f296897830363557c84cc4a942c2cd1f91818ae4/tokenizer.json\n",
      "[INFO|tokenization_utils_base.py:2214] 2024-11-14 13:38:49,404 >> loading file tokenizer.model from cache at None\n",
      "[INFO|tokenization_utils_base.py:2214] 2024-11-14 13:38:49,404 >> loading file added_tokens.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:2214] 2024-11-14 13:38:49,404 >> loading file special_tokens_map.json from cache at /Utilisateurs/umushtaq/.cache/huggingface/hub/models--unsloth--llama-3-8b-Instruct-bnb-4bit/snapshots/f296897830363557c84cc4a942c2cd1f91818ae4/special_tokens_map.json\n",
      "[INFO|tokenization_utils_base.py:2214] 2024-11-14 13:38:49,404 >> loading file tokenizer_config.json from cache at /Utilisateurs/umushtaq/.cache/huggingface/hub/models--unsloth--llama-3-8b-Instruct-bnb-4bit/snapshots/f296897830363557c84cc4a942c2cd1f91818ae4/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2478] 2024-11-14 13:38:49,796 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "[INFO|configuration_utils.py:672] 2024-11-14 13:38:50,329 >> loading configuration file config.json from cache at /Utilisateurs/umushtaq/.cache/huggingface/hub/models--unsloth--llama-3-8b-Instruct-bnb-4bit/snapshots/f296897830363557c84cc4a942c2cd1f91818ae4/config.json\n",
      "[INFO|configuration_utils.py:739] 2024-11-14 13:38:50,330 >> Model config LlamaConfig {\n",
      "  \"_name_or_path\": \"unsloth/llama-3-8b-Instruct-bnb-4bit\",\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 128000,\n",
      "  \"eos_token_id\": 128009,\n",
      "  \"head_dim\": 128,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 4096,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 14336,\n",
      "  \"max_position_embeddings\": 8192,\n",
      "  \"mlp_bias\": false,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"num_key_value_heads\": 8,\n",
      "  \"pad_token_id\": 128255,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"quantization_config\": {\n",
      "    \"_load_in_4bit\": true,\n",
      "    \"_load_in_8bit\": false,\n",
      "    \"bnb_4bit_compute_dtype\": \"bfloat16\",\n",
      "    \"bnb_4bit_quant_storage\": \"uint8\",\n",
      "    \"bnb_4bit_quant_type\": \"nf4\",\n",
      "    \"bnb_4bit_use_double_quant\": true,\n",
      "    \"llm_int8_enable_fp32_cpu_offload\": false,\n",
      "    \"llm_int8_has_fp16_weight\": false,\n",
      "    \"llm_int8_skip_modules\": null,\n",
      "    \"llm_int8_threshold\": 6.0,\n",
      "    \"load_in_4bit\": true,\n",
      "    \"load_in_8bit\": false,\n",
      "    \"quant_method\": \"bitsandbytes\"\n",
      "  },\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 500000.0,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.45.0\",\n",
      "  \"unsloth_version\": \"2024.9\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 128256\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:2214] 2024-11-14 13:38:50,518 >> loading file tokenizer.json from cache at /Utilisateurs/umushtaq/.cache/huggingface/hub/models--unsloth--llama-3-8b-Instruct-bnb-4bit/snapshots/f296897830363557c84cc4a942c2cd1f91818ae4/tokenizer.json\n",
      "[INFO|tokenization_utils_base.py:2214] 2024-11-14 13:38:50,518 >> loading file tokenizer.model from cache at None\n",
      "[INFO|tokenization_utils_base.py:2214] 2024-11-14 13:38:50,519 >> loading file added_tokens.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:2214] 2024-11-14 13:38:50,519 >> loading file special_tokens_map.json from cache at /Utilisateurs/umushtaq/.cache/huggingface/hub/models--unsloth--llama-3-8b-Instruct-bnb-4bit/snapshots/f296897830363557c84cc4a942c2cd1f91818ae4/special_tokens_map.json\n",
      "[INFO|tokenization_utils_base.py:2214] 2024-11-14 13:38:50,519 >> loading file tokenizer_config.json from cache at /Utilisateurs/umushtaq/.cache/huggingface/hub/models--unsloth--llama-3-8b-Instruct-bnb-4bit/snapshots/f296897830363557c84cc4a942c2cd1f91818ae4/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2478] 2024-11-14 13:38:51,099 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/14/2024 13:38:51 - INFO - llamafactory.data.template - Replace eos token: <|eot_id|>\n",
      "11/14/2024 13:38:51 - INFO - llamafactory.data.loader - Loading dataset /Utilisateurs/umushtaq/emotion_analysis_comics/finetuning/datasets/comics35_utterance_pg_classp_train.json...\n",
      "11/14/2024 13:38:51 - INFO - llamafactory.data.template - Replace eos token: <|eot_id|>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting format of dataset: 100%|██████████| 718/718 [00:00<00:00, 7965.34 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/14/2024 13:38:53 - INFO - llamafactory.data.loader - Loading dataset /Utilisateurs/umushtaq/emotion_analysis_comics/finetuning/datasets/comics35_utterance_pg_classp_train.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running tokenizer on dataset: 100%|██████████| 718/718 [00:01<00:00, 696.34 examples/s]\n",
      "[INFO|configuration_utils.py:672] 2024-11-14 13:38:54,305 >> loading configuration file config.json from cache at /Utilisateurs/umushtaq/.cache/huggingface/hub/models--unsloth--llama-3-8b-Instruct-bnb-4bit/snapshots/f296897830363557c84cc4a942c2cd1f91818ae4/config.json\n",
      "[INFO|configuration_utils.py:739] 2024-11-14 13:38:54,305 >> Model config LlamaConfig {\n",
      "  \"_name_or_path\": \"unsloth/llama-3-8b-Instruct-bnb-4bit\",\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 128000,\n",
      "  \"eos_token_id\": 128009,\n",
      "  \"head_dim\": 128,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 4096,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 14336,\n",
      "  \"max_position_embeddings\": 8192,\n",
      "  \"mlp_bias\": false,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"num_key_value_heads\": 8,\n",
      "  \"pad_token_id\": 128255,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"quantization_config\": {\n",
      "    \"_load_in_4bit\": true,\n",
      "    \"_load_in_8bit\": false,\n",
      "    \"bnb_4bit_compute_dtype\": \"bfloat16\",\n",
      "    \"bnb_4bit_quant_storage\": \"uint8\",\n",
      "    \"bnb_4bit_quant_type\": \"nf4\",\n",
      "    \"bnb_4bit_use_double_quant\": true,\n",
      "    \"llm_int8_enable_fp32_cpu_offload\": false,\n",
      "    \"llm_int8_has_fp16_weight\": false,\n",
      "    \"llm_int8_skip_modules\": null,\n",
      "    \"llm_int8_threshold\": 6.0,\n",
      "    \"load_in_4bit\": true,\n",
      "    \"load_in_8bit\": false,\n",
      "    \"quant_method\": \"bitsandbytes\"\n",
      "  },\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 500000.0,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.45.0\",\n",
      "  \"unsloth_version\": \"2024.9\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 128256\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training example:\n",
      "input_ids:\n",
      "[128000, 128006, 882, 128007, 271, 14711, 5867, 6082, 18825, 33257, 15766, 271, 2675, 527, 459, 11084, 20356, 6492, 6335, 58394, 304, 20303, 2363, 21976, 23692, 13, 4718, 3465, 374, 311, 24564, 22256, 3095, 323, 10765, 872, 14604, 2262, 382, 30521, 512, 12, 1472, 690, 5371, 264, 1160, 315, 22256, 3095, 505, 264, 2199, 304, 264, 20303, 2363, 198, 12, 578, 22256, 685, 1253, 3237, 832, 477, 5361, 21958, 271, 66913, 512, 16, 13, 10852, 3725, 24564, 279, 14604, 2317, 323, 16630, 315, 1855, 22256, 685, 304, 279, 2199, 198, 17, 13, 65647, 8581, 21958, 505, 279, 2768, 6989, 512, 256, 330, 4091, 498, 330, 4338, 70, 592, 498, 330, 69, 686, 498, 330, 83214, 2136, 498, 330, 20370, 9868, 498, 330, 4215, 498, 330, 60668, 702, 18, 13, 1789, 1855, 22256, 685, 304, 264, 20303, 2199, 11, 10765, 682, 21958, 3118, 323, 471, 459, 1358, 315, 20356, 18893, 304, 2015, 382, 1999, 35009, 304, 16543, 2956, 512, 12, 19788, 25, 220, 1419, 13, 15, 14062, 12, 68162, 25, 220, 18, 13, 18, 14062, 12, 8850, 25, 220, 1114, 13, 15, 14062, 12, 51978, 25, 220, 1114, 13, 15, 14062, 12, 13051, 25, 220, 972, 13, 15, 14062, 12, 16267, 25, 220, 1114, 13, 15, 14062, 12, 21277, 25, 220, 19, 13, 15, 15804, 99843, 25, 21829, 1521, 538, 34873, 994, 3339, 11429, 1418, 20958, 13708, 627, 1084, 93016, 50, 512, 16, 13, 5560, 27785, 279, 9382, 10212, 3485, 198, 17, 13, 9442, 2011, 387, 264, 4823, 449, 3254, 1401, 330, 2964, 62, 6339, 685, 23319, 41356, 702, 18, 13, 5273, 2011, 387, 459, 1358, 1405, 512, 256, 482, 9062, 2449, 374, 459, 1358, 315, 21958, 369, 832, 22256, 685, 198, 256, 482, 7365, 9248, 279, 1988, 22256, 3095, 2015, 198, 256, 482, 29911, 21958, 527, 5535, 824, 22256, 685, 198, 19, 13, 2360, 41941, 11, 1193, 4823, 2612, 271, 99843, 512, 12, 9062, 1358, 2449, 34310, 311, 832, 22256, 685, 198, 12, 3861, 22256, 685, 649, 617, 5361, 21958, 198, 12, 87477, 4839, 43529, 323, 1162, 315, 20356, 9382, 198, 12, 13969, 21958, 304, 18893, 1524, 369, 3254, 21958, 271, 7184, 24564, 1521, 22256, 3095, 505, 264, 2199, 304, 264, 29159, 2363, 512, 16, 13, 10245, 650, 3015, 4534, 1753, 99550, 1507, 3247, 50297, 7354, 6483, 50, 3083, 18725, 6570, 6005, 50, 1981, 720, 17, 13, 4696, 8871, 393, 1899, 35457, 18725, 7354, 58376, 2843, 1112, 25832, 1750, 6486, 1981, 3651, 23214, 8871, 7354, 16929, 4716, 61094, 627, 18, 13, 18725, 72297, 4999, 19, 13, 54233, 4999, 20, 13, 11155, 358, 19102, 4276, 6969, 4157, 35, 10245, 29637, 39023, 13398, 10245, 25404, 5257, 36757, 8871, 480, 1308, 12073, 4999, 21, 13, 11947, 984, 386, 33937, 4999, 22, 13, 358, 19102, 7837, 36, 5257, 3501, 48, 313, 4999, 23, 13, 38535, 7233, 24, 13, 1198, 1669, 26336, 30, 4999, 605, 13, 5782, 0, 5782, 0, 128009, 128006, 78191, 128007, 271, 5018, 2964, 62, 6339, 685, 23319, 41356, 794, 79786, 4091, 8073, 4482, 4091, 8073, 4482, 69, 686, 8073, 4482, 69, 686, 8073, 4482, 69, 686, 498, 330, 83214, 2136, 8073, 4482, 83214, 2136, 8073, 4482, 4091, 8073, 4482, 20370, 9868, 8073, 4482, 20370, 9868, 8073, 4482, 69, 686, 498, 330, 20370, 9868, 1365, 14316, 128009]\n",
      "inputs:\n",
      "<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "### Emotion Analysis Expert Role\n",
      "\n",
      "You are an advanced emotion analysis expert specializing in comic book dialogue interpretation. Your task is to analyze utterances and identify their emotional content.\n",
      "\n",
      "INPUT:\n",
      "- You will receive a list of utterances from a page in a comic book\n",
      "- The utterance may express one or multiple emotions\n",
      "\n",
      "TASK:\n",
      "1. Carefully analyze the emotional context and tone of each utterance in the page\n",
      "2. Identify applicable emotions from the following classes:\n",
      "   \"anger\", \"disgust\", \"fear\", \"sadness\", \"surprise\", \"joy\", \"neutral\"\n",
      "3. For each utterance in a comic page, identify all emotions present and return an array of emotion arrays in order.\n",
      "\n",
      "Class Distribution in Training Data:\n",
      "- anger: 23.0%\n",
      "- disgust: 3.3%\n",
      "- fear: 17.0%\n",
      "- sadness: 17.0%\n",
      "- surprise: 18.0%\n",
      "- joy: 17.0%\n",
      "- neutral: 4.0%\n",
      "\n",
      "IMPORTANT: Consider these class frequencies when making decisions while maintaining accuracy.\n",
      "    \n",
      "RULES:\n",
      "1. Use ONLY the labels listed above\n",
      "2. Output must be a JSON with single key \"page_utterance_emotions\"\n",
      "3. Value must be an array where:\n",
      "   - Each element is an array of emotions for one utterance\n",
      "   - Order matches the input utterances order\n",
      "   - Multiple emotions are allowed per utterance\n",
      "4. No explanations, only JSON output\n",
      "\n",
      "IMPORTANT:\n",
      "- Each array element corresponds to one utterance\n",
      "- One utterance can have multiple emotions\n",
      "- Maintain exact spelling and case of emotion labels\n",
      "- Keep emotions in arrays even for single emotions\n",
      "\n",
      "Now analyze these utterances from a page in a comics book:\n",
      "1. THIS VILE THING ATTACKED THE SMALL BEASTS OF MY SHORES… \n",
      "2. … IT PUNCHED MY BEAUTIFUL MATILDA… AND NOW IT BEGS FOR LIFE.\n",
      "3. MY MASTER!\n",
      "4. PLEASE!\n",
      "5. BUT I HAVE NOT CHASED THIS MONSTER ALL THIS WAY TO LET IT GROVEL!\n",
      "6. HEAL MEEE!\n",
      "7. I HAVE COME TO CONQ--!\n",
      "8. WHAT--\n",
      "9. --IS THAT?!\n",
      "10. NO! NO!<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "{\"page_utterance_emotions\": [[\"anger\"], [\"anger\"], [\"fear\"], [\"fear\"], [\"fear\", \"sadness\"], [\"sadness\"], [\"anger\"], [\"surprise\"], [\"surprise\"], [\"fear\", \"surprise\"]]}<|eot_id|>\n",
      "label_ids:\n",
      "[128000, 128006, 882, 128007, 271, 14711, 5867, 6082, 18825, 33257, 15766, 271, 2675, 527, 459, 11084, 20356, 6492, 6335, 58394, 304, 20303, 2363, 21976, 23692, 13, 4718, 3465, 374, 311, 24564, 22256, 3095, 323, 10765, 872, 14604, 2262, 382, 30521, 512, 12, 1472, 690, 5371, 264, 1160, 315, 22256, 3095, 505, 264, 2199, 304, 264, 20303, 2363, 198, 12, 578, 22256, 685, 1253, 3237, 832, 477, 5361, 21958, 271, 66913, 512, 16, 13, 10852, 3725, 24564, 279, 14604, 2317, 323, 16630, 315, 1855, 22256, 685, 304, 279, 2199, 198, 17, 13, 65647, 8581, 21958, 505, 279, 2768, 6989, 512, 256, 330, 4091, 498, 330, 4338, 70, 592, 498, 330, 69, 686, 498, 330, 83214, 2136, 498, 330, 20370, 9868, 498, 330, 4215, 498, 330, 60668, 702, 18, 13, 1789, 1855, 22256, 685, 304, 264, 20303, 2199, 11, 10765, 682, 21958, 3118, 323, 471, 459, 1358, 315, 20356, 18893, 304, 2015, 382, 1999, 35009, 304, 16543, 2956, 512, 12, 19788, 25, 220, 1419, 13, 15, 14062, 12, 68162, 25, 220, 18, 13, 18, 14062, 12, 8850, 25, 220, 1114, 13, 15, 14062, 12, 51978, 25, 220, 1114, 13, 15, 14062, 12, 13051, 25, 220, 972, 13, 15, 14062, 12, 16267, 25, 220, 1114, 13, 15, 14062, 12, 21277, 25, 220, 19, 13, 15, 15804, 99843, 25, 21829, 1521, 538, 34873, 994, 3339, 11429, 1418, 20958, 13708, 627, 1084, 93016, 50, 512, 16, 13, 5560, 27785, 279, 9382, 10212, 3485, 198, 17, 13, 9442, 2011, 387, 264, 4823, 449, 3254, 1401, 330, 2964, 62, 6339, 685, 23319, 41356, 702, 18, 13, 5273, 2011, 387, 459, 1358, 1405, 512, 256, 482, 9062, 2449, 374, 459, 1358, 315, 21958, 369, 832, 22256, 685, 198, 256, 482, 7365, 9248, 279, 1988, 22256, 3095, 2015, 198, 256, 482, 29911, 21958, 527, 5535, 824, 22256, 685, 198, 19, 13, 2360, 41941, 11, 1193, 4823, 2612, 271, 99843, 512, 12, 9062, 1358, 2449, 34310, 311, 832, 22256, 685, 198, 12, 3861, 22256, 685, 649, 617, 5361, 21958, 198, 12, 87477, 4839, 43529, 323, 1162, 315, 20356, 9382, 198, 12, 13969, 21958, 304, 18893, 1524, 369, 3254, 21958, 271, 7184, 24564, 1521, 22256, 3095, 505, 264, 2199, 304, 264, 29159, 2363, 512, 16, 13, 10245, 650, 3015, 4534, 1753, 99550, 1507, 3247, 50297, 7354, 6483, 50, 3083, 18725, 6570, 6005, 50, 1981, 720, 17, 13, 4696, 8871, 393, 1899, 35457, 18725, 7354, 58376, 2843, 1112, 25832, 1750, 6486, 1981, 3651, 23214, 8871, 7354, 16929, 4716, 61094, 627, 18, 13, 18725, 72297, 4999, 19, 13, 54233, 4999, 20, 13, 11155, 358, 19102, 4276, 6969, 4157, 35, 10245, 29637, 39023, 13398, 10245, 25404, 5257, 36757, 8871, 480, 1308, 12073, 4999, 21, 13, 11947, 984, 386, 33937, 4999, 22, 13, 358, 19102, 7837, 36, 5257, 3501, 48, 313, 4999, 23, 13, 38535, 7233, 24, 13, 1198, 1669, 26336, 30, 4999, 605, 13, 5782, 0, 5782, 0, 128009, 128006, 78191, 128007, 271, 5018, 2964, 62, 6339, 685, 23319, 41356, 794, 79786, 4091, 8073, 4482, 4091, 8073, 4482, 69, 686, 8073, 4482, 69, 686, 8073, 4482, 69, 686, 498, 330, 83214, 2136, 8073, 4482, 83214, 2136, 8073, 4482, 4091, 8073, 4482, 20370, 9868, 8073, 4482, 20370, 9868, 8073, 4482, 69, 686, 498, 330, 20370, 9868, 1365, 14316, 128009]\n",
      "labels:\n",
      "<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "### Emotion Analysis Expert Role\n",
      "\n",
      "You are an advanced emotion analysis expert specializing in comic book dialogue interpretation. Your task is to analyze utterances and identify their emotional content.\n",
      "\n",
      "INPUT:\n",
      "- You will receive a list of utterances from a page in a comic book\n",
      "- The utterance may express one or multiple emotions\n",
      "\n",
      "TASK:\n",
      "1. Carefully analyze the emotional context and tone of each utterance in the page\n",
      "2. Identify applicable emotions from the following classes:\n",
      "   \"anger\", \"disgust\", \"fear\", \"sadness\", \"surprise\", \"joy\", \"neutral\"\n",
      "3. For each utterance in a comic page, identify all emotions present and return an array of emotion arrays in order.\n",
      "\n",
      "Class Distribution in Training Data:\n",
      "- anger: 23.0%\n",
      "- disgust: 3.3%\n",
      "- fear: 17.0%\n",
      "- sadness: 17.0%\n",
      "- surprise: 18.0%\n",
      "- joy: 17.0%\n",
      "- neutral: 4.0%\n",
      "\n",
      "IMPORTANT: Consider these class frequencies when making decisions while maintaining accuracy.\n",
      "    \n",
      "RULES:\n",
      "1. Use ONLY the labels listed above\n",
      "2. Output must be a JSON with single key \"page_utterance_emotions\"\n",
      "3. Value must be an array where:\n",
      "   - Each element is an array of emotions for one utterance\n",
      "   - Order matches the input utterances order\n",
      "   - Multiple emotions are allowed per utterance\n",
      "4. No explanations, only JSON output\n",
      "\n",
      "IMPORTANT:\n",
      "- Each array element corresponds to one utterance\n",
      "- One utterance can have multiple emotions\n",
      "- Maintain exact spelling and case of emotion labels\n",
      "- Keep emotions in arrays even for single emotions\n",
      "\n",
      "Now analyze these utterances from a page in a comics book:\n",
      "1. THIS VILE THING ATTACKED THE SMALL BEASTS OF MY SHORES… \n",
      "2. … IT PUNCHED MY BEAUTIFUL MATILDA… AND NOW IT BEGS FOR LIFE.\n",
      "3. MY MASTER!\n",
      "4. PLEASE!\n",
      "5. BUT I HAVE NOT CHASED THIS MONSTER ALL THIS WAY TO LET IT GROVEL!\n",
      "6. HEAL MEEE!\n",
      "7. I HAVE COME TO CONQ--!\n",
      "8. WHAT--\n",
      "9. --IS THAT?!\n",
      "10. NO! NO!<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "{\"page_utterance_emotions\": [[\"anger\"], [\"anger\"], [\"fear\"], [\"fear\"], [\"fear\", \"sadness\"], [\"sadness\"], [\"anger\"], [\"surprise\"], [\"surprise\"], [\"fear\", \"surprise\"]]}<|eot_id|>\n",
      "11/14/2024 13:38:54 - WARNING - llamafactory.model.model_utils.quantization - `quantization_bit` will not affect on the PTQ-quantized models.\n",
      "11/14/2024 13:38:54 - INFO - llamafactory.model.model_utils.quantization - Loading ?-bit BITSANDBYTES-quantized model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING|quantization_config.py:400] 2024-11-14 13:38:54,370 >> Unused kwargs: ['_load_in_4bit', '_load_in_8bit', 'quant_method']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.\n",
      "Unused kwargs: ['_load_in_4bit', '_load_in_8bit', 'quant_method']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/14/2024 13:38:54 - WARNING - llamafactory.model.model_utils.quantization - `quantization_bit` will not affect on the PTQ-quantized models.\n",
      "11/14/2024 13:38:54 - INFO - llamafactory.model.model_utils.quantization - Loading ?-bit BITSANDBYTES-quantized model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|modeling_utils.py:3726] 2024-11-14 13:38:54,615 >> loading weights file model.safetensors from cache at /Utilisateurs/umushtaq/.cache/huggingface/hub/models--unsloth--llama-3-8b-Instruct-bnb-4bit/snapshots/f296897830363557c84cc4a942c2cd1f91818ae4/model.safetensors\n",
      "[INFO|modeling_utils.py:1622] 2024-11-14 13:38:54,662 >> Instantiating LlamaForCausalLM model under default dtype torch.float16.\n",
      "[INFO|configuration_utils.py:1099] 2024-11-14 13:38:54,666 >> Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 128000,\n",
      "  \"eos_token_id\": 128009,\n",
      "  \"pad_token_id\": 128255\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:4568] 2024-11-14 13:38:58,239 >> All model checkpoint weights were used when initializing LlamaForCausalLM.\n",
      "\n",
      "[INFO|modeling_utils.py:4576] 2024-11-14 13:38:58,240 >> All the weights of LlamaForCausalLM were initialized from the model checkpoint at unsloth/llama-3-8b-Instruct-bnb-4bit.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use LlamaForCausalLM for predictions without further training.\n",
      "[INFO|configuration_utils.py:1054] 2024-11-14 13:38:58,376 >> loading configuration file generation_config.json from cache at /Utilisateurs/umushtaq/.cache/huggingface/hub/models--unsloth--llama-3-8b-Instruct-bnb-4bit/snapshots/f296897830363557c84cc4a942c2cd1f91818ae4/generation_config.json\n",
      "[INFO|configuration_utils.py:1099] 2024-11-14 13:38:58,376 >> Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 128000,\n",
      "  \"do_sample\": true,\n",
      "  \"eos_token_id\": [\n",
      "    128001,\n",
      "    128009\n",
      "  ],\n",
      "  \"max_length\": 8192,\n",
      "  \"pad_token_id\": 128255,\n",
      "  \"temperature\": 0.6,\n",
      "  \"top_p\": 0.9\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/14/2024 13:38:58 - INFO - llamafactory.model.model_utils.checkpointing - Gradient checkpointing enabled.\n",
      "11/14/2024 13:38:58 - INFO - llamafactory.model.model_utils.attention - Using torch SDPA for faster training and inference.\n",
      "11/14/2024 13:38:58 - INFO - llamafactory.model.adapter - Upcasting trainable params to float32.\n",
      "11/14/2024 13:38:58 - INFO - llamafactory.model.adapter - Fine-tuning method: LoRA\n",
      "11/14/2024 13:38:58 - INFO - llamafactory.model.model_utils.misc - Found linear modules: o_proj,down_proj,gate_proj,up_proj,q_proj,v_proj,k_proj\n",
      "11/14/2024 13:38:58 - INFO - llamafactory.model.model_utils.checkpointing - Gradient checkpointing enabled.\n",
      "11/14/2024 13:38:58 - INFO - llamafactory.model.model_utils.attention - Using torch SDPA for faster training and inference.\n",
      "11/14/2024 13:38:58 - INFO - llamafactory.model.adapter - Upcasting trainable params to float32.\n",
      "11/14/2024 13:38:58 - INFO - llamafactory.model.adapter - Fine-tuning method: LoRA\n",
      "11/14/2024 13:38:58 - INFO - llamafactory.model.model_utils.misc - Found linear modules: o_proj,q_proj,down_proj,v_proj,up_proj,gate_proj,k_proj\n",
      "11/14/2024 13:38:59 - INFO - llamafactory.model.loader - trainable params: 20,971,520 || all params: 8,051,232,768 || trainable%: 0.2605\n",
      "11/14/2024 13:38:59 - INFO - llamafactory.model.loader - trainable params: 20,971,520 || all params: 8,051,232,768 || trainable%: 0.2605\n",
      "11/14/2024 13:38:59 - WARNING - llamafactory.train.callbacks - Previous trainer log in this folder will be deleted.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Utilisateurs/umushtaq/.conda/envs/er_nb_env/lib/python3.11/site-packages/accelerate/accelerator.py:494: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n",
      "/Utilisateurs/umushtaq/.conda/envs/er_nb_env/lib/python3.11/site-packages/accelerate/accelerator.py:494: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n",
      "[INFO|trainer.py:667] 2024-11-14 13:38:59,247 >> Using auto half precision backend\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/14/2024 13:38:59 - INFO - llamafactory.train.trainer_utils - Using LoRA+ optimizer with loraplus lr ratio 16.00.\n",
      "11/14/2024 13:38:59 - INFO - llamafactory.train.trainer_utils - Using LoRA+ optimizer with loraplus lr ratio 16.00.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:2243] 2024-11-14 13:39:00,345 >> ***** Running training *****\n",
      "[INFO|trainer.py:2244] 2024-11-14 13:39:00,346 >>   Num examples = 646\n",
      "[INFO|trainer.py:2245] 2024-11-14 13:39:00,346 >>   Num Epochs = 8\n",
      "[INFO|trainer.py:2246] 2024-11-14 13:39:00,346 >>   Instantaneous batch size per device = 2\n",
      "[INFO|trainer.py:2249] 2024-11-14 13:39:00,346 >>   Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "[INFO|trainer.py:2250] 2024-11-14 13:39:00,346 >>   Gradient Accumulation steps = 4\n",
      "[INFO|trainer.py:2251] 2024-11-14 13:39:00,346 >>   Total optimization steps = 320\n",
      "[INFO|trainer.py:2252] 2024-11-14 13:39:00,351 >>   Number of trainable parameters = 20,971,520\n",
      "  0%|          | 0/320 [00:00<?, ?it/s]/Utilisateurs/umushtaq/.conda/envs/er_nb_env/lib/python3.11/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/Utilisateurs/umushtaq/.conda/envs/er_nb_env/lib/python3.11/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "  3%|▎         | 10/320 [00:28<14:27,  2.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0996, 'grad_norm': 0.7909560203552246, 'learning_rate': 1.5625e-05, 'epoch': 0.25}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 20/320 [00:56<14:03,  2.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0313, 'grad_norm': 0.26241010427474976, 'learning_rate': 3.125e-05, 'epoch': 0.49}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 30/320 [01:24<13:31,  2.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6409, 'grad_norm': 0.36431631445884705, 'learning_rate': 4.6875e-05, 'epoch': 0.74}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▎        | 40/320 [01:52<12:56,  2.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5895, 'grad_norm': 0.19260142743587494, 'learning_rate': 4.990486745229364e-05, 'epoch': 0.99}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 50/320 [02:20<12:33,  2.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5904, 'grad_norm': 0.2630353569984436, 'learning_rate': 4.951963201008076e-05, 'epoch': 1.23}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 60/320 [02:48<12:07,  2.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5505, 'grad_norm': 0.36447471380233765, 'learning_rate': 4.884292376870567e-05, 'epoch': 1.48}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 70/320 [03:16<11:34,  2.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5347, 'grad_norm': 0.34646075963974, 'learning_rate': 4.788278697798618e-05, 'epoch': 1.73}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 80/320 [03:44<11:07,  2.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5579, 'grad_norm': 0.1862306296825409, 'learning_rate': 4.665063509461097e-05, 'epoch': 1.98}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 90/320 [04:12<10:47,  2.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4567, 'grad_norm': 0.22033601999282837, 'learning_rate': 4.516111510668707e-05, 'epoch': 2.22}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███▏      | 100/320 [04:40<10:10,  2.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.515, 'grad_norm': 0.26645323634147644, 'learning_rate': 4.34319334202531e-05, 'epoch': 2.47}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 110/320 [05:07<09:42,  2.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4695, 'grad_norm': 0.24547894299030304, 'learning_rate': 4.148364537750172e-05, 'epoch': 2.72}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 120/320 [05:35<09:12,  2.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.482, 'grad_norm': 0.17021995782852173, 'learning_rate': 3.933941090877615e-05, 'epoch': 2.96}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 130/320 [06:03<08:55,  2.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4415, 'grad_norm': 0.2723681330680847, 'learning_rate': 3.702471922298469e-05, 'epoch': 3.21}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 140/320 [06:31<08:24,  2.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3964, 'grad_norm': 0.2880382835865021, 'learning_rate': 3.456708580912725e-05, 'epoch': 3.46}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 150/320 [06:59<07:48,  2.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3622, 'grad_norm': 0.21489258110523224, 'learning_rate': 3.1995725350774806e-05, 'epoch': 3.7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 160/320 [07:27<07:28,  2.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4027, 'grad_norm': 0.2247658222913742, 'learning_rate': 2.9341204441673266e-05, 'epoch': 3.95}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 170/320 [07:55<06:57,  2.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3327, 'grad_norm': 0.3428665101528168, 'learning_rate': 2.663507823075358e-05, 'epoch': 4.2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▋    | 180/320 [08:23<06:27,  2.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2855, 'grad_norm': 0.44825848937034607, 'learning_rate': 2.3909515315866605e-05, 'epoch': 4.44}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 190/320 [08:51<06:01,  2.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2907, 'grad_norm': 0.3208509087562561, 'learning_rate': 2.1196915345252084e-05, 'epoch': 4.69}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▎   | 200/320 [09:19<05:37,  2.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2754, 'grad_norm': 0.3338504433631897, 'learning_rate': 1.852952387243698e-05, 'epoch': 4.94}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 210/320 [09:46<05:07,  2.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2123, 'grad_norm': 0.5683068633079529, 'learning_rate': 1.5939049042907462e-05, 'epoch': 5.19}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 220/320 [10:14<04:39,  2.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1896, 'grad_norm': 0.3351783752441406, 'learning_rate': 1.3456284669124158e-05, 'epoch': 5.43}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 230/320 [10:42<04:10,  2.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1834, 'grad_norm': 0.32702669501304626, 'learning_rate': 1.1110744174509952e-05, 'epoch': 5.68}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 240/320 [11:10<03:42,  2.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1949, 'grad_norm': 0.3648878335952759, 'learning_rate': 8.930309757836517e-06, 'epoch': 5.93}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 250/320 [11:38<03:16,  2.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1461, 'grad_norm': 0.3857353925704956, 'learning_rate': 6.940900948506113e-06, 'epoch': 6.17}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████▏ | 260/320 [12:06<02:46,  2.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1157, 'grad_norm': 0.31393128633499146, 'learning_rate': 5.166166492719124e-06, 'epoch': 6.42}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 270/320 [12:34<02:20,  2.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1274, 'grad_norm': 0.44889265298843384, 'learning_rate': 3.6272032331763408e-06, 'epoch': 6.67}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 280/320 [13:02<01:52,  2.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1146, 'grad_norm': 0.3365296423435211, 'learning_rate': 2.3423053240837515e-06, 'epoch': 6.91}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 290/320 [13:30<01:23,  2.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0968, 'grad_norm': 0.2950623631477356, 'learning_rate': 1.3267467626223606e-06, 'epoch': 7.16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 300/320 [13:58<00:55,  2.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.084, 'grad_norm': 0.31089645624160767, 'learning_rate': 5.925998220016659e-07, 'epoch': 7.41}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 310/320 [14:26<00:27,  2.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0837, 'grad_norm': 0.3233325183391571, 'learning_rate': 1.4859154444200884e-07, 'epoch': 7.65}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 320/320 [14:53<00:00,  2.78s/it][INFO|trainer.py:3705] 2024-11-14 13:53:54,660 >> Saving model checkpoint to /Utilisateurs/umushtaq/emotion_analysis_comics/finetuning/saved_models/comics35_pg_nb_xx_llama-3-8b-Instruct-bnb-4bit/checkpoint-320\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.086, 'grad_norm': 0.3689030408859253, 'learning_rate': 0.0, 'epoch': 7.9}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|configuration_utils.py:672] 2024-11-14 13:53:54,980 >> loading configuration file config.json from cache at /Utilisateurs/umushtaq/.cache/huggingface/hub/models--unsloth--llama-3-8b-Instruct-bnb-4bit/snapshots/f296897830363557c84cc4a942c2cd1f91818ae4/config.json\n",
      "[INFO|configuration_utils.py:739] 2024-11-14 13:53:54,980 >> Model config LlamaConfig {\n",
      "  \"_name_or_path\": \"unsloth/llama-3-8b-Instruct\",\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 128000,\n",
      "  \"eos_token_id\": 128009,\n",
      "  \"head_dim\": 128,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 4096,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 14336,\n",
      "  \"max_position_embeddings\": 8192,\n",
      "  \"mlp_bias\": false,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"num_key_value_heads\": 8,\n",
      "  \"pad_token_id\": 128255,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"quantization_config\": {\n",
      "    \"_load_in_4bit\": true,\n",
      "    \"_load_in_8bit\": false,\n",
      "    \"bnb_4bit_compute_dtype\": \"bfloat16\",\n",
      "    \"bnb_4bit_quant_storage\": \"uint8\",\n",
      "    \"bnb_4bit_quant_type\": \"nf4\",\n",
      "    \"bnb_4bit_use_double_quant\": true,\n",
      "    \"llm_int8_enable_fp32_cpu_offload\": false,\n",
      "    \"llm_int8_has_fp16_weight\": false,\n",
      "    \"llm_int8_skip_modules\": null,\n",
      "    \"llm_int8_threshold\": 6.0,\n",
      "    \"load_in_4bit\": true,\n",
      "    \"load_in_8bit\": false,\n",
      "    \"quant_method\": \"bitsandbytes\"\n",
      "  },\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 500000.0,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.45.0\",\n",
      "  \"unsloth_version\": \"2024.9\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 128256\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:2649] 2024-11-14 13:53:55,950 >> tokenizer config file saved in /Utilisateurs/umushtaq/emotion_analysis_comics/finetuning/saved_models/comics35_pg_nb_xx_llama-3-8b-Instruct-bnb-4bit/checkpoint-320/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2658] 2024-11-14 13:53:55,951 >> Special tokens file saved in /Utilisateurs/umushtaq/emotion_analysis_comics/finetuning/saved_models/comics35_pg_nb_xx_llama-3-8b-Instruct-bnb-4bit/checkpoint-320/special_tokens_map.json\n",
      "[INFO|trainer.py:2505] 2024-11-14 13:53:58,220 >> \n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "100%|██████████| 320/320 [14:57<00:00,  2.80s/it]\n",
      "[INFO|trainer.py:3705] 2024-11-14 13:53:58,226 >> Saving model checkpoint to /Utilisateurs/umushtaq/emotion_analysis_comics/finetuning/saved_models/comics35_pg_nb_xx_llama-3-8b-Instruct-bnb-4bit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 897.8693, 'train_samples_per_second': 5.756, 'train_steps_per_second': 0.356, 'train_loss': 0.4043539797887206, 'epoch': 7.9}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|configuration_utils.py:672] 2024-11-14 13:53:58,503 >> loading configuration file config.json from cache at /Utilisateurs/umushtaq/.cache/huggingface/hub/models--unsloth--llama-3-8b-Instruct-bnb-4bit/snapshots/f296897830363557c84cc4a942c2cd1f91818ae4/config.json\n",
      "[INFO|configuration_utils.py:739] 2024-11-14 13:53:58,504 >> Model config LlamaConfig {\n",
      "  \"_name_or_path\": \"unsloth/llama-3-8b-Instruct\",\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 128000,\n",
      "  \"eos_token_id\": 128009,\n",
      "  \"head_dim\": 128,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 4096,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 14336,\n",
      "  \"max_position_embeddings\": 8192,\n",
      "  \"mlp_bias\": false,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"num_key_value_heads\": 8,\n",
      "  \"pad_token_id\": 128255,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"quantization_config\": {\n",
      "    \"_load_in_4bit\": true,\n",
      "    \"_load_in_8bit\": false,\n",
      "    \"bnb_4bit_compute_dtype\": \"bfloat16\",\n",
      "    \"bnb_4bit_quant_storage\": \"uint8\",\n",
      "    \"bnb_4bit_quant_type\": \"nf4\",\n",
      "    \"bnb_4bit_use_double_quant\": true,\n",
      "    \"llm_int8_enable_fp32_cpu_offload\": false,\n",
      "    \"llm_int8_has_fp16_weight\": false,\n",
      "    \"llm_int8_skip_modules\": null,\n",
      "    \"llm_int8_threshold\": 6.0,\n",
      "    \"load_in_4bit\": true,\n",
      "    \"load_in_8bit\": false,\n",
      "    \"quant_method\": \"bitsandbytes\"\n",
      "  },\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 500000.0,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.45.0\",\n",
      "  \"unsloth_version\": \"2024.9\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 128256\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:2649] 2024-11-14 13:53:59,466 >> tokenizer config file saved in /Utilisateurs/umushtaq/emotion_analysis_comics/finetuning/saved_models/comics35_pg_nb_xx_llama-3-8b-Instruct-bnb-4bit/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2658] 2024-11-14 13:53:59,467 >> Special tokens file saved in /Utilisateurs/umushtaq/emotion_analysis_comics/finetuning/saved_models/comics35_pg_nb_xx_llama-3-8b-Instruct-bnb-4bit/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** train metrics *****\n",
      "  epoch                    =      7.9012\n",
      "  total_flos               = 133911409GF\n",
      "  train_loss               =      0.4044\n",
      "  train_runtime            =  0:14:57.86\n",
      "  train_samples_per_second =       5.756\n",
      "  train_steps_per_second   =       0.356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|modelcard.py:449] 2024-11-14 13:53:59,759 >> Dropping the following result as it does not have all the necessary fields:\n",
      "{'task': {'name': 'Causal Language Modeling', 'type': 'text-generation'}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = dict(\n",
    "  model_name_or_path=BASE_MODEL, # use bnb-4bit-quantized Llama-3-8B-Instruct model\n",
    "  adapter_name_or_path=str(OUTPUT_DIR),            # load the saved LoRA adapters\n",
    "  template=\"llama3\",                     # same to the one in training\n",
    "  finetuning_type=\"lora\",                  # same to the one in training\n",
    "  quantization_bit=4,                    # load 4-bit quantized model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|configuration_utils.py:672] 2024-11-14 13:54:02,203 >> loading configuration file config.json from cache at /Utilisateurs/umushtaq/.cache/huggingface/hub/models--unsloth--llama-3-8b-Instruct-bnb-4bit/snapshots/f296897830363557c84cc4a942c2cd1f91818ae4/config.json\n",
      "[INFO|configuration_utils.py:739] 2024-11-14 13:54:02,204 >> Model config LlamaConfig {\n",
      "  \"_name_or_path\": \"unsloth/llama-3-8b-Instruct-bnb-4bit\",\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 128000,\n",
      "  \"eos_token_id\": 128009,\n",
      "  \"head_dim\": 128,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 4096,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 14336,\n",
      "  \"max_position_embeddings\": 8192,\n",
      "  \"mlp_bias\": false,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"num_key_value_heads\": 8,\n",
      "  \"pad_token_id\": 128255,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"quantization_config\": {\n",
      "    \"_load_in_4bit\": true,\n",
      "    \"_load_in_8bit\": false,\n",
      "    \"bnb_4bit_compute_dtype\": \"bfloat16\",\n",
      "    \"bnb_4bit_quant_storage\": \"uint8\",\n",
      "    \"bnb_4bit_quant_type\": \"nf4\",\n",
      "    \"bnb_4bit_use_double_quant\": true,\n",
      "    \"llm_int8_enable_fp32_cpu_offload\": false,\n",
      "    \"llm_int8_has_fp16_weight\": false,\n",
      "    \"llm_int8_skip_modules\": null,\n",
      "    \"llm_int8_threshold\": 6.0,\n",
      "    \"load_in_4bit\": true,\n",
      "    \"load_in_8bit\": false,\n",
      "    \"quant_method\": \"bitsandbytes\"\n",
      "  },\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 500000.0,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.45.0\",\n",
      "  \"unsloth_version\": \"2024.9\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 128256\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:2214] 2024-11-14 13:54:02,329 >> loading file tokenizer.json from cache at /Utilisateurs/umushtaq/.cache/huggingface/hub/models--unsloth--llama-3-8b-Instruct-bnb-4bit/snapshots/f296897830363557c84cc4a942c2cd1f91818ae4/tokenizer.json\n",
      "[INFO|tokenization_utils_base.py:2214] 2024-11-14 13:54:02,329 >> loading file tokenizer.model from cache at None\n",
      "[INFO|tokenization_utils_base.py:2214] 2024-11-14 13:54:02,331 >> loading file added_tokens.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:2214] 2024-11-14 13:54:02,332 >> loading file special_tokens_map.json from cache at /Utilisateurs/umushtaq/.cache/huggingface/hub/models--unsloth--llama-3-8b-Instruct-bnb-4bit/snapshots/f296897830363557c84cc4a942c2cd1f91818ae4/special_tokens_map.json\n",
      "[INFO|tokenization_utils_base.py:2214] 2024-11-14 13:54:02,333 >> loading file tokenizer_config.json from cache at /Utilisateurs/umushtaq/.cache/huggingface/hub/models--unsloth--llama-3-8b-Instruct-bnb-4bit/snapshots/f296897830363557c84cc4a942c2cd1f91818ae4/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2478] 2024-11-14 13:54:02,729 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "[INFO|configuration_utils.py:672] 2024-11-14 13:54:03,229 >> loading configuration file config.json from cache at /Utilisateurs/umushtaq/.cache/huggingface/hub/models--unsloth--llama-3-8b-Instruct-bnb-4bit/snapshots/f296897830363557c84cc4a942c2cd1f91818ae4/config.json\n",
      "[INFO|configuration_utils.py:739] 2024-11-14 13:54:03,230 >> Model config LlamaConfig {\n",
      "  \"_name_or_path\": \"unsloth/llama-3-8b-Instruct-bnb-4bit\",\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 128000,\n",
      "  \"eos_token_id\": 128009,\n",
      "  \"head_dim\": 128,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 4096,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 14336,\n",
      "  \"max_position_embeddings\": 8192,\n",
      "  \"mlp_bias\": false,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"num_key_value_heads\": 8,\n",
      "  \"pad_token_id\": 128255,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"quantization_config\": {\n",
      "    \"_load_in_4bit\": true,\n",
      "    \"_load_in_8bit\": false,\n",
      "    \"bnb_4bit_compute_dtype\": \"bfloat16\",\n",
      "    \"bnb_4bit_quant_storage\": \"uint8\",\n",
      "    \"bnb_4bit_quant_type\": \"nf4\",\n",
      "    \"bnb_4bit_use_double_quant\": true,\n",
      "    \"llm_int8_enable_fp32_cpu_offload\": false,\n",
      "    \"llm_int8_has_fp16_weight\": false,\n",
      "    \"llm_int8_skip_modules\": null,\n",
      "    \"llm_int8_threshold\": 6.0,\n",
      "    \"load_in_4bit\": true,\n",
      "    \"load_in_8bit\": false,\n",
      "    \"quant_method\": \"bitsandbytes\"\n",
      "  },\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 500000.0,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.45.0\",\n",
      "  \"unsloth_version\": \"2024.9\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 128256\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:2214] 2024-11-14 13:54:03,359 >> loading file tokenizer.json from cache at /Utilisateurs/umushtaq/.cache/huggingface/hub/models--unsloth--llama-3-8b-Instruct-bnb-4bit/snapshots/f296897830363557c84cc4a942c2cd1f91818ae4/tokenizer.json\n",
      "[INFO|tokenization_utils_base.py:2214] 2024-11-14 13:54:03,359 >> loading file tokenizer.model from cache at None\n",
      "[INFO|tokenization_utils_base.py:2214] 2024-11-14 13:54:03,361 >> loading file added_tokens.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:2214] 2024-11-14 13:54:03,362 >> loading file special_tokens_map.json from cache at /Utilisateurs/umushtaq/.cache/huggingface/hub/models--unsloth--llama-3-8b-Instruct-bnb-4bit/snapshots/f296897830363557c84cc4a942c2cd1f91818ae4/special_tokens_map.json\n",
      "[INFO|tokenization_utils_base.py:2214] 2024-11-14 13:54:03,363 >> loading file tokenizer_config.json from cache at /Utilisateurs/umushtaq/.cache/huggingface/hub/models--unsloth--llama-3-8b-Instruct-bnb-4bit/snapshots/f296897830363557c84cc4a942c2cd1f91818ae4/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2478] 2024-11-14 13:54:03,761 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/14/2024 13:54:03 - INFO - llamafactory.data.template - Replace eos token: <|eot_id|>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|configuration_utils.py:672] 2024-11-14 13:54:03,899 >> loading configuration file config.json from cache at /Utilisateurs/umushtaq/.cache/huggingface/hub/models--unsloth--llama-3-8b-Instruct-bnb-4bit/snapshots/f296897830363557c84cc4a942c2cd1f91818ae4/config.json\n",
      "[INFO|configuration_utils.py:739] 2024-11-14 13:54:03,901 >> Model config LlamaConfig {\n",
      "  \"_name_or_path\": \"unsloth/llama-3-8b-Instruct-bnb-4bit\",\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 128000,\n",
      "  \"eos_token_id\": 128009,\n",
      "  \"head_dim\": 128,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 4096,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 14336,\n",
      "  \"max_position_embeddings\": 8192,\n",
      "  \"mlp_bias\": false,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"num_key_value_heads\": 8,\n",
      "  \"pad_token_id\": 128255,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"quantization_config\": {\n",
      "    \"_load_in_4bit\": true,\n",
      "    \"_load_in_8bit\": false,\n",
      "    \"bnb_4bit_compute_dtype\": \"bfloat16\",\n",
      "    \"bnb_4bit_quant_storage\": \"uint8\",\n",
      "    \"bnb_4bit_quant_type\": \"nf4\",\n",
      "    \"bnb_4bit_use_double_quant\": true,\n",
      "    \"llm_int8_enable_fp32_cpu_offload\": false,\n",
      "    \"llm_int8_has_fp16_weight\": false,\n",
      "    \"llm_int8_skip_modules\": null,\n",
      "    \"llm_int8_threshold\": 6.0,\n",
      "    \"load_in_4bit\": true,\n",
      "    \"load_in_8bit\": false,\n",
      "    \"quant_method\": \"bitsandbytes\"\n",
      "  },\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 500000.0,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.45.0\",\n",
      "  \"unsloth_version\": \"2024.9\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 128256\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/14/2024 13:54:03 - WARNING - llamafactory.model.model_utils.quantization - `quantization_bit` will not affect on the PTQ-quantized models.\n",
      "11/14/2024 13:54:03 - INFO - llamafactory.model.model_utils.quantization - Loading ?-bit BITSANDBYTES-quantized model.\n",
      "11/14/2024 13:54:03 - INFO - llamafactory.model.patcher - Using KV cache for faster generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING|quantization_config.py:400] 2024-11-14 13:54:04,027 >> Unused kwargs: ['_load_in_4bit', '_load_in_8bit', 'quant_method']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.\n",
      "[INFO|modeling_utils.py:3726] 2024-11-14 13:54:04,358 >> loading weights file model.safetensors from cache at /Utilisateurs/umushtaq/.cache/huggingface/hub/models--unsloth--llama-3-8b-Instruct-bnb-4bit/snapshots/f296897830363557c84cc4a942c2cd1f91818ae4/model.safetensors\n",
      "[INFO|modeling_utils.py:1622] 2024-11-14 13:54:04,402 >> Instantiating LlamaForCausalLM model under default dtype torch.bfloat16.\n",
      "[INFO|configuration_utils.py:1099] 2024-11-14 13:54:04,407 >> Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 128000,\n",
      "  \"eos_token_id\": 128009,\n",
      "  \"pad_token_id\": 128255\n",
      "}\n",
      "\n",
      "[INFO|quantizer_bnb_4bit.py:122] 2024-11-14 13:54:04,577 >> target_dtype {target_dtype} is replaced by `CustomDtype.INT4` for 4-bit BnB quantization\n",
      "[INFO|modeling_utils.py:4568] 2024-11-14 13:54:06,735 >> All model checkpoint weights were used when initializing LlamaForCausalLM.\n",
      "\n",
      "[INFO|modeling_utils.py:4576] 2024-11-14 13:54:06,736 >> All the weights of LlamaForCausalLM were initialized from the model checkpoint at unsloth/llama-3-8b-Instruct-bnb-4bit.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use LlamaForCausalLM for predictions without further training.\n",
      "[INFO|configuration_utils.py:1054] 2024-11-14 13:54:06,858 >> loading configuration file generation_config.json from cache at /Utilisateurs/umushtaq/.cache/huggingface/hub/models--unsloth--llama-3-8b-Instruct-bnb-4bit/snapshots/f296897830363557c84cc4a942c2cd1f91818ae4/generation_config.json\n",
      "[INFO|configuration_utils.py:1099] 2024-11-14 13:54:06,859 >> Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 128000,\n",
      "  \"do_sample\": true,\n",
      "  \"eos_token_id\": [\n",
      "    128001,\n",
      "    128009\n",
      "  ],\n",
      "  \"max_length\": 8192,\n",
      "  \"pad_token_id\": 128255,\n",
      "  \"temperature\": 0.6,\n",
      "  \"top_p\": 0.9\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/14/2024 13:54:07 - INFO - llamafactory.model.model_utils.attention - Using torch SDPA for faster training and inference.\n",
      "11/14/2024 13:54:09 - INFO - llamafactory.model.adapter - Loaded adapter(s): /Utilisateurs/umushtaq/emotion_analysis_comics/finetuning/saved_models/comics35_pg_nb_xx_llama-3-8b-Instruct-bnb-4bit\n",
      "11/14/2024 13:54:09 - INFO - llamafactory.model.loader - all params: 8,051,232,768\n"
     ]
    }
   ],
   "source": [
    "model = ChatModel(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<llamafactory.chat.hf_engine.HuggingfaceEngine at 0x7f5a357e5b50>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'huggingface'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.engine_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(test_dataset_file, \"r+\") as fh:\n",
    "    test_dataset = json.load(fh)\n",
    "\n",
    "test_prompts = []\n",
    "test_grounds = []\n",
    "\n",
    "for sample in test_dataset:\n",
    "    test_prompts.append(sample[\"instruction\"] + sample[\"input\"])\n",
    "    #test_prompts.append(sample[\"input\"])\n",
    "    test_grounds.append(sample[\"output\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running inferences ...:   6%|▌         | 9/156 [00:44<12:30,  5.11s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING|logging.py:328] 2024-11-14 13:54:12,132 >> Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running inferences ...: 100%|██████████| 156/156 [09:54<00:00,  3.81s/it]\n"
     ]
    }
   ],
   "source": [
    "messages = []\n",
    "\n",
    "for prompt in tqdm(test_prompts, desc=\"Running inferences ...\"):\n",
    "    #print(type(prompt))\n",
    "    #messages.append({\"role\": \"user\", \"content\": prompt})\n",
    "    message = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    test_predictions.append(model.chat(message))\n",
    "    #test_predictions.append(model.chat(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size = 1  # Adjust batch size according to memory and model limitations\n",
    "\n",
    "# # Initialize list to hold predictions\n",
    "# test_predictions = []\n",
    "\n",
    "# # Iterate over test_prompts in batches\n",
    "# for i in tqdm(range(0, len(test_prompts), batch_size), desc=\"Running inferences ...\"):\n",
    "#     # Create a batch of messages\n",
    "#     batch_prompts = test_prompts[i:i + batch_size]\n",
    "    \n",
    "#     # Prepare the messages for the batch\n",
    "#     batch_messages = [[{\"role\": \"user\", \"content\": prompt}] for prompt in batch_prompts]\n",
    "    \n",
    "#     # Perform inference on the batch and store predictions\n",
    "#     for message in batch_messages:\n",
    "#         prediction = model.chat(message)\n",
    "#         test_predictions.append(prediction)  # Collect batch predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[Response(response_text='{\"page_utterance_emotions\": [[\"surprise\"], [\"surprise\"], [\"surprise\"], [\"joy\"], [\"joy\"], [\"joy\"], [\"surprise\"], [\"joy\"], [\"joy\"], [\"neutral\"], [\"neutral\"]]}', response_length=47, prompt_length=461, finish_reason='stop')],\n",
       " [Response(response_text='{\"page_utterance_emotions\": [[\"sadness\"], [\"sadness\"], [\"anger\"], [\"anger\"], [\"sadness\"], [\"fear\", \"sadness\"], [\"sadness\"]]}', response_length=40, prompt_length=605, finish_reason='stop')],\n",
       " [Response(response_text='{\"page_utterance_emotions\": [[\"anger\"], [\"anger\"], [\"anger\"], [\"fear\", \"surprise\"], [\"anger\"], [\"fear\"], [\"anger\"], [\"anger\"], [\"anger\"], [\"joy\"], [\"anger\"], [\"anger\"], [\"anger\"], [\"joy\"], [\"joy\"], [\"joy\"]]}', response_length=64, prompt_length=700, finish_reason='stop')],\n",
       " [Response(response_text='{\"page_utterance_emotions\": [[\"anger\", \"sadness\"], [\"anger\", \"sadness\"], [\"anger\", \"sadness\"], [\"anger\", \"surprise\"], [\"anger\", \"surprise\"], [\"anger\"], [\"anger\"], [\"anger\"], [\"anger\"], [\"anger\"], [\"anger\"], [\"anger\"], [\"anger\"], [\"anger\"], [\"anger\"], [\"joy\"], [\"joy\"], [\"joy\"], [\"joy\"], [\"anger\", \"surprise\"], [\"anger\"]]}', response_length=97, prompt_length=789, finish_reason='stop')],\n",
       " [Response(response_text='{\"page_utterance_emotions\": [[\"anger\"], [\"joy\"], [\"joy\"]]}', response_length=19, prompt_length=438, finish_reason='stop')],\n",
       " [Response(response_text='{\"page_utterance_emotions\": [[\"neutral\"], [\"fear\"], [\"neutral\"], [\"fear\", \"sadness\"], [\"joy\"], [\"anger\"], [\"fear\", \"sadness\"], [\"sadness\"], [\"joy\"], [\"joy\"], [\"fear\", \"sadness\"], [\"joy\"], [\"neutral\"], [\"joy\"], [\"joy\"], [\"joy\"], [\"joy\"], [\"anger\", \"sadness\"], [\"anger\", \"sadness\"], [\"anger\"]]}', response_length=95, prompt_length=724, finish_reason='stop')],\n",
       " [Response(response_text='{\"page_utterance_emotions\": [[\"anger\", \"sadness\"], [\"anger\", \"sadness\"], [\"neutral\"], [\"neutral\"], [\"neutral\"], [\"neutral\"], [\"neutral\"], [\"neutral\"], [\"neutral\"], [\"joy\"], [\"joy\"], [\"neutral\"], [\"neutral\"], [\"anger\", \"sadness\"], [\"anger\", \"joy\"]]}', response_length=70, prompt_length=773, finish_reason='stop')],\n",
       " [Response(response_text='{\"page_utterance_emotions\": [[\"neutral\"], [\"fear\"], [\"anger\"], [\"neutral\"], [\"fear\"], [\"anger\"], [\"anger\"], [\"anger\", \"surprise\"], [\"anger\", \"disgust\"], [\"anger\"], [\"surprise\"], [\"anger\"], [\"anger\"], [\"anger\"], [\"fear\", \"surprise\"], [\"joy\"]]}', response_length=75, prompt_length=636, finish_reason='stop')],\n",
       " [Response(response_text='{\"page_utterance_emotions\": [[\"joy\"], [\"joy\"], [\"joy\"], [\"joy\"], [\"surprise\", \"joy\"], [\"surprise\", \"joy\"], [\"sadness\", \"joy\"], [\"sadness\", \"joy\"], [\"anger\", \"surprise\"], [\"anger\"], [\"surprise\"], [\"surprise\"]]}', response_length=68, prompt_length=545, finish_reason='stop')],\n",
       " [Response(response_text='{\"page_utterance_emotions\": [[\"anger\"], [\"anger\", \"surprise\"], [\"anger\"], [\"anger\"], [\"anger\"], [\"anger\"], [\"anger\"], [\"anger\"], [\"anger\", \"sadness\"], [\"anger\", \"sadness\"], [\"anger\", \"sadness\"]]}', response_length=59, prompt_length=528, finish_reason='stop')],\n",
       " [Response(response_text='{\"page_utterance_emotions\": [[\"surprise\"], [\"sadness\"], [\"sadness\"], [\"sadness\"], [\"joy\"], [\"joy\"], [\"joy\"], [\"fear\", \"sadness\"], [\"fear\", \"sadness\"], [\"anger\"], [\"anger\"], [\"sadness\"], [\"sadness\"], [\"sadness\"]]}', response_length=69, prompt_length=622, finish_reason='stop')],\n",
       " [Response(response_text='{\"page_utterance_emotions\": [[\"joy\"], [\"joy\"], [\"joy\"], [\"joy\"]]}', response_length=22, prompt_length=469, finish_reason='stop')],\n",
       " [Response(response_text='{\"page_utterance_emotions\": [[\"fear\"], [\"surprise\"], [\"fear\"], [\"anger\"], [\"disgust\", \"sadness\"], [\"surprise\"], [\"surprise\"], [\"sadness\"], [\"joy\"], [\"anger\"], [\"sadness\"], [\"neutral\"], [\"neutral\"]]}', response_length=62, prompt_length=556, finish_reason='stop')],\n",
       " [Response(response_text='{\"page_utterance_emotions\": [[\"fear\", \"surprise\"], [\"joy\"], [\"joy\"], [\"anger\"], [\"neutral\"], [\"joy\"], [\"joy\"], [\"surprise\", \"joy\"], [\"joy\"]]}', response_length=46, prompt_length=504, finish_reason='stop')],\n",
       " [Response(response_text='{\"page_utterance_emotions\": [[\"neutral\"], [\"sadness\"], [\"sadness\"], [\"fear\", \"sadness\"], [\"anger\", \"sadness\"], [\"anger\", \"sadness\"], [\"anger\", \"sadness\"], [\"anger\", \"fear\", \"sadness\"], [\"anger\", \"sadness\"], [\"anger\", \"sadness\"], [\"anger\", \"sadness\"], [\"anger\", \"sadness\"], [\"anger\", \"sadness\"], [\"anger\", \"joy\"], [\"anger\"], [\"anger\"], [\"anger\"], [\"anger\"], [\"anger\"], [\"anger\"], [\"anger\"], [\"anger\"], [\"anger\"], [\"anger\", \"joy\"]]}', response_length=135, prompt_length=1069, finish_reason='stop')],\n",
       " [Response(response_text='{\"page_utterance_emotions\": [[\"joy\"], [\"joy\"], [\"joy\"], [\"joy\"], [\"joy\"], [\"joy\"], [\"joy\"], [\"joy\"], [\"joy\"], [\"joy\"], [\"joy\"], [\"joy\"], [\"joy\"], [\"joy\"], [\"joy\"], [\"joy\"], [\"joy\"], [\"joy\"], [\"joy\"], [\"joy\"], [\"joy\"], [\"joy\"], [\"joy\"]]}', response_length=79, prompt_length=721, finish_reason='stop')],\n",
       " [Response(response_text='{\"page_utterance_emotions\": [[\"sadness\"], [\"surprise\"], [\"sadness\"], [\"sadness\"], [\"sadness\"], [\"sadness\"], [\"sadness\"], [\"surprise\"], [\"anger\"], [\"surprise\"], [\"anger\"], [\"anger\"], [\"anger\"]]}', response_length=58, prompt_length=632, finish_reason='stop')],\n",
       " [Response(response_text='{\"page_utterance_emotions\": [[\"joy\"], [\"surprise\"], [\"joy\"], [\"anger\"], [\"anger\"], [\"sadness\"], [\"joy\"], [\"surprise\"], [\"anger\", \"sadness\"], [\"anger\"], [\"joy\"], [\"joy\"]]}', response_length=53, prompt_length=615, finish_reason='stop')],\n",
       " [Response(response_text='{\"page_utterance_emotions\": [[\"surprise\", \"joy\"], [\"joy\"], [\"joy\"], [\"joy\"], [\"joy\"], [\"joy\"], [\"surprise\", \"joy\"], [\"joy\"], [\"joy\"], [\"joy\"], [\"joy\"], [\"surprise\"], [\"surprise\", \"joy\"]]}', response_length=62, prompt_length=705, finish_reason='stop')],\n",
       " [Response(response_text='{\"page_utterance_emotions\": [[\"joy\"], [\"fear\"], [\"anger\"], [\"fear\", \"sadness\"], [\"fear\", \"sadness\"], [\"fear\", \"surprise\"], [\"joy\"], [\"joy\"], [\"anger\"], [\"sadness\"], [\"surprise\", \"joy\"], [\"surprise\", \"joy\"], [\"fear\", \"sadness\"], [\"joy\"]]}', response_length=82, prompt_length=598, finish_reason='stop')],\n",
       " [Response(response_text='{\"page_utterance_emotions\": [[\"sadness\"], [\"joy\"], [\"joy\"], [\"surprise\"], [\"surprise\"], [\"surprise\"], [\"joy\"], [\"joy\"], [\"joy\"], [\"fear\", \"surprise\"]]}', response_length=49, prompt_length=514, finish_reason='stop')],\n",
       " [Response(response_text='{\"page_utterance_emotions\": [[\"anger\", \"sadness\"], [\"joy\"], [\"surprise\"], [\"joy\"], [\"joy\"], [\"joy\"], [\"joy\"], [\"joy\"], [\"joy\"], [\"fear\", \"joy\"], [\"joy\"]]}', response_length=52, prompt_length=619, finish_reason='stop')],\n",
       " [Response(response_text='{\"page_utterance_emotions\": [[\"joy\"], [\"joy\"], [\"joy\"], [\"joy\"], [\"joy\"], [\"joy\"], [\"joy\"], [\"joy\"], [\"joy\"], [\"surprise\"], [\"anger\", \"surprise\"]]}', response_length=48, prompt_length=535, finish_reason='stop')],\n",
       " [Response(response_text='{\"page_utterance_emotions\": [[\"surprise\"], [\"surprise\"], [\"neutral\"], [\"surprise\"], [\"surprise\"], [\"fear\", \"joy\"], [\"fear\", \"joy\"], [\"joy\"], [\"joy\"], [\"anger\", \"sadness\"]]}', response_length=56, prompt_length=508, finish_reason='stop')],\n",
       " [Response(response_text='{\"page_utterance_emotions\": [[\"fear\", \"surprise\"], [\"fear\", \"surprise\"], [\"anger\"], [\"neutral\"], [\"neutral\"], [\"neutral\"], [\"joy\"], [\"anger\"], [\"fear\"], [\"surprise\"], [\"anger\"], [\"fear\", \"surprise\"], [\"fear\", \"surprise\"]]}', response_length=71, prompt_length=564, finish_reason='stop')],\n",
       " [Response(response_text='{\"page_utterance_emotions\": [[\"anger\", \"disgust\"], [\"fear\", \"sadness\"], [\"fear\", \"surprise\"], [\"fear\", \"sadness\"], [\"fear\", \"sadness\", \"joy\"], [\"fear\", \"sadness\", \"joy\"], [\"fear\", \"sadness\"], [\"surprise\"], [\"fear\"], [\"anger\"], [\"anger\"], [\"sadness\"], [\"sadness\"]]}', response_length=94, prompt_length=562, finish_reason='stop')],\n",
       " [Response(response_text='{\"page_utterance_emotions\": [[\"sadness\"], [\"neutral\"], [\"neutral\"], [\"joy\"], [\"joy\"], [\"anger\"], [\"surprise\"], [\"joy\"], [\"joy\"], [\"joy\"], [\"surprise\"], [\"surprise\"], [\"surprise\", \"joy\"]]}', response_length=57, prompt_length=645, finish_reason='stop')],\n",
       " [Response(response_text='{\"page_utterance_emotions\": [[\"neutral\"], [\"joy\"], [\"joy\"], [\"fear\", \"surprise\"], [\"surprise\"], [\"fear\", \"surprise\"], [\"fear\", \"surprise\"], [\"fear\"], [\"fear\", \"joy\"], [\"fear\", \"joy\"], [\"fear\", \"surprise\"], [\"fear\", \"sadness\"], [\"fear\", \"sadness\"], [\"fear\", \"sadness\"], [\"neutral\"], [\"neutral\"], [\"neutral\"], [\"neutral\"]]}', response_length=109, prompt_length=819, finish_reason='stop')],\n",
       " [Response(response_text='{\"page_utterance_emotions\": [[\"disgust\"], [\"disgust\"], [\"anger\", \"surprise\"], [\"anger\"], [\"anger\"], [\"anger\", \"joy\"]]}', response_length=39, prompt_length=476, finish_reason='stop')],\n",
       " [Response(response_text='{\"page_utterance_emotions\": [[\"fear\"], [\"anger\"], [\"anger\"], [\"anger\", \"disgust\"]]}', response_length=28, prompt_length=417, finish_reason='stop')],\n",
       " [Response(response_text='{\"page_utterance_emotions\": [[\"joy\"], [\"fear\"], [\"anger\"], [\"anger\"], [\"anger\"], [\"anger\"]]}', response_length=29, prompt_length=488, finish_reason='stop')],\n",
       " [Response(response_text='{\"page_utterance_emotions\": [[\"anger\", \"fear\"], [\"fear\", \"surprise\"], [\"fear\", \"sadness\"], [\"fear\", \"sadness\"], [\"sadness\"], [\"surprise\"], [\"surprise\"]]}', response_length=53, prompt_length=441, finish_reason='stop')],\n",
       " [Response(response_text='{\"page_utterance_emotions\": [[\"surprise\"], [\"surprise\"], [\"surprise\", \"joy\"], [\"sadness\", \"joy\"], [\"joy\"], [\"joy\"], [\"fear\"], [\"fear\"], [\"fear\"]]}', response_length=50, prompt_length=496, finish_reason='stop')],\n",
       " [Response(response_text='{\"page_utterance_emotions\": [[\"anger\", \"sadness\"], [\"anger\", \"fear\", \"surprise\"], [\"sadness\"], [\"anger\", \"surprise\"], [\"sadness\"], [\"anger\", \"fear\", \"surprise\"], [\"anger\", \"disgust\", \"fear\", \"surprise\"], [\"anger\"], [\"disgust\", \"surprise\"], [\"disgust\"]]}', response_length=87, prompt_length=577, finish_reason='stop')],\n",
       " [Response(response_text='{\"page_utterance_emotions\": [[\"anger\", \"disgust\"], [\"anger\"], [\"anger\"], [\"anger\"], [\"anger\", \"sadness\"], [\"anger\"], [\"anger\"], [\"fear\"], [\"anger\"], [\"anger\"]]}', response_length=50, prompt_length=538, finish_reason='stop')],\n",
       " [Response(response_text='{\"page_utterance_emotions\": [[\"anger\", \"surprise\"], [\"anger\"], [\"anger\"], [\"anger\", \"surprise\"], [\"anger\", \"surprise\"], [\"anger\", \"surprise\"], [\"fear\", \"surprise\"], [\"fear\", \"surprise\"], [\"joy\"]]}', response_length=63, prompt_length=537, finish_reason='stop')],\n",
       " [Response(response_text='{\"page_utterance_emotions\": [[\"joy\"], [\"joy\"], [\"joy\"], [\"surprise\", \"joy\"], [\"surprise\"], [\"anger\"], [\"anger\"], [\"anger\", \"sadness\"], [\"anger\", \"sadness\"], [\"anger\", \"fear\"], [\"anger\", \"fear\"], [\"anger\", \"fear\", \"sadness\"], [\"anger\", \"fear\", \"sadness\"], [\"anger\", \"surprise\"], [\"anger\", \"sadness\"], [\"joy\"], [\"anger\", \"disgust\", \"surprise\"]]}', response_length=115, prompt_length=720, finish_reason='stop')],\n",
       " [Response(response_text='{\"page_utterance_emotions\": [[\"anger\", \"fear\"], [\"anger\", \"fear\"], [\"fear\"], [\"surprise\"], [\"surprise\"]]}', response_length=36, prompt_length=437, finish_reason='stop')],\n",
       " [Response(response_text='{\"page_utterance_emotions\": [[\"fear\", \"surprise\"]]}', response_length=18, prompt_length=383, finish_reason='stop')],\n",
       " [Response(response_text='{\"page_utterance_emotions\": [[\"anger\", \"sadness\"], [\"anger\"]]}', response_length=20, prompt_length=383, finish_reason='stop')],\n",
       " [Response(response_text='{\"page_utterance_emotions\": [[\"anger\", \"surprise\"], [\"anger\", \"surprise\"], [\"anger\", \"surprise\"], [\"anger\", \"fear\"], [\"fear\"], [\"anger\"]]}', response_length=45, prompt_length=501, finish_reason='stop')],\n",
       " [Response(response_text='{\"page_utterance_emotions\": [[\"anger\", \"surprise\"], [\"fear\", \"sadness\"], [\"fear\", \"sadness\"], [\"anger\"], [\"anger\"]]}', response_length=39, prompt_length=447, finish_reason='stop')],\n",
       " [Response(response_text='{\"page_utterance_emotions\": [[\"anger\", \"sadness\"], [\"anger\", \"sadness\"]]}', response_length=24, prompt_length=403, finish_reason='stop')],\n",
       " [Response(response_text='{\"page_utterance_emotions\": [[\"anger\", \"surprise\"], [\"anger\", \"joy\"], [\"anger\", \"joy\"], [\"anger\", \"joy\"], [\"anger\", \"surprise\"], [\"anger\", \"surprise\"], [\"anger\"], [\"anger\", \"surprise\"]]}', response_length=59, prompt_length=487, finish_reason='stop')],\n",
       " [Response(response_text='{\"page_utterance_emotions\": [[\"joy\"], [\"anger\"], [\"surprise\"], [\"anger\"], [\"joy\"], [\"joy\"], [\"surprise\"]]}', response_length=33, prompt_length=452, finish_reason='stop')],\n",
       " [Response(response_text='{\"page_utterance_emotions\": [[\"fear\"], [\"fear\"], [\"fear\"], [\"fear\", \"sadness\"], [\"fear\", \"sadness\"], [\"fear\", \"sadness\"], [\"anger\"], [\"surprise\"], [\"sadness\"], [\"sadness\"], [\"sadness\"], [\"joy\"], [\"sadness\", \"surprise\"]]}', response_length=76, prompt_length=579, finish_reason='stop')],\n",
       " [Response(response_text='{\"page_utterance_emotions\": [[\"fear\", \"sadness\"], [\"fear\", \"sadness\"], [\"fear\", \"sadness\"], [\"anger\", \"sadness\"], [\"anger\"], [\"anger\", \"surprise\"], [\"anger\"], [\"sadness\"], [\"anger\", \"sadness\"], [\"anger\", \"surprise\"], [\"anger\", \"surprise\"]]}', response_length=79, prompt_length=539, finish_reason='stop')],\n",
       " [Response(response_text='{\"page_utterance_emotions\": [[\"sadness\"], [\"anger\"], [\"anger\", \"sadness\"], [\"anger\", \"sadness\"]]}', response_length=31, prompt_length=443, finish_reason='stop')],\n",
       " [Response(response_text='{\"page_utterance_emotions\": [[\"fear\"], [\"fear\", \"surprise\"]]}', response_length=22, prompt_length=397, finish_reason='stop')],\n",
       " [Response(response_text='{\"page_utterance_emotions\": [[\"anger\", \"fear\"], [\"fear\", \"surprise\"], [\"anger\"], [\"anger\"], [\"joy\"], [\"surprise\", \"joy\"], [\"anger\", \"fear\"], [\"fear\", \"surprise\", \"joy\"], [\"anger\"], [\"anger\"]]}', response_length=65, prompt_length=513, finish_reason='stop')],\n",
       " [Response(response_text='{\"page_utterance_emotions\": [[\"fear\", \"surprise\"], [\"joy\"], [\"joy\"]]}', response_length=24, prompt_length=398, finish_reason='stop')],\n",
       " [Response(response_text='{\"page_utterance_emotions\": [[\"anger\", \"fear\"], [\"sadness\"], [\"fear\", \"surprise\"], [\"anger\"], [\"surprise\"], [\"fear\"], [\"anger\"], [\"anger\"]]}', response_length=46, prompt_length=503, finish_reason='stop')],\n",
       " [Response(response_text='{\"page_utterance_emotions\": [[\"surprise\", \"joy\"], [\"joy\"], [\"sadness\", \"joy\"], [\"joy\"], [\"joy\"], [\"anger\"], [\"anger\"], [\"anger\", \"sadness\"], [\"anger\", \"sadness\"], [\"joy\"], [\"sadness\"]]}', response_length=60, prompt_length=606, finish_reason='stop')],\n",
       " [Response(response_text='{\"page_utterance_emotions\": [[\"anger\"], [\"anger\", \"disgust\"], [\"anger\"]]}', response_length=24, prompt_length=433, finish_reason='stop')],\n",
       " [Response(response_text='{\"page_utterance_emotions\": [[\"surprise\"], [\"fear\", \"surprise\"], [\"joy\"], [\"joy\"], [\"fear\"], [\"fear\", \"joy\"], [\"anger\", \"fear\"]]}', response_length=46, prompt_length=546, finish_reason='stop')],\n",
       " [Response(response_text='{\"page_utterance_emotions\": [[\"sadness\"], [\"fear\"], [\"fear\", \"surprise\"], [\"fear\"], [\"anger\"], [\"fear\", \"sadness\"], [\"fear\", \"sadness\"], [\"anger\"]]}', response_length=52, prompt_length=519, finish_reason='stop')],\n",
       " [Response(response_text='{\"page_utterance_emotions\": [[\"fear\"], [\"joy\"], [\"joy\"], [\"anger\", \"surprise\"], [\"joy\"], [\"fear\"], [\"anger\"]]}', response_length=37, prompt_length=516, finish_reason='stop')],\n",
       " [Response(response_text='{\"page_utterance_emotions\": [[\"neutral\"], [\"neutral\"], [\"sadness\"], [\"sadness\"]]}', response_length=24, prompt_length=458, finish_reason='stop')],\n",
       " [Response(response_text='{\"page_utterance_emotions\": [[\"anger\", \"sadness\"], [\"anger\", \"sadness\"], [\"anger\"], [\"anger\"], [\"anger\"], [\"anger\", \"sadness\"]]}', response_length=40, prompt_length=505, finish_reason='stop')],\n",
       " [Response(response_text='{\"page_utterance_emotions\": [[\"joy\"], [\"anger\", \"fear\", \"surprise\"], [\"joy\"], [\"joy\"], [\"anger\", \"fear\", \"sadness\", \"surprise\"], [\"anger\", \"surprise\"]]}', response_length=52, prompt_length=476, finish_reason='stop')],\n",
       " [Response(response_text='{\"page_utterance_emotions\": [[\"sadness\"], [\"sadness\"], [\"sadness\"], [\"sadness\"]]}', response_length=26, prompt_length=465, finish_reason='stop')],\n",
       " [Response(response_text='{\"page_utterance_emotions\": [[\"sadness\"], [\"anger\"], [\"sadness\"], [\"sadness\"]]}', response_length=25, prompt_length=419, finish_reason='stop')],\n",
       " [Response(response_text='{\"page_utterance_emotions\": [[\"sadness\"], [\"sadness\"], [\"sadness\"], [\"sadness\"], [\"sadness\", \"surprise\"], [\"sadness\", \"surprise\"], [\"fear\", \"surprise\"]]}', response_length=50, prompt_length=516, finish_reason='stop')],\n",
       " [Response(response_text='{\"page_utterance_emotions\": [[\"sadness\"], [\"joy\"], [\"joy\"], [\"joy\"], [\"joy\"], [\"joy\"], [\"sadness\"]]}', response_length=33, prompt_length=511, finish_reason='stop')],\n",
       " [Response(response_text='{\"page_utterance_emotions\": [[\"fear\"], [\"fear\"], [\"surprise\", \"joy\"], [\"surprise\", \"joy\"], [\"sadness\"], [\"anger\", \"sadness\"], [\"anger\"]]}', response_length=46, prompt_length=473, finish_reason='stop')],\n",
       " [Response(response_text='{\"page_utterance_emotions\": [[\"surprise\", \"joy\"], [\"joy\"], [\"joy\"], [\"joy\"], [\"anger\", \"sadness\"], [\"anger\", \"surprise\"], [\"anger\", \"sadness\"], [\"anger\"]]}', response_length=50, prompt_length=534, finish_reason='stop')],\n",
       " [Response(response_text='{\"page_utterance_emotions\": [[\"anger\", \"fear\"], [\"fear\", \"surprise\"], [\"fear\", \"surprise\"]]}', response_length=33, prompt_length=384, finish_reason='stop')],\n",
       " [Response(response_text='{\"page_utterance_emotions\": [[\"joy\"], [\"joy\"], [\"anger\"], [\"fear\", \"surprise\"], [\"sadness\"], [\"surprise\", \"joy\"], [\"sadness\"], [\"joy\"], [\"joy\"]]}', response_length=48, prompt_length=488, finish_reason='stop')],\n",
       " [Response(response_text='{\"page_utterance_emotions\": [[\"joy\"], [\"sadness\"], [\"sadness\", \"surprise\"], [\"sadness\"]]}', response_length=29, prompt_length=424, finish_reason='stop')],\n",
       " [Response(response_text='{\"page_utterance_emotions\": [[\"sadness\"], [\"sadness\"], [\"sadness\"], [\"sadness\"], [\"sadness\"], [\"sadness\"]]}', response_length=34, prompt_length=517, finish_reason='stop')],\n",
       " [Response(response_text='{\"page_utterance_emotions\": [[\"anger\", \"disgust\"], [\"sadness\"]]}', response_length=22, prompt_length=386, finish_reason='stop')],\n",
       " [Response(response_text='{\"page_utterance_emotions\": [[\"sadness\"], [\"fear\"], [\"fear\", \"sadness\"], [\"sadness\"], [\"sadness\"], [\"sadness\"], [\"sadness\", \"surprise\"], [\"sadness\"]]}', response_length=50, prompt_length=482, finish_reason='stop')],\n",
       " [Response(response_text='{\"page_utterance_emotions\": [[\"disgust\", \"sadness\"], [\"disgust\", \"sadness\"], [\"disgust\", \"sadness\"], [\"joy\"], [\"sadness\"]]}', response_length=44, prompt_length=424, finish_reason='stop')],\n",
       " [Response(response_text='{\"page_utterance_emotions\": [[\"fear\", \"surprise\"], [\"anger\"], [\"anger\", \"sadness\"], [\"anger\", \"sadness\"], [\"anger\"], [\"fear\"]]}', response_length=42, prompt_length=436, finish_reason='stop')],\n",
       " [Response(response_text='{\"page_utterance_emotions\": [[\"fear\", \"surprise\"], [\"anger\", \"fear\"]]}', response_length=25, prompt_length=386, finish_reason='stop')],\n",
       " [Response(response_text='{\"page_utterance_emotions\": [[\"joy\"], [\"anger\", \"joy\"]]}', response_length=19, prompt_length=383, finish_reason='stop')],\n",
       " [Response(response_text='{\"page_utterance_emotions\": [[\"anger\", \"surprise\"], [\"joy\"], [\"anger\"], [\"anger\"], [\"surprise\"], [\"neutral\"], [\"surprise\"]]}', response_length=37, prompt_length=470, finish_reason='stop')],\n",
       " [Response(response_text='{\"page_utterance_emotions\": [[\"anger\"], [\"anger\", \"surprise\"], [\"neutral\"], [\"disgust\", \"surprise\"], [\"neutral\"], [\"anger\", \"fear\"]]}', response_length=42, prompt_length=449, finish_reason='stop')],\n",
       " [Response(response_text='{\"page_utterance_emotions\": [[\"surprise\"], [\"surprise\"]]}', response_length=18, prompt_length=393, finish_reason='stop')],\n",
       " [Response(response_text='{\"page_utterance_emotions\": [[\"joy\"], [\"surprise\"], [\"joy\"], [\"joy\"], [\"anger\", \"surprise\"], [\"surprise\"], [\"anger\"], [\"surprise\", \"joy\"]]}', response_length=44, prompt_length=508, finish_reason='stop')],\n",
       " [Response(response_text='{\"page_utterance_emotions\": [[\"anger\", \"disgust\"], [\"sadness\"], [\"fear\"], [\"fear\", \"sadness\"], [\"anger\", \"surprise\"], [\"sadness\"], [\"fear\"], [\"anger\"]]}', response_length=52, prompt_length=619, finish_reason='stop')],\n",
       " [Response(response_text='{\"page_utterance_emotions\": [[\"sadness\"], [\"fear\", \"surprise\"], [\"surprise\"], [\"anger\"], [\"anger\", \"joy\"], [\"joy\"], [\"disgust\", \"surprise\"], [\"disgust\"], [\"anger\"], [\"anger\"], [\"sadness\"], [\"anger\", \"sadness\"]]}', response_length=69, prompt_length=548, finish_reason='stop')],\n",
       " [Response(response_text='{\"page_utterance_emotions\": [[\"sadness\"], [\"sadness\", \"surprise\"], [\"anger\", \"sadness\"], [\"anger\", \"fear\", \"surprise\"], [\"anger\", \"fear\"], [\"surprise\", \"joy\"], [\"anger\"], [\"joy\"], [\"joy\"], [\"joy\"]]}', response_length=66, prompt_length=495, finish_reason='stop')],\n",
       " [Response(response_text='{\"page_utterance_emotions\": [[\"anger\"], [\"anger\"], [\"anger\", \"sadness\"], [\"anger\", \"fear\", \"surprise\"], [\"anger\", \"fear\"], [\"anger\"], [\"anger\"], [\"anger\", \"sadness\"], [\"anger\"]]}', response_length=57, prompt_length=488, finish_reason='stop')],\n",
       " [Response(response_text='{\"page_utterance_emotions\": [[\"anger\", \"disgust\"], [\"anger\", \"surprise\"], [\"anger\", \"sadness\"], [\"anger\"], [\"anger\"], [\"anger\"], [\"anger\"], [\"joy\"], [\"fear\"], [\"anger\", \"sadness\"], [\"anger\", \"sadness\"], [\"anger\"], [\"anger\", \"surprise\"], [\"anger\"], [\"anger\"]]}', response_length=81, prompt_length=693, finish_reason='stop')],\n",
       " [Response(response_text='{\"page_utterance_emotions\": [[\"joy\"], [\"anger\"], [\"anger\", \"disgust\"], [\"anger\", \"disgust\"], [\"anger\", \"disgust\"], [\"sadness\", \"surprise\"], [\"sadness\", \"surprise\"], [\"sadness\", \"surprise\"], [\"sadness\", \"surprise\"], [\"anger\", \"fear\"], [\"fear\", \"surprise\"], [\"fear\", \"surprise\"], [\"fear\", \"surprise\"], [\"joy\"]]}', response_length=106, prompt_length=583, finish_reason='stop')],\n",
       " [Response(response_text='{\"page_utterance_emotions\": [[\"joy\"], [\"fear\"], [\"fear\", \"surprise\"], [\"surprise\"], [\"joy\"], [\"neutral\"], [\"anger\"], [\"sadness\"], [\"sadness\"], [\"anger\"]]}', response_length=49, prompt_length=565, finish_reason='stop')],\n",
       " [Response(response_text='{\"page_utterance_emotions\": [[\"surprise\"], [\"fear\", \"surprise\"], [\"fear\", \"surprise\"], [\"anger\", \"fear\", \"surprise\"], [\"surprise\"], [\"joy\"], [\"joy\"], [\"disgust\", \"joy\"], [\"anger\", \"surprise\"], [\"anger\", \"surprise\"], [\"joy\"], [\"anger\", \"surprise\"], [\"anger\", \"surprise\"], [\"surprise\"], [\"surprise\"]]}', response_length=98, prompt_length=608, finish_reason='stop')],\n",
       " [Response(response_text='{\"page_utterance_emotions\": [[\"anger\", \"sadness\"], [\"joy\"], [\"joy\"], [\"neutral\"], [\"fear\", \"surprise\"], [\"joy\"], [\"joy\"], [\"joy\"], [\"joy\"], [\"joy\"]]}', response_length=49, prompt_length=557, finish_reason='stop')],\n",
       " [Response(response_text='{\"page_utterance_emotions\": [[\"surprise\", \"joy\"]]}', response_length=17, prompt_length=380, finish_reason='stop')],\n",
       " [Response(response_text='{\"page_utterance_emotions\": [[\"joy\"], [\"joy\"]]}', response_length=16, prompt_length=403, finish_reason='stop')],\n",
       " [Response(response_text='{\"page_utterance_emotions\": [[\"anger\"], [\"anger\"], [\"joy\"], [\"anger\"], [\"anger\"], [\"anger\"], [\"anger\"], [\"anger\"]]}', response_length=34, prompt_length=525, finish_reason='stop')],\n",
       " [Response(response_text='{\"page_utterance_emotions\": [[\"joy\"], [\"fear\", \"surprise\"], [\"surprise\"], [\"fear\"], [\"joy\"], [\"joy\"], [\"surprise\"], [\"surprise\"]]}', response_length=43, prompt_length=476, finish_reason='stop')],\n",
       " [Response(response_text='{\"page_utterance_emotions\": [[\"sadness\"], [\"sadness\"], [\"sadness\"]]}', response_length=22, prompt_length=383, finish_reason='stop')],\n",
       " [Response(response_text='{\"page_utterance_emotions\": [[\"joy\"], [\"joy\"], [\"joy\"], [\"joy\"], [\"fear\", \"surprise\"], [\"anger\", \"fear\"]]}', response_length=37, prompt_length=423, finish_reason='stop')],\n",
       " [Response(response_text='{\"page_utterance_emotions\": [[\"anger\"], [\"anger\"], [\"fear\"], [\"anger\", \"disgust\"]]}', response_length=28, prompt_length=403, finish_reason='stop')],\n",
       " [Response(response_text='{\"page_utterance_emotions\": [[\"sadness\", \"surprise\"]]}', response_length=18, prompt_length=377, finish_reason='stop')],\n",
       " [Response(response_text='{\"page_utterance_emotions\": [[\"fear\", \"surprise\"], [\"fear\", \"surprise\"], [\"joy\"], [\"anger\"], [\"neutral\"], [\"surprise\"], [\"sadness\"], [\"neutral\"], [\"neutral\"], [\"fear\", \"surprise\"]]}', response_length=57, prompt_length=714, finish_reason='stop')],\n",
       " [Response(response_text='{\"page_utterance_emotions\": [[\"neutral\"], [\"anger\", \"disgust\", \"joy\"], [\"fear\", \"surprise\"], [\"neutral\"], [\"fear\", \"surprise\"], [\"disgust\", \"fear\", \"surprise\"], [\"disgust\", \"fear\"], [\"fear\", \"sadness\"]]}', response_length=73, prompt_length=669, finish_reason='stop')],\n",
       " [Response(response_text='{\"page_utterance_emotions\": [[\"joy\"], [\"joy\"], [\"surprise\"], [\"sadness\"], [\"joy\"], [\"fear\"], [\"joy\"], [\"joy\"], [\"joy\"], [\"joy\"], [\"joy\"], [\"sadness\"], [\"joy\"]]}', response_length=53, prompt_length=640, finish_reason='stop')],\n",
       " [Response(response_text='{\"page_utterance_emotions\": [[\"joy\"], [\"fear\", \"surprise\"], [\"fear\", \"surprise\"]]}', response_length=29, prompt_length=406, finish_reason='stop')],\n",
       " [Response(response_text='{\"page_utterance_emotions\": [[\"anger\", \"surprise\"], [\"fear\", \"surprise\"], [\"fear\", \"surprise\"], [\"sadness\"], [\"fear\", \"surprise\"], [\"fear\", \"surprise\"], [\"fear\", \"surprise\"]]}', response_length=61, prompt_length=430, finish_reason='stop')],\n",
       " [Response(response_text='{\"page_utterance_emotions\": [[\"fear\", \"surprise\"], [\"anger\", \"surprise\"]]}', response_length=25, prompt_length=389, finish_reason='stop')],\n",
       " [Response(response_text='{\"page_utterance_emotions\": [[\"anger\", \"disgust\", \"surprise\"], [\"anger\", \"fear\", \"surprise\"], [\"sadness\"], [\"anger\", \"fear\"], [\"anger\", \"fear\"], [\"anger\", \"fear\"], [\"anger\", \"fear\"], [\"anger\", \"fear\"], [\"anger\", \"fear\"], [\"anger\", \"fear\"], [\"anger\", \"fear\"], [\"anger\", \"fear\"]]}', response_length=100, prompt_length=766, finish_reason='stop')],\n",
       " [Response(response_text='{\"page_utterance_emotions\": [[\"joy\"], [\"joy\"], [\"sadness\", \"joy\"], [\"joy\"], [\"anger\", \"sadness\"], [\"joy\"], [\"joy\"], [\"joy\"]]}', response_length=42, prompt_length=620, finish_reason='stop')],\n",
       " [Response(response_text='{\"page_utterance_emotions\": [[\"sadness\"], [\"sadness\"], [\"anger\", \"surprise\"], [\"anger\", \"surprise\"], [\"sadness\"], [\"neutral\"]]}', response_length=39, prompt_length=538, finish_reason='stop')],\n",
       " [Response(response_text='{\"page_utterance_emotions\": [[\"fear\"], [\"surprise\", \"joy\"], [\"fear\", \"sadness\"], [\"fear\", \"sadness\"], [\"fear\", \"sadness\"]]}', response_length=45, prompt_length=439, finish_reason='stop')],\n",
       " [Response(response_text='{\"page_utterance_emotions\": [[\"neutral\"], [\"sadness\"], [\"sadness\"], [\"surprise\"], [\"surprise\"], [\"sadness\"], [\"sadness\"], [\"surprise\"]]}', response_length=41, prompt_length=480, finish_reason='stop')],\n",
       " [Response(response_text='{\"page_utterance_emotions\": [[\"sadness\"], [\"sadness\"], [\"anger\", \"disgust\", \"fear\", \"sadness\"], [\"fear\", \"sadness\"], [\"anger\", \"disgust\", \"fear\"], [\"anger\", \"sadness\"], [\"anger\", \"sadness\"]]}', response_length=68, prompt_length=523, finish_reason='stop')],\n",
       " [Response(response_text='{\"page_utterance_emotions\": [[\"anger\", \"joy\"], [\"anger\"], [\"disgust\", \"joy\"], [\"sadness\", \"joy\"]]}', response_length=34, prompt_length=480, finish_reason='stop')],\n",
       " [Response(response_text='{\"page_utterance_emotions\": [[\"anger\"], [\"anger\", \"sadness\"], [\"fear\"], [\"anger\"], [\"anger\"], [\"surprise\"]]}', response_length=34, prompt_length=466, finish_reason='stop')],\n",
       " [Response(response_text='{\"page_utterance_emotions\": [[\"joy\"]]}', response_length=13, prompt_length=374, finish_reason='stop')],\n",
       " [Response(response_text='{\"page_utterance_emotions\": [[\"anger\", \"fear\", \"surprise\"], [\"anger\", \"fear\"], [\"fear\"], [\"anger\", \"fear\"], [\"anger\", \"fear\", \"surprise\"], [\"surprise\"]]}', response_length=54, prompt_length=443, finish_reason='stop')],\n",
       " [Response(response_text='{\"page_utterance_emotions\": [[\"anger\", \"surprise\"]]}', response_length=17, prompt_length=375, finish_reason='stop')],\n",
       " [Response(response_text='{\"page_utterance_emotions\": [[\"sadness\"], [\"sadness\"], [\"sadness\"]]}', response_length=22, prompt_length=450, finish_reason='stop')],\n",
       " [Response(response_text='{\"page_utterance_emotions\": [[\"sadness\"], [\"sadness\"], [\"sadness\"], [\"sadness\"], [\"sadness\"], [\"sadness\"], [\"neutral\"], [\"sadness\"], [\"sadness\"], [\"fear\"], [\"anger\", \"sadness\"], [\"anger\", \"sadness\"], [\"sadness\"]]}', response_length=67, prompt_length=756, finish_reason='stop')],\n",
       " [Response(response_text='{\"page_utterance_emotions\": [[\"fear\"], [\"fear\", \"sadness\"], [\"fear\", \"sadness\"], [\"fear\", \"sadness\"], [\"fear\", \"sadness\"], [\"sadness\", \"joy\"], [\"sadness\"], [\"sadness\"], [\"joy\"]]}', response_length=64, prompt_length=679, finish_reason='stop')],\n",
       " [Response(response_text='{\"page_utterance_emotions\": [[\"sadness\"], [\"joy\"], [\"fear\", \"surprise\"], [\"sadness\", \"surprise\"], [\"sadness\", \"surprise\"], [\"neutral\"], [\"anger\"], [\"sadness\"], [\"sadness\"]]}', response_length=55, prompt_length=494, finish_reason='stop')],\n",
       " [Response(response_text='{\"page_utterance_emotions\": [[\"sadness\", \"surprise\"], [\"sadness\"], [\"sadness\"], [\"anger\", \"sadness\"], [\"sadness\"], [\"sadness\"], [\"sadness\"], [\"anger\", \"surprise\"], [\"sadness\"], [\"neutral\"], [\"surprise\", \"joy\"], [\"surprise\", \"joy\"]]}', response_length=73, prompt_length=647, finish_reason='stop')],\n",
       " [Response(response_text='{\"page_utterance_emotions\": [[\"sadness\", \"joy\"], [\"joy\"], [\"fear\", \"sadness\", \"joy\"], [\"neutral\"], [\"fear\", \"surprise\"], [\"neutral\"], [\"neutral\"], [\"neutral\"], [\"fear\", \"sadness\"], [\"sadness\"], [\"fear\", \"sadness\"], [\"fear\", \"surprise\"], [\"surprise\"]]}', response_length=83, prompt_length=630, finish_reason='stop')],\n",
       " [Response(response_text='{\"page_utterance_emotions\": [[\"anger\", \"surprise\"], [\"sadness\"], [\"sadness\"], [\"sadness\", \"surprise\"], [\"sadness\"], [\"sadness\"], [\"fear\", \"sadness\"], [\"sadness\"], [\"sadness\"], [\"sadness\"], [\"sadness\"], [\"fear\", \"sadness\"], [\"fear\", \"sadness\"], [\"sadness\"], [\"sadness\", \"surprise\"], [\"sadness\"], \"joy\"]}', response_length=99, prompt_length=620, finish_reason='stop')],\n",
       " [Response(response_text='{\"page_utterance_emotions\": [[\"surprise\"], [\"surprise\"], [\"joy\"], [\"joy\"], [\"neutral\"], [\"fear\", \"surprise\"], [\"surprise\"], [\"joy\"], [\"joy\"], [\"joy\"], [\"joy\"], [\"neutral\"], [\"neutral\"], [\"joy\"], [\"joy\"], [\"joy\"], [\"joy\"], [\"joy\"], [\"joy\"]]}', response_length=75, prompt_length=821, finish_reason='stop')],\n",
       " [Response(response_text='{\"page_utterance_emotions\": [[\"anger\", \"surprise\"], [\"anger\", \"fear\", \"surprise\"], [\"anger\", \"fear\"], [\"neutral\"], [\"fear\"], [\"anger\"], [\"fear\"], [\"anger\"], [\"sadness\"], [\"sadness\"], [\"anger\", \"disgust\", \"sadness\"], [\"anger\"], [\"joy\"]]}', response_length=78, prompt_length=618, finish_reason='stop')],\n",
       " [Response(response_text='{\"page_utterance_emotions\": [[\"surprise\"], [\"neutral\"], [\"sadness\"], [\"joy\"], [\"sadness\"], [\"surprise\"], [\"sadness\"], [\"sadness\"], [\"sadness\"], [\"surprise\", \"joy\"], [\"sadness\"]]}', response_length=55, prompt_length=581, finish_reason='stop')],\n",
       " [Response(response_text='{\"page_utterance_emotions\": [[\"surprise\"], [\"surprise\"], [\"joy\"], [\"sadness\"], [\"sadness\"], [\"sadness\"], [\"sadness\"], [\"sadness\"], [\"sadness\"], [\"surprise\"], [\"sadness\"], [\"sadness\"], [\"joy\"], [\"joy\"]]}', response_length=63, prompt_length=665, finish_reason='stop')],\n",
       " [Response(response_text='{\"page_utterance_emotions\": [[\"anger\"], [\"anger\"], [\"anger\"], [\"anger\", \"sadness\"], [\"anger\", \"fear\", \"surprise\"], [\"anger\", \"sadness\"], [\"anger\", \"fear\"], [\"anger\", \"sadness\"], [\"anger\", \"disgust\"], [\"fear\", \"surprise\"]]}', response_length=74, prompt_length=545, finish_reason='stop')],\n",
       " [Response(response_text='{\"page_utterance_emotions\": [[\"surprise\"], [\"anger\", \"surprise\"], [\"sadness\"], [\"anger\", \"fear\", \"surprise\"], [\"anger\", \"sadness\"], [\"anger\", \"sadness\"], [\"sadness\"], [\"sadness\"], [\"anger\"], [\"anger\"], [\"fear\", \"surprise\"], [\"fear\", \"surprise\"], [\"sadness\"]]}', response_length=84, prompt_length=624, finish_reason='stop')],\n",
       " [Response(response_text='{\"page_utterance_emotions\": [[\"anger\", \"surprise\"], [\"anger\", \"surprise\"], [\"anger\", \"surprise\"], [\"anger\"], [\"anger\"], [\"anger\"], [\"anger\"], [\"anger\"], [\"fear\", \"surprise\"], [\"anger\", \"sadness\"], [\"anger\", \"sadness\"], [\"anger\"]]}', response_length=71, prompt_length=731, finish_reason='stop')],\n",
       " [Response(response_text='{\"page_utterance_emotions\": [[\"anger\", \"joy\"], [\"anger\", \"joy\"], [\"anger\", \"joy\"], [\"anger\"], [\"anger\"], [\"anger\"], [\"anger\"]]}', response_length=40, prompt_length=503, finish_reason='stop')],\n",
       " [Response(response_text='{\"page_utterance_emotions\": [[\"surprise\"], [\"sadness\"], [\"sadness\"], [\"sadness\"], [\"sadness\"], [\"anger\"], [\"anger\"], [\"neutral\"], [\"sadness\"], [\"sadness\"], [\"surprise\"], [\"sadness\"]]}', response_length=55, prompt_length=632, finish_reason='stop')],\n",
       " [Response(response_text='{\"page_utterance_emotions\": [[\"sadness\"], [\"surprise\"], [\"neutral\"], [\"neutral\"], [\"sadness\"], [\"sadness\"], [\"sadness\"]]}', response_length=36, prompt_length=452, finish_reason='stop')],\n",
       " [Response(response_text='{\"page_utterance_emotions\": [[\"sadness\"], [\"sadness\"], [\"sadness\"], [\"sadness\"], [\"fear\", \"surprise\"], [\"surprise\"], [\"joy\"], [\"joy\"]]}', response_length=44, prompt_length=498, finish_reason='stop')],\n",
       " [Response(response_text='{\"page_utterance_emotions\": [[\"joy\"], [\"anger\", \"joy\"], [\"anger\", \"joy\"], [\"anger\"], [\"sadness\", \"joy\"], [\"sadness\", \"joy\"], [\"sadness\"], [\"sadness\"], [\"sadness\"], [\"anger\"], [\"anger\"]]}', response_length=60, prompt_length=557, finish_reason='stop')],\n",
       " [Response(response_text='{\"page_utterance_emotions\": [[\"sadness\"], [\"sadness\"], [\"anger\"], [\"anger\"], [\"surprise\"], [\"fear\", \"sadness\"], [\"sadness\"], [\"sadness\"]]}', response_length=44, prompt_length=453, finish_reason='stop')],\n",
       " [Response(response_text='{\"page_utterance_emotions\": [[\"joy\"], [\"fear\", \"sadness\", \"joy\"], [\"fear\", \"surprise\"], [\"fear\", \"surprise\"], [\"fear\", \"surprise\"], [\"joy\"], [\"fear\", \"sadness\", \"joy\"], [\"sadness\", \"joy\"], [\"joy\"]]}', response_length=72, prompt_length=558, finish_reason='stop')],\n",
       " [Response(response_text='{\"page_utterance_emotions\": [[\"anger\", \"sadness\"], [\"anger\", \"sadness\"], [\"anger\"]]}', response_length=27, prompt_length=418, finish_reason='stop')],\n",
       " [Response(response_text='{\"page_utterance_emotions\": [[\"fear\"], [\"anger\"]]}', response_length=17, prompt_length=397, finish_reason='stop')],\n",
       " [Response(response_text='{\"page_utterance_emotions\": [[\"fear\", \"surprise\"], [\"fear\", \"surprise\"], [\"fear\", \"surprise\"], [\"surprise\"], [\"anger\", \"fear\", \"surprise\"], [\"fear\", \"surprise\"]]}', response_length=57, prompt_length=439, finish_reason='stop')],\n",
       " [Response(response_text='{\"page_utterance_emotions\": [[\"fear\", \"surprise\"], [\"fear\", \"surprise\"], [\"fear\", \"surprise\"], [\"fear\", \"surprise\"], [\"fear\", \"surprise\"], [\"anger\", \"disgust\"], [\"fear\", \"surprise\"]]}', response_length=66, prompt_length=441, finish_reason='stop')],\n",
       " [Response(response_text='{\"page_utterance_emotions\": [[\"fear\", \"surprise\"], [\"surprise\", \"joy\"], [\"surprise\", \"joy\"], [\"fear\", \"sadness\"], [\"fear\", \"surprise\"], [\"anger\"]]}', response_length=51, prompt_length=435, finish_reason='stop')],\n",
       " [Response(response_text='{\"page_utterance_emotions\": [[\"surprise\"], [\"surprise\"], [\"anger\", \"fear\", \"surprise\"], [\"anger\", \"disgust\"], [\"anger\"], [\"anger\", \"fear\"]]}', response_length=47, prompt_length=444, finish_reason='stop')],\n",
       " [Response(response_text='{\"page_utterance_emotions\": [[\"anger\"], [\"fear\", \"surprise\"], [\"anger\", \"fear\"], [\"anger\"], [\"fear\", \"surprise\"], [\"anger\"]]}', response_length=42, prompt_length=430, finish_reason='stop')],\n",
       " [Response(response_text='{\"page_utterance_emotions\": [[\"fear\", \"surprise\"], [\"anger\", \"surprise\"], [\"anger\", \"surprise\"], [\"anger\"], [\"anger\", \"surprise\"]]}', response_length=42, prompt_length=410, finish_reason='stop')],\n",
       " [Response(response_text='{\"page_utterance_emotions\": [[\"fear\", \"sadness\"], [\"fear\", \"sadness\"], [\"fear\", \"sadness\"], [\"fear\", \"surprise\"], [\"anger\", \"fear\"], [\"anger\"]]}', response_length=52, prompt_length=457, finish_reason='stop')],\n",
       " [Response(response_text='{\"page_utterance_emotions\": [[\"anger\"], [\"anger\"], [\"anger\"], [\"anger\", \"surprise\"]]}', response_length=26, prompt_length=399, finish_reason='stop')],\n",
       " [Response(response_text='{\"page_utterance_emotions\": [[\"surprise\"], [\"anger\"], [\"fear\", \"surprise\"], [\"fear\", \"surprise\"], [\"fear\"], [\"fear\", \"surprise\"], [\"fear\", \"sadness\"], [\"anger\"], [\"anger\"], [\"anger\"], [\"anger\"], [\"anger\"]]}', response_length=68, prompt_length=543, finish_reason='stop')],\n",
       " [Response(response_text='{\"page_utterance_emotions\": [[\"joy\"], [\"joy\"], [\"sadness\"], [\"surprise\"], [\"surprise\"], [\"joy\"], [\"anger\", \"joy\"], [\"anger\", \"joy\"], [\"joy\"]]}', response_length=46, prompt_length=494, finish_reason='stop')],\n",
       " [Response(response_text='{\"page_utterance_emotions\": [[\"anger\", \"disgust\"], [\"anger\", \"disgust\"], [\"anger\"], [\"sadness\"], [\"sadness\", \"joy\"], [\"anger\", \"sadness\"]]}', response_length=47, prompt_length=450, finish_reason='stop')],\n",
       " [Response(response_text='{\"page_utterance_emotions\": [[\"anger\"], [\"surprise\"], [\"fear\", \"surprise\"], [\"anger\"], [\"surprise\"], [\"sadness\"], [\"sadness\"], [\"anger\"], [\"anger\", \"sadness\"], [\"anger\", \"fear\"], [\"anger\", \"fear\"], [\"anger\"], [\"anger\"], [\"sadness\"], [\"fear\", \"sadness\"], [\"sadness\"]]}', response_length=86, prompt_length=569, finish_reason='stop')],\n",
       " [Response(response_text='{\"page_utterance_emotions\": [[\"anger\", \"surprise\"], [\"sadness\"], [\"anger\", \"sadness\"], [\"surprise\"], [\"sadness\"], [\"sadness\"], [\"fear\", \"surprise\"], [\"surprise\"], [\"surprise\"], [\"surprise\"], [\"joy\"]]}', response_length=63, prompt_length=518, finish_reason='stop')],\n",
       " [Response(response_text='{\"page_utterance_emotions\": [[\"anger\"], [\"anger\"], [\"fear\", \"surprise\"], [\"surprise\"], [\"anger\", \"fear\"], [\"neutral\"], [\"neutral\"], [\"anger\"], [\"anger\"], [\"anger\"], [\"surprise\"]]}', response_length=54, prompt_length=490, finish_reason='stop')],\n",
       " [Response(response_text='{\"page_utterance_emotions\": [[\"fear\"], [\"sadness\", \"surprise\"], [\"fear\"], [\"neutral\"], [\"surprise\"], [\"surprise\"], [\"fear\"], [\"fear\"], [\"anger\"], [\"sadness\"], [\"sadness\"], [\"joy\"], [\"joy\"], [\"joy\"]]}', response_length=65, prompt_length=596, finish_reason='stop')],\n",
       " [Response(response_text='{\"page_utterance_emotions\": [[\"surprise\"], [\"sadness\"], [\"sadness\", \"surprise\"], [\"sadness\"], [\"sadness\"], [\"sadness\", \"joy\"], [\"joy\"]]}', response_length=44, prompt_length=508, finish_reason='stop')],\n",
       " [Response(response_text='{\"page_utterance_emotions\": [[\"joy\"], [\"fear\", \"surprise\"], [\"surprise\"], [\"surprise\"], [\"joy\"], [\"joy\"], [\"surprise\"], [\"anger\"], [\"anger\"], [\"anger\"], [\"anger\"]]}', response_length=51, prompt_length=529, finish_reason='stop')],\n",
       " [Response(response_text='{\"page_utterance_emotions\": [[\"sadness\"], [\"surprise\"], [\"sadness\", \"joy\"], [\"surprise\"], [\"sadness\"], [\"neutral\"], [\"surprise\"], [\"neutral\"], [\"surprise\"], [\"joy\"], [\"joy\"], [\"joy\"]]}', response_length=56, prompt_length=577, finish_reason='stop')],\n",
       " [Response(response_text='{\"page_utterance_emotions\": [[\"joy\"]]}', response_length=13, prompt_length=384, finish_reason='stop')]]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_preds = []\n",
    "bad_idx = []\n",
    "\n",
    "for i, raw_pred in enumerate(test_predictions):\n",
    "    try:\n",
    "        x = json.loads(raw_pred[0].response_text)[\"page_utterance_emotions\"]\n",
    "        processed_preds.append(x)\n",
    "    except:\n",
    "        print(i)\n",
    "        bad_idx.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bad_idx.sort(reverse=True)\n",
    "\n",
    "# # Remove elements from 'grounds' at the specified indices\n",
    "# for idx in bad_idx:\n",
    "    \n",
    "#     #del processed_grounds[idx]\n",
    "#     del processed_preds[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(processed_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_grounds = []\n",
    "\n",
    "for ground in test_grounds:\n",
    "    x = json.loads(ground)[\"page_utterance_emotions\"]\n",
    "    processed_grounds.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(processed_grounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_idx.sort(reverse=True)\n",
    "\n",
    "# Remove elements from 'grounds' at the specified indices\n",
    "for idx in bad_idx:\n",
    "    \n",
    "    del processed_grounds[idx]\n",
    "    #del processed_preds[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 23 24\n",
      "27 17 18\n",
      "85 13 14\n",
      "103 13 12\n"
     ]
    }
   ],
   "source": [
    "bad_idx = []\n",
    "\n",
    "for idx, (i,j) in enumerate(zip(processed_grounds, processed_preds)):\n",
    "    if len(i) != len(j):\n",
    "        print(idx, len(i), len(j))\n",
    "        bad_idx.append(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_idx.sort(reverse=True)\n",
    "\n",
    "# Remove elements from 'grounds' at the specified indices\n",
    "for idx in bad_idx:\n",
    "    \n",
    "    del processed_grounds[idx]\n",
    "    del processed_preds[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(152, 152)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(processed_grounds), len(processed_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "grounds = [item for sublist in processed_grounds for item in sublist]\n",
    "predictions = [item for sublist in processed_preds for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1260, 1260)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(grounds), len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "mlb = MultiLabelBinarizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Utilisateurs/umushtaq/.conda/envs/er_nb_env/lib/python3.11/site-packages/sklearn/preprocessing/_label.py:900: UserWarning: unknown class(es) ['j', 'o', 'y'] will be ignored\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "y_true_mhot = mlb.fit_transform(grounds)\n",
    "y_pred_mhot = mlb.transform(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1260, 7), (1260, 7))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true_mhot.shape, y_pred_mhot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_labels = mlb.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['anger', 'disgust', 'fear', 'joy', 'neutral', 'sadness',\n",
       "       'surprise'], dtype=object)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger      0.609     0.577     0.593       430\n",
      "     disgust      0.171     0.150     0.160        40\n",
      "        fear      0.538     0.443     0.486       287\n",
      "         joy      0.514     0.559     0.536       290\n",
      "     neutral      0.407     0.250     0.310        96\n",
      "     sadness      0.494     0.512     0.503       324\n",
      "    surprise      0.568     0.500     0.532       342\n",
      "\n",
      "   micro avg      0.535     0.500     0.517      1809\n",
      "   macro avg      0.472     0.427     0.445      1809\n",
      "weighted avg      0.534     0.500     0.514      1809\n",
      " samples avg      0.550     0.519     0.509      1809\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Utilisateurs/umushtaq/.conda/envs/er_nb_env/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true_mhot, y_pred_mhot, target_names=class_labels, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open({Path(FT_DIR)} / \"classification_report.pickle\", 'wb') as fh:\n",
    "    \n",
    "#      pickle.dump(classification_report(y_true_mhot, y_pred_mhot, target_names=class_labels, digits=3, output_dict=True), fh)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "unsloth/Meta-Llama-3.1-70B-Instruct, 8 Epochs.\n",
    "\n",
    "precision    recall  f1-score   support\n",
    "\n",
    "       anger      0.601     0.569     0.584       445\n",
    "     disgust      0.160     0.174     0.167        46\n",
    "        fear      0.454     0.505     0.478       293\n",
    "         joy      0.534     0.465     0.497       271\n",
    "     neutral      0.574     0.321     0.412       109\n",
    "     sadness      0.535     0.601     0.566       333\n",
    "    surprise      0.580     0.678     0.625       342\n",
    "\n",
    "   micro avg      0.536     0.545     0.541      1839\n",
    "   macro avg      0.491     0.473     0.476      1839\n",
    "weighted avg      0.539     0.545     0.538      1839\n",
    " samples avg      0.555     0.557     0.532      1839"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "unsloth/llama-3-8b-Instruct-bnb-4bit, 8 epochs\n",
    "\n",
    "precision    recall  f1-score   support\n",
    "\n",
    "       anger      0.625     0.528     0.572       417\n",
    "     disgust      0.182     0.154     0.167        39\n",
    "        fear      0.520     0.449     0.482       294\n",
    "         joy      0.540     0.580     0.559       281\n",
    "     neutral      0.518     0.406     0.455       106\n",
    "     sadness      0.499     0.557     0.526       323\n",
    "    surprise      0.579     0.606     0.593       343\n",
    "\n",
    "   micro avg      0.546     0.528     0.537      1803\n",
    "   macro avg      0.495     0.469     0.479      1803\n",
    "weighted avg      0.547     0.528     0.535      1803\n",
    " samples avg      0.561     0.548     0.529      1803"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "unsloth/Meta-Llama-3.1-8B-Instruct-bnb-4bit\n",
    "\n",
    "precision    recall  f1-score   support\n",
    "\n",
    "       anger      0.557     0.582     0.570       443\n",
    "     disgust      0.196     0.200     0.198        50\n",
    "        fear      0.504     0.465     0.484       284\n",
    "         joy      0.529     0.583     0.555       278\n",
    "     neutral      0.397     0.237     0.297        97\n",
    "     sadness      0.509     0.515     0.512       328\n",
    "    surprise      0.616     0.624     0.620       348\n",
    "\n",
    "   micro avg      0.532     0.531     0.532      1828\n",
    "   macro avg      0.473     0.458     0.462      1828\n",
    "weighted avg      0.529     0.531     0.529      1828\n",
    " samples avg      0.550     0.544     0.523      1828"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "unsloth/Llama-3.2-3B-Instruct-bnb-4bit\n",
    "\n",
    "precision    recall  f1-score   support\n",
    "\n",
    "       anger      0.525     0.524     0.525       416\n",
    "     disgust      0.200     0.150     0.171        40\n",
    "        fear      0.438     0.491     0.463       281\n",
    "         joy      0.496     0.442     0.468       269\n",
    "     neutral      0.447     0.337     0.384       101\n",
    "     sadness      0.509     0.523     0.516       308\n",
    "    surprise      0.585     0.543     0.563       337\n",
    "\n",
    "   micro avg      0.504     0.490     0.497      1752\n",
    "   macro avg      0.457     0.430     0.441      1752\n",
    "weighted avg      0.504     0.490     0.496      1752\n",
    " samples avg      0.524     0.505     0.491      1752"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "unsloth/Llama-3.2-1B-Instruct-bnb-4bit\n",
    "\n",
    "precision    recall  f1-score   support\n",
    "\n",
    "       anger      0.489     0.538     0.512       398\n",
    "     disgust      0.250     0.175     0.206        40\n",
    "        fear      0.330     0.422     0.371       232\n",
    "         joy      0.450     0.440     0.445       243\n",
    "     neutral      0.241     0.169     0.198        77\n",
    "     sadness      0.472     0.449     0.461       267\n",
    "    surprise      0.490     0.507     0.498       294\n",
    "\n",
    "   micro avg      0.439     0.456     0.448      1551\n",
    "   macro avg      0.389     0.386     0.384      1551\n",
    "weighted avg      0.438     0.456     0.445      1551\n",
    " samples avg      0.457     0.468     0.437      1551"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "unsloth/Qwen2.5-32B-Instruct-bnb-4bit\n",
    "\n",
    "precision    recall  f1-score   support\n",
    "\n",
    "       anger      0.526     0.493     0.509       450\n",
    "     disgust      0.194     0.240     0.214        50\n",
    "        fear      0.481     0.438     0.459       297\n",
    "         joy      0.580     0.610     0.595       290\n",
    "     neutral      0.486     0.321     0.387       109\n",
    "     sadness      0.522     0.588     0.553       342\n",
    "    surprise      0.593     0.583     0.588       355\n",
    "\n",
    "   micro avg      0.528     0.520     0.524      1893\n",
    "   macro avg      0.483     0.468     0.472      1893\n",
    "weighted avg      0.528     0.520     0.522      1893\n",
    " samples avg      0.546     0.537     0.515      1893"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "unsloth/Qwen2.5-72B-Instruct-bnb-4bit\n",
    "\n",
    "precision    recall  f1-score   support\n",
    "\n",
    "       anger      0.577     0.562     0.569       447\n",
    "     disgust      0.136     0.130     0.133        46\n",
    "        fear      0.460     0.458     0.459       299\n",
    "         joy      0.560     0.558     0.559       294\n",
    "     neutral      0.440     0.346     0.387       107\n",
    "     sadness      0.518     0.594     0.553       342\n",
    "    surprise      0.599     0.555     0.576       353\n",
    "\n",
    "   micro avg      0.531     0.526     0.529      1888\n",
    "   macro avg      0.470     0.458     0.462      1888\n",
    "weighted avg      0.531     0.526     0.528      1888\n",
    " samples avg      0.550     0.547     0.521      1888"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "unsloth/Phi-3-medium-4k-instruct-bnb-4bit\n",
    "\n",
    "precision    recall  f1-score   support\n",
    "\n",
    "       anger      0.558     0.570     0.564       416\n",
    "     disgust      0.133     0.103     0.116        39\n",
    "        fear      0.473     0.441     0.457       281\n",
    "         joy      0.557     0.551     0.554       283\n",
    "     neutral      0.326     0.316     0.321        95\n",
    "     sadness      0.494     0.541     0.517       314\n",
    "    surprise      0.525     0.534     0.529       320\n",
    "\n",
    "   micro avg      0.507     0.510     0.509      1748\n",
    "   macro avg      0.438     0.437     0.437      1748\n",
    "weighted avg      0.504     0.510     0.507      1748\n",
    " samples avg      0.525     0.531     0.502      1748"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "precision    recall  f1-score   support\n",
    "\n",
    "       anger      0.570     0.584     0.577       445\n",
    "     disgust      0.296     0.174     0.219        46\n",
    "        fear      0.468     0.468     0.468       293\n",
    "         joy      0.544     0.476     0.508       271\n",
    "     neutral      0.506     0.385     0.438       109\n",
    "     sadness      0.508     0.601     0.550       333\n",
    "    surprise      0.628     0.608     0.618       342\n",
    "\n",
    "   micro avg      0.540     0.535     0.538      1839\n",
    "   macro avg      0.503     0.471     0.483      1839\n",
    "weighted avg      0.539     0.535     0.535      1839\n",
    " samples avg      0.556     0.550     0.529      1839\n",
    "\n",
    "\n",
    " w class probabilities. llama 8b"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
