{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.0,
  "eval_steps": 36,
  "global_step": 177,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.005649717514124294,
      "grad_norm": 3.6147007942199707,
      "learning_rate": 2e-05,
      "loss": 2.9691,
      "step": 1
    },
    {
      "epoch": 0.011299435028248588,
      "grad_norm": 3.763885021209717,
      "learning_rate": 4e-05,
      "loss": 2.9006,
      "step": 2
    },
    {
      "epoch": 0.01694915254237288,
      "grad_norm": 3.5195956230163574,
      "learning_rate": 6e-05,
      "loss": 2.8638,
      "step": 3
    },
    {
      "epoch": 0.022598870056497175,
      "grad_norm": 3.0708441734313965,
      "learning_rate": 8e-05,
      "loss": 2.7111,
      "step": 4
    },
    {
      "epoch": 0.02824858757062147,
      "grad_norm": 2.4800708293914795,
      "learning_rate": 0.0001,
      "loss": 2.5168,
      "step": 5
    },
    {
      "epoch": 0.03389830508474576,
      "grad_norm": 2.12060546875,
      "learning_rate": 0.00012,
      "loss": 2.2923,
      "step": 6
    },
    {
      "epoch": 0.03954802259887006,
      "grad_norm": 1.9959428310394287,
      "learning_rate": 0.00014,
      "loss": 2.1056,
      "step": 7
    },
    {
      "epoch": 0.04519774011299435,
      "grad_norm": 1.940605878829956,
      "learning_rate": 0.00016,
      "loss": 1.8964,
      "step": 8
    },
    {
      "epoch": 0.05084745762711865,
      "grad_norm": 1.88239324092865,
      "learning_rate": 0.00018,
      "loss": 1.6293,
      "step": 9
    },
    {
      "epoch": 0.05649717514124294,
      "grad_norm": 1.7332160472869873,
      "learning_rate": 0.0002,
      "loss": 1.3603,
      "step": 10
    },
    {
      "epoch": 0.062146892655367235,
      "grad_norm": 2.0415499210357666,
      "learning_rate": 0.00019880239520958084,
      "loss": 1.1088,
      "step": 11
    },
    {
      "epoch": 0.06779661016949153,
      "grad_norm": 1.7313051223754883,
      "learning_rate": 0.0001976047904191617,
      "loss": 0.8882,
      "step": 12
    },
    {
      "epoch": 0.07344632768361582,
      "grad_norm": 1.8082748651504517,
      "learning_rate": 0.00019640718562874253,
      "loss": 0.675,
      "step": 13
    },
    {
      "epoch": 0.07909604519774012,
      "grad_norm": 1.2425915002822876,
      "learning_rate": 0.00019520958083832338,
      "loss": 0.5169,
      "step": 14
    },
    {
      "epoch": 0.0847457627118644,
      "grad_norm": 0.9620150327682495,
      "learning_rate": 0.00019401197604790419,
      "loss": 0.4097,
      "step": 15
    },
    {
      "epoch": 0.0903954802259887,
      "grad_norm": 0.6274466514587402,
      "learning_rate": 0.00019281437125748504,
      "loss": 0.3989,
      "step": 16
    },
    {
      "epoch": 0.096045197740113,
      "grad_norm": 1.1136754751205444,
      "learning_rate": 0.00019161676646706587,
      "loss": 0.3595,
      "step": 17
    },
    {
      "epoch": 0.1016949152542373,
      "grad_norm": 0.2930084466934204,
      "learning_rate": 0.0001904191616766467,
      "loss": 0.3308,
      "step": 18
    },
    {
      "epoch": 0.10734463276836158,
      "grad_norm": 0.30406931042671204,
      "learning_rate": 0.00018922155688622756,
      "loss": 0.3257,
      "step": 19
    },
    {
      "epoch": 0.11299435028248588,
      "grad_norm": 0.2763116955757141,
      "learning_rate": 0.0001880239520958084,
      "loss": 0.2972,
      "step": 20
    },
    {
      "epoch": 0.11864406779661017,
      "grad_norm": 0.3343603014945984,
      "learning_rate": 0.00018682634730538924,
      "loss": 0.3003,
      "step": 21
    },
    {
      "epoch": 0.12429378531073447,
      "grad_norm": 0.19918715953826904,
      "learning_rate": 0.00018562874251497007,
      "loss": 0.2975,
      "step": 22
    },
    {
      "epoch": 0.12994350282485875,
      "grad_norm": 0.21245896816253662,
      "learning_rate": 0.00018443113772455093,
      "loss": 0.3052,
      "step": 23
    },
    {
      "epoch": 0.13559322033898305,
      "grad_norm": 0.18136188387870789,
      "learning_rate": 0.00018323353293413173,
      "loss": 0.2787,
      "step": 24
    },
    {
      "epoch": 0.14124293785310735,
      "grad_norm": 0.18799424171447754,
      "learning_rate": 0.00018203592814371256,
      "loss": 0.2777,
      "step": 25
    },
    {
      "epoch": 0.14689265536723164,
      "grad_norm": 0.20719414949417114,
      "learning_rate": 0.00018083832335329342,
      "loss": 0.2586,
      "step": 26
    },
    {
      "epoch": 0.15254237288135594,
      "grad_norm": 0.22491177916526794,
      "learning_rate": 0.00017964071856287425,
      "loss": 0.2587,
      "step": 27
    },
    {
      "epoch": 0.15819209039548024,
      "grad_norm": 0.24009403586387634,
      "learning_rate": 0.0001784431137724551,
      "loss": 0.268,
      "step": 28
    },
    {
      "epoch": 0.1638418079096045,
      "grad_norm": 0.2434244453907013,
      "learning_rate": 0.00017724550898203594,
      "loss": 0.2579,
      "step": 29
    },
    {
      "epoch": 0.1694915254237288,
      "grad_norm": 0.2402014583349228,
      "learning_rate": 0.0001760479041916168,
      "loss": 0.2453,
      "step": 30
    },
    {
      "epoch": 0.1751412429378531,
      "grad_norm": 0.2765374779701233,
      "learning_rate": 0.00017485029940119762,
      "loss": 0.238,
      "step": 31
    },
    {
      "epoch": 0.1807909604519774,
      "grad_norm": 0.2786140739917755,
      "learning_rate": 0.00017365269461077845,
      "loss": 0.2487,
      "step": 32
    },
    {
      "epoch": 0.1864406779661017,
      "grad_norm": 0.2790966331958771,
      "learning_rate": 0.00017245508982035928,
      "loss": 0.2382,
      "step": 33
    },
    {
      "epoch": 0.192090395480226,
      "grad_norm": 0.2642367482185364,
      "learning_rate": 0.0001712574850299401,
      "loss": 0.2183,
      "step": 34
    },
    {
      "epoch": 0.1977401129943503,
      "grad_norm": 0.3274858891963959,
      "learning_rate": 0.00017005988023952097,
      "loss": 0.1972,
      "step": 35
    },
    {
      "epoch": 0.2033898305084746,
      "grad_norm": 0.3384608328342438,
      "learning_rate": 0.0001688622754491018,
      "loss": 0.2011,
      "step": 36
    },
    {
      "epoch": 0.2033898305084746,
      "eval_loss": 0.31947556138038635,
      "eval_runtime": 106.9216,
      "eval_samples_per_second": 9.886,
      "eval_steps_per_second": 3.301,
      "step": 36
    },
    {
      "epoch": 0.20903954802259886,
      "grad_norm": 0.3698844611644745,
      "learning_rate": 0.00016766467065868263,
      "loss": 0.1873,
      "step": 37
    },
    {
      "epoch": 0.21468926553672316,
      "grad_norm": 0.436627060174942,
      "learning_rate": 0.00016646706586826348,
      "loss": 0.2064,
      "step": 38
    },
    {
      "epoch": 0.22033898305084745,
      "grad_norm": 0.4647083580493927,
      "learning_rate": 0.00016526946107784431,
      "loss": 0.1826,
      "step": 39
    },
    {
      "epoch": 0.22598870056497175,
      "grad_norm": 0.4939833879470825,
      "learning_rate": 0.00016407185628742517,
      "loss": 0.1911,
      "step": 40
    },
    {
      "epoch": 0.23163841807909605,
      "grad_norm": 0.5678521394729614,
      "learning_rate": 0.000162874251497006,
      "loss": 0.185,
      "step": 41
    },
    {
      "epoch": 0.23728813559322035,
      "grad_norm": 0.6429062485694885,
      "learning_rate": 0.00016167664670658683,
      "loss": 0.1739,
      "step": 42
    },
    {
      "epoch": 0.24293785310734464,
      "grad_norm": 0.7716258764266968,
      "learning_rate": 0.00016047904191616766,
      "loss": 0.1642,
      "step": 43
    },
    {
      "epoch": 0.24858757062146894,
      "grad_norm": 1.0052106380462646,
      "learning_rate": 0.0001592814371257485,
      "loss": 0.1485,
      "step": 44
    },
    {
      "epoch": 0.2542372881355932,
      "grad_norm": 1.407415747642517,
      "learning_rate": 0.00015808383233532935,
      "loss": 0.8864,
      "step": 45
    },
    {
      "epoch": 0.2598870056497175,
      "grad_norm": 1.446999192237854,
      "learning_rate": 0.00015688622754491018,
      "loss": 0.6789,
      "step": 46
    },
    {
      "epoch": 0.2655367231638418,
      "grad_norm": 1.657862901687622,
      "learning_rate": 0.00015568862275449103,
      "loss": 0.5841,
      "step": 47
    },
    {
      "epoch": 0.2711864406779661,
      "grad_norm": 2.3898541927337646,
      "learning_rate": 0.00015449101796407186,
      "loss": 0.4993,
      "step": 48
    },
    {
      "epoch": 0.2768361581920904,
      "grad_norm": 3.1319785118103027,
      "learning_rate": 0.00015329341317365272,
      "loss": 0.4939,
      "step": 49
    },
    {
      "epoch": 0.2824858757062147,
      "grad_norm": 3.463898181915283,
      "learning_rate": 0.00015209580838323355,
      "loss": 0.4423,
      "step": 50
    },
    {
      "epoch": 0.288135593220339,
      "grad_norm": 2.9350156784057617,
      "learning_rate": 0.00015089820359281438,
      "loss": 0.4365,
      "step": 51
    },
    {
      "epoch": 0.2937853107344633,
      "grad_norm": 1.1365524530410767,
      "learning_rate": 0.0001497005988023952,
      "loss": 0.4173,
      "step": 52
    },
    {
      "epoch": 0.2994350282485876,
      "grad_norm": 1.074143648147583,
      "learning_rate": 0.00014850299401197604,
      "loss": 0.415,
      "step": 53
    },
    {
      "epoch": 0.3050847457627119,
      "grad_norm": 1.8777259588241577,
      "learning_rate": 0.0001473053892215569,
      "loss": 0.3742,
      "step": 54
    },
    {
      "epoch": 0.3107344632768362,
      "grad_norm": 2.347874402999878,
      "learning_rate": 0.00014610778443113772,
      "loss": 0.331,
      "step": 55
    },
    {
      "epoch": 0.3163841807909605,
      "grad_norm": 2.4757180213928223,
      "learning_rate": 0.00014491017964071858,
      "loss": 0.3347,
      "step": 56
    },
    {
      "epoch": 0.3220338983050847,
      "grad_norm": 2.297769069671631,
      "learning_rate": 0.0001437125748502994,
      "loss": 0.3159,
      "step": 57
    },
    {
      "epoch": 0.327683615819209,
      "grad_norm": 2.2354073524475098,
      "learning_rate": 0.00014251497005988024,
      "loss": 0.2944,
      "step": 58
    },
    {
      "epoch": 0.3333333333333333,
      "grad_norm": 1.2527252435684204,
      "learning_rate": 0.0001413173652694611,
      "loss": 0.2811,
      "step": 59
    },
    {
      "epoch": 0.3389830508474576,
      "grad_norm": 0.5294889807701111,
      "learning_rate": 0.00014011976047904193,
      "loss": 0.277,
      "step": 60
    },
    {
      "epoch": 0.3446327683615819,
      "grad_norm": 1.615409255027771,
      "learning_rate": 0.00013892215568862276,
      "loss": 0.261,
      "step": 61
    },
    {
      "epoch": 0.3502824858757062,
      "grad_norm": 2.3565826416015625,
      "learning_rate": 0.00013772455089820359,
      "loss": 0.2326,
      "step": 62
    },
    {
      "epoch": 0.3559322033898305,
      "grad_norm": 2.2676644325256348,
      "learning_rate": 0.00013652694610778444,
      "loss": 0.2441,
      "step": 63
    },
    {
      "epoch": 0.3615819209039548,
      "grad_norm": 2.6172778606414795,
      "learning_rate": 0.00013532934131736527,
      "loss": 0.2257,
      "step": 64
    },
    {
      "epoch": 0.3672316384180791,
      "grad_norm": 2.2219784259796143,
      "learning_rate": 0.0001341317365269461,
      "loss": 0.2009,
      "step": 65
    },
    {
      "epoch": 0.3728813559322034,
      "grad_norm": 1.60747492313385,
      "learning_rate": 0.00013293413173652696,
      "loss": 0.2051,
      "step": 66
    },
    {
      "epoch": 0.3785310734463277,
      "grad_norm": 0.9059460759162903,
      "learning_rate": 0.0001317365269461078,
      "loss": 0.2189,
      "step": 67
    },
    {
      "epoch": 0.384180790960452,
      "grad_norm": 0.48767775297164917,
      "learning_rate": 0.00013053892215568865,
      "loss": 0.1772,
      "step": 68
    },
    {
      "epoch": 0.3898305084745763,
      "grad_norm": 0.22183433175086975,
      "learning_rate": 0.00012934131736526947,
      "loss": 0.1788,
      "step": 69
    },
    {
      "epoch": 0.3954802259887006,
      "grad_norm": 0.21199893951416016,
      "learning_rate": 0.0001281437125748503,
      "loss": 0.1638,
      "step": 70
    },
    {
      "epoch": 0.4011299435028249,
      "grad_norm": 0.2798916697502136,
      "learning_rate": 0.00012694610778443113,
      "loss": 0.164,
      "step": 71
    },
    {
      "epoch": 0.4067796610169492,
      "grad_norm": 0.3008389472961426,
      "learning_rate": 0.00012574850299401196,
      "loss": 0.1851,
      "step": 72
    },
    {
      "epoch": 0.4067796610169492,
      "eval_loss": 0.220395028591156,
      "eval_runtime": 107.0473,
      "eval_samples_per_second": 9.874,
      "eval_steps_per_second": 3.298,
      "step": 72
    },
    {
      "epoch": 0.4124293785310734,
      "grad_norm": 0.2752411663532257,
      "learning_rate": 0.00012455089820359282,
      "loss": 0.1646,
      "step": 73
    },
    {
      "epoch": 0.4180790960451977,
      "grad_norm": 0.22836175560951233,
      "learning_rate": 0.00012335329341317365,
      "loss": 0.1495,
      "step": 74
    },
    {
      "epoch": 0.423728813559322,
      "grad_norm": 0.19651535153388977,
      "learning_rate": 0.0001221556886227545,
      "loss": 0.1539,
      "step": 75
    },
    {
      "epoch": 0.4293785310734463,
      "grad_norm": 0.17783139646053314,
      "learning_rate": 0.00012095808383233534,
      "loss": 0.1376,
      "step": 76
    },
    {
      "epoch": 0.4350282485875706,
      "grad_norm": 0.1941981315612793,
      "learning_rate": 0.00011976047904191617,
      "loss": 0.1589,
      "step": 77
    },
    {
      "epoch": 0.4406779661016949,
      "grad_norm": 0.1967797428369522,
      "learning_rate": 0.00011856287425149701,
      "loss": 0.1161,
      "step": 78
    },
    {
      "epoch": 0.4463276836158192,
      "grad_norm": 0.17558464407920837,
      "learning_rate": 0.00011736526946107784,
      "loss": 0.1378,
      "step": 79
    },
    {
      "epoch": 0.4519774011299435,
      "grad_norm": 0.1675860434770584,
      "learning_rate": 0.0001161676646706587,
      "loss": 0.1119,
      "step": 80
    },
    {
      "epoch": 0.4576271186440678,
      "grad_norm": 0.15039336681365967,
      "learning_rate": 0.00011497005988023953,
      "loss": 0.1193,
      "step": 81
    },
    {
      "epoch": 0.4632768361581921,
      "grad_norm": 0.1406513899564743,
      "learning_rate": 0.00011377245508982037,
      "loss": 0.1044,
      "step": 82
    },
    {
      "epoch": 0.4689265536723164,
      "grad_norm": 0.15886755287647247,
      "learning_rate": 0.0001125748502994012,
      "loss": 0.1052,
      "step": 83
    },
    {
      "epoch": 0.4745762711864407,
      "grad_norm": 0.1567404717206955,
      "learning_rate": 0.00011137724550898203,
      "loss": 0.1087,
      "step": 84
    },
    {
      "epoch": 0.480225988700565,
      "grad_norm": 0.16100694239139557,
      "learning_rate": 0.00011017964071856288,
      "loss": 0.104,
      "step": 85
    },
    {
      "epoch": 0.4858757062146893,
      "grad_norm": 0.16900992393493652,
      "learning_rate": 0.00010898203592814371,
      "loss": 0.1021,
      "step": 86
    },
    {
      "epoch": 0.4915254237288136,
      "grad_norm": 0.12511375546455383,
      "learning_rate": 0.00010778443113772456,
      "loss": 0.0829,
      "step": 87
    },
    {
      "epoch": 0.4971751412429379,
      "grad_norm": 0.1421051025390625,
      "learning_rate": 0.00010658682634730539,
      "loss": 0.0631,
      "step": 88
    },
    {
      "epoch": 0.5028248587570622,
      "grad_norm": 0.6861942410469055,
      "learning_rate": 0.00010538922155688624,
      "loss": 0.6787,
      "step": 89
    },
    {
      "epoch": 0.5084745762711864,
      "grad_norm": 0.6297979950904846,
      "learning_rate": 0.00010419161676646707,
      "loss": 0.5635,
      "step": 90
    },
    {
      "epoch": 0.5141242937853108,
      "grad_norm": 0.5136308073997498,
      "learning_rate": 0.0001029940119760479,
      "loss": 0.4844,
      "step": 91
    },
    {
      "epoch": 0.519774011299435,
      "grad_norm": 0.4297943413257599,
      "learning_rate": 0.00010179640718562875,
      "loss": 0.4773,
      "step": 92
    },
    {
      "epoch": 0.5254237288135594,
      "grad_norm": 0.3608500063419342,
      "learning_rate": 0.00010059880239520958,
      "loss": 0.4166,
      "step": 93
    },
    {
      "epoch": 0.5310734463276836,
      "grad_norm": 0.26745396852493286,
      "learning_rate": 9.940119760479042e-05,
      "loss": 0.401,
      "step": 94
    },
    {
      "epoch": 0.536723163841808,
      "grad_norm": 0.2633970379829407,
      "learning_rate": 9.820359281437126e-05,
      "loss": 0.3432,
      "step": 95
    },
    {
      "epoch": 0.5423728813559322,
      "grad_norm": 0.31500741839408875,
      "learning_rate": 9.700598802395209e-05,
      "loss": 0.3579,
      "step": 96
    },
    {
      "epoch": 0.5480225988700564,
      "grad_norm": 0.3390897810459137,
      "learning_rate": 9.580838323353294e-05,
      "loss": 0.3631,
      "step": 97
    },
    {
      "epoch": 0.5536723163841808,
      "grad_norm": 0.27916306257247925,
      "learning_rate": 9.461077844311378e-05,
      "loss": 0.317,
      "step": 98
    },
    {
      "epoch": 0.559322033898305,
      "grad_norm": 0.3229704797267914,
      "learning_rate": 9.341317365269462e-05,
      "loss": 0.3123,
      "step": 99
    },
    {
      "epoch": 0.5649717514124294,
      "grad_norm": 0.3030564486980438,
      "learning_rate": 9.221556886227547e-05,
      "loss": 0.2994,
      "step": 100
    },
    {
      "epoch": 0.5706214689265536,
      "grad_norm": 0.31848517060279846,
      "learning_rate": 9.101796407185628e-05,
      "loss": 0.2929,
      "step": 101
    },
    {
      "epoch": 0.576271186440678,
      "grad_norm": 0.23326922953128815,
      "learning_rate": 8.982035928143712e-05,
      "loss": 0.252,
      "step": 102
    },
    {
      "epoch": 0.5819209039548022,
      "grad_norm": 0.29668137431144714,
      "learning_rate": 8.862275449101797e-05,
      "loss": 0.23,
      "step": 103
    },
    {
      "epoch": 0.5875706214689266,
      "grad_norm": 0.23686793446540833,
      "learning_rate": 8.742514970059881e-05,
      "loss": 0.2511,
      "step": 104
    },
    {
      "epoch": 0.5932203389830508,
      "grad_norm": 0.22393594682216644,
      "learning_rate": 8.622754491017964e-05,
      "loss": 0.2345,
      "step": 105
    },
    {
      "epoch": 0.5988700564971752,
      "grad_norm": 0.22732016444206238,
      "learning_rate": 8.502994011976048e-05,
      "loss": 0.2176,
      "step": 106
    },
    {
      "epoch": 0.6045197740112994,
      "grad_norm": 0.20238593220710754,
      "learning_rate": 8.383233532934131e-05,
      "loss": 0.2242,
      "step": 107
    },
    {
      "epoch": 0.6101694915254238,
      "grad_norm": 0.19426694512367249,
      "learning_rate": 8.263473053892216e-05,
      "loss": 0.2132,
      "step": 108
    },
    {
      "epoch": 0.6101694915254238,
      "eval_loss": 0.21775253117084503,
      "eval_runtime": 106.5714,
      "eval_samples_per_second": 9.918,
      "eval_steps_per_second": 3.312,
      "step": 108
    },
    {
      "epoch": 0.615819209039548,
      "grad_norm": 0.18457385897636414,
      "learning_rate": 8.1437125748503e-05,
      "loss": 0.1814,
      "step": 109
    },
    {
      "epoch": 0.6214689265536724,
      "grad_norm": 0.20592333376407623,
      "learning_rate": 8.023952095808383e-05,
      "loss": 0.1828,
      "step": 110
    },
    {
      "epoch": 0.6271186440677966,
      "grad_norm": 0.15009023249149323,
      "learning_rate": 7.904191616766467e-05,
      "loss": 0.1771,
      "step": 111
    },
    {
      "epoch": 0.632768361581921,
      "grad_norm": 0.147037535905838,
      "learning_rate": 7.784431137724552e-05,
      "loss": 0.1781,
      "step": 112
    },
    {
      "epoch": 0.6384180790960452,
      "grad_norm": 0.15673331916332245,
      "learning_rate": 7.664670658682636e-05,
      "loss": 0.1724,
      "step": 113
    },
    {
      "epoch": 0.6440677966101694,
      "grad_norm": 0.16703544557094574,
      "learning_rate": 7.544910179640719e-05,
      "loss": 0.167,
      "step": 114
    },
    {
      "epoch": 0.6497175141242938,
      "grad_norm": 0.17096459865570068,
      "learning_rate": 7.425149700598802e-05,
      "loss": 0.1782,
      "step": 115
    },
    {
      "epoch": 0.655367231638418,
      "grad_norm": 0.20043537020683289,
      "learning_rate": 7.305389221556886e-05,
      "loss": 0.1611,
      "step": 116
    },
    {
      "epoch": 0.6610169491525424,
      "grad_norm": 0.1732831448316574,
      "learning_rate": 7.18562874251497e-05,
      "loss": 0.1638,
      "step": 117
    },
    {
      "epoch": 0.6666666666666666,
      "grad_norm": 0.15368014574050903,
      "learning_rate": 7.065868263473055e-05,
      "loss": 0.1497,
      "step": 118
    },
    {
      "epoch": 0.672316384180791,
      "grad_norm": 0.17223909497261047,
      "learning_rate": 6.946107784431138e-05,
      "loss": 0.1484,
      "step": 119
    },
    {
      "epoch": 0.6779661016949152,
      "grad_norm": 0.13687589764595032,
      "learning_rate": 6.826347305389222e-05,
      "loss": 0.1285,
      "step": 120
    },
    {
      "epoch": 0.6836158192090396,
      "grad_norm": 0.14853788912296295,
      "learning_rate": 6.706586826347305e-05,
      "loss": 0.1371,
      "step": 121
    },
    {
      "epoch": 0.6892655367231638,
      "grad_norm": 0.14367909729480743,
      "learning_rate": 6.58682634730539e-05,
      "loss": 0.1281,
      "step": 122
    },
    {
      "epoch": 0.6949152542372882,
      "grad_norm": 0.13876837491989136,
      "learning_rate": 6.467065868263474e-05,
      "loss": 0.1136,
      "step": 123
    },
    {
      "epoch": 0.7005649717514124,
      "grad_norm": 0.1379079669713974,
      "learning_rate": 6.347305389221557e-05,
      "loss": 0.1154,
      "step": 124
    },
    {
      "epoch": 0.7062146892655368,
      "grad_norm": 0.1340416520833969,
      "learning_rate": 6.227544910179641e-05,
      "loss": 0.1095,
      "step": 125
    },
    {
      "epoch": 0.711864406779661,
      "grad_norm": 0.1338007003068924,
      "learning_rate": 6.107784431137725e-05,
      "loss": 0.1053,
      "step": 126
    },
    {
      "epoch": 0.7175141242937854,
      "grad_norm": 0.1506124585866928,
      "learning_rate": 5.988023952095808e-05,
      "loss": 0.1077,
      "step": 127
    },
    {
      "epoch": 0.7231638418079096,
      "grad_norm": 0.14503540098667145,
      "learning_rate": 5.868263473053892e-05,
      "loss": 0.0999,
      "step": 128
    },
    {
      "epoch": 0.7288135593220338,
      "grad_norm": 0.1353173553943634,
      "learning_rate": 5.748502994011976e-05,
      "loss": 0.1069,
      "step": 129
    },
    {
      "epoch": 0.7344632768361582,
      "grad_norm": 0.13092388212680817,
      "learning_rate": 5.62874251497006e-05,
      "loss": 0.0858,
      "step": 130
    },
    {
      "epoch": 0.7401129943502824,
      "grad_norm": 0.1237475574016571,
      "learning_rate": 5.508982035928144e-05,
      "loss": 0.0731,
      "step": 131
    },
    {
      "epoch": 0.7457627118644068,
      "grad_norm": 0.11273428797721863,
      "learning_rate": 5.389221556886228e-05,
      "loss": 0.063,
      "step": 132
    },
    {
      "epoch": 0.751412429378531,
      "grad_norm": 0.5986006855964661,
      "learning_rate": 5.269461077844312e-05,
      "loss": 0.6658,
      "step": 133
    },
    {
      "epoch": 0.7570621468926554,
      "grad_norm": 0.49597811698913574,
      "learning_rate": 5.149700598802395e-05,
      "loss": 0.5022,
      "step": 134
    },
    {
      "epoch": 0.7627118644067796,
      "grad_norm": 0.405394047498703,
      "learning_rate": 5.029940119760479e-05,
      "loss": 0.4502,
      "step": 135
    },
    {
      "epoch": 0.768361581920904,
      "grad_norm": 0.38469064235687256,
      "learning_rate": 4.910179640718563e-05,
      "loss": 0.4558,
      "step": 136
    },
    {
      "epoch": 0.7740112994350282,
      "grad_norm": 0.3563584089279175,
      "learning_rate": 4.790419161676647e-05,
      "loss": 0.4138,
      "step": 137
    },
    {
      "epoch": 0.7796610169491526,
      "grad_norm": 0.3308485746383667,
      "learning_rate": 4.670658682634731e-05,
      "loss": 0.382,
      "step": 138
    },
    {
      "epoch": 0.7853107344632768,
      "grad_norm": 0.29341256618499756,
      "learning_rate": 4.550898203592814e-05,
      "loss": 0.35,
      "step": 139
    },
    {
      "epoch": 0.7909604519774012,
      "grad_norm": 0.2654128074645996,
      "learning_rate": 4.4311377245508984e-05,
      "loss": 0.3538,
      "step": 140
    },
    {
      "epoch": 0.7966101694915254,
      "grad_norm": 0.2395174354314804,
      "learning_rate": 4.311377245508982e-05,
      "loss": 0.3155,
      "step": 141
    },
    {
      "epoch": 0.8022598870056498,
      "grad_norm": 0.21632720530033112,
      "learning_rate": 4.191616766467066e-05,
      "loss": 0.3062,
      "step": 142
    },
    {
      "epoch": 0.807909604519774,
      "grad_norm": 0.20059946179389954,
      "learning_rate": 4.07185628742515e-05,
      "loss": 0.2833,
      "step": 143
    },
    {
      "epoch": 0.8135593220338984,
      "grad_norm": 0.20851485431194305,
      "learning_rate": 3.9520958083832336e-05,
      "loss": 0.2855,
      "step": 144
    },
    {
      "epoch": 0.8135593220338984,
      "eval_loss": 0.2149861752986908,
      "eval_runtime": 106.7502,
      "eval_samples_per_second": 9.902,
      "eval_steps_per_second": 3.307,
      "step": 144
    },
    {
      "epoch": 0.8192090395480226,
      "grad_norm": 0.22147683799266815,
      "learning_rate": 3.832335329341318e-05,
      "loss": 0.2619,
      "step": 145
    },
    {
      "epoch": 0.8248587570621468,
      "grad_norm": 0.24266557395458221,
      "learning_rate": 3.712574850299401e-05,
      "loss": 0.2683,
      "step": 146
    },
    {
      "epoch": 0.8305084745762712,
      "grad_norm": 0.23427943885326385,
      "learning_rate": 3.592814371257485e-05,
      "loss": 0.2584,
      "step": 147
    },
    {
      "epoch": 0.8361581920903954,
      "grad_norm": 0.2117406278848648,
      "learning_rate": 3.473053892215569e-05,
      "loss": 0.2409,
      "step": 148
    },
    {
      "epoch": 0.8418079096045198,
      "grad_norm": 0.21371567249298096,
      "learning_rate": 3.3532934131736525e-05,
      "loss": 0.2308,
      "step": 149
    },
    {
      "epoch": 0.847457627118644,
      "grad_norm": 0.20808511972427368,
      "learning_rate": 3.233532934131737e-05,
      "loss": 0.2042,
      "step": 150
    },
    {
      "epoch": 0.8531073446327684,
      "grad_norm": 0.20601212978363037,
      "learning_rate": 3.1137724550898205e-05,
      "loss": 0.2221,
      "step": 151
    },
    {
      "epoch": 0.8587570621468926,
      "grad_norm": 0.20834806561470032,
      "learning_rate": 2.994011976047904e-05,
      "loss": 0.2065,
      "step": 152
    },
    {
      "epoch": 0.864406779661017,
      "grad_norm": 0.20465004444122314,
      "learning_rate": 2.874251497005988e-05,
      "loss": 0.2017,
      "step": 153
    },
    {
      "epoch": 0.8700564971751412,
      "grad_norm": 0.2176462858915329,
      "learning_rate": 2.754491017964072e-05,
      "loss": 0.1896,
      "step": 154
    },
    {
      "epoch": 0.8757062146892656,
      "grad_norm": 0.22713586688041687,
      "learning_rate": 2.634730538922156e-05,
      "loss": 0.1888,
      "step": 155
    },
    {
      "epoch": 0.8813559322033898,
      "grad_norm": 0.19702695310115814,
      "learning_rate": 2.5149700598802394e-05,
      "loss": 0.201,
      "step": 156
    },
    {
      "epoch": 0.8870056497175142,
      "grad_norm": 0.19277504086494446,
      "learning_rate": 2.3952095808383234e-05,
      "loss": 0.1788,
      "step": 157
    },
    {
      "epoch": 0.8926553672316384,
      "grad_norm": 0.19548949599266052,
      "learning_rate": 2.275449101796407e-05,
      "loss": 0.1782,
      "step": 158
    },
    {
      "epoch": 0.8983050847457628,
      "grad_norm": 0.1779787391424179,
      "learning_rate": 2.155688622754491e-05,
      "loss": 0.1611,
      "step": 159
    },
    {
      "epoch": 0.903954802259887,
      "grad_norm": 0.18503552675247192,
      "learning_rate": 2.035928143712575e-05,
      "loss": 0.1623,
      "step": 160
    },
    {
      "epoch": 0.9096045197740112,
      "grad_norm": 0.1787511259317398,
      "learning_rate": 1.916167664670659e-05,
      "loss": 0.1425,
      "step": 161
    },
    {
      "epoch": 0.9152542372881356,
      "grad_norm": 0.15806742012500763,
      "learning_rate": 1.7964071856287426e-05,
      "loss": 0.1551,
      "step": 162
    },
    {
      "epoch": 0.9209039548022598,
      "grad_norm": 0.17348995804786682,
      "learning_rate": 1.6766467065868263e-05,
      "loss": 0.1299,
      "step": 163
    },
    {
      "epoch": 0.9265536723163842,
      "grad_norm": 0.1587734818458557,
      "learning_rate": 1.5568862275449103e-05,
      "loss": 0.1406,
      "step": 164
    },
    {
      "epoch": 0.9322033898305084,
      "grad_norm": 0.16241435706615448,
      "learning_rate": 1.437125748502994e-05,
      "loss": 0.1246,
      "step": 165
    },
    {
      "epoch": 0.9378531073446328,
      "grad_norm": 0.17490270733833313,
      "learning_rate": 1.317365269461078e-05,
      "loss": 0.1144,
      "step": 166
    },
    {
      "epoch": 0.943502824858757,
      "grad_norm": 0.14761649072170258,
      "learning_rate": 1.1976047904191617e-05,
      "loss": 0.1218,
      "step": 167
    },
    {
      "epoch": 0.9491525423728814,
      "grad_norm": 0.17359408736228943,
      "learning_rate": 1.0778443113772455e-05,
      "loss": 0.1189,
      "step": 168
    },
    {
      "epoch": 0.9548022598870056,
      "grad_norm": 0.16124659776687622,
      "learning_rate": 9.580838323353295e-06,
      "loss": 0.1065,
      "step": 169
    },
    {
      "epoch": 0.96045197740113,
      "grad_norm": 0.16228976845741272,
      "learning_rate": 8.383233532934131e-06,
      "loss": 0.1017,
      "step": 170
    },
    {
      "epoch": 0.9661016949152542,
      "grad_norm": 0.15846465528011322,
      "learning_rate": 7.18562874251497e-06,
      "loss": 0.1097,
      "step": 171
    },
    {
      "epoch": 0.9717514124293786,
      "grad_norm": 0.1658899486064911,
      "learning_rate": 5.9880239520958085e-06,
      "loss": 0.0982,
      "step": 172
    },
    {
      "epoch": 0.9774011299435028,
      "grad_norm": 0.1833268254995346,
      "learning_rate": 4.7904191616766475e-06,
      "loss": 0.1017,
      "step": 173
    },
    {
      "epoch": 0.9830508474576272,
      "grad_norm": 0.1874803751707077,
      "learning_rate": 3.592814371257485e-06,
      "loss": 0.0888,
      "step": 174
    },
    {
      "epoch": 0.9887005649717514,
      "grad_norm": 0.19307436048984528,
      "learning_rate": 2.3952095808383237e-06,
      "loss": 0.0767,
      "step": 175
    },
    {
      "epoch": 0.9943502824858758,
      "grad_norm": 0.22479045391082764,
      "learning_rate": 1.1976047904191619e-06,
      "loss": 0.0747,
      "step": 176
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.6120132207870483,
      "learning_rate": 0.0,
      "loss": 0.0708,
      "step": 177
    }
  ],
  "logging_steps": 1,
  "max_steps": 177,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 6373537555783680.0,
  "train_batch_size": 24,
  "trial_name": null,
  "trial_params": null
}
