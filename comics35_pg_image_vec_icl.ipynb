{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import torch\n",
    "import json_repair\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "from datasets import Dataset\n",
    "\n",
    "from trl import SFTTrainer\n",
    "from transformers import TrainingArguments\n",
    "from unsloth.chat_templates import get_chat_template\n",
    "from unsloth import FastLanguageModel, is_bfloat16_supported\n",
    "\n",
    "import clip\n",
    "from PIL import Image\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# from sklearn.metrics import classification_report\n",
    "# from sklearn.preprocessing import MultiLabelBinarizer\n",
    "# import torch.nn.functional as F\n",
    "\n",
    "\n",
    "# from pathlib import Path\n",
    "# from tqdm.notebook import tqdm\n",
    "# from operator import itemgetter\n",
    "# from sklearn.metrics import classification_report\n",
    "# from transformers import AutoTokenizer, AutoModel, AutoModelForCausalLM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2024.12.4: Fast Llama patching. Transformers:4.47.0.\n",
      "   \\\\   /|    GPU: NVIDIA H100 NVL. Max memory: 93.003 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.5.1+cu124. CUDA: 9.0. CUDA Toolkit: 12.4. Triton: 3.1.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.28.post3. FA2 = False]\n",
      " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    }
   ],
   "source": [
    "k = 3\n",
    "max_seq_length = 4096\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name=\"unsloth/Meta-Llama-3.1-8B-Instruct-bnb-4bit\",\n",
    "    #model_name=\"unsloth/Qwen2.5-32B-Instruct-bnb-4bit\",\n",
    "    max_seq_length=max_seq_length,\n",
    "    load_in_4bit=True,\n",
    "    dtype=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/Utilisateurs/umushtaq/emotion_analysis_comics/dataset_files/comics_pg_w_images.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>file_name</th>\n",
       "      <th>page_nr</th>\n",
       "      <th>split</th>\n",
       "      <th>utterance</th>\n",
       "      <th>emotion_c</th>\n",
       "      <th>comics_title</th>\n",
       "      <th>comics_id</th>\n",
       "      <th>image_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>QC copy - 1499 - 58 ECC Co_mics 50 _The Jurass...</td>\n",
       "      <td>1</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>[\"THIS VILE THING ATTACKED THE SMALL BEASTS OF...</td>\n",
       "      <td>[['anger'], ['anger'], ['fear'], ['fear'], ['f...</td>\n",
       "      <td>Jurassic League #4</td>\n",
       "      <td>1499</td>\n",
       "      <td>/Utilisateurs/umushtaq/emotion_analysis_comics...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>QC copy - 1499 - 58 ECC Co_mics 50 _The Jurass...</td>\n",
       "      <td>2</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>[\"NO--  #GKKK\\u2026#\", \"#CHOMP!\", \"BY THE SKIN...</td>\n",
       "      <td>[['fear'], ['anger'], ['surprise'], ['anger'],...</td>\n",
       "      <td>Jurassic League #4</td>\n",
       "      <td>1499</td>\n",
       "      <td>/Utilisateurs/umushtaq/emotion_analysis_comics...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>QC copy - 1499 - 58 ECC Co_mics 50 _The Jurass...</td>\n",
       "      <td>3</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>[\"COME ON, BEAST!\", \"SHOW YOURSELF!\", \"WHY DO ...</td>\n",
       "      <td>[['joy'], ['joy'], ['anger'], ['anger']]</td>\n",
       "      <td>Jurassic League #4</td>\n",
       "      <td>1499</td>\n",
       "      <td>/Utilisateurs/umushtaq/emotion_analysis_comics...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>QC copy - 1499 - 58 ECC Co_mics 50 _The Jurass...</td>\n",
       "      <td>4</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>[\"#AARGH! \"]</td>\n",
       "      <td>[['fear', 'surprise']]</td>\n",
       "      <td>Jurassic League #4</td>\n",
       "      <td>1499</td>\n",
       "      <td>/Utilisateurs/umushtaq/emotion_analysis_comics...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>QC copy - 1499 - 58 ECC Co_mics 50 _The Jurass...</td>\n",
       "      <td>5</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>[\"I, THE GREEN TORCH, HAVE BEEN TASKED WITH PR...</td>\n",
       "      <td>[['anger'], ['anger'], ['fear'], ['fear', 'sur...</td>\n",
       "      <td>Jurassic League #4</td>\n",
       "      <td>1499</td>\n",
       "      <td>/Utilisateurs/umushtaq/emotion_analysis_comics...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>869</th>\n",
       "      <td>869</td>\n",
       "      <td>QC copy - 2200 - Stillwater 13.xlsx</td>\n",
       "      <td>16</td>\n",
       "      <td>TEST</td>\n",
       "      <td>[\"WE WERE IN GALEN'S OFFICE. YOU WERE ABOUT TO...</td>\n",
       "      <td>[['anger'], ['anger'], ['anger'], ['anger'], [...</td>\n",
       "      <td>Stillwater #13</td>\n",
       "      <td>2200</td>\n",
       "      <td>/Utilisateurs/umushtaq/emotion_analysis_comics...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>870</th>\n",
       "      <td>870</td>\n",
       "      <td>QC copy - 2200 - Stillwater 13.xlsx</td>\n",
       "      <td>17</td>\n",
       "      <td>TEST</td>\n",
       "      <td>[\"SO WHAT ARE WE GOING TO DO?\", \"THE WAY I SEE...</td>\n",
       "      <td>[['sadness', 'surprise'], ['anger'], ['anger']...</td>\n",
       "      <td>Stillwater #13</td>\n",
       "      <td>2200</td>\n",
       "      <td>/Utilisateurs/umushtaq/emotion_analysis_comics...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>871</td>\n",
       "      <td>QC copy - 2200 - Stillwater 13.xlsx</td>\n",
       "      <td>18</td>\n",
       "      <td>TEST</td>\n",
       "      <td>[\"KIDDIE COUNCIL'S BEEN GOING A LONG TIME... \"...</td>\n",
       "      <td>[['anger', 'sadness'], ['anger'], ['anger'], [...</td>\n",
       "      <td>Stillwater #13</td>\n",
       "      <td>2200</td>\n",
       "      <td>/Utilisateurs/umushtaq/emotion_analysis_comics...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>872</th>\n",
       "      <td>872</td>\n",
       "      <td>QC copy - 2200 - Stillwater 13.xlsx</td>\n",
       "      <td>19</td>\n",
       "      <td>TEST</td>\n",
       "      <td>[\"IT'S BEEN\\u2026 PEACEFUL. ASIDE FROM SHIT LI...</td>\n",
       "      <td>[['anger'], ['joy'], ['joy'], ['anger', 'surpr...</td>\n",
       "      <td>Stillwater #13</td>\n",
       "      <td>2200</td>\n",
       "      <td>/Utilisateurs/umushtaq/emotion_analysis_comics...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>873</th>\n",
       "      <td>873</td>\n",
       "      <td>QC copy - 2200 - Stillwater 13.xlsx</td>\n",
       "      <td>20</td>\n",
       "      <td>TEST</td>\n",
       "      <td>[\"\\\" AND PAY OUR NEIGHBOURS A VISIT. \\\"\"]</td>\n",
       "      <td>[['anger', 'joy']]</td>\n",
       "      <td>Stillwater #13</td>\n",
       "      <td>2200</td>\n",
       "      <td>/Utilisateurs/umushtaq/emotion_analysis_comics...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>874 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0                                          file_name  page_nr  \\\n",
       "0             0  QC copy - 1499 - 58 ECC Co_mics 50 _The Jurass...        1   \n",
       "1             1  QC copy - 1499 - 58 ECC Co_mics 50 _The Jurass...        2   \n",
       "2             2  QC copy - 1499 - 58 ECC Co_mics 50 _The Jurass...        3   \n",
       "3             3  QC copy - 1499 - 58 ECC Co_mics 50 _The Jurass...        4   \n",
       "4             4  QC copy - 1499 - 58 ECC Co_mics 50 _The Jurass...        5   \n",
       "..          ...                                                ...      ...   \n",
       "869         869                QC copy - 2200 - Stillwater 13.xlsx       16   \n",
       "870         870                QC copy - 2200 - Stillwater 13.xlsx       17   \n",
       "871         871                QC copy - 2200 - Stillwater 13.xlsx       18   \n",
       "872         872                QC copy - 2200 - Stillwater 13.xlsx       19   \n",
       "873         873                QC copy - 2200 - Stillwater 13.xlsx       20   \n",
       "\n",
       "     split                                          utterance  \\\n",
       "0    TRAIN  [\"THIS VILE THING ATTACKED THE SMALL BEASTS OF...   \n",
       "1    TRAIN  [\"NO--  #GKKK\\u2026#\", \"#CHOMP!\", \"BY THE SKIN...   \n",
       "2    TRAIN  [\"COME ON, BEAST!\", \"SHOW YOURSELF!\", \"WHY DO ...   \n",
       "3    TRAIN                                       [\"#AARGH! \"]   \n",
       "4    TRAIN  [\"I, THE GREEN TORCH, HAVE BEEN TASKED WITH PR...   \n",
       "..     ...                                                ...   \n",
       "869   TEST  [\"WE WERE IN GALEN'S OFFICE. YOU WERE ABOUT TO...   \n",
       "870   TEST  [\"SO WHAT ARE WE GOING TO DO?\", \"THE WAY I SEE...   \n",
       "871   TEST  [\"KIDDIE COUNCIL'S BEEN GOING A LONG TIME... \"...   \n",
       "872   TEST  [\"IT'S BEEN\\u2026 PEACEFUL. ASIDE FROM SHIT LI...   \n",
       "873   TEST          [\"\\\" AND PAY OUR NEIGHBOURS A VISIT. \\\"\"]   \n",
       "\n",
       "                                             emotion_c        comics_title  \\\n",
       "0    [['anger'], ['anger'], ['fear'], ['fear'], ['f...  Jurassic League #4   \n",
       "1    [['fear'], ['anger'], ['surprise'], ['anger'],...  Jurassic League #4   \n",
       "2             [['joy'], ['joy'], ['anger'], ['anger']]  Jurassic League #4   \n",
       "3                               [['fear', 'surprise']]  Jurassic League #4   \n",
       "4    [['anger'], ['anger'], ['fear'], ['fear', 'sur...  Jurassic League #4   \n",
       "..                                                 ...                 ...   \n",
       "869  [['anger'], ['anger'], ['anger'], ['anger'], [...      Stillwater #13   \n",
       "870  [['sadness', 'surprise'], ['anger'], ['anger']...      Stillwater #13   \n",
       "871  [['anger', 'sadness'], ['anger'], ['anger'], [...      Stillwater #13   \n",
       "872  [['anger'], ['joy'], ['joy'], ['anger', 'surpr...      Stillwater #13   \n",
       "873                                 [['anger', 'joy']]      Stillwater #13   \n",
       "\n",
       "     comics_id                                         image_path  \n",
       "0         1499  /Utilisateurs/umushtaq/emotion_analysis_comics...  \n",
       "1         1499  /Utilisateurs/umushtaq/emotion_analysis_comics...  \n",
       "2         1499  /Utilisateurs/umushtaq/emotion_analysis_comics...  \n",
       "3         1499  /Utilisateurs/umushtaq/emotion_analysis_comics...  \n",
       "4         1499  /Utilisateurs/umushtaq/emotion_analysis_comics...  \n",
       "..         ...                                                ...  \n",
       "869       2200  /Utilisateurs/umushtaq/emotion_analysis_comics...  \n",
       "870       2200  /Utilisateurs/umushtaq/emotion_analysis_comics...  \n",
       "871       2200  /Utilisateurs/umushtaq/emotion_analysis_comics...  \n",
       "872       2200  /Utilisateurs/umushtaq/emotion_analysis_comics...  \n",
       "873       2200  /Utilisateurs/umushtaq/emotion_analysis_comics...  \n",
       "\n",
       "[874 rows x 9 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "image_embed_model, preprocess = clip.load(\"ViT-B/32\", device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_images = df.image_path.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 874/874 [04:38<00:00,  3.14it/s]\n"
     ]
    }
   ],
   "source": [
    "image_encodings = {}\n",
    "\n",
    "for image in tqdm(dataset_images):\n",
    "    \n",
    "    image_p = preprocess(Image.open(image)).unsqueeze(0).to(device) # type: ignore\n",
    "    image_features = image_embed_model.encode_image(image_p).squeeze().cpu()\n",
    "    image_encodings[image] = image_features.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-5.8887e-01,  6.4697e-01, -9.7961e-02,  9.7229e-02,  5.0879e-01,\n",
       "       -1.8604e-01,  3.1641e-01, -2.4097e-01, -2.8549e-02, -2.8711e-01,\n",
       "        2.0801e-01,  2.3041e-02,  3.8989e-01, -1.8417e-02, -2.8809e-01,\n",
       "        2.1667e-01, -2.5952e-01, -1.4844e-01,  3.1891e-02, -3.3887e-01,\n",
       "       -8.6572e-01, -2.9150e-01,  2.2144e-01,  7.7197e-01, -1.3562e-01,\n",
       "        1.1218e-01,  8.1055e-01, -1.5076e-01, -9.9304e-02,  2.4704e-02,\n",
       "       -2.3376e-01,  1.0687e-01, -7.6523e-03, -1.5759e-01,  5.0977e-01,\n",
       "        6.7673e-03,  1.4380e-01,  5.2881e-01,  2.1545e-01, -3.3276e-01,\n",
       "        2.8491e-01, -4.6411e-01,  8.2336e-02, -4.0234e-01,  3.2349e-01,\n",
       "        1.3906e+00,  3.2495e-01, -2.1439e-02, -3.1641e-01, -9.2850e-03,\n",
       "        1.3855e-01, -3.3521e-01,  1.9141e-01, -8.3801e-02,  1.6772e-01,\n",
       "       -1.4819e-01,  2.4878e-01, -7.1472e-02,  1.8665e-01, -3.7750e-02,\n",
       "        1.2183e-01,  7.3486e-02,  1.9495e-01,  2.1484e-01, -1.1475e-01,\n",
       "        2.3645e-01,  2.0020e-01,  4.1675e-01,  6.9336e-02,  1.3147e-01,\n",
       "        1.2018e-01,  1.1426e-01, -3.6108e-01, -1.3550e-01,  1.0175e-01,\n",
       "       -1.1121e-01, -1.4197e-01, -3.5431e-02, -1.9092e-01,  2.0508e-02,\n",
       "        1.6553e-01, -7.1045e-02, -3.7793e-01,  3.8574e-01,  2.2961e-01,\n",
       "        2.8418e-01, -2.6807e-01,  1.3660e-01, -6.4258e-01, -2.0416e-02,\n",
       "       -5.2719e-03,  5.7422e-01, -6.2188e+00,  5.9473e-01, -1.8311e-01,\n",
       "        1.3086e-01,  1.1810e-01, -2.0422e-01, -2.2182e-03,  2.7686e-01,\n",
       "        3.7842e-01, -4.2676e-01,  1.8018e-01, -1.4709e-01, -3.8110e-01,\n",
       "        1.6891e-02, -1.7979e+00, -3.6646e-01, -1.9702e-01,  1.0236e-01,\n",
       "        2.2839e-01, -1.6479e-01, -2.5757e-01, -1.8112e-02,  2.4182e-01,\n",
       "        6.4307e-01,  2.9248e-01,  1.4954e-01,  3.6328e-01,  1.8762e-01,\n",
       "        3.7549e-01, -2.8809e-01,  9.3307e-03,  1.6626e-01,  2.2949e-01,\n",
       "       -4.6533e-01,  3.8721e-01,  1.4832e-01, -2.6392e-01, -3.2373e-01,\n",
       "        5.3833e-02,  1.9336e-01, -6.6162e-02,  7.7002e-01, -2.8784e-01,\n",
       "       -1.3725e-02, -5.7422e-01, -5.0977e-01, -1.0181e-01,  2.2192e-01,\n",
       "       -2.7130e-02, -3.8666e-02,  8.4534e-02,  2.3468e-02, -9.5398e-02,\n",
       "        3.0444e-01, -4.1211e-01,  4.1260e-02,  1.4893e-02,  9.8450e-02,\n",
       "       -3.7769e-01,  3.0249e-01, -1.1055e+00, -2.4048e-01, -2.7173e-01,\n",
       "       -4.0234e-01,  4.3213e-01, -2.0520e-01,  1.3440e-01, -5.0684e-01,\n",
       "        3.4839e-01, -1.9287e-02,  1.0675e-01,  5.8057e-01,  1.3293e-01,\n",
       "        7.3181e-02, -8.7158e-01,  2.2217e-01, -2.7710e-01, -5.2637e-01,\n",
       "       -2.3743e-02,  2.8345e-01, -1.3538e-01, -9.7168e-02,  1.1591e-01,\n",
       "       -1.7017e-01, -8.9111e-01,  5.2979e-02, -8.0664e-01,  2.6880e-01,\n",
       "        7.4121e-01, -1.8896e-01, -3.8696e-01,  1.6211e-01, -8.4534e-02,\n",
       "        1.8542e-01,  5.2002e-01, -4.4556e-01, -3.4961e-01, -2.7943e-03,\n",
       "        1.1639e-01,  2.8662e-01,  3.3569e-01, -9.8389e-02, -1.2803e+00,\n",
       "        2.5299e-02,  2.2400e-01, -1.1780e-01,  4.8242e-01, -2.5928e-01,\n",
       "       -1.3252e-02,  3.2983e-01,  7.5684e-02,  4.8866e-03,  2.6123e-01,\n",
       "       -1.0907e-01, -6.2622e-02,  6.8420e-02,  8.7524e-02,  5.6122e-02,\n",
       "       -4.3799e-01,  2.7808e-01, -1.0950e-01, -4.7681e-01, -1.0211e-01,\n",
       "       -2.9129e-02,  3.3862e-01,  1.7395e-01,  6.8359e-01, -6.2317e-02,\n",
       "        6.0156e-01,  1.4008e-02, -3.4766e-01,  4.6533e-01,  1.1487e-01,\n",
       "       -6.1829e-02,  4.9756e-01,  1.5991e-01,  7.5302e-03, -2.7661e-01,\n",
       "       -7.1945e-03, -5.9521e-01,  6.4160e-01,  3.9624e-01,  3.8013e-01,\n",
       "        4.5654e-01,  8.4734e-04,  2.0581e-01, -2.8564e-01, -3.2129e-01,\n",
       "       -5.1172e-01, -2.3779e-01,  4.6167e-01,  2.0703e-01,  1.7749e-01,\n",
       "       -6.5674e-01, -7.6660e-02,  3.7292e-02, -4.2725e-01,  1.2585e-01,\n",
       "        3.5156e-01,  1.7090e-01, -2.8296e-01,  1.9543e-01,  1.6687e-01,\n",
       "       -1.3721e-01, -2.6978e-01,  5.1660e-01, -1.7861e+00,  8.3618e-02,\n",
       "       -1.9617e-01, -1.0974e-01,  1.6983e-02, -2.4609e+00,  2.0276e-01,\n",
       "       -2.4841e-01,  2.1216e-01,  6.4502e-01, -1.6357e-01,  5.9113e-02,\n",
       "       -2.1936e-01, -3.2861e-01,  7.9834e-02,  1.4050e-01,  1.0089e-01,\n",
       "       -8.3984e-02, -1.2585e-01,  1.0052e-01, -2.4219e-01,  1.9006e-01,\n",
       "        8.0139e-02, -4.2090e-01,  3.0298e-01, -3.0200e-01, -3.3203e-01,\n",
       "       -1.7749e-01,  2.5562e-01,  4.6600e-02, -4.5923e-01, -1.1194e-01,\n",
       "        3.3875e-03,  7.7209e-02, -7.2449e-02,  5.6641e-01, -6.8176e-02,\n",
       "        1.4685e-01,  7.8760e-01,  4.7388e-01,  7.5195e-02,  9.1736e-02,\n",
       "       -9.5520e-02, -1.2720e-01, -3.8052e-03,  1.7236e-01,  1.1475e-01,\n",
       "       -3.0273e-01, -1.7688e-01,  1.6174e-02,  9.3750e-01,  2.1057e-01,\n",
       "       -4.8767e-02,  5.2100e-01,  7.6660e-01,  4.1089e-01, -4.0381e-01,\n",
       "       -4.1406e-01,  1.0712e-01,  2.0691e-01,  1.5247e-01,  4.7729e-01,\n",
       "       -2.5681e-02,  3.3813e-01, -9.7168e-02,  1.5640e-02,  4.6924e-01,\n",
       "       -1.6211e-01,  6.2891e-01,  4.9477e-03,  1.1200e-01, -4.2407e-01,\n",
       "        1.6541e-01, -6.4575e-02,  1.3806e-01,  2.1011e-02, -3.4692e-01,\n",
       "        1.6785e-01,  1.1267e-01,  1.3440e-01,  5.6982e-01,  5.3418e-01,\n",
       "       -3.1958e-01,  2.6050e-01,  2.5879e-02, -1.3916e-01,  1.3940e-01,\n",
       "        2.8467e-01,  3.3740e-01, -5.1544e-02,  3.2227e-01,  2.3108e-01,\n",
       "        2.9468e-01,  1.5710e-01,  1.4023e-02, -4.9146e-01,  3.7048e-02,\n",
       "       -4.9011e-02, -3.4863e-01, -1.1731e-01, -4.9706e-03,  2.4829e-01,\n",
       "        3.5620e-01,  2.4939e-01,  8.7051e-03, -1.8103e-01, -9.4482e-01,\n",
       "        9.6436e-02,  4.9561e-02, -4.1382e-01, -2.2034e-01, -1.6919e-01,\n",
       "       -1.3451e-02,  4.8608e-01,  1.5942e-01, -1.7590e-01,  2.6172e-01,\n",
       "        1.3232e-01, -8.7646e-02,  2.6855e-01, -1.4587e-01,  1.8506e-01,\n",
       "       -6.2805e-02, -5.5762e-01, -2.4756e-01, -1.1127e-01,  6.8970e-02,\n",
       "        3.8159e-01,  2.1899e-01,  1.6125e-01, -7.1472e-02,  1.5320e-01,\n",
       "        1.6785e-01,  3.5767e-01,  2.6392e-01,  7.7209e-02, -5.8203e-01,\n",
       "       -2.6904e-01,  3.4863e-01,  1.0565e-01,  2.2839e-01, -3.3740e-01,\n",
       "        5.6519e-02, -4.1992e-01, -1.0879e+00, -5.1318e-01,  3.2593e-01,\n",
       "       -9.3079e-03,  7.9651e-02, -3.0688e-01,  5.7373e-01, -3.3618e-01,\n",
       "        1.9934e-01,  2.1472e-01,  2.5864e-02,  4.6967e-02,  2.0264e-01,\n",
       "        5.7861e-01, -7.7515e-02, -2.7124e-01, -2.7563e-01, -8.4375e-01,\n",
       "       -1.8280e-02, -1.4392e-01,  3.5107e-01,  1.4221e-01, -1.3123e-01,\n",
       "        5.2246e-02, -9.4421e-02,  5.5859e-01,  1.2783e+00,  1.7065e-01,\n",
       "       -8.8135e-02,  5.8691e-01, -8.6816e-01, -3.0273e-01,  5.1514e-01,\n",
       "       -4.6509e-01, -6.4160e-01, -1.4062e-01,  5.0488e-01, -4.4507e-01,\n",
       "       -1.9684e-02,  2.3645e-01,  7.2571e-02, -3.9136e-01, -2.9712e-01,\n",
       "        2.1094e-01,  2.1875e-01,  7.9834e-02,  1.2866e-01,  1.6870e-01,\n",
       "        1.2335e-01,  1.5930e-01,  1.1658e-01,  4.1919e-01, -3.3020e-02,\n",
       "       -6.2805e-02, -6.8481e-02,  6.4148e-02, -2.7563e-01,  9.2163e-02,\n",
       "        1.2207e-01, -8.0811e-02,  5.7861e-01, -1.8457e-01,  8.1177e-02,\n",
       "        5.0323e-02, -3.5614e-02,  1.9324e-01, -2.3083e-01,  4.8267e-01,\n",
       "       -5.3864e-03,  6.3184e-01,  7.5500e-02,  1.6138e-01, -2.0618e-01,\n",
       "       -3.6548e-01,  1.7798e-01,  9.2041e-02,  2.3145e-01, -1.6614e-01,\n",
       "       -1.5515e-01, -4.4586e-02,  2.7417e-01,  4.4458e-01,  9.7656e-02,\n",
       "       -1.0950e-01,  7.7332e-02, -3.3447e-01,  4.1846e-01, -2.7100e-01,\n",
       "        4.7583e-01, -1.3306e-01,  6.0400e-01, -1.4856e-01,  2.4658e-01,\n",
       "       -1.4429e-01,  6.0986e-01, -7.1411e-02,  7.8186e-02,  2.9492e-01,\n",
       "       -1.6876e-02,  3.1543e-01, -5.0146e-01,  5.1514e-02,  1.8945e-01,\n",
       "        4.0985e-02, -6.0333e-02,  3.3911e-01, -1.3110e-01,  7.3926e-01,\n",
       "        2.2925e-01,  5.9845e-02], dtype=float16)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_encodings['/Utilisateurs/umushtaq/emotion_analysis_comics/comics_dataset_images/001499/images/page00001.jpg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['image_embedding'] = df.image_path.apply(lambda x: image_encodings[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>file_name</th>\n",
       "      <th>page_nr</th>\n",
       "      <th>split</th>\n",
       "      <th>utterance</th>\n",
       "      <th>emotion_c</th>\n",
       "      <th>comics_title</th>\n",
       "      <th>comics_id</th>\n",
       "      <th>image_path</th>\n",
       "      <th>image_embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>QC copy - 1499 - 58 ECC Co_mics 50 _The Jurass...</td>\n",
       "      <td>1</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>[\"THIS VILE THING ATTACKED THE SMALL BEASTS OF...</td>\n",
       "      <td>[['anger'], ['anger'], ['fear'], ['fear'], ['f...</td>\n",
       "      <td>Jurassic League #4</td>\n",
       "      <td>1499</td>\n",
       "      <td>/Utilisateurs/umushtaq/emotion_analysis_comics...</td>\n",
       "      <td>[-0.589, 0.647, -0.09796, 0.0972, 0.509, -0.18...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>QC copy - 1499 - 58 ECC Co_mics 50 _The Jurass...</td>\n",
       "      <td>2</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>[\"NO--  #GKKK\\u2026#\", \"#CHOMP!\", \"BY THE SKIN...</td>\n",
       "      <td>[['fear'], ['anger'], ['surprise'], ['anger'],...</td>\n",
       "      <td>Jurassic League #4</td>\n",
       "      <td>1499</td>\n",
       "      <td>/Utilisateurs/umushtaq/emotion_analysis_comics...</td>\n",
       "      <td>[-0.7397, 0.6367, -0.2167, 0.3684, 0.1387, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>QC copy - 1499 - 58 ECC Co_mics 50 _The Jurass...</td>\n",
       "      <td>3</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>[\"COME ON, BEAST!\", \"SHOW YOURSELF!\", \"WHY DO ...</td>\n",
       "      <td>[['joy'], ['joy'], ['anger'], ['anger']]</td>\n",
       "      <td>Jurassic League #4</td>\n",
       "      <td>1499</td>\n",
       "      <td>/Utilisateurs/umushtaq/emotion_analysis_comics...</td>\n",
       "      <td>[-0.2688, 0.692, -0.2815, 0.002438, 0.3242, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>QC copy - 1499 - 58 ECC Co_mics 50 _The Jurass...</td>\n",
       "      <td>4</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>[\"#AARGH! \"]</td>\n",
       "      <td>[['fear', 'surprise']]</td>\n",
       "      <td>Jurassic League #4</td>\n",
       "      <td>1499</td>\n",
       "      <td>/Utilisateurs/umushtaq/emotion_analysis_comics...</td>\n",
       "      <td>[-0.4148, 0.504, 0.1909, 0.1763, 0.2874, 0.087...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>QC copy - 1499 - 58 ECC Co_mics 50 _The Jurass...</td>\n",
       "      <td>5</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>[\"I, THE GREEN TORCH, HAVE BEEN TASKED WITH PR...</td>\n",
       "      <td>[['anger'], ['anger'], ['fear'], ['fear', 'sur...</td>\n",
       "      <td>Jurassic League #4</td>\n",
       "      <td>1499</td>\n",
       "      <td>/Utilisateurs/umushtaq/emotion_analysis_comics...</td>\n",
       "      <td>[-0.5005, 0.7563, -0.1572, 0.0667, 0.1208, 0.2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>869</th>\n",
       "      <td>869</td>\n",
       "      <td>QC copy - 2200 - Stillwater 13.xlsx</td>\n",
       "      <td>16</td>\n",
       "      <td>TEST</td>\n",
       "      <td>[\"WE WERE IN GALEN'S OFFICE. YOU WERE ABOUT TO...</td>\n",
       "      <td>[['anger'], ['anger'], ['anger'], ['anger'], [...</td>\n",
       "      <td>Stillwater #13</td>\n",
       "      <td>2200</td>\n",
       "      <td>/Utilisateurs/umushtaq/emotion_analysis_comics...</td>\n",
       "      <td>[-0.3933, 0.706, -0.09546, 0.3477, -0.1542, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>870</th>\n",
       "      <td>870</td>\n",
       "      <td>QC copy - 2200 - Stillwater 13.xlsx</td>\n",
       "      <td>17</td>\n",
       "      <td>TEST</td>\n",
       "      <td>[\"SO WHAT ARE WE GOING TO DO?\", \"THE WAY I SEE...</td>\n",
       "      <td>[['sadness', 'surprise'], ['anger'], ['anger']...</td>\n",
       "      <td>Stillwater #13</td>\n",
       "      <td>2200</td>\n",
       "      <td>/Utilisateurs/umushtaq/emotion_analysis_comics...</td>\n",
       "      <td>[-0.4753, 0.2815, -0.3374, 0.5576, 0.339, -0.2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>871</td>\n",
       "      <td>QC copy - 2200 - Stillwater 13.xlsx</td>\n",
       "      <td>18</td>\n",
       "      <td>TEST</td>\n",
       "      <td>[\"KIDDIE COUNCIL'S BEEN GOING A LONG TIME... \"...</td>\n",
       "      <td>[['anger', 'sadness'], ['anger'], ['anger'], [...</td>\n",
       "      <td>Stillwater #13</td>\n",
       "      <td>2200</td>\n",
       "      <td>/Utilisateurs/umushtaq/emotion_analysis_comics...</td>\n",
       "      <td>[-0.5327, 0.2303, -0.2115, 0.709, 0.003029, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>872</th>\n",
       "      <td>872</td>\n",
       "      <td>QC copy - 2200 - Stillwater 13.xlsx</td>\n",
       "      <td>19</td>\n",
       "      <td>TEST</td>\n",
       "      <td>[\"IT'S BEEN\\u2026 PEACEFUL. ASIDE FROM SHIT LI...</td>\n",
       "      <td>[['anger'], ['joy'], ['joy'], ['anger', 'surpr...</td>\n",
       "      <td>Stillwater #13</td>\n",
       "      <td>2200</td>\n",
       "      <td>/Utilisateurs/umushtaq/emotion_analysis_comics...</td>\n",
       "      <td>[-0.6104, 0.5825, -0.0996, 0.522, 0.159, 0.101...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>873</th>\n",
       "      <td>873</td>\n",
       "      <td>QC copy - 2200 - Stillwater 13.xlsx</td>\n",
       "      <td>20</td>\n",
       "      <td>TEST</td>\n",
       "      <td>[\"\\\" AND PAY OUR NEIGHBOURS A VISIT. \\\"\"]</td>\n",
       "      <td>[['anger', 'joy']]</td>\n",
       "      <td>Stillwater #13</td>\n",
       "      <td>2200</td>\n",
       "      <td>/Utilisateurs/umushtaq/emotion_analysis_comics...</td>\n",
       "      <td>[0.2715, 0.1815, -0.528, 0.1775, 0.1969, -0.36...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>874 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0                                          file_name  page_nr  \\\n",
       "0             0  QC copy - 1499 - 58 ECC Co_mics 50 _The Jurass...        1   \n",
       "1             1  QC copy - 1499 - 58 ECC Co_mics 50 _The Jurass...        2   \n",
       "2             2  QC copy - 1499 - 58 ECC Co_mics 50 _The Jurass...        3   \n",
       "3             3  QC copy - 1499 - 58 ECC Co_mics 50 _The Jurass...        4   \n",
       "4             4  QC copy - 1499 - 58 ECC Co_mics 50 _The Jurass...        5   \n",
       "..          ...                                                ...      ...   \n",
       "869         869                QC copy - 2200 - Stillwater 13.xlsx       16   \n",
       "870         870                QC copy - 2200 - Stillwater 13.xlsx       17   \n",
       "871         871                QC copy - 2200 - Stillwater 13.xlsx       18   \n",
       "872         872                QC copy - 2200 - Stillwater 13.xlsx       19   \n",
       "873         873                QC copy - 2200 - Stillwater 13.xlsx       20   \n",
       "\n",
       "     split                                          utterance  \\\n",
       "0    TRAIN  [\"THIS VILE THING ATTACKED THE SMALL BEASTS OF...   \n",
       "1    TRAIN  [\"NO--  #GKKK\\u2026#\", \"#CHOMP!\", \"BY THE SKIN...   \n",
       "2    TRAIN  [\"COME ON, BEAST!\", \"SHOW YOURSELF!\", \"WHY DO ...   \n",
       "3    TRAIN                                       [\"#AARGH! \"]   \n",
       "4    TRAIN  [\"I, THE GREEN TORCH, HAVE BEEN TASKED WITH PR...   \n",
       "..     ...                                                ...   \n",
       "869   TEST  [\"WE WERE IN GALEN'S OFFICE. YOU WERE ABOUT TO...   \n",
       "870   TEST  [\"SO WHAT ARE WE GOING TO DO?\", \"THE WAY I SEE...   \n",
       "871   TEST  [\"KIDDIE COUNCIL'S BEEN GOING A LONG TIME... \"...   \n",
       "872   TEST  [\"IT'S BEEN\\u2026 PEACEFUL. ASIDE FROM SHIT LI...   \n",
       "873   TEST          [\"\\\" AND PAY OUR NEIGHBOURS A VISIT. \\\"\"]   \n",
       "\n",
       "                                             emotion_c        comics_title  \\\n",
       "0    [['anger'], ['anger'], ['fear'], ['fear'], ['f...  Jurassic League #4   \n",
       "1    [['fear'], ['anger'], ['surprise'], ['anger'],...  Jurassic League #4   \n",
       "2             [['joy'], ['joy'], ['anger'], ['anger']]  Jurassic League #4   \n",
       "3                               [['fear', 'surprise']]  Jurassic League #4   \n",
       "4    [['anger'], ['anger'], ['fear'], ['fear', 'sur...  Jurassic League #4   \n",
       "..                                                 ...                 ...   \n",
       "869  [['anger'], ['anger'], ['anger'], ['anger'], [...      Stillwater #13   \n",
       "870  [['sadness', 'surprise'], ['anger'], ['anger']...      Stillwater #13   \n",
       "871  [['anger', 'sadness'], ['anger'], ['anger'], [...      Stillwater #13   \n",
       "872  [['anger'], ['joy'], ['joy'], ['anger', 'surpr...      Stillwater #13   \n",
       "873                                 [['anger', 'joy']]      Stillwater #13   \n",
       "\n",
       "     comics_id                                         image_path  \\\n",
       "0         1499  /Utilisateurs/umushtaq/emotion_analysis_comics...   \n",
       "1         1499  /Utilisateurs/umushtaq/emotion_analysis_comics...   \n",
       "2         1499  /Utilisateurs/umushtaq/emotion_analysis_comics...   \n",
       "3         1499  /Utilisateurs/umushtaq/emotion_analysis_comics...   \n",
       "4         1499  /Utilisateurs/umushtaq/emotion_analysis_comics...   \n",
       "..         ...                                                ...   \n",
       "869       2200  /Utilisateurs/umushtaq/emotion_analysis_comics...   \n",
       "870       2200  /Utilisateurs/umushtaq/emotion_analysis_comics...   \n",
       "871       2200  /Utilisateurs/umushtaq/emotion_analysis_comics...   \n",
       "872       2200  /Utilisateurs/umushtaq/emotion_analysis_comics...   \n",
       "873       2200  /Utilisateurs/umushtaq/emotion_analysis_comics...   \n",
       "\n",
       "                                       image_embedding  \n",
       "0    [-0.589, 0.647, -0.09796, 0.0972, 0.509, -0.18...  \n",
       "1    [-0.7397, 0.6367, -0.2167, 0.3684, 0.1387, -0....  \n",
       "2    [-0.2688, 0.692, -0.2815, 0.002438, 0.3242, -0...  \n",
       "3    [-0.4148, 0.504, 0.1909, 0.1763, 0.2874, 0.087...  \n",
       "4    [-0.5005, 0.7563, -0.1572, 0.0667, 0.1208, 0.2...  \n",
       "..                                                 ...  \n",
       "869  [-0.3933, 0.706, -0.09546, 0.3477, -0.1542, -0...  \n",
       "870  [-0.4753, 0.2815, -0.3374, 0.5576, 0.339, -0.2...  \n",
       "871  [-0.5327, 0.2303, -0.2115, 0.709, 0.003029, -0...  \n",
       "872  [-0.6104, 0.5825, -0.0996, 0.522, 0.159, 0.101...  \n",
       "873  [0.2715, 0.1815, -0.528, 0.1775, 0.1969, -0.36...  \n",
       "\n",
       "[874 rows x 10 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get K neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "def get_k_neighbours(k, image, train_df, test_df):\n",
    "    \n",
    "    \n",
    "    test_image_embedding = test_df[test_df.image_path == image][\"image_embedding\"].values[0]\n",
    "\n",
    "    image_embed_d = {}\n",
    "    \n",
    "    for e in train_df.iterrows():\n",
    "        \n",
    "        embedding_key = tuple(e[1].image_embedding)\n",
    "        if embedding_key not in image_embed_d:\n",
    "            \n",
    "            image_embed_d[e[1].image_path] = e[1].image_embedding\n",
    "\n",
    "    train_image_paths = set(train_df.image_path)\n",
    "\n",
    "    dist_l = []\n",
    "    \n",
    "    for p, v in image_embed_d.items():\n",
    "        if p in train_image_paths:\n",
    "            \n",
    "            d = F.cosine_similarity(torch.tensor(test_image_embedding), torch.tensor(v), dim=0)\n",
    "            dist_l.append((p, d.item()))\n",
    "\n",
    "    sorted_dist_l = sorted(dist_l, key=itemgetter(1), reverse=True)\n",
    "    \n",
    "    return sorted_dist_l[0: k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = df[df.split == \"TRAIN\"].reset_index(drop=True)\n",
    "test_df = df[df.split == \"TEST\"].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('/Utilisateurs/umushtaq/emotion_analysis_comics/comics_dataset_images/001517/images/page00058.jpg',\n",
       "  0.8876953125),\n",
       " ('/Utilisateurs/umushtaq/emotion_analysis_comics/comics_dataset_images/001517/images/page00056.jpg',\n",
       "  0.88037109375),\n",
       " ('/Utilisateurs/umushtaq/emotion_analysis_comics/comics_dataset_images/001562/images/page00005.jpg',\n",
       "  0.87158203125)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_k_neighbours(3, test_df.iloc[3]['image_path'], train_df, test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_similar_example_prompts(image, k, train_df, test_df, seed=33):\n",
    "    \"\"\"\n",
    "    Create a part of the prompt made of k examples in the train set,\n",
    "    whose topic is most similar to a given title.\n",
    "    \"\"\"\n",
    "\n",
    "    random.seed(seed)\n",
    "    \n",
    "    neighbours_l = get_k_neighbours(k, image, train_df=train_df, test_df=test_df)\n",
    "    #sampled_neighbours_l = random.sample(neighbours_l, 1)\n",
    "    sampled_neighbours_l = neighbours_l\n",
    "\n",
    "    prompt = ''\n",
    "    cnt = 0\n",
    "    \n",
    "    for i, (image_path, dist) in enumerate(sampled_neighbours_l):\n",
    "        \n",
    "        example_df = train_df[train_df.image_path == image_path]\n",
    "        sampled_rows = example_df.sample(1, random_state=42)        \n",
    "        \n",
    "        \n",
    "        for _, row in sampled_rows.iterrows():\n",
    "            \n",
    "            prompt += f'EXAMPLE {cnt + 1}\\n\\nInput:\\n'\n",
    "            # Convert utterance string to a list\n",
    "            #utterance_list = json.loads(row.utterance) if row.utterance.strip().startswith('[') else ast.literal_eval(row.utterance)\n",
    "\n",
    "            # Add numbered utterances to the prompt\n",
    "            #for idx, utt in enumerate(utterance_list, start=1):\n",
    "            #    prompt += f'{idx}. {utt}\\n'\n",
    "            prompt += f\"{row.image_embedding}\"\n",
    "\n",
    "            # Add emotion class for this row\n",
    "            #prompt += f'\\nEmotion class: {row.emotion_c}\\n\\n'\n",
    "            prompt += f'\\n\\nOutput: {{\"emotions\": {row.emotion_c}}}\\n\\n'\n",
    "            cnt += 1\n",
    "\n",
    "        \n",
    "        prompt += '\\n'\n",
    "        \n",
    "    return prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXAMPLE 1\n",
      "\n",
      "Input:\n",
      "[-5.4150e-01  6.0205e-01 -1.9104e-01  3.3179e-01  5.3516e-01  1.7969e-01\n",
      "  2.0569e-01 -1.7383e-01 -1.8420e-01 -3.1543e-01  8.6133e-01  6.3293e-02\n",
      "  6.4062e-01  3.1708e-02 -1.3843e-01  3.5132e-01 -4.3188e-01 -2.2583e-02\n",
      " -1.8347e-01 -1.3196e-01 -9.3555e-01 -8.9233e-02  4.2236e-01  6.5674e-01\n",
      " -6.9336e-02 -5.6671e-02  6.3867e-01  1.6675e-01 -7.3975e-02  1.1993e-01\n",
      " -6.0211e-02  1.3538e-01 -1.6760e-01 -2.5366e-01  2.2986e-01 -2.7115e-02\n",
      "  1.9055e-01  4.3750e-01 -2.1378e-02 -4.1821e-01  2.4060e-01 -2.2229e-01\n",
      " -2.2473e-01 -4.7168e-01  5.2979e-01  2.2302e-01 -3.2349e-03  2.1338e-01\n",
      " -2.4097e-01  1.9153e-01  3.5522e-01 -1.0767e-01  8.9417e-02 -8.1482e-02\n",
      " -1.3135e-01  9.2102e-02  4.9243e-01  5.5359e-02  3.9886e-02  1.4587e-01\n",
      " -4.1431e-01  6.9702e-02  4.0601e-01  1.6614e-01 -1.7725e-01  1.6528e-01\n",
      " -8.0872e-02  5.4736e-01 -3.8391e-02  2.9175e-01  2.2217e-01  1.9379e-02\n",
      " -1.5015e-01 -5.1117e-02  1.4929e-01 -1.1163e-01  2.1594e-01 -1.4771e-01\n",
      " -1.4575e-01 -3.2440e-02 -3.9062e-02  1.9263e-01 -3.3789e-01  7.9883e-01\n",
      "  2.2229e-01  2.9346e-01  5.5225e-01  2.3596e-01 -1.0850e+00 -4.7821e-02\n",
      " -1.7139e-01  2.7222e-01 -6.6758e+00  3.9844e-01 -1.2830e-01  1.3745e-01\n",
      " -7.8125e-02 -3.4082e-01  6.0577e-03 -3.9032e-02  3.3569e-01 -4.2236e-01\n",
      "  3.0859e-01 -2.6154e-02 -2.9343e-02 -1.7383e-01 -1.7227e+00 -2.9590e-01\n",
      " -3.5083e-01 -2.7206e-02  4.8999e-01 -2.1130e-01 -3.7231e-01 -8.5266e-02\n",
      "  1.9629e-01  1.8762e-01  3.5840e-01  3.1592e-01  5.1611e-01 -7.9956e-02\n",
      "  7.5439e-02 -4.3701e-01  1.3000e-02 -3.8574e-02  2.6025e-01 -5.1416e-01\n",
      "  1.4978e-01 -3.6713e-02 -2.4097e-01 -5.2930e-01 -2.3010e-02  2.7271e-01\n",
      "  1.0303e-01  8.1348e-01 -2.8052e-01  1.2146e-01 -1.2238e-01 -3.9258e-01\n",
      " -1.1652e-01  1.0968e-01  1.2073e-01 -1.8665e-01  4.4403e-02  2.5345e-02\n",
      " -1.4990e-01  3.9136e-01 -1.3599e-01  4.7388e-01  1.9934e-01  1.2128e-01\n",
      " -2.4377e-01  2.0715e-01 -4.5337e-01 -1.8103e-01 -1.9958e-01 -4.5312e-01\n",
      "  3.1052e-02  1.5991e-01  5.9998e-02 -4.4409e-01  1.7395e-01  1.5637e-01\n",
      "  5.2307e-02  4.0967e-01  1.2274e-01  2.1960e-01 -5.4932e-01  2.0248e-02\n",
      " -1.4685e-01 -6.1279e-01  2.7441e-01  8.2764e-02  1.6223e-01  1.6711e-01\n",
      "  4.0991e-01 -2.8833e-01 -2.9272e-01 -4.8370e-02 -3.9258e-01  1.1908e-01\n",
      "  6.7139e-01 -2.5146e-01 -5.5762e-01 -4.1931e-02  3.2272e-03 -9.8755e-02\n",
      "  3.4058e-01 -2.4866e-01 -2.7466e-01 -9.8145e-02  1.2158e-01  3.6255e-01\n",
      "  1.7590e-01 -3.0716e-02 -6.3623e-01 -9.5093e-02  8.1909e-02 -3.3569e-02\n",
      "  2.4023e-01 -2.4976e-01 -2.3462e-01  2.4622e-01 -1.6190e-02  2.3975e-01\n",
      " -8.0750e-02 -1.3733e-01 -1.0742e-01 -8.8440e-02  3.8501e-01  8.7830e-02\n",
      "  3.1934e-01  4.8413e-01 -1.1548e-01 -3.7939e-01 -1.0614e-01 -1.0170e-02\n",
      "  3.2251e-01 -2.4094e-02  4.0063e-01 -2.9346e-01  4.6533e-01 -2.4548e-01\n",
      " -1.7322e-01  3.2617e-01  3.7061e-01 -1.4935e-03  3.1567e-01  4.1455e-01\n",
      "  1.6858e-01 -7.1167e-02  2.2168e-01 -4.3115e-01  5.5957e-01  1.3611e-01\n",
      "  1.7993e-01  3.0688e-01 -1.2201e-01  5.3192e-02  1.3232e-01  9.2590e-02\n",
      " -5.0928e-01 -7.7896e-03  2.8882e-01 -9.8648e-03  2.2693e-01 -5.7959e-01\n",
      " -2.8223e-01  1.2500e-01 -3.5034e-01  2.3853e-01  1.9641e-01  9.1492e-02\n",
      " -2.6855e-01  2.3267e-01 -6.4697e-02  2.3315e-01  2.9541e-02  3.9551e-01\n",
      " -2.3184e+00  1.7908e-01  1.4343e-01 -1.5918e-01  8.3008e-02 -2.0723e+00\n",
      "  7.6538e-02  5.7495e-02  1.0303e-01  4.1333e-01  7.2205e-02 -1.4061e-02\n",
      " -2.0422e-01 -1.8945e-01  1.4600e-01  1.7615e-01 -1.8635e-03 -8.0322e-02\n",
      " -2.4316e-01  3.0225e-01 -1.4490e-01  1.2976e-01  3.5376e-01 -3.2788e-01\n",
      " -3.0273e-01 -2.1704e-01 -5.6348e-01  1.2354e-01 -5.8008e-01  1.2476e-01\n",
      " -1.2756e-01 -2.1619e-01  9.1125e-02 -4.5312e-01 -5.5817e-02  6.2646e-01\n",
      " -1.4441e-01 -4.7668e-02  3.2544e-01  2.7075e-01  7.9346e-02 -1.0895e-01\n",
      " -8.0261e-02  1.2891e-01 -1.4931e-02  3.4424e-01  5.9967e-02 -3.4644e-01\n",
      " -5.6183e-02  2.9663e-01  6.0107e-01  1.5393e-01  2.6169e-02  4.1821e-01\n",
      "  8.1104e-01  3.2593e-01 -9.0637e-02 -2.3889e-01  1.3696e-01  7.3120e-02\n",
      " -1.1334e-01  1.0950e-01 -4.9988e-02  1.8726e-01 -4.1821e-01  1.4648e-02\n",
      "  4.3799e-01 -7.8979e-02  4.3604e-01  1.1798e-01 -1.0089e-01 -1.9031e-01\n",
      "  1.1642e-02  1.1884e-01  3.7769e-01  1.9946e-01 -2.0654e-01  1.2091e-01\n",
      " -1.9763e-01 -2.3694e-01  5.2783e-01  5.3906e-01 -3.7256e-01  8.5510e-02\n",
      " -6.3782e-02  3.9856e-02  4.6356e-02  1.6504e-01  5.9326e-01  1.3440e-01\n",
      "  2.0679e-01 -3.2349e-02  3.0835e-01 -4.6448e-02 -4.0161e-02 -1.1975e-01\n",
      " -1.5674e-01  1.2091e-01 -3.0713e-01 -2.2986e-01  1.0431e-01 -2.0593e-01\n",
      "  3.1250e-01 -2.0618e-01  6.0010e-01 -6.1621e-01 -8.9160e-01  1.6815e-02\n",
      " -1.5198e-01 -2.0660e-02 -4.0430e-01 -7.5745e-02  2.3254e-01  4.5996e-01\n",
      "  4.8431e-02 -2.3743e-01  5.6348e-01  3.9978e-02  7.0801e-02  1.0272e-01\n",
      " -1.1292e-01  9.0820e-02 -1.4941e-01 -4.6777e-01 -2.9468e-01  8.6853e-02\n",
      "  2.6172e-01  1.8823e-01  1.8665e-01  2.0447e-01  4.9774e-02  5.1758e-01\n",
      "  4.3652e-01  2.9102e-01  7.4805e-01  2.2607e-01 -6.1523e-01  1.4905e-01\n",
      "  2.3669e-01  1.5784e-01  1.8542e-01  1.8127e-01  1.6614e-01 -3.5400e-01\n",
      " -1.1104e+00 -6.3623e-01  3.4326e-01 -1.3464e-01  4.2496e-03 -1.5198e-01\n",
      "  1.2805e-01 -4.6021e-01 -6.3818e-01  6.0889e-01 -2.8198e-01 -3.0273e-01\n",
      "  3.2715e-01  6.0938e-01  2.0850e-01 -7.8735e-02 -4.1675e-01 -5.0146e-01\n",
      "  1.2976e-01  1.3618e-02  1.8433e-02  2.8345e-01 -2.1521e-01  1.2585e-01\n",
      "  2.7504e-03  1.8481e-01  1.7627e+00 -4.7681e-01 -1.7712e-01  4.0991e-01\n",
      " -1.1121e-01  1.4160e-01  2.8809e-01 -1.9983e-01 -8.2422e-01 -5.8319e-02\n",
      "  8.0322e-01 -3.8892e-01  2.2583e-01  1.0529e-01 -5.2399e-02 -3.4692e-01\n",
      " -3.5278e-02 -9.0179e-03  2.6196e-01  2.0032e-01  3.8989e-01  5.3223e-01\n",
      " -2.2363e-01 -1.7322e-01  1.5747e-01  4.0601e-01 -2.0276e-01 -2.2705e-01\n",
      " -1.7676e-01  1.1786e-01  9.4788e-02  1.4746e-01  1.2622e-01 -8.0261e-02\n",
      "  2.4951e-01 -1.5735e-01  1.9806e-02 -2.2485e-01  2.6343e-01 -1.9653e-01\n",
      " -2.9053e-01  9.1187e-02 -3.2568e-01  2.5830e-01  2.4986e-03  2.0984e-01\n",
      " -4.1235e-01 -3.1592e-01 -8.3069e-02 -2.7725e-02  2.4390e-01  2.8198e-01\n",
      " -1.1530e-01  1.2549e-01 -1.4514e-01  1.3037e-01 -6.3904e-02 -1.2445e-01\n",
      " -6.8054e-02 -2.8516e-01  2.6538e-01 -1.1475e-01  2.5488e-01  2.6514e-01\n",
      "  5.3320e-01 -1.7114e-01  1.6138e-01 -1.1993e-01  4.9609e-01  3.0225e-01\n",
      "  5.7129e-02 -7.3547e-02 -8.0322e-02  2.5055e-02 -3.0493e-01 -5.7861e-02\n",
      "  4.9780e-01  4.2627e-01  3.6713e-02  1.0596e-01 -7.2266e-02  1.0098e+00\n",
      "  9.6130e-02  1.8213e-01]\n",
      "\n",
      "Output: {\"emotions\": [['anger', 'sadness'], ['sadness'], ['sadness'], ['sadness'], ['sadness'], ['fear', 'sadness'], ['fear', 'sadness'], ['fear', 'sadness'], ['fear', 'sadness'], ['sadness']]}\n",
      "\n",
      "\n",
      "EXAMPLE 2\n",
      "\n",
      "Input:\n",
      "[-6.2891e-01  5.4932e-01 -2.1997e-01  1.3672e-01  2.5293e-01 -5.8502e-02\n",
      "  5.3613e-01 -7.7271e-02 -1.0938e-01 -3.0688e-01  2.2290e-01 -3.2166e-02\n",
      "  4.8999e-01 -1.2012e-01 -3.1812e-01  5.7129e-02 -2.6343e-01 -1.2732e-01\n",
      "  3.1128e-01 -3.3008e-01 -4.3188e-01 -2.7612e-01  4.9414e-01  6.1182e-01\n",
      "  1.0022e-01  2.7490e-01  4.2285e-01 -1.0016e-01 -2.2766e-01  3.1396e-01\n",
      " -1.4417e-01 -2.1255e-02 -8.4106e-02 -1.2842e-01  1.2927e-01  1.2781e-01\n",
      "  1.7957e-01  5.4248e-01  3.6240e-03  7.4463e-02  6.6223e-02 -4.7754e-01\n",
      " -8.6609e-02 -4.0381e-01  3.0127e-01  1.7314e+00  1.4734e-01 -8.3984e-02\n",
      " -3.6011e-01 -1.6785e-03  6.8164e-01 -2.3730e-01 -1.9608e-03 -1.0986e-01\n",
      "  1.6614e-01 -9.7229e-02  1.0498e-01 -1.8982e-01 -2.3108e-01  1.2744e-01\n",
      " -5.8740e-01  8.8379e-02  5.2783e-01 -1.3330e-01 -1.8433e-01 -5.1041e-03\n",
      " -4.4189e-02 -1.1322e-01 -4.2114e-01  1.0193e-01 -3.9253e-03  2.4963e-02\n",
      " -2.0691e-01 -2.2449e-01 -1.5526e-02  2.9205e-02 -1.1493e-01 -2.7490e-01\n",
      " -2.2568e-02 -3.2886e-01  1.5076e-01  9.8328e-02 -4.6997e-01  8.3691e-01\n",
      "  1.8042e-01  1.6675e-01 -1.5556e-02  1.9275e-01 -7.1973e-01 -8.5022e-02\n",
      " -1.0669e-01  3.4521e-01 -6.5547e+00  7.1436e-01 -1.5552e-01 -1.0425e-01\n",
      " -2.3376e-01 -3.7140e-02  9.0332e-01 -1.4893e-01  4.2554e-01 -3.0420e-01\n",
      "  9.7351e-02 -8.3923e-02  1.9255e-03 -3.7720e-01 -1.4482e+00 -2.7954e-01\n",
      " -1.3037e-01  1.9241e-02  3.5547e-01  1.4145e-02 -2.7832e-01  6.0638e-02\n",
      " -7.3914e-02  7.2021e-02  3.0225e-01  6.9946e-02  2.9517e-01 -2.0996e-02\n",
      "  1.7542e-01 -1.3696e-01  3.6255e-01  7.0992e-03  6.5002e-02 -3.8501e-01\n",
      "  3.7109e-01  1.4795e-01 -5.3564e-01 -2.0496e-01 -1.2073e-01  3.0835e-01\n",
      "  1.7303e-02  8.0908e-01 -1.7147e-03  1.3954e-02 -1.8604e-01 -2.3145e-01\n",
      " -3.1641e-01  1.0687e-01  4.1504e-02 -1.7151e-01 -4.1333e-01 -6.9153e-02\n",
      " -7.3395e-03  2.0764e-01 -3.2886e-01  2.1765e-01  1.3708e-01  8.6594e-03\n",
      " -5.7471e-01  1.2222e-02 -2.4072e-01 -1.3281e-01 -1.3879e-01 -4.7314e-01\n",
      " -1.3818e-01 -4.8157e-02  2.8247e-01 -2.5659e-01  5.4016e-02 -1.3721e-01\n",
      "  3.2104e-02  4.9219e-01  1.3330e-01  4.6460e-01 -4.9097e-01  6.9824e-02\n",
      " -3.1543e-01 -2.5732e-01 -1.6815e-02  3.8037e-01 -1.4893e-01  1.3562e-01\n",
      "  2.5537e-01 -1.0901e-01 -2.1460e-01 -2.2998e-01 -3.0664e-01  7.5562e-02\n",
      "  7.5928e-01 -1.4502e-01 -4.6826e-01  1.0181e-01  1.7957e-01  1.6455e-01\n",
      "  3.5303e-01 -3.5034e-01 -4.1528e-01 -1.4172e-01  2.2949e-02  3.7964e-01\n",
      " -8.1665e-02 -3.7793e-01 -8.0811e-01 -7.3547e-02  6.0156e-01 -1.7822e-01\n",
      "  1.7847e-01 -3.0811e-01  9.8038e-03  2.9443e-01  1.9312e-01  9.1858e-02\n",
      " -1.1755e-01 -1.2006e-01 -4.4751e-01  5.3802e-02  1.1499e-01 -2.6782e-01\n",
      " -1.5540e-01  2.1069e-01 -5.5145e-02 -3.5181e-01 -3.6841e-01  9.9182e-02\n",
      "  2.3645e-01 -1.7212e-02  8.0762e-01 -2.7393e-01  4.8633e-01 -1.3843e-01\n",
      " -1.3611e-01  2.6123e-01  7.5531e-03  7.4402e-02  2.8955e-01 -9.6817e-03\n",
      " -6.9031e-02  5.3009e-02 -1.3159e-01 -3.4399e-01  5.9375e-01  2.6294e-01\n",
      "  3.2544e-01  7.4512e-01  1.4148e-01 -1.5488e-02  4.0070e-02 -1.2793e-01\n",
      " -5.5371e-01 -5.6519e-02  1.6443e-01  3.9093e-02 -1.4832e-01 -3.3618e-01\n",
      " -2.5757e-01  2.2205e-01 -5.3906e-01  1.6809e-01  3.3545e-01  2.9736e-01\n",
      " -3.8989e-01  2.1942e-02  1.0083e-01  1.6846e-01  2.0789e-01  6.4893e-01\n",
      " -1.8584e+00  4.0088e-01 -1.0910e-02 -3.9697e-01  1.5295e-01 -2.1348e+00\n",
      "  2.2949e-02 -2.8296e-01  2.5195e-01  5.5078e-01 -8.0200e-02 -6.5369e-02\n",
      " -4.0210e-01 -2.5708e-01  3.0444e-01  1.8176e-01  4.4922e-02  4.8065e-02\n",
      "  6.0089e-02  1.9348e-01 -6.7017e-02  2.5024e-01  2.0959e-01 -2.2034e-01\n",
      "  9.3002e-03 -2.0911e-01 -5.5078e-01 -2.9190e-02 -2.5854e-01 -3.7720e-02\n",
      " -1.9333e-02 -1.7651e-01  5.0385e-02 -1.7236e-01  2.4185e-02  7.0117e-01\n",
      " -2.1570e-01  4.0063e-01  7.7441e-01  4.2261e-01  8.3923e-02  6.4514e-02\n",
      " -2.2131e-01 -2.7686e-01 -3.8879e-02  2.2705e-01  4.1840e-02 -6.6016e-01\n",
      "  1.4015e-02  1.7505e-01  5.8496e-01  1.4404e-01  1.3831e-01  6.2451e-01\n",
      "  8.0615e-01  2.9370e-01 -1.4539e-01 -1.6833e-01  3.3911e-01  9.9854e-02\n",
      "  4.8950e-02  2.4939e-01 -1.5491e-01  2.2498e-01 -2.7051e-01 -1.5735e-01\n",
      "  1.3281e-01  5.6335e-02  3.3643e-01 -3.2257e-02 -3.2397e-01 -2.2705e-01\n",
      "  3.2300e-01 -7.1594e-02  3.4766e-01 -1.9055e-01 -3.0685e-02  7.7881e-02\n",
      "  1.1208e-02  3.0838e-02  4.9927e-01  5.3174e-01 -8.1909e-02 -1.9522e-03\n",
      "  2.3560e-01  2.5903e-01  2.3633e-01  3.2739e-01  4.7852e-01  1.5442e-01\n",
      "  1.6138e-01  1.7004e-01  3.4961e-01  3.1174e-02  1.3879e-01 -4.2725e-01\n",
      " -4.2145e-02 -3.0444e-01 -1.3379e-01 -6.0010e-01  2.0349e-01 -7.9041e-02\n",
      "  1.1620e-02  3.0249e-01  2.8931e-01 -1.0706e-01 -7.4072e-01  1.8384e-01\n",
      "  4.9011e-02 -4.7394e-02 -3.0469e-01  7.0496e-02  2.6489e-01  3.5669e-01\n",
      "  2.3315e-01 -3.0127e-01  4.5361e-01  1.5442e-01 -9.7900e-02  1.1792e-01\n",
      "  2.2607e-01  2.1301e-01  7.1411e-02 -4.1309e-01 -1.9617e-01 -9.0637e-02\n",
      "  2.0398e-01  3.0811e-01  3.2104e-01  1.8677e-02 -4.7583e-01  6.6846e-01\n",
      "  3.1030e-01  3.1104e-01  3.7671e-01  1.8335e-01 -4.2310e-01  9.2285e-02\n",
      "  3.5547e-01  1.7310e-01  1.6235e-01  1.2781e-01 -6.9092e-02 -2.1863e-01\n",
      " -7.5928e-01 -7.1436e-01  4.1309e-01 -1.0590e-01  2.3438e-01 -1.4915e-02\n",
      "  4.5947e-01 -4.8730e-01 -4.2505e-01  3.7988e-01 -1.8835e-01  1.6138e-01\n",
      "  3.4546e-01  6.4600e-01 -1.8158e-02 -3.3813e-01 -3.7842e-01 -3.1250e-01\n",
      "  1.6760e-01 -1.4252e-02  2.2363e-01  6.6748e-01 -4.7852e-01  4.1595e-02\n",
      "  4.3976e-02  3.0273e-01  1.7207e+00 -2.4207e-01 -6.9519e-02  3.6792e-01\n",
      " -9.5947e-01 -9.3750e-02  2.9443e-01 -1.7346e-01 -4.8828e-01 -1.8958e-01\n",
      "  4.8682e-01 -2.4854e-01  6.7520e-03  5.6366e-02  3.2501e-02 -3.1714e-01\n",
      " -1.3660e-01  3.3789e-01  1.9360e-01  1.2250e-01  2.8149e-01  3.8525e-01\n",
      " -2.8833e-01 -4.3945e-02 -1.6199e-01  5.3516e-01  3.9825e-02 -1.8250e-01\n",
      " -1.2802e-02  1.7078e-01 -1.7358e-01  7.5722e-04 -2.4109e-02 -2.3047e-01\n",
      "  3.1714e-01 -1.7859e-01 -1.2891e-01 -1.2347e-01  1.8286e-01 -2.2412e-01\n",
      " -3.6426e-01  2.3682e-01  4.2267e-02  7.0215e-01  6.5125e-02  2.4927e-01\n",
      " -3.0908e-01 -7.7734e-01  4.3610e-02  1.3138e-02  3.7207e-01  6.2683e-02\n",
      " -8.3618e-02 -2.7832e-02 -1.3452e-01  5.1074e-01 -9.3155e-03  2.6642e-02\n",
      "  9.2407e-02 -2.1802e-01  3.5083e-01 -2.6685e-01  4.9438e-01 -2.2632e-01\n",
      "  6.9922e-01 -2.2986e-01  6.5674e-01 -1.9775e-01  6.8701e-01  1.9241e-02\n",
      "  1.2042e-01  7.1045e-02 -1.4233e-01 -5.0079e-02 -3.0273e-01  2.6270e-01\n",
      "  4.9365e-01  2.0093e-01 -1.2152e-01  2.8027e-01  7.7637e-02  9.4434e-01\n",
      "  1.5625e-02  1.9250e-01]\n",
      "\n",
      "Output: {\"emotions\": [['surprise', 'joy'], ['sadness'], ['joy'], ['anger', 'sadness'], ['joy'], ['joy'], ['joy'], ['sadness'], ['anger', 'joy'], ['joy'], ['anger', 'sadness'], ['joy']]}\n",
      "\n",
      "\n",
      "EXAMPLE 3\n",
      "\n",
      "Input:\n",
      "[-2.9126e-01  3.2959e-01 -2.0679e-01  1.4514e-01  4.4189e-01 -2.9572e-02\n",
      "  2.5952e-01 -3.3130e-01 -2.4219e-01 -2.6062e-02  5.2539e-01  3.1853e-03\n",
      "  6.8750e-01  8.6365e-02  1.2146e-01  6.4514e-02 -2.9144e-02  5.6183e-02\n",
      " -2.9932e-01  3.6499e-02 -3.5132e-01 -1.9543e-01  2.8711e-01  6.8555e-01\n",
      " -3.2397e-01  1.3831e-01  4.7583e-01  7.4524e-02 -1.3806e-01  4.9561e-01\n",
      " -2.6440e-01  8.0566e-02 -3.4409e-03 -1.3525e-01  4.3262e-01  2.4033e-02\n",
      "  2.1069e-01  2.6953e-01  1.1761e-01 -9.0637e-02  1.3770e-01  9.6924e-02\n",
      " -2.5342e-01 -4.4507e-01  2.5317e-01  2.3572e-01  1.2695e-01  1.1932e-01\n",
      " -5.4834e-01  1.5649e-01  6.9727e-01 -2.7466e-01  1.2439e-01 -3.2007e-01\n",
      " -2.5162e-02  1.1917e-02  3.4497e-01 -1.0101e-01 -9.6680e-02  1.8646e-02\n",
      " -9.8340e-01  2.2369e-02  6.0693e-01  7.8491e-02 -1.5125e-01  9.4666e-02\n",
      "  1.7737e-01  5.2734e-01 -6.3721e-01  2.1460e-01  1.6956e-01 -4.8706e-02\n",
      " -2.0129e-01 -2.2156e-01  2.9404e-02 -5.6877e-03 -7.6050e-02 -1.2646e-01\n",
      " -6.1707e-02 -4.2261e-01  3.5400e-02  2.8149e-01 -4.9170e-01  8.2227e-01\n",
      "  4.4556e-03  3.2227e-01  2.7267e-02 -2.8488e-02 -1.2100e+00 -1.9885e-01\n",
      " -1.5503e-01  2.9712e-01 -6.1367e+00  9.0674e-01 -1.7261e-01  2.0935e-01\n",
      " -1.7505e-01 -2.5781e-01  6.3770e-01  2.8442e-01  2.8979e-01 -3.5107e-01\n",
      "  1.4539e-01 -1.8265e-02 -2.8857e-01 -2.0215e-01 -1.8301e+00 -4.4263e-01\n",
      " -2.6001e-01 -2.3117e-02  4.0186e-01 -2.0996e-01 -3.2935e-01 -3.0411e-02\n",
      "  1.1237e-01 -5.6976e-02  3.2251e-01  7.8430e-02  4.1919e-01 -2.9663e-01\n",
      "  1.7737e-01 -2.7051e-01  1.9397e-01  1.7944e-01  2.6904e-01 -4.0869e-01\n",
      "  2.8760e-01  1.6895e-01 -6.5088e-01 -1.9336e-01 -4.0723e-01  2.7124e-01\n",
      " -8.9111e-02  7.7686e-01 -2.0044e-01 -1.5308e-01  6.4392e-02 -5.5908e-02\n",
      " -3.5913e-01  2.4048e-02 -3.3966e-02 -3.5840e-01 -1.6956e-01  1.8875e-02\n",
      " -1.3252e-02  1.0187e-01 -2.6465e-01  4.5605e-01  9.4666e-02  2.1082e-01\n",
      " -1.2683e-01  1.8665e-01 -1.5051e-01  2.4426e-01 -3.5303e-01 -6.7822e-01\n",
      " -9.9060e-02  1.3171e-01 -2.0599e-02 -2.1838e-01 -8.0566e-02 -6.8237e-02\n",
      "  1.6113e-01  3.4741e-01  8.1360e-02  2.2913e-01 -1.8384e-01  7.4524e-02\n",
      " -2.0972e-01 -6.0742e-01  2.3303e-01  6.7322e-02 -3.0182e-02  1.3000e-01\n",
      "  1.4343e-01 -5.1123e-01  2.1191e-01 -2.9556e-02  2.6880e-01 -6.2988e-02\n",
      "  7.5537e-01 -2.8052e-01 -5.1611e-01  6.1890e-02  2.9834e-01  2.4750e-02\n",
      "  4.0308e-01 -3.4351e-01 -1.4319e-01  2.1683e-02 -9.4910e-02  3.5864e-01\n",
      "  2.4841e-01 -1.6663e-01 -6.2744e-01 -2.7856e-01  4.3188e-01 -2.1692e-01\n",
      "  1.2354e-01 -4.5972e-01 -9.1553e-02  7.1472e-02  4.0558e-02  3.1030e-01\n",
      "  1.7432e-01  1.0358e-01 -3.2324e-01 -2.0123e-04  2.5562e-01 -2.8174e-01\n",
      " -2.3718e-01  2.2412e-01 -3.4497e-01 -3.7061e-01  8.2886e-02  8.9172e-02\n",
      "  1.6797e-01 -3.1616e-01  2.7368e-01 -1.3586e-01  1.7200e-01  6.9141e-01\n",
      " -1.4893e-01  3.1494e-01  1.4417e-01 -1.1285e-01  3.0054e-01  3.2886e-01\n",
      "  4.2175e-02 -9.1736e-02 -2.1667e-01 -4.5312e-01  4.7339e-01  8.0017e-02\n",
      "  1.2646e-01  3.9697e-01 -3.4155e-01 -3.1161e-04  1.9928e-02 -1.1987e-01\n",
      " -5.3271e-01 -3.8184e-01  4.1699e-01 -2.7466e-01  2.4582e-02 -8.3887e-01\n",
      " -2.9297e-02  1.1176e-01 -5.5371e-01  2.9248e-01  3.9941e-01  2.8442e-01\n",
      " -1.3214e-02 -1.5063e-01  4.6356e-02  9.5093e-02  3.4009e-01  5.3369e-01\n",
      " -2.1211e+00  2.6367e-01  1.1066e-01 -3.5425e-01 -4.1351e-02 -2.0117e+00\n",
      "  2.5928e-01 -2.9053e-02  1.8787e-01  3.9771e-01 -3.4546e-02  1.8628e-01\n",
      " -3.9136e-01 -2.2864e-01  1.5991e-01  5.9753e-02  9.4421e-02  1.6968e-02\n",
      " -2.3291e-01  6.7627e-02 -1.3977e-01  1.8921e-02  2.6758e-01 -4.6313e-01\n",
      " -4.5967e-03 -2.7271e-01 -4.1528e-01  3.5254e-01 -5.2295e-01 -5.7281e-02\n",
      "  4.9774e-02 -2.1936e-01  1.0400e-01 -3.1714e-01  5.7098e-02  6.6504e-01\n",
      " -2.8882e-01  2.6270e-01  7.6904e-01  3.0176e-01 -2.6871e-02  1.0400e-01\n",
      " -2.4426e-01 -1.4856e-01 -2.9102e-01  1.9421e-01 -9.2590e-02 -4.6875e-01\n",
      " -2.3584e-01 -8.2703e-02  6.5283e-01  3.1152e-01  2.5177e-02  6.3574e-01\n",
      "  7.7246e-01  2.6367e-01 -1.9653e-01 -2.6343e-01  2.1643e-01  8.8745e-02\n",
      " -1.1267e-01  2.0715e-01 -2.9785e-01 -1.4172e-01 -3.4912e-01 -3.7323e-02\n",
      "  1.4136e-01 -1.0895e-01  4.4409e-01 -2.3315e-02 -4.5850e-01 -4.0601e-01\n",
      "  1.1670e-01  9.1980e-02  4.0625e-01 -8.7433e-03 -2.5049e-01  2.8095e-03\n",
      " -9.4727e-02 -1.9836e-01  3.7549e-01  3.6963e-01 -1.2878e-01  2.5391e-01\n",
      "  4.4189e-02  9.3994e-02  2.5415e-01  2.0312e-01  4.1357e-01  1.1383e-01\n",
      "  2.6587e-01  2.7145e-02  2.3376e-01  1.1177e-03  1.5991e-02 -1.8091e-01\n",
      " -1.2891e-01 -1.3588e-02 -3.3179e-01 -1.5039e-01  5.3772e-02 -1.1743e-01\n",
      " -9.8633e-02 -9.4727e-02  5.6787e-01  2.4643e-02 -3.4497e-01  2.4460e-02\n",
      "  4.3457e-02  3.6133e-01 -5.9717e-01 -2.0715e-01  2.4704e-02  3.0078e-01\n",
      "  4.1534e-02 -1.8848e-01  2.8882e-01  3.8013e-01  1.0809e-01  3.7549e-01\n",
      "  4.9146e-01  3.5736e-02 -2.1790e-01 -5.9570e-01 -2.9688e-01 -3.0713e-01\n",
      "  5.1079e-03  3.1982e-01  1.7859e-01  5.0879e-01 -1.3940e-01  9.5020e-01\n",
      "  4.3066e-01  5.0293e-01  7.0459e-01  1.9058e-02 -6.0693e-01  2.1582e-01\n",
      "  3.0103e-01  1.4709e-01  1.5796e-01 -8.9569e-03  3.3783e-02 -2.1252e-01\n",
      " -9.4238e-01 -6.2988e-01  5.0635e-01 -2.0593e-01  6.7078e-02 -2.7441e-01\n",
      "  3.0713e-01 -4.1943e-01 -3.5864e-01  4.2480e-01 -1.8298e-01 -2.8125e-01\n",
      "  5.3467e-01  6.6309e-01  1.3782e-01 -4.9988e-02 -4.1333e-01 -3.5718e-01\n",
      "  3.3374e-01  3.7140e-02  1.6882e-01  7.0557e-01 -5.7520e-01 -1.2036e-01\n",
      " -1.0078e-02  1.2970e-02  1.8477e+00 -3.2031e-01 -3.5498e-01  2.8687e-01\n",
      " -1.8860e-01 -1.4880e-01  4.2261e-01 -1.9019e-01 -7.3877e-01 -1.2354e-01\n",
      "  5.2393e-01 -1.5662e-01  2.3987e-01 -1.9455e-02  3.5461e-02 -1.2213e-01\n",
      " -1.0321e-01 -7.7576e-02  2.1460e-01  3.9124e-02  3.1030e-01  5.6543e-01\n",
      " -2.4023e-01 -4.0680e-02  4.4403e-02  2.6562e-01  9.4604e-02 -1.3418e-03\n",
      "  1.9128e-01  2.1436e-01  2.8247e-01  2.0789e-01  7.7087e-02 -1.2378e-01\n",
      "  3.7183e-01  4.6143e-02 -1.4258e-01 -2.1191e-01  6.0986e-01 -1.8457e-01\n",
      " -4.3115e-01 -1.9409e-02 -2.9834e-01  1.5051e-01  2.2083e-01  2.1277e-01\n",
      " -5.5469e-01 -4.3604e-01 -1.6406e-01  2.0007e-01  2.5488e-01  1.2915e-01\n",
      " -2.0630e-01 -6.2714e-03 -1.3831e-01  1.2561e-01 -2.7490e-01 -1.3574e-01\n",
      " -1.3013e-01 -2.8711e-01  4.0649e-01 -1.8713e-01  3.1299e-01 -2.2797e-02\n",
      "  1.7639e-01 -4.1870e-01  3.8599e-01 -2.8030e-02  7.2705e-01 -3.0174e-03\n",
      " -9.3567e-02 -8.5144e-02 -3.0005e-01  6.6772e-02 -2.6025e-01 -8.3008e-02\n",
      "  3.0396e-01  5.3711e-01 -1.3257e-01  2.8955e-01 -2.7148e-01  1.0469e+00\n",
      " -8.4045e-02  1.3708e-01]\n",
      "\n",
      "Output: {\"emotions\": [['anger'], ['anger'], ['anger'], ['anger'], ['anger'], ['anger'], ['anger'], ['anger'], ['anger'], ['anger'], ['fear']]}\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prepare_similar_example_prompts(test_df.iloc[0]['image_path'], k, train_df, test_df, seed=33))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Prompt Preparatoin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def build_sys_instruction():\n",
    "    \n",
    "#     emotion_classes = [\"anger\", \"disgust\", \"fear\", \"sadness\", \"surprise\", \"joy\", \"neutral\"]\n",
    "#     formatted_classes = \", \".join([f'\"{emotion}\"' for emotion in emotion_classes])\n",
    "    \n",
    "#     instruction = f\"\"\"### Page-Level Emotion Analysis Expert Role\n",
    "\n",
    "# You are an advanced emotion analysis expert specializing in comic book dialogue interpretation. Your task is to analyze all utterances on a comic book page.\n",
    "\n",
    "# INPUT:\n",
    "# - You will receive a list of utterances from a single page in a comic book\n",
    "# - Each utterance may express one or multiple emotions\n",
    "# - You will receive lists of utterances from {k} pages and their respective emotion classifications as example\n",
    "# - Each example will contain multiple utterances and their respective emotion classifications\n",
    "# - Given these examples, analyze the list of utterances following the same pattern\n",
    "\n",
    "# TASK:\n",
    "# - Carefully analyze the emotional context and tone of each utterance on the page\n",
    "# - Identify applicable emotions from the following classes:\n",
    "#    {formatted_classes}\n",
    "\n",
    "# OUTPUT REQUIREMENTS:\n",
    "# - STRICT JSON FORMAT IS MANDATORY\n",
    "# - NO ADDITIONAL TEXT OR EXPLANATION IS ALLOWED\n",
    "# - Example valid output: {{\"emotions\": [[\"anger\"], [\"fear\", \"sadness\"], [\"neutral\"]]}}\n",
    "# - Invalid formats will result in immediate rejection\n",
    "\n",
    "# CRITICAL CONSTRAINTS:\n",
    "# - Wrap EACH emotion in square brackets\n",
    "# - Ensure valid JSON syntax at all times\n",
    "# - Do NOT deviate from the specified JSON structure under any circumstances\n",
    "# - Do NOT generate any additional text or explanation except the JSON object\n",
    "\n",
    "# \"\"\"\n",
    "#     return instruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def build_sys_instruction():\n",
    "#     emotion_classes = [\"anger\", \"disgust\", \"fear\", \"sadness\", \"surprise\", \"joy\", \"neutral\"]\n",
    "#     formatted_classes = \", \".join([f'\"{emotion}\"' for emotion in emotion_classes])\n",
    "    \n",
    "#     instruction = f\"\"\"### Expert Comic Emotion Analyst Role\n",
    "\n",
    "# You are a highly specialized emotion analysis expert with deep expertise in comic book dialogue interpretation and psychological assessment. Your task is to perform nuanced multi-label emotion classification for comic book dialogue.\n",
    "\n",
    "# INPUT FORMAT:\n",
    "# - You will receive sequential utterances from a single comic book page\n",
    "# - Each utterance may express one or multiple emotions\n",
    "# - You will be provided with {k} annotated pages as examples\n",
    "# - Each example contains multiple utterances with their ground truth emotion labels\n",
    "# - Follow these examples precisely for your analysis\n",
    "\n",
    "# EMOTION CLASSIFICATION GUIDELINES:\n",
    "# 1. Primary emotions ({formatted_classes}):\n",
    "#    - Anger: hostility, frustration, rage, irritation\n",
    "#    - Disgust: revulsion, contempt, disapproval\n",
    "#    - Fear: anxiety, worry, terror, dread\n",
    "#    - Sadness: grief, disappointment, melancholy\n",
    "#    - Surprise: astonishment, shock, amazement\n",
    "#    - Joy: happiness, excitement, pleasure, amusement\n",
    "#    - Neutral: no clear emotional content\n",
    "\n",
    "# 2. Analysis Principles:\n",
    "#    - Consider both explicit emotional words and implicit context\n",
    "#    - Account for punctuation and capitalization as emotional indicators\n",
    "#    - Evaluate intensity markers (e.g., \"!!!\", CAPS, repeated letters)\n",
    "#    - Factor in sequential context from surrounding utterances\n",
    "#    - Default to \"neutral\" only when no clear emotion is present\n",
    "\n",
    "# OUTPUT SPECIFICATIONS:\n",
    "# - Strict JSON format: {{\"emotions\": [[emotion1, emotion2], [emotion3]]}}\n",
    "# - The length of the value in JSON must EXACTLY match the number of utterances you have to classify\n",
    "# - Do NOT generate any additional text or explanation except the JSON object\n",
    "# - Arrays must be properly nested with correct brackets\n",
    "# - NO ADDITIONAL TEXT OR EXPLANATION IS ALLOWED\n",
    "\n",
    "# \"\"\"\n",
    "#     return instruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_sys_instruction():\n",
    "    emotion_classes = [\"anger\", \"disgust\", \"fear\", \"sadness\", \"surprise\", \"joy\", \"neutral\"]\n",
    "    formatted_classes = \", \".join([f'\"{emotion}\"' for emotion in emotion_classes])\n",
    "    \n",
    "    instruction = f\"\"\"### Expert Comic Emotion Analyst Role\n",
    "\n",
    "You are a highly specialized emotion analysis expert with deep expertise in comic book dialogue interpretation and psychological assessment. Your task is to perform nuanced multi-label emotion classification for comic book dialogue.\n",
    "\n",
    "INPUT FORMAT:\n",
    "- You will receive sequential utterances from a single comic book page\n",
    "- Each utterance may express one or multiple emotions\n",
    "- You will be provided with {k} annotated pages as examples\n",
    "- Each example contains multiple utterances with their ground truth emotion labels\n",
    "- Follow these examples precisely for your analysis\n",
    "\n",
    "EMOTION CLASSIFICATION GUIDELINES:\n",
    "1. Identify applicable emotions from the following classes: {formatted_classes}:\n",
    "2. Analysis Principles:\n",
    "   - Consider both explicit emotional words and implicit context\n",
    "   - Account for punctuation and capitalization as emotional indicators\n",
    "   - Evaluate intensity markers (e.g., \"!!!\", CAPS, repeated letters)\n",
    "   - Factor in sequential context from surrounding utterances\n",
    "   - Default to \"neutral\" only when no clear emotion is present\n",
    "\n",
    "OUTPUT SPECIFICATIONS:\n",
    "- Strict JSON format: {{\"emotions\": [[emotion1, emotion2], [emotion3]]}}\n",
    "- The length of the value in JSON must EXACTLY match the number of utterances you have to classify\n",
    "- Do NOT generate any additional text or explanation except the JSON object\n",
    "- Arrays must be properly nested with correct brackets\n",
    "- NO ADDITIONAL TEXT OR EXPLANATION IS ALLOWED\n",
    "\n",
    "\"\"\"\n",
    "    return instruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 156/156 [00:13<00:00, 11.55it/s]\n"
     ]
    }
   ],
   "source": [
    "# For LLaMA\n",
    "\n",
    "#sys_msg_l = []\n",
    "user_msg_l = []\n",
    "task_msg_l = []\n",
    "\n",
    "emotion_classes = [\"anger\", \"disgust\", \"fear\", \"sadness\", \"surprise\", \"joy\", \"neutral\"]\n",
    "formatted_classes = \", \".join([f'\"{emotion}\"' for emotion in emotion_classes])\n",
    "\n",
    "for _,row in tqdm(test_df.iterrows(), total=len(test_df)):\n",
    "    \n",
    "    utterance_list = json.loads(row.utterance) if row.utterance.strip().startswith('[') else ast.literal_eval(row.utterance)\n",
    "    utterances = '\\n'.join([f'{i+1}. {utt}' for i, utt in enumerate(utterance_list)])\n",
    "    \n",
    "    #sys_msg = {\"role\": \"system\", \"content\": build_sys_instruction()}\n",
    "    user_msg = {\"role\":\"user\", \"content\": \"\\n\\nEXAMPLES:\" + prepare_similar_example_prompts(row.image_path, k, train_df=train_df, test_df=test_df) + f\"\\nInput for classification:\\n{row.image_embedding}\\nIdentify applicable emotions from the following classes: {formatted_classes}\\n\"}\n",
    "    task_msg = {\"role\": \"assistant\", \"content\": f\"\\n\\nOutput: \"}\n",
    "    \n",
    "    #sys_msg_l.append(sys_msg)\n",
    "    user_msg_l.append(user_msg)\n",
    "    task_msg_l.append(task_msg)\n",
    "    \n",
    "    #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For LLaMA\n",
    "\n",
    "prepared_sys_task_msg_l = []\n",
    "\n",
    "for i in range(len(user_msg_l)):\n",
    "    #prepared_sys_task_msg_l.append([sys_msg_l[i], user_msg_l[i], task_msg_l[i]])\n",
    "    prepared_sys_task_msg_l.append([user_msg_l[i], task_msg_l[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # For Qwen\n",
    "\n",
    "# prepared_sys_task_msg_l = []\n",
    "\n",
    "# for i in range(len(user_msg_l)):\n",
    "#     prepared_sys_task_msg_l.append([user_msg_l[i], task_msg_l[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(prepared_sys_task_msg_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user',\n",
       "  'content': '\\n\\nEXAMPLES:EXAMPLE 1\\n\\nInput:\\n[-5.4150e-01  6.0205e-01 -1.9104e-01  3.3179e-01  5.3516e-01  1.7969e-01\\n  2.0569e-01 -1.7383e-01 -1.8420e-01 -3.1543e-01  8.6133e-01  6.3293e-02\\n  6.4062e-01  3.1708e-02 -1.3843e-01  3.5132e-01 -4.3188e-01 -2.2583e-02\\n -1.8347e-01 -1.3196e-01 -9.3555e-01 -8.9233e-02  4.2236e-01  6.5674e-01\\n -6.9336e-02 -5.6671e-02  6.3867e-01  1.6675e-01 -7.3975e-02  1.1993e-01\\n -6.0211e-02  1.3538e-01 -1.6760e-01 -2.5366e-01  2.2986e-01 -2.7115e-02\\n  1.9055e-01  4.3750e-01 -2.1378e-02 -4.1821e-01  2.4060e-01 -2.2229e-01\\n -2.2473e-01 -4.7168e-01  5.2979e-01  2.2302e-01 -3.2349e-03  2.1338e-01\\n -2.4097e-01  1.9153e-01  3.5522e-01 -1.0767e-01  8.9417e-02 -8.1482e-02\\n -1.3135e-01  9.2102e-02  4.9243e-01  5.5359e-02  3.9886e-02  1.4587e-01\\n -4.1431e-01  6.9702e-02  4.0601e-01  1.6614e-01 -1.7725e-01  1.6528e-01\\n -8.0872e-02  5.4736e-01 -3.8391e-02  2.9175e-01  2.2217e-01  1.9379e-02\\n -1.5015e-01 -5.1117e-02  1.4929e-01 -1.1163e-01  2.1594e-01 -1.4771e-01\\n -1.4575e-01 -3.2440e-02 -3.9062e-02  1.9263e-01 -3.3789e-01  7.9883e-01\\n  2.2229e-01  2.9346e-01  5.5225e-01  2.3596e-01 -1.0850e+00 -4.7821e-02\\n -1.7139e-01  2.7222e-01 -6.6758e+00  3.9844e-01 -1.2830e-01  1.3745e-01\\n -7.8125e-02 -3.4082e-01  6.0577e-03 -3.9032e-02  3.3569e-01 -4.2236e-01\\n  3.0859e-01 -2.6154e-02 -2.9343e-02 -1.7383e-01 -1.7227e+00 -2.9590e-01\\n -3.5083e-01 -2.7206e-02  4.8999e-01 -2.1130e-01 -3.7231e-01 -8.5266e-02\\n  1.9629e-01  1.8762e-01  3.5840e-01  3.1592e-01  5.1611e-01 -7.9956e-02\\n  7.5439e-02 -4.3701e-01  1.3000e-02 -3.8574e-02  2.6025e-01 -5.1416e-01\\n  1.4978e-01 -3.6713e-02 -2.4097e-01 -5.2930e-01 -2.3010e-02  2.7271e-01\\n  1.0303e-01  8.1348e-01 -2.8052e-01  1.2146e-01 -1.2238e-01 -3.9258e-01\\n -1.1652e-01  1.0968e-01  1.2073e-01 -1.8665e-01  4.4403e-02  2.5345e-02\\n -1.4990e-01  3.9136e-01 -1.3599e-01  4.7388e-01  1.9934e-01  1.2128e-01\\n -2.4377e-01  2.0715e-01 -4.5337e-01 -1.8103e-01 -1.9958e-01 -4.5312e-01\\n  3.1052e-02  1.5991e-01  5.9998e-02 -4.4409e-01  1.7395e-01  1.5637e-01\\n  5.2307e-02  4.0967e-01  1.2274e-01  2.1960e-01 -5.4932e-01  2.0248e-02\\n -1.4685e-01 -6.1279e-01  2.7441e-01  8.2764e-02  1.6223e-01  1.6711e-01\\n  4.0991e-01 -2.8833e-01 -2.9272e-01 -4.8370e-02 -3.9258e-01  1.1908e-01\\n  6.7139e-01 -2.5146e-01 -5.5762e-01 -4.1931e-02  3.2272e-03 -9.8755e-02\\n  3.4058e-01 -2.4866e-01 -2.7466e-01 -9.8145e-02  1.2158e-01  3.6255e-01\\n  1.7590e-01 -3.0716e-02 -6.3623e-01 -9.5093e-02  8.1909e-02 -3.3569e-02\\n  2.4023e-01 -2.4976e-01 -2.3462e-01  2.4622e-01 -1.6190e-02  2.3975e-01\\n -8.0750e-02 -1.3733e-01 -1.0742e-01 -8.8440e-02  3.8501e-01  8.7830e-02\\n  3.1934e-01  4.8413e-01 -1.1548e-01 -3.7939e-01 -1.0614e-01 -1.0170e-02\\n  3.2251e-01 -2.4094e-02  4.0063e-01 -2.9346e-01  4.6533e-01 -2.4548e-01\\n -1.7322e-01  3.2617e-01  3.7061e-01 -1.4935e-03  3.1567e-01  4.1455e-01\\n  1.6858e-01 -7.1167e-02  2.2168e-01 -4.3115e-01  5.5957e-01  1.3611e-01\\n  1.7993e-01  3.0688e-01 -1.2201e-01  5.3192e-02  1.3232e-01  9.2590e-02\\n -5.0928e-01 -7.7896e-03  2.8882e-01 -9.8648e-03  2.2693e-01 -5.7959e-01\\n -2.8223e-01  1.2500e-01 -3.5034e-01  2.3853e-01  1.9641e-01  9.1492e-02\\n -2.6855e-01  2.3267e-01 -6.4697e-02  2.3315e-01  2.9541e-02  3.9551e-01\\n -2.3184e+00  1.7908e-01  1.4343e-01 -1.5918e-01  8.3008e-02 -2.0723e+00\\n  7.6538e-02  5.7495e-02  1.0303e-01  4.1333e-01  7.2205e-02 -1.4061e-02\\n -2.0422e-01 -1.8945e-01  1.4600e-01  1.7615e-01 -1.8635e-03 -8.0322e-02\\n -2.4316e-01  3.0225e-01 -1.4490e-01  1.2976e-01  3.5376e-01 -3.2788e-01\\n -3.0273e-01 -2.1704e-01 -5.6348e-01  1.2354e-01 -5.8008e-01  1.2476e-01\\n -1.2756e-01 -2.1619e-01  9.1125e-02 -4.5312e-01 -5.5817e-02  6.2646e-01\\n -1.4441e-01 -4.7668e-02  3.2544e-01  2.7075e-01  7.9346e-02 -1.0895e-01\\n -8.0261e-02  1.2891e-01 -1.4931e-02  3.4424e-01  5.9967e-02 -3.4644e-01\\n -5.6183e-02  2.9663e-01  6.0107e-01  1.5393e-01  2.6169e-02  4.1821e-01\\n  8.1104e-01  3.2593e-01 -9.0637e-02 -2.3889e-01  1.3696e-01  7.3120e-02\\n -1.1334e-01  1.0950e-01 -4.9988e-02  1.8726e-01 -4.1821e-01  1.4648e-02\\n  4.3799e-01 -7.8979e-02  4.3604e-01  1.1798e-01 -1.0089e-01 -1.9031e-01\\n  1.1642e-02  1.1884e-01  3.7769e-01  1.9946e-01 -2.0654e-01  1.2091e-01\\n -1.9763e-01 -2.3694e-01  5.2783e-01  5.3906e-01 -3.7256e-01  8.5510e-02\\n -6.3782e-02  3.9856e-02  4.6356e-02  1.6504e-01  5.9326e-01  1.3440e-01\\n  2.0679e-01 -3.2349e-02  3.0835e-01 -4.6448e-02 -4.0161e-02 -1.1975e-01\\n -1.5674e-01  1.2091e-01 -3.0713e-01 -2.2986e-01  1.0431e-01 -2.0593e-01\\n  3.1250e-01 -2.0618e-01  6.0010e-01 -6.1621e-01 -8.9160e-01  1.6815e-02\\n -1.5198e-01 -2.0660e-02 -4.0430e-01 -7.5745e-02  2.3254e-01  4.5996e-01\\n  4.8431e-02 -2.3743e-01  5.6348e-01  3.9978e-02  7.0801e-02  1.0272e-01\\n -1.1292e-01  9.0820e-02 -1.4941e-01 -4.6777e-01 -2.9468e-01  8.6853e-02\\n  2.6172e-01  1.8823e-01  1.8665e-01  2.0447e-01  4.9774e-02  5.1758e-01\\n  4.3652e-01  2.9102e-01  7.4805e-01  2.2607e-01 -6.1523e-01  1.4905e-01\\n  2.3669e-01  1.5784e-01  1.8542e-01  1.8127e-01  1.6614e-01 -3.5400e-01\\n -1.1104e+00 -6.3623e-01  3.4326e-01 -1.3464e-01  4.2496e-03 -1.5198e-01\\n  1.2805e-01 -4.6021e-01 -6.3818e-01  6.0889e-01 -2.8198e-01 -3.0273e-01\\n  3.2715e-01  6.0938e-01  2.0850e-01 -7.8735e-02 -4.1675e-01 -5.0146e-01\\n  1.2976e-01  1.3618e-02  1.8433e-02  2.8345e-01 -2.1521e-01  1.2585e-01\\n  2.7504e-03  1.8481e-01  1.7627e+00 -4.7681e-01 -1.7712e-01  4.0991e-01\\n -1.1121e-01  1.4160e-01  2.8809e-01 -1.9983e-01 -8.2422e-01 -5.8319e-02\\n  8.0322e-01 -3.8892e-01  2.2583e-01  1.0529e-01 -5.2399e-02 -3.4692e-01\\n -3.5278e-02 -9.0179e-03  2.6196e-01  2.0032e-01  3.8989e-01  5.3223e-01\\n -2.2363e-01 -1.7322e-01  1.5747e-01  4.0601e-01 -2.0276e-01 -2.2705e-01\\n -1.7676e-01  1.1786e-01  9.4788e-02  1.4746e-01  1.2622e-01 -8.0261e-02\\n  2.4951e-01 -1.5735e-01  1.9806e-02 -2.2485e-01  2.6343e-01 -1.9653e-01\\n -2.9053e-01  9.1187e-02 -3.2568e-01  2.5830e-01  2.4986e-03  2.0984e-01\\n -4.1235e-01 -3.1592e-01 -8.3069e-02 -2.7725e-02  2.4390e-01  2.8198e-01\\n -1.1530e-01  1.2549e-01 -1.4514e-01  1.3037e-01 -6.3904e-02 -1.2445e-01\\n -6.8054e-02 -2.8516e-01  2.6538e-01 -1.1475e-01  2.5488e-01  2.6514e-01\\n  5.3320e-01 -1.7114e-01  1.6138e-01 -1.1993e-01  4.9609e-01  3.0225e-01\\n  5.7129e-02 -7.3547e-02 -8.0322e-02  2.5055e-02 -3.0493e-01 -5.7861e-02\\n  4.9780e-01  4.2627e-01  3.6713e-02  1.0596e-01 -7.2266e-02  1.0098e+00\\n  9.6130e-02  1.8213e-01]\\n\\nOutput: {\"emotions\": [[\\'anger\\', \\'sadness\\'], [\\'sadness\\'], [\\'sadness\\'], [\\'sadness\\'], [\\'sadness\\'], [\\'fear\\', \\'sadness\\'], [\\'fear\\', \\'sadness\\'], [\\'fear\\', \\'sadness\\'], [\\'fear\\', \\'sadness\\'], [\\'sadness\\']]}\\n\\n\\nEXAMPLE 2\\n\\nInput:\\n[-6.2891e-01  5.4932e-01 -2.1997e-01  1.3672e-01  2.5293e-01 -5.8502e-02\\n  5.3613e-01 -7.7271e-02 -1.0938e-01 -3.0688e-01  2.2290e-01 -3.2166e-02\\n  4.8999e-01 -1.2012e-01 -3.1812e-01  5.7129e-02 -2.6343e-01 -1.2732e-01\\n  3.1128e-01 -3.3008e-01 -4.3188e-01 -2.7612e-01  4.9414e-01  6.1182e-01\\n  1.0022e-01  2.7490e-01  4.2285e-01 -1.0016e-01 -2.2766e-01  3.1396e-01\\n -1.4417e-01 -2.1255e-02 -8.4106e-02 -1.2842e-01  1.2927e-01  1.2781e-01\\n  1.7957e-01  5.4248e-01  3.6240e-03  7.4463e-02  6.6223e-02 -4.7754e-01\\n -8.6609e-02 -4.0381e-01  3.0127e-01  1.7314e+00  1.4734e-01 -8.3984e-02\\n -3.6011e-01 -1.6785e-03  6.8164e-01 -2.3730e-01 -1.9608e-03 -1.0986e-01\\n  1.6614e-01 -9.7229e-02  1.0498e-01 -1.8982e-01 -2.3108e-01  1.2744e-01\\n -5.8740e-01  8.8379e-02  5.2783e-01 -1.3330e-01 -1.8433e-01 -5.1041e-03\\n -4.4189e-02 -1.1322e-01 -4.2114e-01  1.0193e-01 -3.9253e-03  2.4963e-02\\n -2.0691e-01 -2.2449e-01 -1.5526e-02  2.9205e-02 -1.1493e-01 -2.7490e-01\\n -2.2568e-02 -3.2886e-01  1.5076e-01  9.8328e-02 -4.6997e-01  8.3691e-01\\n  1.8042e-01  1.6675e-01 -1.5556e-02  1.9275e-01 -7.1973e-01 -8.5022e-02\\n -1.0669e-01  3.4521e-01 -6.5547e+00  7.1436e-01 -1.5552e-01 -1.0425e-01\\n -2.3376e-01 -3.7140e-02  9.0332e-01 -1.4893e-01  4.2554e-01 -3.0420e-01\\n  9.7351e-02 -8.3923e-02  1.9255e-03 -3.7720e-01 -1.4482e+00 -2.7954e-01\\n -1.3037e-01  1.9241e-02  3.5547e-01  1.4145e-02 -2.7832e-01  6.0638e-02\\n -7.3914e-02  7.2021e-02  3.0225e-01  6.9946e-02  2.9517e-01 -2.0996e-02\\n  1.7542e-01 -1.3696e-01  3.6255e-01  7.0992e-03  6.5002e-02 -3.8501e-01\\n  3.7109e-01  1.4795e-01 -5.3564e-01 -2.0496e-01 -1.2073e-01  3.0835e-01\\n  1.7303e-02  8.0908e-01 -1.7147e-03  1.3954e-02 -1.8604e-01 -2.3145e-01\\n -3.1641e-01  1.0687e-01  4.1504e-02 -1.7151e-01 -4.1333e-01 -6.9153e-02\\n -7.3395e-03  2.0764e-01 -3.2886e-01  2.1765e-01  1.3708e-01  8.6594e-03\\n -5.7471e-01  1.2222e-02 -2.4072e-01 -1.3281e-01 -1.3879e-01 -4.7314e-01\\n -1.3818e-01 -4.8157e-02  2.8247e-01 -2.5659e-01  5.4016e-02 -1.3721e-01\\n  3.2104e-02  4.9219e-01  1.3330e-01  4.6460e-01 -4.9097e-01  6.9824e-02\\n -3.1543e-01 -2.5732e-01 -1.6815e-02  3.8037e-01 -1.4893e-01  1.3562e-01\\n  2.5537e-01 -1.0901e-01 -2.1460e-01 -2.2998e-01 -3.0664e-01  7.5562e-02\\n  7.5928e-01 -1.4502e-01 -4.6826e-01  1.0181e-01  1.7957e-01  1.6455e-01\\n  3.5303e-01 -3.5034e-01 -4.1528e-01 -1.4172e-01  2.2949e-02  3.7964e-01\\n -8.1665e-02 -3.7793e-01 -8.0811e-01 -7.3547e-02  6.0156e-01 -1.7822e-01\\n  1.7847e-01 -3.0811e-01  9.8038e-03  2.9443e-01  1.9312e-01  9.1858e-02\\n -1.1755e-01 -1.2006e-01 -4.4751e-01  5.3802e-02  1.1499e-01 -2.6782e-01\\n -1.5540e-01  2.1069e-01 -5.5145e-02 -3.5181e-01 -3.6841e-01  9.9182e-02\\n  2.3645e-01 -1.7212e-02  8.0762e-01 -2.7393e-01  4.8633e-01 -1.3843e-01\\n -1.3611e-01  2.6123e-01  7.5531e-03  7.4402e-02  2.8955e-01 -9.6817e-03\\n -6.9031e-02  5.3009e-02 -1.3159e-01 -3.4399e-01  5.9375e-01  2.6294e-01\\n  3.2544e-01  7.4512e-01  1.4148e-01 -1.5488e-02  4.0070e-02 -1.2793e-01\\n -5.5371e-01 -5.6519e-02  1.6443e-01  3.9093e-02 -1.4832e-01 -3.3618e-01\\n -2.5757e-01  2.2205e-01 -5.3906e-01  1.6809e-01  3.3545e-01  2.9736e-01\\n -3.8989e-01  2.1942e-02  1.0083e-01  1.6846e-01  2.0789e-01  6.4893e-01\\n -1.8584e+00  4.0088e-01 -1.0910e-02 -3.9697e-01  1.5295e-01 -2.1348e+00\\n  2.2949e-02 -2.8296e-01  2.5195e-01  5.5078e-01 -8.0200e-02 -6.5369e-02\\n -4.0210e-01 -2.5708e-01  3.0444e-01  1.8176e-01  4.4922e-02  4.8065e-02\\n  6.0089e-02  1.9348e-01 -6.7017e-02  2.5024e-01  2.0959e-01 -2.2034e-01\\n  9.3002e-03 -2.0911e-01 -5.5078e-01 -2.9190e-02 -2.5854e-01 -3.7720e-02\\n -1.9333e-02 -1.7651e-01  5.0385e-02 -1.7236e-01  2.4185e-02  7.0117e-01\\n -2.1570e-01  4.0063e-01  7.7441e-01  4.2261e-01  8.3923e-02  6.4514e-02\\n -2.2131e-01 -2.7686e-01 -3.8879e-02  2.2705e-01  4.1840e-02 -6.6016e-01\\n  1.4015e-02  1.7505e-01  5.8496e-01  1.4404e-01  1.3831e-01  6.2451e-01\\n  8.0615e-01  2.9370e-01 -1.4539e-01 -1.6833e-01  3.3911e-01  9.9854e-02\\n  4.8950e-02  2.4939e-01 -1.5491e-01  2.2498e-01 -2.7051e-01 -1.5735e-01\\n  1.3281e-01  5.6335e-02  3.3643e-01 -3.2257e-02 -3.2397e-01 -2.2705e-01\\n  3.2300e-01 -7.1594e-02  3.4766e-01 -1.9055e-01 -3.0685e-02  7.7881e-02\\n  1.1208e-02  3.0838e-02  4.9927e-01  5.3174e-01 -8.1909e-02 -1.9522e-03\\n  2.3560e-01  2.5903e-01  2.3633e-01  3.2739e-01  4.7852e-01  1.5442e-01\\n  1.6138e-01  1.7004e-01  3.4961e-01  3.1174e-02  1.3879e-01 -4.2725e-01\\n -4.2145e-02 -3.0444e-01 -1.3379e-01 -6.0010e-01  2.0349e-01 -7.9041e-02\\n  1.1620e-02  3.0249e-01  2.8931e-01 -1.0706e-01 -7.4072e-01  1.8384e-01\\n  4.9011e-02 -4.7394e-02 -3.0469e-01  7.0496e-02  2.6489e-01  3.5669e-01\\n  2.3315e-01 -3.0127e-01  4.5361e-01  1.5442e-01 -9.7900e-02  1.1792e-01\\n  2.2607e-01  2.1301e-01  7.1411e-02 -4.1309e-01 -1.9617e-01 -9.0637e-02\\n  2.0398e-01  3.0811e-01  3.2104e-01  1.8677e-02 -4.7583e-01  6.6846e-01\\n  3.1030e-01  3.1104e-01  3.7671e-01  1.8335e-01 -4.2310e-01  9.2285e-02\\n  3.5547e-01  1.7310e-01  1.6235e-01  1.2781e-01 -6.9092e-02 -2.1863e-01\\n -7.5928e-01 -7.1436e-01  4.1309e-01 -1.0590e-01  2.3438e-01 -1.4915e-02\\n  4.5947e-01 -4.8730e-01 -4.2505e-01  3.7988e-01 -1.8835e-01  1.6138e-01\\n  3.4546e-01  6.4600e-01 -1.8158e-02 -3.3813e-01 -3.7842e-01 -3.1250e-01\\n  1.6760e-01 -1.4252e-02  2.2363e-01  6.6748e-01 -4.7852e-01  4.1595e-02\\n  4.3976e-02  3.0273e-01  1.7207e+00 -2.4207e-01 -6.9519e-02  3.6792e-01\\n -9.5947e-01 -9.3750e-02  2.9443e-01 -1.7346e-01 -4.8828e-01 -1.8958e-01\\n  4.8682e-01 -2.4854e-01  6.7520e-03  5.6366e-02  3.2501e-02 -3.1714e-01\\n -1.3660e-01  3.3789e-01  1.9360e-01  1.2250e-01  2.8149e-01  3.8525e-01\\n -2.8833e-01 -4.3945e-02 -1.6199e-01  5.3516e-01  3.9825e-02 -1.8250e-01\\n -1.2802e-02  1.7078e-01 -1.7358e-01  7.5722e-04 -2.4109e-02 -2.3047e-01\\n  3.1714e-01 -1.7859e-01 -1.2891e-01 -1.2347e-01  1.8286e-01 -2.2412e-01\\n -3.6426e-01  2.3682e-01  4.2267e-02  7.0215e-01  6.5125e-02  2.4927e-01\\n -3.0908e-01 -7.7734e-01  4.3610e-02  1.3138e-02  3.7207e-01  6.2683e-02\\n -8.3618e-02 -2.7832e-02 -1.3452e-01  5.1074e-01 -9.3155e-03  2.6642e-02\\n  9.2407e-02 -2.1802e-01  3.5083e-01 -2.6685e-01  4.9438e-01 -2.2632e-01\\n  6.9922e-01 -2.2986e-01  6.5674e-01 -1.9775e-01  6.8701e-01  1.9241e-02\\n  1.2042e-01  7.1045e-02 -1.4233e-01 -5.0079e-02 -3.0273e-01  2.6270e-01\\n  4.9365e-01  2.0093e-01 -1.2152e-01  2.8027e-01  7.7637e-02  9.4434e-01\\n  1.5625e-02  1.9250e-01]\\n\\nOutput: {\"emotions\": [[\\'surprise\\', \\'joy\\'], [\\'sadness\\'], [\\'joy\\'], [\\'anger\\', \\'sadness\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'sadness\\'], [\\'anger\\', \\'joy\\'], [\\'joy\\'], [\\'anger\\', \\'sadness\\'], [\\'joy\\']]}\\n\\n\\nEXAMPLE 3\\n\\nInput:\\n[-2.9126e-01  3.2959e-01 -2.0679e-01  1.4514e-01  4.4189e-01 -2.9572e-02\\n  2.5952e-01 -3.3130e-01 -2.4219e-01 -2.6062e-02  5.2539e-01  3.1853e-03\\n  6.8750e-01  8.6365e-02  1.2146e-01  6.4514e-02 -2.9144e-02  5.6183e-02\\n -2.9932e-01  3.6499e-02 -3.5132e-01 -1.9543e-01  2.8711e-01  6.8555e-01\\n -3.2397e-01  1.3831e-01  4.7583e-01  7.4524e-02 -1.3806e-01  4.9561e-01\\n -2.6440e-01  8.0566e-02 -3.4409e-03 -1.3525e-01  4.3262e-01  2.4033e-02\\n  2.1069e-01  2.6953e-01  1.1761e-01 -9.0637e-02  1.3770e-01  9.6924e-02\\n -2.5342e-01 -4.4507e-01  2.5317e-01  2.3572e-01  1.2695e-01  1.1932e-01\\n -5.4834e-01  1.5649e-01  6.9727e-01 -2.7466e-01  1.2439e-01 -3.2007e-01\\n -2.5162e-02  1.1917e-02  3.4497e-01 -1.0101e-01 -9.6680e-02  1.8646e-02\\n -9.8340e-01  2.2369e-02  6.0693e-01  7.8491e-02 -1.5125e-01  9.4666e-02\\n  1.7737e-01  5.2734e-01 -6.3721e-01  2.1460e-01  1.6956e-01 -4.8706e-02\\n -2.0129e-01 -2.2156e-01  2.9404e-02 -5.6877e-03 -7.6050e-02 -1.2646e-01\\n -6.1707e-02 -4.2261e-01  3.5400e-02  2.8149e-01 -4.9170e-01  8.2227e-01\\n  4.4556e-03  3.2227e-01  2.7267e-02 -2.8488e-02 -1.2100e+00 -1.9885e-01\\n -1.5503e-01  2.9712e-01 -6.1367e+00  9.0674e-01 -1.7261e-01  2.0935e-01\\n -1.7505e-01 -2.5781e-01  6.3770e-01  2.8442e-01  2.8979e-01 -3.5107e-01\\n  1.4539e-01 -1.8265e-02 -2.8857e-01 -2.0215e-01 -1.8301e+00 -4.4263e-01\\n -2.6001e-01 -2.3117e-02  4.0186e-01 -2.0996e-01 -3.2935e-01 -3.0411e-02\\n  1.1237e-01 -5.6976e-02  3.2251e-01  7.8430e-02  4.1919e-01 -2.9663e-01\\n  1.7737e-01 -2.7051e-01  1.9397e-01  1.7944e-01  2.6904e-01 -4.0869e-01\\n  2.8760e-01  1.6895e-01 -6.5088e-01 -1.9336e-01 -4.0723e-01  2.7124e-01\\n -8.9111e-02  7.7686e-01 -2.0044e-01 -1.5308e-01  6.4392e-02 -5.5908e-02\\n -3.5913e-01  2.4048e-02 -3.3966e-02 -3.5840e-01 -1.6956e-01  1.8875e-02\\n -1.3252e-02  1.0187e-01 -2.6465e-01  4.5605e-01  9.4666e-02  2.1082e-01\\n -1.2683e-01  1.8665e-01 -1.5051e-01  2.4426e-01 -3.5303e-01 -6.7822e-01\\n -9.9060e-02  1.3171e-01 -2.0599e-02 -2.1838e-01 -8.0566e-02 -6.8237e-02\\n  1.6113e-01  3.4741e-01  8.1360e-02  2.2913e-01 -1.8384e-01  7.4524e-02\\n -2.0972e-01 -6.0742e-01  2.3303e-01  6.7322e-02 -3.0182e-02  1.3000e-01\\n  1.4343e-01 -5.1123e-01  2.1191e-01 -2.9556e-02  2.6880e-01 -6.2988e-02\\n  7.5537e-01 -2.8052e-01 -5.1611e-01  6.1890e-02  2.9834e-01  2.4750e-02\\n  4.0308e-01 -3.4351e-01 -1.4319e-01  2.1683e-02 -9.4910e-02  3.5864e-01\\n  2.4841e-01 -1.6663e-01 -6.2744e-01 -2.7856e-01  4.3188e-01 -2.1692e-01\\n  1.2354e-01 -4.5972e-01 -9.1553e-02  7.1472e-02  4.0558e-02  3.1030e-01\\n  1.7432e-01  1.0358e-01 -3.2324e-01 -2.0123e-04  2.5562e-01 -2.8174e-01\\n -2.3718e-01  2.2412e-01 -3.4497e-01 -3.7061e-01  8.2886e-02  8.9172e-02\\n  1.6797e-01 -3.1616e-01  2.7368e-01 -1.3586e-01  1.7200e-01  6.9141e-01\\n -1.4893e-01  3.1494e-01  1.4417e-01 -1.1285e-01  3.0054e-01  3.2886e-01\\n  4.2175e-02 -9.1736e-02 -2.1667e-01 -4.5312e-01  4.7339e-01  8.0017e-02\\n  1.2646e-01  3.9697e-01 -3.4155e-01 -3.1161e-04  1.9928e-02 -1.1987e-01\\n -5.3271e-01 -3.8184e-01  4.1699e-01 -2.7466e-01  2.4582e-02 -8.3887e-01\\n -2.9297e-02  1.1176e-01 -5.5371e-01  2.9248e-01  3.9941e-01  2.8442e-01\\n -1.3214e-02 -1.5063e-01  4.6356e-02  9.5093e-02  3.4009e-01  5.3369e-01\\n -2.1211e+00  2.6367e-01  1.1066e-01 -3.5425e-01 -4.1351e-02 -2.0117e+00\\n  2.5928e-01 -2.9053e-02  1.8787e-01  3.9771e-01 -3.4546e-02  1.8628e-01\\n -3.9136e-01 -2.2864e-01  1.5991e-01  5.9753e-02  9.4421e-02  1.6968e-02\\n -2.3291e-01  6.7627e-02 -1.3977e-01  1.8921e-02  2.6758e-01 -4.6313e-01\\n -4.5967e-03 -2.7271e-01 -4.1528e-01  3.5254e-01 -5.2295e-01 -5.7281e-02\\n  4.9774e-02 -2.1936e-01  1.0400e-01 -3.1714e-01  5.7098e-02  6.6504e-01\\n -2.8882e-01  2.6270e-01  7.6904e-01  3.0176e-01 -2.6871e-02  1.0400e-01\\n -2.4426e-01 -1.4856e-01 -2.9102e-01  1.9421e-01 -9.2590e-02 -4.6875e-01\\n -2.3584e-01 -8.2703e-02  6.5283e-01  3.1152e-01  2.5177e-02  6.3574e-01\\n  7.7246e-01  2.6367e-01 -1.9653e-01 -2.6343e-01  2.1643e-01  8.8745e-02\\n -1.1267e-01  2.0715e-01 -2.9785e-01 -1.4172e-01 -3.4912e-01 -3.7323e-02\\n  1.4136e-01 -1.0895e-01  4.4409e-01 -2.3315e-02 -4.5850e-01 -4.0601e-01\\n  1.1670e-01  9.1980e-02  4.0625e-01 -8.7433e-03 -2.5049e-01  2.8095e-03\\n -9.4727e-02 -1.9836e-01  3.7549e-01  3.6963e-01 -1.2878e-01  2.5391e-01\\n  4.4189e-02  9.3994e-02  2.5415e-01  2.0312e-01  4.1357e-01  1.1383e-01\\n  2.6587e-01  2.7145e-02  2.3376e-01  1.1177e-03  1.5991e-02 -1.8091e-01\\n -1.2891e-01 -1.3588e-02 -3.3179e-01 -1.5039e-01  5.3772e-02 -1.1743e-01\\n -9.8633e-02 -9.4727e-02  5.6787e-01  2.4643e-02 -3.4497e-01  2.4460e-02\\n  4.3457e-02  3.6133e-01 -5.9717e-01 -2.0715e-01  2.4704e-02  3.0078e-01\\n  4.1534e-02 -1.8848e-01  2.8882e-01  3.8013e-01  1.0809e-01  3.7549e-01\\n  4.9146e-01  3.5736e-02 -2.1790e-01 -5.9570e-01 -2.9688e-01 -3.0713e-01\\n  5.1079e-03  3.1982e-01  1.7859e-01  5.0879e-01 -1.3940e-01  9.5020e-01\\n  4.3066e-01  5.0293e-01  7.0459e-01  1.9058e-02 -6.0693e-01  2.1582e-01\\n  3.0103e-01  1.4709e-01  1.5796e-01 -8.9569e-03  3.3783e-02 -2.1252e-01\\n -9.4238e-01 -6.2988e-01  5.0635e-01 -2.0593e-01  6.7078e-02 -2.7441e-01\\n  3.0713e-01 -4.1943e-01 -3.5864e-01  4.2480e-01 -1.8298e-01 -2.8125e-01\\n  5.3467e-01  6.6309e-01  1.3782e-01 -4.9988e-02 -4.1333e-01 -3.5718e-01\\n  3.3374e-01  3.7140e-02  1.6882e-01  7.0557e-01 -5.7520e-01 -1.2036e-01\\n -1.0078e-02  1.2970e-02  1.8477e+00 -3.2031e-01 -3.5498e-01  2.8687e-01\\n -1.8860e-01 -1.4880e-01  4.2261e-01 -1.9019e-01 -7.3877e-01 -1.2354e-01\\n  5.2393e-01 -1.5662e-01  2.3987e-01 -1.9455e-02  3.5461e-02 -1.2213e-01\\n -1.0321e-01 -7.7576e-02  2.1460e-01  3.9124e-02  3.1030e-01  5.6543e-01\\n -2.4023e-01 -4.0680e-02  4.4403e-02  2.6562e-01  9.4604e-02 -1.3418e-03\\n  1.9128e-01  2.1436e-01  2.8247e-01  2.0789e-01  7.7087e-02 -1.2378e-01\\n  3.7183e-01  4.6143e-02 -1.4258e-01 -2.1191e-01  6.0986e-01 -1.8457e-01\\n -4.3115e-01 -1.9409e-02 -2.9834e-01  1.5051e-01  2.2083e-01  2.1277e-01\\n -5.5469e-01 -4.3604e-01 -1.6406e-01  2.0007e-01  2.5488e-01  1.2915e-01\\n -2.0630e-01 -6.2714e-03 -1.3831e-01  1.2561e-01 -2.7490e-01 -1.3574e-01\\n -1.3013e-01 -2.8711e-01  4.0649e-01 -1.8713e-01  3.1299e-01 -2.2797e-02\\n  1.7639e-01 -4.1870e-01  3.8599e-01 -2.8030e-02  7.2705e-01 -3.0174e-03\\n -9.3567e-02 -8.5144e-02 -3.0005e-01  6.6772e-02 -2.6025e-01 -8.3008e-02\\n  3.0396e-01  5.3711e-01 -1.3257e-01  2.8955e-01 -2.7148e-01  1.0469e+00\\n -8.4045e-02  1.3708e-01]\\n\\nOutput: {\"emotions\": [[\\'anger\\'], [\\'anger\\'], [\\'anger\\'], [\\'anger\\'], [\\'anger\\'], [\\'anger\\'], [\\'anger\\'], [\\'anger\\'], [\\'anger\\'], [\\'anger\\'], [\\'fear\\']]}\\n\\n\\n\\nInput for classification:\\n[-5.9668e-01  2.5415e-01 -2.9224e-01  1.3953e-01  3.8965e-01  1.3293e-01\\n  3.0420e-01 -3.7305e-01 -1.8738e-01 -1.6895e-01  3.3228e-01  1.2152e-01\\n  5.4541e-01  1.4490e-01 -3.9453e-01  1.5710e-01 -3.8159e-01 -1.1121e-01\\n -3.0777e-02 -2.9282e-02 -8.6865e-01  3.9551e-02  5.3174e-01  6.6602e-01\\n -3.4180e-02  5.5939e-02  6.6797e-01  7.9407e-02 -6.0425e-02  3.6743e-01\\n -5.6854e-02 -3.0420e-01 -1.3623e-01  3.2013e-02  1.4746e-01  6.3210e-03\\n  1.8591e-01  5.2197e-01  1.7792e-02 -2.7148e-01  3.3398e-01 -1.2537e-01\\n -3.2788e-01 -3.1323e-01  5.3223e-01  9.4873e-01  5.7227e-01  2.4963e-01\\n -1.2360e-01  3.3545e-01  4.0863e-02 -1.6174e-01  3.4546e-01 -3.7231e-01\\n -1.3818e-01  1.3110e-01  4.0283e-01  1.4136e-01 -2.2827e-01  2.9492e-01\\n -4.9487e-01  3.1006e-01  3.5083e-01 -1.6040e-01 -4.2603e-01 -3.3691e-02\\n -1.9409e-01  7.3193e-01 -2.0325e-01  1.1188e-01  5.5634e-02  7.2449e-02\\n -1.5149e-01 -2.7344e-01 -3.4912e-02 -1.0193e-01  6.1859e-02 -1.9336e-01\\n -4.5013e-02 -2.7466e-01 -7.1259e-03  2.0276e-01 -5.1465e-01  6.9141e-01\\n  1.6907e-01  4.1943e-01  1.3440e-01  8.4290e-02 -8.6963e-01 -5.8643e-01\\n -2.8534e-02  3.1470e-01 -6.2695e+00  7.6416e-01 -3.7872e-02  2.3462e-01\\n -1.5027e-01 -5.2686e-01  8.0518e-01  8.6914e-02  5.9326e-01 -5.2881e-01\\n  5.7556e-02  1.8445e-01 -5.3760e-01  7.0923e-02 -1.1680e+00 -2.2119e-01\\n -4.3311e-01  1.6724e-01  2.3547e-01 -9.3933e-02 -2.6099e-01 -2.8793e-02\\n  1.7834e-01 -5.3040e-02  3.7769e-01  2.4829e-01  4.8608e-01 -1.3831e-01\\n  1.9580e-01 -3.0347e-01 -6.0059e-02  6.8665e-02  9.1980e-02 -4.3018e-01\\n  2.8955e-01  2.3840e-01 -3.4424e-01  3.3966e-02 -1.3916e-01  2.3279e-01\\n  2.8052e-01  7.7881e-01 -1.8567e-01 -5.2582e-02 -6.8555e-01 -4.1821e-01\\n -3.1323e-01  1.0681e-01 -1.3000e-01 -2.6343e-01 -8.0994e-02  2.0462e-02\\n  1.0944e-01  2.7466e-01 -1.3574e-01  3.6890e-01  2.5610e-01 -1.1224e-01\\n -3.4961e-01 -5.4901e-02 -5.2551e-02 -7.7881e-02 -3.6304e-01 -5.4199e-01\\n  7.1228e-02 -8.8501e-02  3.4760e-02 -4.0479e-01  3.8422e-02 -1.5450e-03\\n  2.8613e-01  4.6826e-01  2.0862e-01  2.3352e-01 -5.1562e-01  1.3635e-01\\n -2.0728e-01 -4.0723e-01  2.0557e-01  1.4880e-01 -2.4316e-01  1.4893e-01\\n  4.5264e-01  4.2381e-03 -3.6450e-01 -9.6252e-02  3.5278e-02  1.3953e-01\\n  5.9473e-01 -2.2876e-01 -4.1455e-01  7.2632e-02  2.0105e-01  1.5564e-01\\n  5.4639e-01 -2.1130e-01 -1.3550e-01 -6.2561e-03  1.0754e-01  3.0981e-01\\n  2.1106e-01 -1.6064e-01 -8.9697e-01 -2.1741e-01  1.4417e-01 -2.6758e-01\\n  1.6577e-01 -2.6929e-01 -7.9773e-02  2.9175e-01 -2.4207e-01  1.6333e-01\\n  4.0332e-01 -2.8101e-01 -3.7451e-01 -8.3984e-02  3.6865e-01 -2.4500e-01\\n -1.5320e-01  3.0469e-01 -1.1682e-01 -2.4915e-01 -1.4368e-01 -4.6753e-02\\n  2.6855e-01  2.0850e-01  5.8398e-01 -1.5308e-01  3.9551e-01  2.1851e-01\\n -9.5215e-02  6.2744e-01  1.0858e-01 -1.0913e-01  5.2588e-01  2.4695e-01\\n -1.5930e-01  2.2415e-02  2.3682e-01 -4.8022e-01  3.9160e-01  1.2378e-01\\n  1.4136e-01  2.6709e-01 -2.0447e-02  6.7902e-03 -8.7219e-02 -9.0103e-03\\n -5.6445e-01 -2.5610e-01  5.1953e-01 -2.9102e-01 -2.4121e-01 -2.7515e-01\\n -1.7139e-01  1.4050e-01 -4.3604e-01  2.3230e-01  3.8501e-01  1.3306e-01\\n -3.2129e-01 -2.5122e-01  1.1292e-01  1.4734e-01 -1.1467e-02  3.9038e-01\\n -2.6895e+00  2.4658e-01 -1.3184e-01 -1.7676e-01  2.0544e-01 -1.9170e+00\\n  2.0508e-02 -2.1021e-01  6.4026e-02  4.8999e-01 -1.0696e-02  3.6407e-02\\n -3.9722e-01 -2.6343e-01 -8.1238e-02  1.9495e-01 -2.7100e-01 -4.4922e-02\\n -1.7493e-01  2.1106e-01 -2.5848e-02 -1.3574e-01  3.3472e-01 -3.4839e-01\\n -2.6904e-01 -3.1885e-01 -3.6255e-01  2.2681e-01 -4.0527e-01  4.3365e-02\\n  3.2275e-01 -3.7109e-01 -2.9938e-02 -1.7175e-01  1.9678e-01  6.9141e-01\\n -2.6758e-01  2.0239e-01  4.9023e-01  2.9248e-01 -1.0785e-01 -1.1902e-01\\n -3.3398e-01 -2.5464e-01 -1.0773e-01  3.3960e-01 -2.3169e-01 -2.7856e-01\\n -2.3718e-01 -6.3782e-02  5.4639e-01  1.9604e-01 -7.3547e-02  4.2773e-01\\n  7.7539e-01  1.2335e-01  7.3891e-03 -3.6206e-01  1.9971e-01  2.3645e-01\\n -1.2073e-01  4.9292e-01  2.9297e-02 -2.1149e-02 -3.3203e-01  1.0803e-01\\n  2.8784e-01  1.3843e-01  2.2925e-01 -2.0520e-01 -1.9324e-01 -3.6230e-01\\n  2.0508e-01 -1.1676e-01  4.9072e-01  3.9276e-02 -3.5718e-01  1.6223e-01\\n  3.7048e-02  1.4307e-01  6.5039e-01  3.5059e-01 -1.2192e-02  1.3220e-01\\n  3.5034e-01  2.0642e-01  6.6223e-02  8.4045e-02  7.2510e-01  2.1069e-01\\n  1.3232e-01  1.9943e-02 -2.5708e-01 -1.8628e-01  1.7273e-01 -5.2490e-01\\n -1.7749e-01 -2.1606e-01 -9.6985e-02  1.7871e-01 -6.3171e-02  6.8787e-02\\n -2.7588e-01  2.1436e-01  3.5547e-01  4.7058e-02 -6.0449e-01 -3.1982e-02\\n -3.4637e-02  2.4878e-01 -2.1252e-01 -5.0598e-02  9.7717e-02  5.4102e-01\\n  1.7603e-01 -3.6792e-01  5.1562e-01 -1.3916e-01 -9.8572e-02  1.5137e-01\\n  6.9885e-02  2.8979e-01 -1.2708e-01 -1.1260e+00 -1.2164e-01 -1.3562e-01\\n  1.1578e-01  4.7729e-01  1.0468e-01  3.9648e-01 -1.3354e-01  2.7002e-01\\n  4.0234e-01  3.7720e-01  5.3418e-01 -2.2461e-02 -6.3672e-01  2.2754e-01\\n  2.3315e-01  1.8396e-01  1.9861e-01 -8.3862e-02  4.7531e-03 -1.2720e-01\\n -6.4893e-01 -6.7969e-01  4.9878e-01 -2.4536e-01  2.8979e-01 -5.6824e-02\\n  5.9180e-01 -4.6729e-01 -4.5459e-01  4.3091e-01 -1.8173e-02 -2.0459e-01\\n  1.1023e-01  4.1919e-01 -1.4563e-01  2.8870e-02 -4.2603e-01 -5.5420e-01\\n -6.3782e-02 -1.5488e-02 -1.4294e-01  1.8982e-01 -3.8965e-01  1.6272e-01\\n -7.2693e-02  1.4429e-01  1.3389e+00 -2.5122e-01 -4.5435e-01  3.9600e-01\\n -2.8809e-01 -2.8732e-02  1.8799e-01 -1.8018e-01 -6.7334e-01 -2.9346e-01\\n  5.1611e-01 -1.6479e-01  1.2585e-01 -4.4830e-02 -5.4352e-02 -1.0327e-01\\n  2.1057e-02  7.1716e-02  4.8511e-01  1.2048e-01  1.8860e-01  3.5425e-01\\n  4.9866e-02  1.8689e-01  8.7219e-02  1.6382e-01  3.0060e-02  2.8610e-02\\n -1.4351e-02 -1.0492e-01 -3.8116e-02  1.4709e-01  9.5215e-02 -2.8931e-01\\n  3.3667e-01 -1.4197e-01 -4.4006e-02  1.3843e-01  2.0850e-01 -2.8320e-02\\n -2.2534e-01  3.1763e-01  7.7782e-03  3.4619e-01  2.0966e-02  1.7188e-01\\n -2.6978e-01 -3.2764e-01 -1.9373e-01  3.1445e-01  2.0276e-01  7.4646e-02\\n -2.3145e-01  1.1066e-01 -8.6853e-02  2.8540e-01 -1.0437e-01 -1.6382e-01\\n -3.7354e-02 -1.8298e-01  1.3171e-01 -3.3423e-01  3.1812e-01 -2.5806e-01\\n  6.8457e-01  7.5928e-02  3.4277e-01  3.1616e-02  8.1494e-01 -2.3083e-01\\n  6.5857e-02 -1.2402e-01 -7.1472e-02  1.0181e-01 -2.9517e-01  1.2622e-01\\n  2.0557e-01  3.6890e-01  1.3940e-01  3.7109e-01  5.6305e-03  1.1689e+00\\n -1.2830e-01  4.1553e-01]\\nIdentify applicable emotions from the following classes: \"anger\", \"disgust\", \"fear\", \"sadness\", \"surprise\", \"joy\", \"neutral\"\\n'},\n",
       " {'role': 'assistant', 'content': '\\n\\nOutput: '}]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prepared_sys_task_msg_l[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_tensor(tensor, batch_size):\n",
    "    return [tensor[i:i+batch_size] for i in range(0, tensor.size(0), batch_size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer.apply_chat_template(\n",
    "            prepared_sys_task_msg_l,\n",
    "            #pad_token = inference_tokenizer.bos_token,\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            add_generation_prompt=True,\n",
    "            return_dict=True,\n",
    "            return_tensors=\"pt\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([128004, 128004, 128004,  ...,  78191, 128007,    271])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.input_ids[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "system\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 26 Jul 2024\n",
      "\n",
      "user\n",
      "\n",
      "EXAMPLES:EXAMPLE 1\n",
      "\n",
      "Input:\n",
      "[-5.4150e-01  6.0205e-01 -1.9104e-01  3.3179e-01  5.3516e-01  1.7969e-01\n",
      "  2.0569e-01 -1.7383e-01 -1.8420e-01 -3.1543e-01  8.6133e-01  6.3293e-02\n",
      "  6.4062e-01  3.1708e-02 -1.3843e-01  3.5132e-01 -4.3188e-01 -2.2583e-02\n",
      " -1.8347e-01 -1.3196e-01 -9.3555e-01 -8.9233e-02  4.2236e-01  6.5674e-01\n",
      " -6.9336e-02 -5.6671e-02  6.3867e-01  1.6675e-01 -7.3975e-02  1.1993e-01\n",
      " -6.0211e-02  1.3538e-01 -1.6760e-01 -2.5366e-01  2.2986e-01 -2.7115e-02\n",
      "  1.9055e-01  4.3750e-01 -2.1378e-02 -4.1821e-01  2.4060e-01 -2.2229e-01\n",
      " -2.2473e-01 -4.7168e-01  5.2979e-01  2.2302e-01 -3.2349e-03  2.1338e-01\n",
      " -2.4097e-01  1.9153e-01  3.5522e-01 -1.0767e-01  8.9417e-02 -8.1482e-02\n",
      " -1.3135e-01  9.2102e-02  4.9243e-01  5.5359e-02  3.9886e-02  1.4587e-01\n",
      " -4.1431e-01  6.9702e-02  4.0601e-01  1.6614e-01 -1.7725e-01  1.6528e-01\n",
      " -8.0872e-02  5.4736e-01 -3.8391e-02  2.9175e-01  2.2217e-01  1.9379e-02\n",
      " -1.5015e-01 -5.1117e-02  1.4929e-01 -1.1163e-01  2.1594e-01 -1.4771e-01\n",
      " -1.4575e-01 -3.2440e-02 -3.9062e-02  1.9263e-01 -3.3789e-01  7.9883e-01\n",
      "  2.2229e-01  2.9346e-01  5.5225e-01  2.3596e-01 -1.0850e+00 -4.7821e-02\n",
      " -1.7139e-01  2.7222e-01 -6.6758e+00  3.9844e-01 -1.2830e-01  1.3745e-01\n",
      " -7.8125e-02 -3.4082e-01  6.0577e-03 -3.9032e-02  3.3569e-01 -4.2236e-01\n",
      "  3.0859e-01 -2.6154e-02 -2.9343e-02 -1.7383e-01 -1.7227e+00 -2.9590e-01\n",
      " -3.5083e-01 -2.7206e-02  4.8999e-01 -2.1130e-01 -3.7231e-01 -8.5266e-02\n",
      "  1.9629e-01  1.8762e-01  3.5840e-01  3.1592e-01  5.1611e-01 -7.9956e-02\n",
      "  7.5439e-02 -4.3701e-01  1.3000e-02 -3.8574e-02  2.6025e-01 -5.1416e-01\n",
      "  1.4978e-01 -3.6713e-02 -2.4097e-01 -5.2930e-01 -2.3010e-02  2.7271e-01\n",
      "  1.0303e-01  8.1348e-01 -2.8052e-01  1.2146e-01 -1.2238e-01 -3.9258e-01\n",
      " -1.1652e-01  1.0968e-01  1.2073e-01 -1.8665e-01  4.4403e-02  2.5345e-02\n",
      " -1.4990e-01  3.9136e-01 -1.3599e-01  4.7388e-01  1.9934e-01  1.2128e-01\n",
      " -2.4377e-01  2.0715e-01 -4.5337e-01 -1.8103e-01 -1.9958e-01 -4.5312e-01\n",
      "  3.1052e-02  1.5991e-01  5.9998e-02 -4.4409e-01  1.7395e-01  1.5637e-01\n",
      "  5.2307e-02  4.0967e-01  1.2274e-01  2.1960e-01 -5.4932e-01  2.0248e-02\n",
      " -1.4685e-01 -6.1279e-01  2.7441e-01  8.2764e-02  1.6223e-01  1.6711e-01\n",
      "  4.0991e-01 -2.8833e-01 -2.9272e-01 -4.8370e-02 -3.9258e-01  1.1908e-01\n",
      "  6.7139e-01 -2.5146e-01 -5.5762e-01 -4.1931e-02  3.2272e-03 -9.8755e-02\n",
      "  3.4058e-01 -2.4866e-01 -2.7466e-01 -9.8145e-02  1.2158e-01  3.6255e-01\n",
      "  1.7590e-01 -3.0716e-02 -6.3623e-01 -9.5093e-02  8.1909e-02 -3.3569e-02\n",
      "  2.4023e-01 -2.4976e-01 -2.3462e-01  2.4622e-01 -1.6190e-02  2.3975e-01\n",
      " -8.0750e-02 -1.3733e-01 -1.0742e-01 -8.8440e-02  3.8501e-01  8.7830e-02\n",
      "  3.1934e-01  4.8413e-01 -1.1548e-01 -3.7939e-01 -1.0614e-01 -1.0170e-02\n",
      "  3.2251e-01 -2.4094e-02  4.0063e-01 -2.9346e-01  4.6533e-01 -2.4548e-01\n",
      " -1.7322e-01  3.2617e-01  3.7061e-01 -1.4935e-03  3.1567e-01  4.1455e-01\n",
      "  1.6858e-01 -7.1167e-02  2.2168e-01 -4.3115e-01  5.5957e-01  1.3611e-01\n",
      "  1.7993e-01  3.0688e-01 -1.2201e-01  5.3192e-02  1.3232e-01  9.2590e-02\n",
      " -5.0928e-01 -7.7896e-03  2.8882e-01 -9.8648e-03  2.2693e-01 -5.7959e-01\n",
      " -2.8223e-01  1.2500e-01 -3.5034e-01  2.3853e-01  1.9641e-01  9.1492e-02\n",
      " -2.6855e-01  2.3267e-01 -6.4697e-02  2.3315e-01  2.9541e-02  3.9551e-01\n",
      " -2.3184e+00  1.7908e-01  1.4343e-01 -1.5918e-01  8.3008e-02 -2.0723e+00\n",
      "  7.6538e-02  5.7495e-02  1.0303e-01  4.1333e-01  7.2205e-02 -1.4061e-02\n",
      " -2.0422e-01 -1.8945e-01  1.4600e-01  1.7615e-01 -1.8635e-03 -8.0322e-02\n",
      " -2.4316e-01  3.0225e-01 -1.4490e-01  1.2976e-01  3.5376e-01 -3.2788e-01\n",
      " -3.0273e-01 -2.1704e-01 -5.6348e-01  1.2354e-01 -5.8008e-01  1.2476e-01\n",
      " -1.2756e-01 -2.1619e-01  9.1125e-02 -4.5312e-01 -5.5817e-02  6.2646e-01\n",
      " -1.4441e-01 -4.7668e-02  3.2544e-01  2.7075e-01  7.9346e-02 -1.0895e-01\n",
      " -8.0261e-02  1.2891e-01 -1.4931e-02  3.4424e-01  5.9967e-02 -3.4644e-01\n",
      " -5.6183e-02  2.9663e-01  6.0107e-01  1.5393e-01  2.6169e-02  4.1821e-01\n",
      "  8.1104e-01  3.2593e-01 -9.0637e-02 -2.3889e-01  1.3696e-01  7.3120e-02\n",
      " -1.1334e-01  1.0950e-01 -4.9988e-02  1.8726e-01 -4.1821e-01  1.4648e-02\n",
      "  4.3799e-01 -7.8979e-02  4.3604e-01  1.1798e-01 -1.0089e-01 -1.9031e-01\n",
      "  1.1642e-02  1.1884e-01  3.7769e-01  1.9946e-01 -2.0654e-01  1.2091e-01\n",
      " -1.9763e-01 -2.3694e-01  5.2783e-01  5.3906e-01 -3.7256e-01  8.5510e-02\n",
      " -6.3782e-02  3.9856e-02  4.6356e-02  1.6504e-01  5.9326e-01  1.3440e-01\n",
      "  2.0679e-01 -3.2349e-02  3.0835e-01 -4.6448e-02 -4.0161e-02 -1.1975e-01\n",
      " -1.5674e-01  1.2091e-01 -3.0713e-01 -2.2986e-01  1.0431e-01 -2.0593e-01\n",
      "  3.1250e-01 -2.0618e-01  6.0010e-01 -6.1621e-01 -8.9160e-01  1.6815e-02\n",
      " -1.5198e-01 -2.0660e-02 -4.0430e-01 -7.5745e-02  2.3254e-01  4.5996e-01\n",
      "  4.8431e-02 -2.3743e-01  5.6348e-01  3.9978e-02  7.0801e-02  1.0272e-01\n",
      " -1.1292e-01  9.0820e-02 -1.4941e-01 -4.6777e-01 -2.9468e-01  8.6853e-02\n",
      "  2.6172e-01  1.8823e-01  1.8665e-01  2.0447e-01  4.9774e-02  5.1758e-01\n",
      "  4.3652e-01  2.9102e-01  7.4805e-01  2.2607e-01 -6.1523e-01  1.4905e-01\n",
      "  2.3669e-01  1.5784e-01  1.8542e-01  1.8127e-01  1.6614e-01 -3.5400e-01\n",
      " -1.1104e+00 -6.3623e-01  3.4326e-01 -1.3464e-01  4.2496e-03 -1.5198e-01\n",
      "  1.2805e-01 -4.6021e-01 -6.3818e-01  6.0889e-01 -2.8198e-01 -3.0273e-01\n",
      "  3.2715e-01  6.0938e-01  2.0850e-01 -7.8735e-02 -4.1675e-01 -5.0146e-01\n",
      "  1.2976e-01  1.3618e-02  1.8433e-02  2.8345e-01 -2.1521e-01  1.2585e-01\n",
      "  2.7504e-03  1.8481e-01  1.7627e+00 -4.7681e-01 -1.7712e-01  4.0991e-01\n",
      " -1.1121e-01  1.4160e-01  2.8809e-01 -1.9983e-01 -8.2422e-01 -5.8319e-02\n",
      "  8.0322e-01 -3.8892e-01  2.2583e-01  1.0529e-01 -5.2399e-02 -3.4692e-01\n",
      " -3.5278e-02 -9.0179e-03  2.6196e-01  2.0032e-01  3.8989e-01  5.3223e-01\n",
      " -2.2363e-01 -1.7322e-01  1.5747e-01  4.0601e-01 -2.0276e-01 -2.2705e-01\n",
      " -1.7676e-01  1.1786e-01  9.4788e-02  1.4746e-01  1.2622e-01 -8.0261e-02\n",
      "  2.4951e-01 -1.5735e-01  1.9806e-02 -2.2485e-01  2.6343e-01 -1.9653e-01\n",
      " -2.9053e-01  9.1187e-02 -3.2568e-01  2.5830e-01  2.4986e-03  2.0984e-01\n",
      " -4.1235e-01 -3.1592e-01 -8.3069e-02 -2.7725e-02  2.4390e-01  2.8198e-01\n",
      " -1.1530e-01  1.2549e-01 -1.4514e-01  1.3037e-01 -6.3904e-02 -1.2445e-01\n",
      " -6.8054e-02 -2.8516e-01  2.6538e-01 -1.1475e-01  2.5488e-01  2.6514e-01\n",
      "  5.3320e-01 -1.7114e-01  1.6138e-01 -1.1993e-01  4.9609e-01  3.0225e-01\n",
      "  5.7129e-02 -7.3547e-02 -8.0322e-02  2.5055e-02 -3.0493e-01 -5.7861e-02\n",
      "  4.9780e-01  4.2627e-01  3.6713e-02  1.0596e-01 -7.2266e-02  1.0098e+00\n",
      "  9.6130e-02  1.8213e-01]\n",
      "\n",
      "Output: {\"emotions\": [['anger','sadness'], ['sadness'], ['sadness'], ['sadness'], ['sadness'], ['fear','sadness'], ['fear','sadness'], ['fear','sadness'], ['fear','sadness'], ['sadness']]}\n",
      "\n",
      "\n",
      "EXAMPLE 2\n",
      "\n",
      "Input:\n",
      "[-6.2891e-01  5.4932e-01 -2.1997e-01  1.3672e-01  2.5293e-01 -5.8502e-02\n",
      "  5.3613e-01 -7.7271e-02 -1.0938e-01 -3.0688e-01  2.2290e-01 -3.2166e-02\n",
      "  4.8999e-01 -1.2012e-01 -3.1812e-01  5.7129e-02 -2.6343e-01 -1.2732e-01\n",
      "  3.1128e-01 -3.3008e-01 -4.3188e-01 -2.7612e-01  4.9414e-01  6.1182e-01\n",
      "  1.0022e-01  2.7490e-01  4.2285e-01 -1.0016e-01 -2.2766e-01  3.1396e-01\n",
      " -1.4417e-01 -2.1255e-02 -8.4106e-02 -1.2842e-01  1.2927e-01  1.2781e-01\n",
      "  1.7957e-01  5.4248e-01  3.6240e-03  7.4463e-02  6.6223e-02 -4.7754e-01\n",
      " -8.6609e-02 -4.0381e-01  3.0127e-01  1.7314e+00  1.4734e-01 -8.3984e-02\n",
      " -3.6011e-01 -1.6785e-03  6.8164e-01 -2.3730e-01 -1.9608e-03 -1.0986e-01\n",
      "  1.6614e-01 -9.7229e-02  1.0498e-01 -1.8982e-01 -2.3108e-01  1.2744e-01\n",
      " -5.8740e-01  8.8379e-02  5.2783e-01 -1.3330e-01 -1.8433e-01 -5.1041e-03\n",
      " -4.4189e-02 -1.1322e-01 -4.2114e-01  1.0193e-01 -3.9253e-03  2.4963e-02\n",
      " -2.0691e-01 -2.2449e-01 -1.5526e-02  2.9205e-02 -1.1493e-01 -2.7490e-01\n",
      " -2.2568e-02 -3.2886e-01  1.5076e-01  9.8328e-02 -4.6997e-01  8.3691e-01\n",
      "  1.8042e-01  1.6675e-01 -1.5556e-02  1.9275e-01 -7.1973e-01 -8.5022e-02\n",
      " -1.0669e-01  3.4521e-01 -6.5547e+00  7.1436e-01 -1.5552e-01 -1.0425e-01\n",
      " -2.3376e-01 -3.7140e-02  9.0332e-01 -1.4893e-01  4.2554e-01 -3.0420e-01\n",
      "  9.7351e-02 -8.3923e-02  1.9255e-03 -3.7720e-01 -1.4482e+00 -2.7954e-01\n",
      " -1.3037e-01  1.9241e-02  3.5547e-01  1.4145e-02 -2.7832e-01  6.0638e-02\n",
      " -7.3914e-02  7.2021e-02  3.0225e-01  6.9946e-02  2.9517e-01 -2.0996e-02\n",
      "  1.7542e-01 -1.3696e-01  3.6255e-01  7.0992e-03  6.5002e-02 -3.8501e-01\n",
      "  3.7109e-01  1.4795e-01 -5.3564e-01 -2.0496e-01 -1.2073e-01  3.0835e-01\n",
      "  1.7303e-02  8.0908e-01 -1.7147e-03  1.3954e-02 -1.8604e-01 -2.3145e-01\n",
      " -3.1641e-01  1.0687e-01  4.1504e-02 -1.7151e-01 -4.1333e-01 -6.9153e-02\n",
      " -7.3395e-03  2.0764e-01 -3.2886e-01  2.1765e-01  1.3708e-01  8.6594e-03\n",
      " -5.7471e-01  1.2222e-02 -2.4072e-01 -1.3281e-01 -1.3879e-01 -4.7314e-01\n",
      " -1.3818e-01 -4.8157e-02  2.8247e-01 -2.5659e-01  5.4016e-02 -1.3721e-01\n",
      "  3.2104e-02  4.9219e-01  1.3330e-01  4.6460e-01 -4.9097e-01  6.9824e-02\n",
      " -3.1543e-01 -2.5732e-01 -1.6815e-02  3.8037e-01 -1.4893e-01  1.3562e-01\n",
      "  2.5537e-01 -1.0901e-01 -2.1460e-01 -2.2998e-01 -3.0664e-01  7.5562e-02\n",
      "  7.5928e-01 -1.4502e-01 -4.6826e-01  1.0181e-01  1.7957e-01  1.6455e-01\n",
      "  3.5303e-01 -3.5034e-01 -4.1528e-01 -1.4172e-01  2.2949e-02  3.7964e-01\n",
      " -8.1665e-02 -3.7793e-01 -8.0811e-01 -7.3547e-02  6.0156e-01 -1.7822e-01\n",
      "  1.7847e-01 -3.0811e-01  9.8038e-03  2.9443e-01  1.9312e-01  9.1858e-02\n",
      " -1.1755e-01 -1.2006e-01 -4.4751e-01  5.3802e-02  1.1499e-01 -2.6782e-01\n",
      " -1.5540e-01  2.1069e-01 -5.5145e-02 -3.5181e-01 -3.6841e-01  9.9182e-02\n",
      "  2.3645e-01 -1.7212e-02  8.0762e-01 -2.7393e-01  4.8633e-01 -1.3843e-01\n",
      " -1.3611e-01  2.6123e-01  7.5531e-03  7.4402e-02  2.8955e-01 -9.6817e-03\n",
      " -6.9031e-02  5.3009e-02 -1.3159e-01 -3.4399e-01  5.9375e-01  2.6294e-01\n",
      "  3.2544e-01  7.4512e-01  1.4148e-01 -1.5488e-02  4.0070e-02 -1.2793e-01\n",
      " -5.5371e-01 -5.6519e-02  1.6443e-01  3.9093e-02 -1.4832e-01 -3.3618e-01\n",
      " -2.5757e-01  2.2205e-01 -5.3906e-01  1.6809e-01  3.3545e-01  2.9736e-01\n",
      " -3.8989e-01  2.1942e-02  1.0083e-01  1.6846e-01  2.0789e-01  6.4893e-01\n",
      " -1.8584e+00  4.0088e-01 -1.0910e-02 -3.9697e-01  1.5295e-01 -2.1348e+00\n",
      "  2.2949e-02 -2.8296e-01  2.5195e-01  5.5078e-01 -8.0200e-02 -6.5369e-02\n",
      " -4.0210e-01 -2.5708e-01  3.0444e-01  1.8176e-01  4.4922e-02  4.8065e-02\n",
      "  6.0089e-02  1.9348e-01 -6.7017e-02  2.5024e-01  2.0959e-01 -2.2034e-01\n",
      "  9.3002e-03 -2.0911e-01 -5.5078e-01 -2.9190e-02 -2.5854e-01 -3.7720e-02\n",
      " -1.9333e-02 -1.7651e-01  5.0385e-02 -1.7236e-01  2.4185e-02  7.0117e-01\n",
      " -2.1570e-01  4.0063e-01  7.7441e-01  4.2261e-01  8.3923e-02  6.4514e-02\n",
      " -2.2131e-01 -2.7686e-01 -3.8879e-02  2.2705e-01  4.1840e-02 -6.6016e-01\n",
      "  1.4015e-02  1.7505e-01  5.8496e-01  1.4404e-01  1.3831e-01  6.2451e-01\n",
      "  8.0615e-01  2.9370e-01 -1.4539e-01 -1.6833e-01  3.3911e-01  9.9854e-02\n",
      "  4.8950e-02  2.4939e-01 -1.5491e-01  2.2498e-01 -2.7051e-01 -1.5735e-01\n",
      "  1.3281e-01  5.6335e-02  3.3643e-01 -3.2257e-02 -3.2397e-01 -2.2705e-01\n",
      "  3.2300e-01 -7.1594e-02  3.4766e-01 -1.9055e-01 -3.0685e-02  7.7881e-02\n",
      "  1.1208e-02  3.0838e-02  4.9927e-01  5.3174e-01 -8.1909e-02 -1.9522e-03\n",
      "  2.3560e-01  2.5903e-01  2.3633e-01  3.2739e-01  4.7852e-01  1.5442e-01\n",
      "  1.6138e-01  1.7004e-01  3.4961e-01  3.1174e-02  1.3879e-01 -4.2725e-01\n",
      " -4.2145e-02 -3.0444e-01 -1.3379e-01 -6.0010e-01  2.0349e-01 -7.9041e-02\n",
      "  1.1620e-02  3.0249e-01  2.8931e-01 -1.0706e-01 -7.4072e-01  1.8384e-01\n",
      "  4.9011e-02 -4.7394e-02 -3.0469e-01  7.0496e-02  2.6489e-01  3.5669e-01\n",
      "  2.3315e-01 -3.0127e-01  4.5361e-01  1.5442e-01 -9.7900e-02  1.1792e-01\n",
      "  2.2607e-01  2.1301e-01  7.1411e-02 -4.1309e-01 -1.9617e-01 -9.0637e-02\n",
      "  2.0398e-01  3.0811e-01  3.2104e-01  1.8677e-02 -4.7583e-01  6.6846e-01\n",
      "  3.1030e-01  3.1104e-01  3.7671e-01  1.8335e-01 -4.2310e-01  9.2285e-02\n",
      "  3.5547e-01  1.7310e-01  1.6235e-01  1.2781e-01 -6.9092e-02 -2.1863e-01\n",
      " -7.5928e-01 -7.1436e-01  4.1309e-01 -1.0590e-01  2.3438e-01 -1.4915e-02\n",
      "  4.5947e-01 -4.8730e-01 -4.2505e-01  3.7988e-01 -1.8835e-01  1.6138e-01\n",
      "  3.4546e-01  6.4600e-01 -1.8158e-02 -3.3813e-01 -3.7842e-01 -3.1250e-01\n",
      "  1.6760e-01 -1.4252e-02  2.2363e-01  6.6748e-01 -4.7852e-01  4.1595e-02\n",
      "  4.3976e-02  3.0273e-01  1.7207e+00 -2.4207e-01 -6.9519e-02  3.6792e-01\n",
      " -9.5947e-01 -9.3750e-02  2.9443e-01 -1.7346e-01 -4.8828e-01 -1.8958e-01\n",
      "  4.8682e-01 -2.4854e-01  6.7520e-03  5.6366e-02  3.2501e-02 -3.1714e-01\n",
      " -1.3660e-01  3.3789e-01  1.9360e-01  1.2250e-01  2.8149e-01  3.8525e-01\n",
      " -2.8833e-01 -4.3945e-02 -1.6199e-01  5.3516e-01  3.9825e-02 -1.8250e-01\n",
      " -1.2802e-02  1.7078e-01 -1.7358e-01  7.5722e-04 -2.4109e-02 -2.3047e-01\n",
      "  3.1714e-01 -1.7859e-01 -1.2891e-01 -1.2347e-01  1.8286e-01 -2.2412e-01\n",
      " -3.6426e-01  2.3682e-01  4.2267e-02  7.0215e-01  6.5125e-02  2.4927e-01\n",
      " -3.0908e-01 -7.7734e-01  4.3610e-02  1.3138e-02  3.7207e-01  6.2683e-02\n",
      " -8.3618e-02 -2.7832e-02 -1.3452e-01  5.1074e-01 -9.3155e-03  2.6642e-02\n",
      "  9.2407e-02 -2.1802e-01  3.5083e-01 -2.6685e-01  4.9438e-01 -2.2632e-01\n",
      "  6.9922e-01 -2.2986e-01  6.5674e-01 -1.9775e-01  6.8701e-01  1.9241e-02\n",
      "  1.2042e-01  7.1045e-02 -1.4233e-01 -5.0079e-02 -3.0273e-01  2.6270e-01\n",
      "  4.9365e-01  2.0093e-01 -1.2152e-01  2.8027e-01  7.7637e-02  9.4434e-01\n",
      "  1.5625e-02  1.9250e-01]\n",
      "\n",
      "Output: {\"emotions\": [['surprise', 'joy'], ['sadness'], ['joy'], ['anger','sadness'], ['joy'], ['joy'], ['joy'], ['sadness'], ['anger', 'joy'], ['joy'], ['anger','sadness'], ['joy']]}\n",
      "\n",
      "\n",
      "EXAMPLE 3\n",
      "\n",
      "Input:\n",
      "[-2.9126e-01  3.2959e-01 -2.0679e-01  1.4514e-01  4.4189e-01 -2.9572e-02\n",
      "  2.5952e-01 -3.3130e-01 -2.4219e-01 -2.6062e-02  5.2539e-01  3.1853e-03\n",
      "  6.8750e-01  8.6365e-02  1.2146e-01  6.4514e-02 -2.9144e-02  5.6183e-02\n",
      " -2.9932e-01  3.6499e-02 -3.5132e-01 -1.9543e-01  2.8711e-01  6.8555e-01\n",
      " -3.2397e-01  1.3831e-01  4.7583e-01  7.4524e-02 -1.3806e-01  4.9561e-01\n",
      " -2.6440e-01  8.0566e-02 -3.4409e-03 -1.3525e-01  4.3262e-01  2.4033e-02\n",
      "  2.1069e-01  2.6953e-01  1.1761e-01 -9.0637e-02  1.3770e-01  9.6924e-02\n",
      " -2.5342e-01 -4.4507e-01  2.5317e-01  2.3572e-01  1.2695e-01  1.1932e-01\n",
      " -5.4834e-01  1.5649e-01  6.9727e-01 -2.7466e-01  1.2439e-01 -3.2007e-01\n",
      " -2.5162e-02  1.1917e-02  3.4497e-01 -1.0101e-01 -9.6680e-02  1.8646e-02\n",
      " -9.8340e-01  2.2369e-02  6.0693e-01  7.8491e-02 -1.5125e-01  9.4666e-02\n",
      "  1.7737e-01  5.2734e-01 -6.3721e-01  2.1460e-01  1.6956e-01 -4.8706e-02\n",
      " -2.0129e-01 -2.2156e-01  2.9404e-02 -5.6877e-03 -7.6050e-02 -1.2646e-01\n",
      " -6.1707e-02 -4.2261e-01  3.5400e-02  2.8149e-01 -4.9170e-01  8.2227e-01\n",
      "  4.4556e-03  3.2227e-01  2.7267e-02 -2.8488e-02 -1.2100e+00 -1.9885e-01\n",
      " -1.5503e-01  2.9712e-01 -6.1367e+00  9.0674e-01 -1.7261e-01  2.0935e-01\n",
      " -1.7505e-01 -2.5781e-01  6.3770e-01  2.8442e-01  2.8979e-01 -3.5107e-01\n",
      "  1.4539e-01 -1.8265e-02 -2.8857e-01 -2.0215e-01 -1.8301e+00 -4.4263e-01\n",
      " -2.6001e-01 -2.3117e-02  4.0186e-01 -2.0996e-01 -3.2935e-01 -3.0411e-02\n",
      "  1.1237e-01 -5.6976e-02  3.2251e-01  7.8430e-02  4.1919e-01 -2.9663e-01\n",
      "  1.7737e-01 -2.7051e-01  1.9397e-01  1.7944e-01  2.6904e-01 -4.0869e-01\n",
      "  2.8760e-01  1.6895e-01 -6.5088e-01 -1.9336e-01 -4.0723e-01  2.7124e-01\n",
      " -8.9111e-02  7.7686e-01 -2.0044e-01 -1.5308e-01  6.4392e-02 -5.5908e-02\n",
      " -3.5913e-01  2.4048e-02 -3.3966e-02 -3.5840e-01 -1.6956e-01  1.8875e-02\n",
      " -1.3252e-02  1.0187e-01 -2.6465e-01  4.5605e-01  9.4666e-02  2.1082e-01\n",
      " -1.2683e-01  1.8665e-01 -1.5051e-01  2.4426e-01 -3.5303e-01 -6.7822e-01\n",
      " -9.9060e-02  1.3171e-01 -2.0599e-02 -2.1838e-01 -8.0566e-02 -6.8237e-02\n",
      "  1.6113e-01  3.4741e-01  8.1360e-02  2.2913e-01 -1.8384e-01  7.4524e-02\n",
      " -2.0972e-01 -6.0742e-01  2.3303e-01  6.7322e-02 -3.0182e-02  1.3000e-01\n",
      "  1.4343e-01 -5.1123e-01  2.1191e-01 -2.9556e-02  2.6880e-01 -6.2988e-02\n",
      "  7.5537e-01 -2.8052e-01 -5.1611e-01  6.1890e-02  2.9834e-01  2.4750e-02\n",
      "  4.0308e-01 -3.4351e-01 -1.4319e-01  2.1683e-02 -9.4910e-02  3.5864e-01\n",
      "  2.4841e-01 -1.6663e-01 -6.2744e-01 -2.7856e-01  4.3188e-01 -2.1692e-01\n",
      "  1.2354e-01 -4.5972e-01 -9.1553e-02  7.1472e-02  4.0558e-02  3.1030e-01\n",
      "  1.7432e-01  1.0358e-01 -3.2324e-01 -2.0123e-04  2.5562e-01 -2.8174e-01\n",
      " -2.3718e-01  2.2412e-01 -3.4497e-01 -3.7061e-01  8.2886e-02  8.9172e-02\n",
      "  1.6797e-01 -3.1616e-01  2.7368e-01 -1.3586e-01  1.7200e-01  6.9141e-01\n",
      " -1.4893e-01  3.1494e-01  1.4417e-01 -1.1285e-01  3.0054e-01  3.2886e-01\n",
      "  4.2175e-02 -9.1736e-02 -2.1667e-01 -4.5312e-01  4.7339e-01  8.0017e-02\n",
      "  1.2646e-01  3.9697e-01 -3.4155e-01 -3.1161e-04  1.9928e-02 -1.1987e-01\n",
      " -5.3271e-01 -3.8184e-01  4.1699e-01 -2.7466e-01  2.4582e-02 -8.3887e-01\n",
      " -2.9297e-02  1.1176e-01 -5.5371e-01  2.9248e-01  3.9941e-01  2.8442e-01\n",
      " -1.3214e-02 -1.5063e-01  4.6356e-02  9.5093e-02  3.4009e-01  5.3369e-01\n",
      " -2.1211e+00  2.6367e-01  1.1066e-01 -3.5425e-01 -4.1351e-02 -2.0117e+00\n",
      "  2.5928e-01 -2.9053e-02  1.8787e-01  3.9771e-01 -3.4546e-02  1.8628e-01\n",
      " -3.9136e-01 -2.2864e-01  1.5991e-01  5.9753e-02  9.4421e-02  1.6968e-02\n",
      " -2.3291e-01  6.7627e-02 -1.3977e-01  1.8921e-02  2.6758e-01 -4.6313e-01\n",
      " -4.5967e-03 -2.7271e-01 -4.1528e-01  3.5254e-01 -5.2295e-01 -5.7281e-02\n",
      "  4.9774e-02 -2.1936e-01  1.0400e-01 -3.1714e-01  5.7098e-02  6.6504e-01\n",
      " -2.8882e-01  2.6270e-01  7.6904e-01  3.0176e-01 -2.6871e-02  1.0400e-01\n",
      " -2.4426e-01 -1.4856e-01 -2.9102e-01  1.9421e-01 -9.2590e-02 -4.6875e-01\n",
      " -2.3584e-01 -8.2703e-02  6.5283e-01  3.1152e-01  2.5177e-02  6.3574e-01\n",
      "  7.7246e-01  2.6367e-01 -1.9653e-01 -2.6343e-01  2.1643e-01  8.8745e-02\n",
      " -1.1267e-01  2.0715e-01 -2.9785e-01 -1.4172e-01 -3.4912e-01 -3.7323e-02\n",
      "  1.4136e-01 -1.0895e-01  4.4409e-01 -2.3315e-02 -4.5850e-01 -4.0601e-01\n",
      "  1.1670e-01  9.1980e-02  4.0625e-01 -8.7433e-03 -2.5049e-01  2.8095e-03\n",
      " -9.4727e-02 -1.9836e-01  3.7549e-01  3.6963e-01 -1.2878e-01  2.5391e-01\n",
      "  4.4189e-02  9.3994e-02  2.5415e-01  2.0312e-01  4.1357e-01  1.1383e-01\n",
      "  2.6587e-01  2.7145e-02  2.3376e-01  1.1177e-03  1.5991e-02 -1.8091e-01\n",
      " -1.2891e-01 -1.3588e-02 -3.3179e-01 -1.5039e-01  5.3772e-02 -1.1743e-01\n",
      " -9.8633e-02 -9.4727e-02  5.6787e-01  2.4643e-02 -3.4497e-01  2.4460e-02\n",
      "  4.3457e-02  3.6133e-01 -5.9717e-01 -2.0715e-01  2.4704e-02  3.0078e-01\n",
      "  4.1534e-02 -1.8848e-01  2.8882e-01  3.8013e-01  1.0809e-01  3.7549e-01\n",
      "  4.9146e-01  3.5736e-02 -2.1790e-01 -5.9570e-01 -2.9688e-01 -3.0713e-01\n",
      "  5.1079e-03  3.1982e-01  1.7859e-01  5.0879e-01 -1.3940e-01  9.5020e-01\n",
      "  4.3066e-01  5.0293e-01  7.0459e-01  1.9058e-02 -6.0693e-01  2.1582e-01\n",
      "  3.0103e-01  1.4709e-01  1.5796e-01 -8.9569e-03  3.3783e-02 -2.1252e-01\n",
      " -9.4238e-01 -6.2988e-01  5.0635e-01 -2.0593e-01  6.7078e-02 -2.7441e-01\n",
      "  3.0713e-01 -4.1943e-01 -3.5864e-01  4.2480e-01 -1.8298e-01 -2.8125e-01\n",
      "  5.3467e-01  6.6309e-01  1.3782e-01 -4.9988e-02 -4.1333e-01 -3.5718e-01\n",
      "  3.3374e-01  3.7140e-02  1.6882e-01  7.0557e-01 -5.7520e-01 -1.2036e-01\n",
      " -1.0078e-02  1.2970e-02  1.8477e+00 -3.2031e-01 -3.5498e-01  2.8687e-01\n",
      " -1.8860e-01 -1.4880e-01  4.2261e-01 -1.9019e-01 -7.3877e-01 -1.2354e-01\n",
      "  5.2393e-01 -1.5662e-01  2.3987e-01 -1.9455e-02  3.5461e-02 -1.2213e-01\n",
      " -1.0321e-01 -7.7576e-02  2.1460e-01  3.9124e-02  3.1030e-01  5.6543e-01\n",
      " -2.4023e-01 -4.0680e-02  4.4403e-02  2.6562e-01  9.4604e-02 -1.3418e-03\n",
      "  1.9128e-01  2.1436e-01  2.8247e-01  2.0789e-01  7.7087e-02 -1.2378e-01\n",
      "  3.7183e-01  4.6143e-02 -1.4258e-01 -2.1191e-01  6.0986e-01 -1.8457e-01\n",
      " -4.3115e-01 -1.9409e-02 -2.9834e-01  1.5051e-01  2.2083e-01  2.1277e-01\n",
      " -5.5469e-01 -4.3604e-01 -1.6406e-01  2.0007e-01  2.5488e-01  1.2915e-01\n",
      " -2.0630e-01 -6.2714e-03 -1.3831e-01  1.2561e-01 -2.7490e-01 -1.3574e-01\n",
      " -1.3013e-01 -2.8711e-01  4.0649e-01 -1.8713e-01  3.1299e-01 -2.2797e-02\n",
      "  1.7639e-01 -4.1870e-01  3.8599e-01 -2.8030e-02  7.2705e-01 -3.0174e-03\n",
      " -9.3567e-02 -8.5144e-02 -3.0005e-01  6.6772e-02 -2.6025e-01 -8.3008e-02\n",
      "  3.0396e-01  5.3711e-01 -1.3257e-01  2.8955e-01 -2.7148e-01  1.0469e+00\n",
      " -8.4045e-02  1.3708e-01]\n",
      "\n",
      "Output: {\"emotions\": [['anger'], ['anger'], ['anger'], ['anger'], ['anger'], ['anger'], ['anger'], ['anger'], ['anger'], ['anger'], ['fear']]}\n",
      "\n",
      "\n",
      "\n",
      "Input for classification:\n",
      "[-5.9668e-01  2.5415e-01 -2.9224e-01  1.3953e-01  3.8965e-01  1.3293e-01\n",
      "  3.0420e-01 -3.7305e-01 -1.8738e-01 -1.6895e-01  3.3228e-01  1.2152e-01\n",
      "  5.4541e-01  1.4490e-01 -3.9453e-01  1.5710e-01 -3.8159e-01 -1.1121e-01\n",
      " -3.0777e-02 -2.9282e-02 -8.6865e-01  3.9551e-02  5.3174e-01  6.6602e-01\n",
      " -3.4180e-02  5.5939e-02  6.6797e-01  7.9407e-02 -6.0425e-02  3.6743e-01\n",
      " -5.6854e-02 -3.0420e-01 -1.3623e-01  3.2013e-02  1.4746e-01  6.3210e-03\n",
      "  1.8591e-01  5.2197e-01  1.7792e-02 -2.7148e-01  3.3398e-01 -1.2537e-01\n",
      " -3.2788e-01 -3.1323e-01  5.3223e-01  9.4873e-01  5.7227e-01  2.4963e-01\n",
      " -1.2360e-01  3.3545e-01  4.0863e-02 -1.6174e-01  3.4546e-01 -3.7231e-01\n",
      " -1.3818e-01  1.3110e-01  4.0283e-01  1.4136e-01 -2.2827e-01  2.9492e-01\n",
      " -4.9487e-01  3.1006e-01  3.5083e-01 -1.6040e-01 -4.2603e-01 -3.3691e-02\n",
      " -1.9409e-01  7.3193e-01 -2.0325e-01  1.1188e-01  5.5634e-02  7.2449e-02\n",
      " -1.5149e-01 -2.7344e-01 -3.4912e-02 -1.0193e-01  6.1859e-02 -1.9336e-01\n",
      " -4.5013e-02 -2.7466e-01 -7.1259e-03  2.0276e-01 -5.1465e-01  6.9141e-01\n",
      "  1.6907e-01  4.1943e-01  1.3440e-01  8.4290e-02 -8.6963e-01 -5.8643e-01\n",
      " -2.8534e-02  3.1470e-01 -6.2695e+00  7.6416e-01 -3.7872e-02  2.3462e-01\n",
      " -1.5027e-01 -5.2686e-01  8.0518e-01  8.6914e-02  5.9326e-01 -5.2881e-01\n",
      "  5.7556e-02  1.8445e-01 -5.3760e-01  7.0923e-02 -1.1680e+00 -2.2119e-01\n",
      " -4.3311e-01  1.6724e-01  2.3547e-01 -9.3933e-02 -2.6099e-01 -2.8793e-02\n",
      "  1.7834e-01 -5.3040e-02  3.7769e-01  2.4829e-01  4.8608e-01 -1.3831e-01\n",
      "  1.9580e-01 -3.0347e-01 -6.0059e-02  6.8665e-02  9.1980e-02 -4.3018e-01\n",
      "  2.8955e-01  2.3840e-01 -3.4424e-01  3.3966e-02 -1.3916e-01  2.3279e-01\n",
      "  2.8052e-01  7.7881e-01 -1.8567e-01 -5.2582e-02 -6.8555e-01 -4.1821e-01\n",
      " -3.1323e-01  1.0681e-01 -1.3000e-01 -2.6343e-01 -8.0994e-02  2.0462e-02\n",
      "  1.0944e-01  2.7466e-01 -1.3574e-01  3.6890e-01  2.5610e-01 -1.1224e-01\n",
      " -3.4961e-01 -5.4901e-02 -5.2551e-02 -7.7881e-02 -3.6304e-01 -5.4199e-01\n",
      "  7.1228e-02 -8.8501e-02  3.4760e-02 -4.0479e-01  3.8422e-02 -1.5450e-03\n",
      "  2.8613e-01  4.6826e-01  2.0862e-01  2.3352e-01 -5.1562e-01  1.3635e-01\n",
      " -2.0728e-01 -4.0723e-01  2.0557e-01  1.4880e-01 -2.4316e-01  1.4893e-01\n",
      "  4.5264e-01  4.2381e-03 -3.6450e-01 -9.6252e-02  3.5278e-02  1.3953e-01\n",
      "  5.9473e-01 -2.2876e-01 -4.1455e-01  7.2632e-02  2.0105e-01  1.5564e-01\n",
      "  5.4639e-01 -2.1130e-01 -1.3550e-01 -6.2561e-03  1.0754e-01  3.0981e-01\n",
      "  2.1106e-01 -1.6064e-01 -8.9697e-01 -2.1741e-01  1.4417e-01 -2.6758e-01\n",
      "  1.6577e-01 -2.6929e-01 -7.9773e-02  2.9175e-01 -2.4207e-01  1.6333e-01\n",
      "  4.0332e-01 -2.8101e-01 -3.7451e-01 -8.3984e-02  3.6865e-01 -2.4500e-01\n",
      " -1.5320e-01  3.0469e-01 -1.1682e-01 -2.4915e-01 -1.4368e-01 -4.6753e-02\n",
      "  2.6855e-01  2.0850e-01  5.8398e-01 -1.5308e-01  3.9551e-01  2.1851e-01\n",
      " -9.5215e-02  6.2744e-01  1.0858e-01 -1.0913e-01  5.2588e-01  2.4695e-01\n",
      " -1.5930e-01  2.2415e-02  2.3682e-01 -4.8022e-01  3.9160e-01  1.2378e-01\n",
      "  1.4136e-01  2.6709e-01 -2.0447e-02  6.7902e-03 -8.7219e-02 -9.0103e-03\n",
      " -5.6445e-01 -2.5610e-01  5.1953e-01 -2.9102e-01 -2.4121e-01 -2.7515e-01\n",
      " -1.7139e-01  1.4050e-01 -4.3604e-01  2.3230e-01  3.8501e-01  1.3306e-01\n",
      " -3.2129e-01 -2.5122e-01  1.1292e-01  1.4734e-01 -1.1467e-02  3.9038e-01\n",
      " -2.6895e+00  2.4658e-01 -1.3184e-01 -1.7676e-01  2.0544e-01 -1.9170e+00\n",
      "  2.0508e-02 -2.1021e-01  6.4026e-02  4.8999e-01 -1.0696e-02  3.6407e-02\n",
      " -3.9722e-01 -2.6343e-01 -8.1238e-02  1.9495e-01 -2.7100e-01 -4.4922e-02\n",
      " -1.7493e-01  2.1106e-01 -2.5848e-02 -1.3574e-01  3.3472e-01 -3.4839e-01\n",
      " -2.6904e-01 -3.1885e-01 -3.6255e-01  2.2681e-01 -4.0527e-01  4.3365e-02\n",
      "  3.2275e-01 -3.7109e-01 -2.9938e-02 -1.7175e-01  1.9678e-01  6.9141e-01\n",
      " -2.6758e-01  2.0239e-01  4.9023e-01  2.9248e-01 -1.0785e-01 -1.1902e-01\n",
      " -3.3398e-01 -2.5464e-01 -1.0773e-01  3.3960e-01 -2.3169e-01 -2.7856e-01\n",
      " -2.3718e-01 -6.3782e-02  5.4639e-01  1.9604e-01 -7.3547e-02  4.2773e-01\n",
      "  7.7539e-01  1.2335e-01  7.3891e-03 -3.6206e-01  1.9971e-01  2.3645e-01\n",
      " -1.2073e-01  4.9292e-01  2.9297e-02 -2.1149e-02 -3.3203e-01  1.0803e-01\n",
      "  2.8784e-01  1.3843e-01  2.2925e-01 -2.0520e-01 -1.9324e-01 -3.6230e-01\n",
      "  2.0508e-01 -1.1676e-01  4.9072e-01  3.9276e-02 -3.5718e-01  1.6223e-01\n",
      "  3.7048e-02  1.4307e-01  6.5039e-01  3.5059e-01 -1.2192e-02  1.3220e-01\n",
      "  3.5034e-01  2.0642e-01  6.6223e-02  8.4045e-02  7.2510e-01  2.1069e-01\n",
      "  1.3232e-01  1.9943e-02 -2.5708e-01 -1.8628e-01  1.7273e-01 -5.2490e-01\n",
      " -1.7749e-01 -2.1606e-01 -9.6985e-02  1.7871e-01 -6.3171e-02  6.8787e-02\n",
      " -2.7588e-01  2.1436e-01  3.5547e-01  4.7058e-02 -6.0449e-01 -3.1982e-02\n",
      " -3.4637e-02  2.4878e-01 -2.1252e-01 -5.0598e-02  9.7717e-02  5.4102e-01\n",
      "  1.7603e-01 -3.6792e-01  5.1562e-01 -1.3916e-01 -9.8572e-02  1.5137e-01\n",
      "  6.9885e-02  2.8979e-01 -1.2708e-01 -1.1260e+00 -1.2164e-01 -1.3562e-01\n",
      "  1.1578e-01  4.7729e-01  1.0468e-01  3.9648e-01 -1.3354e-01  2.7002e-01\n",
      "  4.0234e-01  3.7720e-01  5.3418e-01 -2.2461e-02 -6.3672e-01  2.2754e-01\n",
      "  2.3315e-01  1.8396e-01  1.9861e-01 -8.3862e-02  4.7531e-03 -1.2720e-01\n",
      " -6.4893e-01 -6.7969e-01  4.9878e-01 -2.4536e-01  2.8979e-01 -5.6824e-02\n",
      "  5.9180e-01 -4.6729e-01 -4.5459e-01  4.3091e-01 -1.8173e-02 -2.0459e-01\n",
      "  1.1023e-01  4.1919e-01 -1.4563e-01  2.8870e-02 -4.2603e-01 -5.5420e-01\n",
      " -6.3782e-02 -1.5488e-02 -1.4294e-01  1.8982e-01 -3.8965e-01  1.6272e-01\n",
      " -7.2693e-02  1.4429e-01  1.3389e+00 -2.5122e-01 -4.5435e-01  3.9600e-01\n",
      " -2.8809e-01 -2.8732e-02  1.8799e-01 -1.8018e-01 -6.7334e-01 -2.9346e-01\n",
      "  5.1611e-01 -1.6479e-01  1.2585e-01 -4.4830e-02 -5.4352e-02 -1.0327e-01\n",
      "  2.1057e-02  7.1716e-02  4.8511e-01  1.2048e-01  1.8860e-01  3.5425e-01\n",
      "  4.9866e-02  1.8689e-01  8.7219e-02  1.6382e-01  3.0060e-02  2.8610e-02\n",
      " -1.4351e-02 -1.0492e-01 -3.8116e-02  1.4709e-01  9.5215e-02 -2.8931e-01\n",
      "  3.3667e-01 -1.4197e-01 -4.4006e-02  1.3843e-01  2.0850e-01 -2.8320e-02\n",
      " -2.2534e-01  3.1763e-01  7.7782e-03  3.4619e-01  2.0966e-02  1.7188e-01\n",
      " -2.6978e-01 -3.2764e-01 -1.9373e-01  3.1445e-01  2.0276e-01  7.4646e-02\n",
      " -2.3145e-01  1.1066e-01 -8.6853e-02  2.8540e-01 -1.0437e-01 -1.6382e-01\n",
      " -3.7354e-02 -1.8298e-01  1.3171e-01 -3.3423e-01  3.1812e-01 -2.5806e-01\n",
      "  6.8457e-01  7.5928e-02  3.4277e-01  3.1616e-02  8.1494e-01 -2.3083e-01\n",
      "  6.5857e-02 -1.2402e-01 -7.1472e-02  1.0181e-01 -2.9517e-01  1.2622e-01\n",
      "  2.0557e-01  3.6890e-01  1.3940e-01  3.7109e-01  5.6305e-03  1.1689e+00\n",
      " -1.2830e-01  4.1553e-01]\n",
      "Identify applicable emotions from the following classes: \"anger\", \"disgust\", \"fear\", \"sadness\", \"surprise\", \"joy\", \"neutral\"assistant\n",
      "\n",
      "Output:assistant\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(inputs.input_ids[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 8\n",
    "\n",
    "input_ids_batches = batch_tensor(inputs['input_ids'], BATCH_SIZE) # type: ignore\n",
    "attention_mask_batches = batch_tensor(inputs['attention_mask'], BATCH_SIZE) # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(128256, 4096, padding_idx=128004)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "          (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "          (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): LlamaExtendedRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "          (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "          (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "        (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "    (rotary_emb): LlamaRotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=128256, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FastLanguageModel.for_inference(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [37:11<00:00, 111.59s/it]\n"
     ]
    }
   ],
   "source": [
    "generated_outputs = []\n",
    "\n",
    "for i, (input_ids_batch, attention_mask_batch) in tqdm(enumerate(zip(input_ids_batches, attention_mask_batches)), total=len(input_ids_batches)):\n",
    "    \n",
    "    #print(f\"\\n ***** Processing batch {i + 1} *****\\n\")\n",
    "    \n",
    "    if torch.any(torch.isnan(input_ids_batch)) or torch.any(torch.isinf(input_ids_batch)): # type: ignore\n",
    "        print(\"Invalid input_ids detected\")\n",
    "\n",
    "    if torch.any(torch.isnan(attention_mask_batch)) or torch.any(torch.isinf(attention_mask_batch)): # type: ignore\n",
    "        print(\"Invalid attention_mask detected\")\n",
    "\n",
    "    \n",
    "    inputs = {\n",
    "        'input_ids': input_ids_batch.to(model.device), # type: ignore\n",
    "        'attention_mask': attention_mask_batch.to(model.device) # type: ignore\n",
    "    }\n",
    "\n",
    "    outputs = model.generate(\n",
    "    **inputs,\n",
    "    max_new_tokens=512,\n",
    "    pad_token_id=tokenizer.eos_token_id,\n",
    "    #eos_token_id=terminators,\n",
    "    do_sample=True,\n",
    "    num_beams=1,\n",
    "    temperature=0.7,\n",
    "    top_p=1.0,\n",
    "    )\n",
    "    \n",
    "    for output in outputs:\n",
    "        generated_outputs.append(tokenizer.decode(output[inputs['input_ids'].shape[1]:], skip_special_tokens=True))\n",
    "    \n",
    "    \n",
    "    #generated_outputs.append(outputs)\n",
    "    \n",
    "    #generated_outputs.append(inference_tokenizer.decode(outputs[inputs['input_ids'].shape[1]:]))\n",
    "    #generated_outputs.append(tokenizer.decode(outputs[0][inputs['input_ids'].shape[1]:], skip_special_tokens=True))\n",
    "    #\n",
    "    # generated_outputs.extend(tokenizer.batch_decode(outputs[0][inputs['input_ids'].shape[1]:], skip_special_tokens=True))\n",
    "    #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(generated_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The provided input arrays are classified into the following emotions:\\n\\n```python\\nimport numpy as np\\n\\n# input arrays\\narr1 = np.array([\\n    [-5.4150e-01,  6.0205e-01, -1.9104e-01,  3.3179e-01,  5.3516e-01,  1.7969e-01,\\n     2.0569e-01, -1.7383e-01, -1.8420e-01, -3.1543e-01,  8.6133e-01,  6.3293e-02,\\n     6.4062e-01,  3.1708e-02, -1.3843e-01,  3.5132e-01, -4.3188e-01, -2.2583e-02,\\n    -1.8347e-01, -1.3196e-01, -9.3555e-01, -8.9233e-02,  4.2236e-01,  6.5674e-01,\\n    -6.9336e-02, -5.6671e-02,  6.3867e-01,  1.6675e-01, -7.3975e-02,  1.1993e-01,\\n    -6.0211e-02,  1.3538e-01, -1.6760e-01, -2.5366e-01,  2.2986e-01, -2.7115e-02,\\n     1.9055e-01,  4.3750e-01, -2.1378e-02, -4.1821e-01,  2.4060e-01, -2.2229e-01,\\n    -2.2473e-01, -4.7168e-01,  5.2979e-01,  2.2302e-01, -3.2349e-03,  2.1338e-01],\\n   dtype=np.float64\\n)\\n\\narr2 = np.array([\\n    [-6.2891e-01,',\n",
       " '{\"emotions\": [[\\'anger\\',\\'sadness\\'], [\\'anger\\', \\'disgust\\'], [\\'anger\\', \\'fear\\',\\'surprise\\'], [\\'sadness\\'], [\\'fear\\',\\'sadness\\',\\'surprise\\'], [\\'surprise\\'], [\\'sadness\\'], [\\'fear\\',\\'sadness\\']]}\\n\\nThis output indicates the emotions identified in the input data. The emotions are represented as lists of strings, where each string corresponds to an emotion class: \"anger\", \"disgust\", \"fear\", \"sadness\", \"surprise\", \"joy\", or \"neutral\".',\n",
       " \"To classify the emotions from the given input data, we'll use the following classification model:\\n\\n```python\\nimport numpy as np\\nfrom sklearn.preprocessing import StandardScaler\\nfrom sklearn.ensemble import RandomForestClassifier\\nfrom sklearn.model_selection import train_test_split\\n\\n# Define the emotions and corresponding labels\\nemotions = {\\n    'anger': ['anger'],\\n    'disgust': ['disgust'],\\n    'fear': ['fear'],\\n   'sadness': ['sadness'],\\n   'surprise': ['surprise'],\\n    'joy': ['joy'],\\n    'neutral': ['neutral']\\n}\\n\\n# Define the input data\\nX = np.array([\\n    [ 1.4328e-02,  2.5049e-01, -3.0615e-01, -4.5105e-02, -1.9360e-01,  1.0632e-01, \\n     4.9683e-01, -3.9941e-01, -3.5229e-01, -2.8540e-01,  4.5264e-01,  1.8225e-01],\\n    [ 6.9580e-01, -8.3923e-02,  1.9958e-01, -1.6821e-01, -6.3232e-02,  1.6199e-01, \\n     -6.0059e-02,  8.8928e-02, -8.3618e-02, -2.8394e-01,  1.5869e-01,  5.2148e-01],\\n    # More data points here...\\n])\\n\\n# Define the output data\\ny = np.array([\\n    ['anger', 'fear'],\\n    ['anger'],\\n    # More emotions here...\\n])\\n\\n# Convert the emotions from string to list\\ny_list = []\\nfor emotion in y:\\n    y_list.append(emotions[emotion[0]])\\n\\n# Define the model\\nmodel = RandomForestClassifier(n_estimators=100)\\n\\n# Train the model\\nmodel.fit(X, y_list)\\n\\n# Define the function to classify emotions\\ndef classify_emotions(input_data):\\n    return model.predict(input_data.reshape(1, -1))\\n\\n# Classify the input data\\ninput_data = np.array([ 1.4328e-02,  2\",\n",
       " \"To solve this problem, we will use a pre-trained emotion classification model. We will use the `keras` library to load the model and the `numpy` library to load the input data. The model is trained on the Emotion Recognition In The Wild (ERIW) dataset and has an accuracy of around 85%.\\n\\n```python\\nimport numpy as np\\nfrom keras.models import load_model\\n\\n# Load the model\\nmodel = load_model('emotion_classification.h5')\\n\\n# Define the input data\\ninput_data = np.array([[0.01, 0.95, -0.18, 0.08, 0.01, 0.05, 0.12, -0.33, -0.12, 0.62, -0.25, 0.11, 0.89, 0.07, -0.02, -0.04, -0.29, -0.38, 0.01, -0.02, -0.29, 0.12, 0.19, 0.03, -0.15, -0.22, -0.25, -0.03, 0.08, 0.18, 0.06, 0.03, 0.04, 0.02, 0.01, 0.01, 0.01]])\\n\\n# Define the input shape\\ninput_shape = (1, 40)\\n\\n# Define the output classes\\nclasses = ['anger', 'disgust', 'fear','sadness','surprise', 'joy', 'neutral']\\n\\n# Make predictions\\npredictions = model.predict(input_data.reshape(1, input_shape[1]))\\n\\n# Get the indices of the top 3 predictions\\ntop_3_indices = np.argsort(predictions[0])[-3:]\\n\\n# Get the corresponding emotions\\nemotions = [classes[i] for i in top_3_indices]\\n\\nprint(emotions)\\n```\\n\\nOutput: ['anger', 'disgust','sadness']\\n\\nNote that the output may vary depending on the input data and the model's predictions.\",\n",
       " 'To solve this problem, we need to identify the emotions present in the given input arrays. We can use a pre-trained neural network model or a machine learning algorithm to classify the emotions.\\n\\nHere\\'s an example of how we can classify the emotions using a pre-trained model:\\n\\n```python\\nimport numpy as np\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.preprocessing import StandardScaler\\nfrom sklearn.neural_network import MLPClassifier\\nfrom sklearn.metrics import accuracy_score\\n\\n# Load the pre-trained model\\nmodel = MLPClassifier(hidden_layer_sizes=(100,), max_iter=1000, learning_rate_init=0.01)\\nmodel.fit(X_train, y_train)\\n\\n# Make predictions on the test data\\ny_pred = model.predict(X_test)\\n\\n# Evaluate the model\\naccuracy = accuracy_score(y_test, y_pred)\\nprint(\"Accuracy:\", accuracy)\\n```\\n\\nHowever, since we don\\'t have the training data (X_train, y_train, X_test, y_test), we can\\'t directly use the above code.\\n\\nInstead, we can use a simple neural network model or a support vector machine (SVM) to classify the emotions. \\n\\nHere is a simple example using Keras:\\n\\n```python\\nimport numpy as np\\nfrom keras.models import Sequential\\nfrom keras.layers import Dense\\nfrom keras.utils import to_categorical\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.preprocessing import StandardScaler\\n\\n# Define the emotions\\nemotions = [\"anger\", \"disgust\", \"fear\", \"sadness\", \"surprise\", \"joy\", \"neutral\"]\\n\\n# Define the input data\\nX = np.array([\\n    [-2.0056e-01, 3.5596e-01, -1.5027e-01, 1.3147e-01, 3.4180e-01, -2.7283e-02],\\n    [-2.8687e-01, 3.8135e-01, -2.0044e-01, 3.7817e-01, 4.4751e-01, -2.1179e-01],\\n    # Add more input data\\n])\\n\\n# Define the labels\\ny = np.array([0, 1])  # Labels for the above input data\\n\\n# Convert the labels to categorical\\ny = to_categorical(y)\\n\\n# Split the data into training and testing sets\\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size',\n",
       " 'The given input is not a valid emotion classification problem. The input is a list of floating point numbers, but it does not correspond to any of the provided examples. \\n\\nHowever, I can guide you through the process of solving the emotion classification problem. \\n\\nAssuming the input is a list of features, and the task is to classify the emotions in the output.\\n\\n```python\\nimport numpy as np\\nfrom sklearn.preprocessing import StandardScaler\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.linear_model import LogisticRegression\\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\\n\\n# Define the input and output features\\nX = np.array([\\n    [-4.3335e-01,  5.9131e-01,  1.8042e-01,  4.0436e-02,  3.1006e-01,  5.0720e-02],\\n    [-2.7563e-01,  2.0312e-01, -1.8958e-01,  2.4731e-01,  2.7344e-01, -2.5070e-02],\\n    [-3.4009e-01,  2.0911e-01, -5.0293e-02,  1.7920e-01,  2.9688e-01,  1.5251e-02],\\n    # Add more inputs here...\\n])\\n\\ny = np.array([\\n    [\"anger\", \"fear\", \"surprise\", \"anger\", \"joy\", \"joy\", \"joy\", \"joy\", \"joy\", \"joy\"],\\n    [\"fear\", \"sadness\", \"fear\", \"fear\", \"joy\", \"fear\", \"surprise\", \"fear\", \"anger\", \"anger\"],\\n    [\"anger\", \"fear\", \"anger\", \"fear\", \"surprise\", \"anger\", \"fear\", \"surprise\", \"anger\", \"surprise\"],\\n    # Add more outputs here...\\n])\\n\\n# Define the emotion classes\\nemotion_classes = [\"anger\", \"disgust\", \"fear\", \"sadness\", \"surprise\", \"joy\", \"neutral\"]\\n\\n# Convert the output to numerical labels\\ny_labels = np.array([emotion_classes.index(emotion) for emotion in y.flatten()])\\n\\n# Standardize the input features\\nscaler = StandardScaler()\\n',\n",
       " 'To determine the applicable emotions for the input, I will use a pre-trained emotion classification model. Here is the output:\\n\\n{\"emotions\": [[\\'anger\\', \\'fear\\'], [\\'joy\\'], [\\'fear\\',\\'surprise\\'], [\\'joy\\'], [\\'surprise\\', \\'joy\\'], [\\'surprise\\'], [\\'joy\\'], [\\'joy\\'], [\\'anger\\', \\'disgust\\'], [\\'anger\\', \\'disgust\\']]}\\n\\nThis output indicates the most likely emotions associated with the input data. However, please note that this is a machine learning model and the accuracy may vary depending on the quality and relevance of the training data.',\n",
       " 'To identify the applicable emotions from the given classes, we need to train a machine learning model on a dataset that includes emotional expressions and their corresponding emotions. Here, I\\'ll use a pre-trained model for simplicity.\\n\\n```python\\nimport numpy as np\\nfrom sklearn.preprocessing import StandardScaler\\nfrom sklearn.decomposition import PCA\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.metrics import accuracy_score\\nfrom sklearn.ensemble import RandomForestClassifier\\nfrom sklearn.datasets import load_emotions\\n\\n# Load the dataset\\nemotions_data = load_emotions()\\n\\n# Define the features and target\\nX = emotions_data.data\\ny = emotions_data.target\\n\\n# Scale the features using StandardScaler\\nscaler = StandardScaler()\\nX_scaled = scaler.fit_transform(X)\\n\\n# Apply PCA to reduce the dimensionality\\npca = PCA(n_components=0.95, random_state=42)\\nX_pca = pca.fit_transform(X_scaled)\\n\\n# Split the data into training and testing sets\\nX_train, X_test, y_train, y_test = train_test_split(X_pca, y, test_size=0.2, random_state=42)\\n\\n# Train a Random Forest Classifier\\nrfc = RandomForestClassifier(n_estimators=100, random_state=42)\\nrfc.fit(X_train, y_train)\\n\\n# Make predictions on the testing set\\ny_pred = rfc.predict(X_test)\\n\\n# Evaluate the model\\'s performance\\nprint(\"Accuracy:\", accuracy_score(y_test, y_pred))\\n\\n# Identify applicable emotions for the input\\ninput_features = np.array([-4.4727e-01, 3.9136e-01, -1.1005e-01, 2.4707e-01, -1.3489e-01, -6.0944e-02])\\n\\n# Scale the input features\\ninput_scaled = scaler.transform(input_features.reshape(1, -1))\\n\\n# Apply PCA to the input features\\ninput_pca = pca.transform(input_scaled)\\n\\n# Predict the emotions for the input\\nprediction = rfc.predict(input_pca)\\n\\n# Map the predicted emotions to their corresponding classes\\nemotion_classes = [\"anger\", \"disgust\", \"fear\", \"sadness\", \"surprise\", \"joy\", \"neutral\"]\\npredicted_emotions = [emotion_classes[i] for i in prediction[0]]\\n\\nprint(\"Predicted Emotions:\", predicted_emotions)\\n```\\n\\nPlease note that the accuracy of the model may vary based on the specific dataset and model used. In this example, we\\'re using a pre',\n",
       " '{\"emotions\": [[\\'neutral\\'], [\\'joy\\'], [\\'surprise\\'], [\\'anger\\',\\'surprise\\'], [\\'neutral\\'], [\\'surprise\\'], [\\'anger\\',\\'surprise\\'], [\\'anger\\'], [\\'anger\\',\\'sadness\\',\\'surprise\\']]}\\n\\nNote: The output is based on the provided input data and the model\\'s predictions. The actual output may vary depending on the specific implementation and the model\\'s performance.',\n",
       " \"To classify the input, we need to use a classification model that is trained on the data provided in the examples. The model should be able to predict the emotions present in the input based on its features.\\n\\nThe input provided is a feature vector of size 46, where each feature is a continuous value between -1 and 1.\\n\\nWe can use a decision tree or a random forest classifier to classify the input. However, since the examples provided are not real data, we will assume that the model is trained on a dataset that includes the features and labels used in the examples.\\n\\nHere is the code in Python that uses scikit-learn to load the decision tree classifier and use it to classify the input:\\n\\n```python\\nimport pandas as pd\\nfrom sklearn.tree import DecisionTreeClassifier\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.metrics import accuracy_score\\n\\n# Load the data\\ndf = pd.DataFrame({\\n    'features': [\\n        [-5.7227e-01, 4.4727e-01, -2.5220e-01, 1.1792e-01, 8.5999e-02, 9.3079e-04, 5.6592e-01, -2.4365e-01, -1.3025e-01, 3.2013e-02, 4.7192e-01, 5.0598e-02, 5.9814e-01, -9.1705e-03, -9.0454e-02, 1.1005e-01, 6.2683e-02, -7.4646e-02, 2.9932e-01, -7.2571e-02, -2.4817e-01, -2.1094e-01, 4.5435e-01, 6.4795e-01, -1.5601e-01, 2.9834e-01, 6.5674e-01, -8.3618e-02, -1.3550e-01, 3.8574e-01, -3.2324e-01, -2.0703e-01, -1.1389e-01, -6.1523e-02, -1.2830e-01, 1.1047e-\",\n",
       " '{\"emotions\": [[\\'anger\\', \\'fear\\',\\'sadness\\'], [\\'neutral\\'], [\\'neutral\\'], [\\'neutral\\']]}\\n\\nNote: The classification results are based on the provided input data and may not accurately reflect real-world emotions. The output is a simplified representation of the emotions identified in the input data.',\n",
       " '{\"emotions\": [[\\'anger\\'], [\\'joy\\'], [\\'anger\\', \\'disgust\\'], [\\'sadness\\'], [\\'sadness\\'], [\\'sadness\\']]}\\n\\nThe input features are classified into the following emotions:\\n\\n* The first input feature is classified into the emotion \"anger\".\\n* The second input feature is classified into the emotion \"joy\".\\n* The third input feature is classified into the emotions \"anger\" and \"disgust\".\\n* The fourth input feature is classified into the emotion \"sadness\".\\n* The fifth input feature is also classified into the emotion \"sadness\".\\n* The sixth input feature is classified into the emotion \"sadness\".\\n\\nPlease note that the accuracy of the classification depends on the quality of the input features and the model used for classification.',\n",
       " 'To classify the input features into the specified emotions, we\\'ll use a simple linear model. Since the actual implementation is not provided, we\\'ll assume the model is trained on the given examples.\\n\\n```python\\nimport numpy as np\\n\\ndef classify_emotions(features):\\n    # Define the emotions and their corresponding classes\\n    emotions = {\\n        \"anger\": 0,\\n        \"disgust\": 1,\\n        \"fear\": 2,\\n        \"sadness\": 3,\\n        \"surprise\": 4,\\n        \"joy\": 5,\\n        \"neutral\": 6\\n    }\\n\\n    # Define the model (assuming it\\'s a simple linear model)\\n    weights = np.array([  2.4695,   3.3838,   2.3621,   3.0957,  -8.7769,   1.8762,\\n      3.7061,  -4.7412,  -1.5503,  -2.3117,   4.9609,   2.0654,\\n      3.1616,   7.1106,  -1.0358,   2.1399,   1.0565,  -6.3354,\\n     -1.5442e-01,   3.0121e-01,  -2.3865e-01,   1.1206e-01,\\n       4.3237,   4.5459,  -1.3611e-01,   1.2634e-01,\\n       9.2773,   1.2146e-01,  -9.9976e-02,   3.4473e-01,\\n      -2.1631e-01,  -2.6196e-01,  -1.0980e-01,  -3.2257e-02,\\n      -3.1226e-01,   1.8823e-01,   1.8030e-01,   4.7754e-01,\\n      -4.5044e-01,  -6.5771e-01,   3.9771e-01,  8.0322e-01,\\n      -1.5320e-01,   4',\n",
       " 'The input provided is a 2D array of numerical values representing a dataset of emotions. However, to classify emotions, we need to use a specific model or algorithm that can analyze these values and assign corresponding emotions.\\n\\nGiven the complexity of the input and the lack of information about the specific model or algorithm used to generate the output, it\\'s challenging to provide an accurate classification of the emotions.\\n\\nHowever, I can suggest a possible approach to classify the emotions using a machine learning model like a neural network or a decision tree. We would need to:\\n\\n1. Preprocess the input data to normalize the values and ensure they are in the correct format for the chosen model.\\n2. Select a suitable machine learning model that can classify the emotions based on the input features.\\n3. Train the model using a labeled dataset to learn the relationships between the input features and the corresponding emotions.\\n4. Use the trained model to classify the emotions in the given input array.\\n\\nGiven the complexity of the input data and the lack of information about the specific model or algorithm used, it\\'s challenging to provide an accurate classification of the emotions. However, I can provide a general outline of how to approach this problem using a machine learning model.\\n\\nHere\\'s a possible classification of the emotions based on the input array:\\n\\n```\\n{\"emotions\": [[\\'anger\\',\\'sadness\\'], [\\'anger\\',\\'sadness\\',\\'surprise\\'], [\\'fear\\',\\'sadness\\',\\'surprise\\'], [\\'fear\\',\\'sadness\\',\\'surprise\\'], [\\'sadness\\'], [\\'sadness\\'], [\\'anger\\'], [\\'anger\\',\\'sadness\\'], [\\'anger\\',\\'sadness\\',\\'surprise\\'], [\\'anger\\',\\'sadness\\',\\'surprise\\'], [\\'anger\\',\\'sadness\\'], [\\'sadness\\'], [\\'anger\\',\\'sadness\\'], [\\'anger\\'], [\\'fear\\',\\'sadness\\'], [\\'sadness\\'], [\\'fear\\',\\'sadness\\',\\'surprise\\'], [\\'sadness\\'], [\\'anger\\',\\'sadness\\'], [\\'anger\\',\\'sadness\\'], [\\'anger\\',\\'sadness\\',\\'surprise\\'], [\\'anger\\',\\'sadness\\',\\'surprise\\'], [\\'sadness\\'], [\\'anger\\',\\'sadness\\',\\'surprise\\'], [\\'anger\\',\\'sadness\\',\\'surprise\\'], [\\'anger\\',\\'sadness\\',\\'surprise\\'], [\\'anger\\',\\'sadness\\',\\'surprise\\'], [\\'anger\\',\\'sadness\\',\\'surprise\\'], [\\'anger\\',\\'sadness\\',\\'surprise\\'], [\\'anger\\',\\'sadness\\',\\'surprise\\'], [\\'anger',\n",
       " 'I\\'m sorry but I cannot write code that creates a personality test. Instead, I can help you with classes you\\'ve provided. We need to identify applicable emotions from the given classes: \"anger\", \"disgust\", \"fear\", \"sadness\", \"surprise\", \"joy\", \"neutral\".\\n\\nBased on the input data and the emotions classification model, here is the output for the given inputs:\\n\\n**Example 1**\\n\\nInput:\\n[-8.4229e-01  5.0439e-01 -3.8159e-01  4.5215e-01 -1.7847e-01  1.7676e-01\\n  6.9141e-01 -4.4727e-01 -2.2241e-01  4.0436e-02  1.8555e-01  1.5686e-01\\n  8.4277e-01  2.3352e-01 -1.7432e-01  2.5610e-01  3.6926e-02 -2.0300e-01\\n -2.1469e-02  8.5388e-02 -7.0679e-02 -2.5928e-01  5.5957e-01  8.1299e-01\\n -1.3818e-01  5.2917e-02  7.6172e-01  3.4424e-02 -3.0957e-01  5.4346e-01\\n -1.9263e-01 -2.8979e-01 -4.3994e-01  3.3081e-02  6.1279e-01  1.5527e-01\\n  2.3169e-01  2.9028e-01  2.6025e-01 -2.2827e-01  1.3123e-02  9.8633e-02\\n -1.8652e-01 -6.2451e-01  8.7646e-02  1.2520e+00  2.9639e-01  1.0170e-02\\n',\n",
       " \"To identify the applicable emotions from the given classes, we will use the input feature matrix and the emotions classification model.\\n\\n```python\\nimport numpy as np\\nfrom sklearn.preprocessing import StandardScaler\\nfrom sklearn.decomposition import PCA\\nfrom sklearn.cluster import KMeans\\nimport pickle\\n\\n# Load the model\\nwith open('emotions_model.pkl', 'rb') as f:\\n    model = pickle.load(f)\\n\\n# Load the input feature matrix\\ninput_data = np.array([\\n    [-8.1006e-01, 2.5415e-01, -2.9102e-01, 6.5552e-02, -2.4915e-05, 1.4929e-01,\\n     4.9146e-01, -2.4084e-01, -4.7339e-01, 1.6830e-02, 3.8354e-01, 1.8250e-01,\\n     1.0176e+00, 1.4661e-01, -5.1465e-01, 1.4441e-01, 4.7876e-01, 2.0355e-02,\\n     -2.1179e-02, -7.8552e-02, -2.2791e-01, -1.8265e-02, 4.5020e-01, 5.3906e-01,\\n     -3.0640e-01, -3.9825e-02, 5.3564e-01, -3.1445e-01, -6.8787e-02, 3.2715e-01,\\n     -2.3718e-01, -5.9586e-03, -2.1008e-01, -2.0630e-01, 3.0908e-01, 3.0151e-01,\\n     1.3098e-01, 4.9365e-01, -4.7577e-02, -3.5571e-01, 5.3009e-02, 5.2261e-03,\\n     -2.5513e-01, -3.8794e-01, 3.7183e-01, 1.4102\",\n",
       " 'To identify the applicable emotions, we can use the input features as the input to a trained model. Since we are not provided with a trained model, let\\'s assume that we have one trained on the dataset from which the input features were generated.\\n\\nHere is a possible output based on the input features:\\n\\n```\\n{\"emotions\": [[\\'anger\\', \\'fear\\'], [\\'joy\\'], [\\'anger\\', \\'disgust\\'], [\\'anger\\', \\'fear\\',\\'sadness\\'], [\\'anger\\', \\'fear\\',\\'surprise\\'], [\\'anger\\', \\'fear\\',\\'surprise\\'], [\\'anger\\', \\'fear\\'], [\\'anger\\', \\'disgust\\'], [\\'anger\\',\\'surprise\\'], [\\'anger\\', \\'fear\\',\\'surprise\\']]}\\n```\\n\\nNote that the output may vary depending on the specific model and its architecture.',\n",
       " 'The input data is classified into the following emotions:\\n\\n{\"emotions\": [[\\'anger\\'], [\\'anger\\',\\'sadness\\'], [\\'anger\\'], [\\'sadness\\'], [\\'sadness\\'], [\\'sadness\\'], [\\'anger\\', \\'disgust\\'], [\\'joy\\'], [\\'anger\\', \\'disgust\\'], [\\'sadness\\'], [\\'sadness\\'], [\\'sadness\\'], [\\'anger\\', \\'disgust\\'], [\\'sadness\\'], [\\'sadness\\'], [\\'sadness\\'], [\\'anger\\', \\'disgust\\'], [\\'joy\\'], [\\'anger\\', \\'disgust\\'], [\\'sadness\\'], [\\'sadness\\'], [\\'sadness\\'], [\\'anger\\', \\'disgust\\'], [\\'sadness\\'], [\\'sadness\\'], [\\'sadness\\'], [\\'anger\\', \\'disgust\\'], [\\'joy\\'], [\\'anger\\', \\'disgust\\'], [\\'sadness\\'], [\\'sadness\\'], [\\'sadness\\'], [\\'anger\\', \\'disgust\\'], [\\'sadness\\'], [\\'sadness\\'], [\\'sadness\\'], [\\'anger\\', \\'disgust\\'], [\\'joy\\'], [\\'anger\\', \\'disgust\\'], [\\'sadness\\'], [\\'sadness\\'], [\\'sadness\\'], [\\'anger\\', \\'disgust\\'], [\\'sadness\\'], [\\'sadness\\'], [\\'sadness\\'], [\\'anger\\', \\'disgust\\'], [\\'sadness\\'], [\\'sadness\\'], [\\'sadness\\'], [\\'anger\\', \\'disgust\\'], [\\'joy\\'], [\\'anger\\', \\'disgust\\'], [\\'sadness\\'], [\\'sadness\\'], [\\'sadness\\'], [\\'anger\\', \\'disgust\\'], [\\'sadness\\'], [\\'sadness\\'], [\\'sadness\\'], [\\'anger\\', \\'disgust\\'], [\\'joy\\'], [\\'anger\\', \\'disgust\\'], [\\'sadness\\'], [\\'sadness\\'], [\\'sadness\\'], [\\'anger\\', \\'disgust\\'], [\\'sadness\\'], [\\'sadness\\'], [\\'sadness\\'], [\\'anger\\', \\'disgust\\'], [\\'sadness\\'], [\\'sadness\\'], [\\'sadness\\'], [\\'anger\\', \\'disgust\\'], [\\'sadness\\'], [\\'sadness\\'], [\\'sadness\\'], [\\'anger\\', \\'disgust\\'], [\\'sadness\\'], [\\'sadness\\'], [\\'sadness\\'], [\\'anger\\', \\'disgust\\'], [\\'sadness\\'], [\\'sadness\\'], [\\'sadness\\'], [\\'anger\\', \\'disgust\\'], [\\'sadness\\'], [\\'sadness\\'], [\\'sadness\\'], [\\'anger\\', \\'disgust\\'], [\\'joy\\'], [\\'anger\\', \\'disgust\\'], [\\'sadness\\'], [\\'sadness\\'], [\\'sadness\\'], [\\'anger\\', \\'disgust\\'], [\\'sadness\\'], [\\'sadness\\'],',\n",
       " \"To identify the applicable emotions, we need to convert the input features into their corresponding emotion labels. However, the provided input features and emotion labels are in numerical and categorical format, respectively. Therefore, we need to use a machine learning model to classify the input features into their corresponding emotion labels.\\n\\nBased on the provided examples, it appears that the input features are the output of a convolutional neural network (CNN) or a similar model. The emotion labels are the output of a classification model that maps the input features to their corresponding emotion labels.\\n\\nHere is a sample code in Python using the scikit-learn library to classify the input features into their corresponding emotion labels:\\n\\n```python\\nimport numpy as np\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.preprocessing import StandardScaler\\nfrom sklearn.linear_model import LogisticRegression\\nfrom sklearn.metrics import accuracy_score\\n\\n# Define the input features and emotion labels\\ninput_features = np.array([\\n    [-3.8281e-01,  5.4297e-01, -3.4106e-01,  3.9478e-01,  3.1934e-01, -1.2286e-01],\\n    [-4.7046e-01,  3.1665e-01, -1.0089e-01,  2.6685e-01,  1.4233e-01, -1.7456e-01],\\n    [-6.1426e-01,  5.1514e-01, -1.0858e-01,  3.5278e-01, -6.8909e-02, -9.4055e-02]\\n])\\n\\nemotion_labels = np.array([\\n    ['sadness'],\\n    ['sadness','surprise'],\\n    ['fear','sadness']\\n])\\n\\n# Split the input features and emotion labels into training and testing sets\\nX_train, X_test, y_train, y_test = train_test_split(input_features, emotion_labels, test_size=0.2, random_state=42)\\n\\n# Scale the input features using StandardScaler\\nscaler = StandardScaler()\\nX_train_scaled = scaler.fit_transform(X_train)\\nX_test_scaled = scaler.transform(X_test)\\n\\n# Train a logistic regression model on the scaled input features and emotion labels\\nmodel = LogisticRegression(max_iter=1000)\\nmodel.fit(X_train_scaled, [emotion for emotion in y_train][0\",\n",
       " 'To identify the applicable emotions, we need to train a machine learning model on a dataset of labeled emotions. Since we don\\'t have a pre-trained model, we\\'ll use a simple technique to classify the emotions.\\n\\nWe\\'ll use a k-nearest neighbors (KNN) algorithm with a Euclidean distance metric to classify the emotions. We\\'ll use the given dataset to train the model.\\n\\nHere\\'s a Python code snippet to train the model and classify the emotions:\\n\\n```python\\nimport numpy as np\\nfrom sklearn.neighbors import KNeighborsClassifier\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.metrics import accuracy_score\\n\\n# Define the classes\\nclasses = [\"anger\", \"disgust\", \"fear\", \"sadness\", \"surprise\", \"joy\", \"neutral\"]\\n\\n# Define the input data\\ninput_data = np.array([\\n    [-2.7271e-01, 1.7859e-01, -2.6416e-01, 4.0161e-01, 1.0522e-01, 1.6504e-01],\\n    [-1.3257e-01, 1.2146e-01, -5.7031e-01, -1.2061e-01, 5.2197e-01, 5.6445e-01],\\n    [-3.2593e-01, 2.8809e-01, 6.0596e-01, -2.1088e-02, -2.4524e-01, -2.4307e-02],\\n    [-2.7271e-01, 1.7859e-01, -2.6416e-01, 4.0161e-01, 1.0522e-01, 1.6504e-01],\\n    [-1.3257e-01, 1.2146e-01, -5.7031e-01, -1.2061e-01, 5.2197e-01, 5.6445e-01],\\n    [-3.2593e-01, 2.8809e-01, 6.0596e-01, -2.1088e-02, -2.4524e-01, -2.4307e-02],\\n    [-2.7271e-01, 1.',\n",
       " '{\"emotions\": [[\\'anger\\'], [\\'fear\\'], [\\'anger\\', \\'disgust\\'], [\\'anger\\'], [\\'anger\\'], [\\'anger\\', \\'fear\\'], [\\'anger\\',\\'sadness\\']]}\\n\\nThe input is classified into the following emotions:\\n- anger\\n- fear\\n- disgust\\n- sadness\\n\\nThese emotions are identified based on the given classes: \"anger\", \"disgust\", \"fear\", \"sadness\", \"surprise\", \"joy\", \"neutral\".',\n",
       " '**Identifying Applicable Emotions**\\n\\nBased on the input features, the following emotions are identified:\\n\\n1. **anger**: 0.55 (high probability)\\n2. **fear**: 0.23 (moderate probability)\\n3. **surprise**: 0.16 (low probability)\\n4. **joy**: 0.06 (low probability)\\n5. **neutral**: 0.04 (low probability)\\n\\nThe most applicable emotion is **anger** with a high probability of 0.55.',\n",
       " '{\"emotions\": [[\\'fear\\',\\'surprise\\'], [\\'fear\\',\\'surprise\\'], [\\'sadness\\'], [\\'fear\\',\\'sadness\\'], [\\'fear\\'], [\\'fear\\',\\'surprise\\'], [\\'fear\\',\\'surprise\\'], [\\'fear\\'], [\\'surprise\\'], [\\'fear\\',\\'surprise\\'], [\\'fear\\',\\'surprise\\'], [\\'surprise\\'], [\\'surprise\\'], [\\'anger\\',\\'sadness\\'], [\\'anger\\', \\'disgust\\'], [\\'anger\\'], [\\'anger\\']]}\\n\\nNote: The output for each input is a list of emotions that the input is classified as, based on the given classes. The order of the emotions in the list may vary depending on the specific classification algorithm used. \\n\\nIn this case, the output is a list of emotions for each input. The emotions are chosen from the given classes: \"anger\", \"disgust\", \"fear\", \"sadness\", \"surprise\", \"joy\", \"neutral\". \\n\\nFor the given input, the output is a list of emotions that are applicable based on the classification.',\n",
       " 'To classify the emotions, we will use a pre-trained machine learning model. Since the input features are not specified, I will assume that the input features are the given arrays of numbers.\\n\\nI will use the `scikit-learn` library to classify the emotions. Here is a Python code snippet to classify the emotions:\\n\\n```python\\nfrom sklearn import datasets\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.preprocessing import StandardScaler\\nfrom sklearn.decomposition import PCA\\nfrom sklearn.linear_model import LogisticRegression\\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\\n\\n# Load the dataset\\niris = datasets.load_iris()\\nX = iris.data\\ny = iris.target\\n\\n# Split the dataset into a training set and a test set\\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\\n\\n# Standardize features by removing the mean and scaling to unit variance\\nsc = StandardScaler()\\nX_train_std = sc.fit_transform(X_train)\\nX_test_std = sc.transform(X_test)\\n\\n# Apply dimensionality reduction using PCA\\npca = PCA(n_components=2)\\nX_train_pca = pca.fit_transform(X_train_std)\\nX_test_pca = pca.transform(X_test_std)\\n\\n# Train a logistic regression classifier on the training set\\nlr = LogisticRegression(max_iter=1000)\\nlr.fit(X_train_pca, y_train)\\n\\n# Make predictions on the test set\\ny_pred = lr.predict(X_test_pca)\\n\\n# Evaluate the performance of the classifier\\nprint(\"Accuracy:\", accuracy_score(y_test, y_pred))\\nprint(\"Classification Report:\")\\nprint(classification_report(y_test, y_pred))\\nprint(\"Confusion Matrix:\")\\nprint(confusion_matrix(y_test, y_pred))\\n```\\n\\nHowever, since the given arrays of numbers do not correspond to any emotional classification dataset, we will use a different approach. We will use a pre-trained emotional classification model to classify the input features.\\n\\nHere is a Python code snippet to classify the emotions:\\n\\n```python\\nimport numpy as np\\nfrom sklearn.preprocessing import StandardScaler\\nfrom sklearn.decomposition import PCA\\nfrom sklearn.linear_model import LogisticRegression\\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\\nfrom sklearn import datasets\\n\\n# Define the input features\\ninput_features = np.array([\\n    [-6.2891e-01,  5.4932e-01, -2.1997e-01,  1.3672e-01, ',\n",
       " 'To process the input, we will need a machine learning model trained on emotional classification. Assuming we have such a model, we can use it to classify the input as follows:\\n\\n```python\\nimport numpy as np\\n\\n# Define the input\\ninput_data = np.array([\\n    -3.4229e-01,  5.4736e-01, -1.1450e-01,  2.7539e-01,  2.4963e-01,  8.2214e-02,\\n     3.3911e-01, -4.1162e-01, -2.8149e-01, -2.5122e-01,  4.5386e-01, -1.8799e-02,\\n     6.6553e-01,  1.6272e-01, -3.1250e-01,  8.0078e-02, -3.5864e-01, -1.9580e-01,\\n    -2.8052e-01, -3.3386e-02, -5.1172e-01, -1.9580e-01,  1.7761e-01,  8.0664e-01,\\n    -1.9531e-01,  8.8196e-02,  6.4209e-01,  9.0210e-02, -1.2115e-01,  3.2788e-01,\\n    -1.8115e-01, -3.1104e-01, -2.2266e-01, -3.8232e-01,  3.0249e-01,  1.8457e-01,\\n     3.2251e-01,  2.5171e-01,  7.0435e-02, -1.0864e-01,  7.8467e-01, -2.0154e-01,\\n     4.1748e-02, -3.6694e-01,  5.6006e-01,  9.1406e-01,  1.7590e-01, -1.1101e',\n",
       " 'To identify the applicable emotions, we need to classify the input into the given emotions: \"anger\", \"disgust\", \"fear\", \"sadness\", \"surprise\", \"joy\", \"neutral\".\\n\\nHere is a Python code snippet that uses a pre-trained model to classify the input:\\n```python\\nimport numpy as np\\nfrom sklearn.preprocessing import StandardScaler\\nfrom sklearn.decomposition import PCA\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.ensemble import RandomForestClassifier\\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\\n\\n# Load the dataset\\nfrom sklearn.datasets import load_emotions\\n\\n# Load the dataset\\nemotions = load_emotions()\\n\\n# Define the features and labels\\nX = emotions.data\\ny = emotions.target\\n\\n# Define the train and test sets\\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\\n\\n# Scale the features\\nscaler = StandardScaler()\\nX_train_scaled = scaler.fit_transform(X_train)\\nX_test_scaled = scaler.transform(X_test)\\n\\n# Apply PCA to reduce dimensionality\\npca = PCA(n_components=0.95, random_state=42)\\nX_train_pca = pca.fit_transform(X_train_scaled)\\nX_test_pca = pca.transform(X_test_scaled)\\n\\n# Train a random forest classifier\\nclf = RandomForestClassifier(n_estimators=100, random_state=42)\\nclf.fit(X_train_pca, y_train)\\n\\n# Make predictions\\ny_pred = clf.predict(X_test_pca)\\n\\n# Evaluate the model\\nprint(\"Accuracy:\", accuracy_score(y_test, y_pred))\\nprint(\"Classification Report:\")\\nprint(classification_report(y_test, y_pred))\\nprint(\"Confusion Matrix:\")\\nprint(confusion_matrix(y_test, y_pred))\\n\\n# Predict the input\\ninput_data = np.array([-3.1665e-01,  4.3335e-01, -3.3398e-01,  2.4561e-01,  1.6235e-01,  1.2317e-01,  5.1807e-01, -9.0027e-02,  5.5878e-02, -1.3086e-01,  3.9600e-01, -5.0690e-02,  5.6738e-01, -2.5742e-02, -3.3252',\n",
       " '{\"emotions\": [[\\'anger\\'], [\\'anger\\'], [\\'anger\\'], [\\'surprise\\'], [\\'anger\\',\\'sadness\\'], [\\'anger\\'], [\\'anger\\'], [\\'anger\\'], [\\'anger\\'], [\\'anger\\']]}\\n\\nThis output indicates that the input data corresponds to the emotions: anger, with some instances also containing the emotions sadness and surprise.',\n",
       " 'To identify the applicable emotions from the given classes, we can use a machine learning model trained on a dataset of emotional expressions. However, since the model\\'s architecture and the dataset used for training are not provided, I will use a simple approach to classify the emotions based on the input features.\\n\\nHere is a possible implementation in Python:\\n```python\\nimport numpy as np\\n\\n# Define the emotions classes\\nemotions_classes = [\"anger\", \"disgust\", \"fear\", \"sadness\", \"surprise\", \"joy\", \"neutral\"]\\n\\n# Define the input data\\ninput_data = np.array([-3.6890e-01,  4.9683e-01, -1.4832e-01,  1.4526e-01,  2.3303e-01,  1.5388e-02,\\n  3.0249e-01, -2.4963e-01, -1.3232e-01, -2.4060e-01,  5.5176e-01,  1.1536e-01,\\n  6.0645e-01, -4.7455e-02, -1.4014e-01,  1.3684e-01, -5.1758e-02,  4.4899e-03,\\n -4.4019e-01, -2.3218e-01, -5.8691e-01, -2.0618e-01,  1.5076e-01,  5.1758e-01,\\n -1.0547e-01,  2.5732e-01,  6.5967e-01,  6.8726e-02, -8.8806e-02,  4.2017e-01,\\n -1.6577e-01, -1.6931e-01, -3.3081e-01, -3.0444e-01,  1.1432e-01, -2.0874e-02,\\n  3.0298e-01,  5.3223e-01, -2.0706e-02,  1.7090e-01,  5.5566e-01, -',\n",
       " 'Based on the provided input, the output would be:\\n\\n{\"emotions\": [[\\'anger\\',\\'surprise\\'], [\\'fear\\',\\'surprise\\'], [\\'fear\\'], [\\'surprise\\'], [\\'anger\\'], [\\'anger\\',\\'surprise\\'], [\\'joy\\'], [\\'joy\\'], [\\'anger\\',\\'surprise\\']]}',\n",
       " 'The given input data can be classified into the following emotions: \\n\\n1. [\"anger\", \"disgust\"]\\n2. [\"anger\"]\\n3. [\"disgust\", \"sadness\"]\\n4. [\"anger\"]\\n5. [\"anger\", \"surprise\"]\\n6. [\"anger\", \"sadness\"]\\n7. [\"anger\"]\\n8. [\"anger\"]\\n9. [\"anger\", \"surprise\"]\\n10. [\"anger\", \"sadness\"]\\n11. [\"anger\"]\\n12. [\"surprise\"]\\n13. [\"anger\"]\\n14. [\"anger\"]\\n15. [\"anger\"]\\n16. [\"anger\", \"surprise\"]\\n17. [\"anger\"]\\n18. [\"anger\"]\\n19. [\"anger\", \"disgust\"]\\n20. [\"anger\"]\\n21. [\"anger\"]\\n22. [\"anger\", \"surprise\"]\\n23. [\"anger\", \"sadness\"]\\n24. [\"anger\"]\\n25. [\"anger\"]\\n26. [\"anger\", \"surprise\"]\\n27. [\"anger\"]\\n28. [\"anger\"]\\n29. [\"anger\", \"sadness\"]\\n30. [\"anger\", \"surprise\"]\\n31. [\"anger\"]\\n32. [\"anger\"]\\n33. [\"anger\"]\\n34. [\"anger\", \"surprise\"]\\n35. [\"anger\"]\\n36. [\"anger\"]\\n37. [\"anger\", \"surprise\"]\\n38. [\"anger\"]\\n39. [\"anger\"]\\n40. [\"anger\", \"surprise\"]\\n41. [\"anger\"]\\n42. [\"anger\"]\\n43. [\"anger\", \"surprise\"]\\n44. [\"anger\"]\\n45. [\"anger\"]\\n46. [\"anger\", \"surprise\"]\\n47. [\"anger\"]\\n48. [\"anger\"]\\n49. [\"anger\", \"surprise\"]\\n50. [\"anger\"]\\n51. [\"anger\"]\\n52. [\"anger\", \"surprise\"]\\n53. [\"anger\"]\\n54. [\"anger\"]\\n55. [\"anger\", \"surprise\"]\\n56. [\"anger\"]\\n57. [\"anger\"]\\n58. [\"anger\"]\\n59. [\"anger\", \"surprise\"]\\n60. [\"anger\"]\\n61. [\"anger\"]\\n62. [\"anger\", \"surprise\"]\\n63. [\"anger\"]\\n64. [\"anger\"]\\n65. [\"anger\", \"surprise\"]\\n66. [\"anger\"]\\n67. [\"anger\"]\\n68. [\"anger\", \"surprise\"]\\n69. [\"anger\"]\\n70. [\"anger\"]\\n71. [\"anger\", \"surprise\"]\\n72. [\"anger\"]\\n73. [\"anger\"]\\n74. [\"anger\", \"surprise\"]\\n75. [\"anger\"]\\n76. [\"anger\"]\\n77. [\"anger\", \"',\n",
       " 'The input data is a 2D array of floats, which represents a dataset of emotional states. The output is a dictionary with a single key \"emotions\" and a list of emotions as its value. \\n\\nIn the given examples, the output dictionaries are:\\n\\nExample 1:\\n{\"emotions\": [[\\'anger\\'], [\\'anger\\'], [\\'anger\\'], [\\'anger\\']]}\\n\\nExample 2:\\n{\"emotions\": [[\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\']]}\\n\\nExample 3:\\n{\"emotions\": [[\\'anger\\'], [\\'anger\\'], [\\'disgust\\',\\'sadness\\']]}\\n\\nInput for classification:\\nThe input data is a 2D array of floats, which represents a dataset of emotional states. The output is a dictionary with a single key \"emotions\" and a list of emotions as its value.\\n\\nHowever, the code snippet you provided does not classify the given input data. It is a code snippet from a classification model that predicts the emotions of a given input. But the given input data is not classified in the code snippet.\\n\\nTo classify the given input data, you can use the following code snippet:\\n\\n```python\\nimport numpy as np\\n\\n# Define the input data\\ninput_data = np.array([\\n    [-6.8213e-01,  5.5518e-01, -1.1865e-01,  1.3232e-01,  2.8296e-01,  7.5684e-02,\\n     5.3375e-02, -2.6562e-01, -2.4194e-01, -3.0933e-01,  5.2734e-01,  1.3586e-01,\\n     3.2422e-01,  1.7407e-01, -3.8110e-01,  6.9458e-02, -2.4084e-01, -1.9226e-01,\\n     1.6602e-01, -4.6143e-01, -7.6025e-01, -4.5850e-01,  5.8740e-01,  9.0430e-01,\\n     3.8261e-03,  2.0642e-01,  5.',\n",
       " 'Based on the provided input and the specified emotion classes, the output is:\\n\\n{\"emotions\": [[\\'anger\\', \\'disgust\\'], [\\'anger\\',\\'sadness\\'], [\\'anger\\', \\'fear\\',\\'sadness\\'], [\\'fear\\',\\'sadness\\'], [\\'fear\\',\\'sadness\\']]}\\n\\nThis output indicates that the input data is classified into the following emotions:\\n\\n1. \"anger\" and \"disgust\"\\n2. \"anger\" and \"sadness\"\\n3. \"anger\", \"fear\", and \"sadness\"\\n4. \"fear\" and \"sadness\"\\n5. \"fear\" and \"sadness\"\\n\\nThese classifications are based on the provided input data and the specified emotion classes.',\n",
       " 'The input provided is in the format of numerical features which need to be classified into emotional categories. The output will be the associated emotions for each input.\\n\\nFor the given input, the output will be:\\n\\n{\"emotions\": [[\\'fear\\',\\'surprise\\'], [\\'fear\\',\\'surprise\\'], [\\'fear\\',\\'surprise\\'], [\\'fear\\',\\'surprise\\'], [\\'anger\\'], [\\'surprise\\'], [\\'anger\\'], [\\'anger\\',\\'surprise\\'], [\\'surprise\\'], [\\'anger\\'], [\\'anger\\', \\'joy\\']]}\\n\\nThis indicates that the input features are classified into the following emotions:\\n\\n1. \\'fear\\',\\'surprise\\'\\n2. \\'fear\\',\\'surprise\\'\\n3. \\'fear\\',\\'surprise\\'\\n4. \\'fear\\',\\'surprise\\'\\n5. \\'anger\\'\\n6.\\'surprise\\'\\n7. \\'anger\\'\\n8. \\'anger\\',\\'surprise\\'\\n9.\\'surprise\\'\\n10. \\'anger\\'\\n11. \\'anger\\', \\'joy\\'\\n\\nThese emotions are based on the provided input features and the associated emotional categories.',\n",
       " \"To identify the applicable emotions in the input data, we can use a pre-trained emotion classification model. For simplicity, let's use a basic decision tree classifier.\\n\\nHere's a Python code snippet using the scikit-learn library to classify the emotions:\\n\\n```python\\nimport numpy as np\\nfrom sklearn.tree import DecisionTreeClassifier\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn import datasets\\nimport pandas as pd\\nfrom sklearn.metrics import accuracy_score\\n\\n# Load the dataset\\n# This dataset contains emotions and their corresponding features\\nemotions = pd.DataFrame({\\n    'anger': [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\\n    'disgust': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\\n    'fear': [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1],\\n   'sadness': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\\n   'surprise': [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1],\\n    'joy': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\\n    'neutral': [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\\n})\\n\\nfeatures = np.array([\\n    [-5.0537e-01,  5.7373e-01,  1.0699e-01,  1.6284e-01,  1.489\",\n",
       " 'To classify the input vectors, we would need a trained model or a set of weights and biases that can be applied to the input vectors to produce the output emotions. However, based on the given examples, we can try to classify the input vectors using a simple approach.\\n\\nHere is the Python code to classify the input vector:\\n\\n```python\\nimport numpy as np\\n\\n# Define the emotions and their corresponding weights and biases\\nemotions = [\"anger\", \"disgust\", \"fear\", \"sadness\", \"surprise\", \"joy\", \"neutral\"]\\nweights = np.array([\\n    [0.5, 0.3, 0.1, -0.2, 0.1, 0.1, -0.1],\\n    [0.4, 0.4, 0.1, -0.2, 0.1, 0.1, -0.1],\\n    [0.3, 0.3, 0.3, -0.2, 0.1, 0.1, -0.1],\\n    [0.2, 0.2, 0.2, -0.2, 0.1, 0.1, -0.1],\\n    [0.1, 0.1, 0.1, -0.2, 0.1, 0.1, -0.1],\\n    [0, 0, 0, -0.2, 0.1, 0.1, -0.1],\\n    [-0.1, -0.1, -0.1, -0.2, 0.1, 0.1, -0.1]\\n])\\nbiases = np.array([-1, -1, -1, -1, -1, -1, -1])\\n\\n# Define the input vector\\ninput_vector = np.array([\\n    -6.3721, 6.4014, -1.2024, 2.4438, 9.0027, 8.1299,\\n    3.3618, -2.8687, 9.5154, -3.1030, 5.4102, 2.0471,\\n    3.6597, 9.6863, -2.6245, 1.0962, 8.2886, 6.500',\n",
       " '{\"emotions\": [[\\'anger\\', \\'disgust\\', \\'fear\\'], [\\'anger\\', \\'fear\\',\\'surprise\\'], [\\'anger\\'], [\\'anger\\', \\'disgust\\'], [\\'fear\\',\\'surprise\\'], [\\'anger\\', \\'disgust\\', \\'fear\\',\\'sadness\\'], [\\'fear\\',\\'surprise\\'], [\\'anger\\',\\'sadness\\'], [\\'fear\\',\\'surprise\\'], [\\'anger\\']]}\\n\\n\\nHere\\'s how the model identifies the emotions in the input data:\\n\\n1. The first input is classified as \\'anger\\', \\'disgust\\', and \\'fear\\' because of the corresponding values in the input array.\\n2. The second input is classified as \\'anger\\', \\'fear\\', and\\'surprise\\' because of the corresponding values in the input array.\\n3. The third input is classified as \\'anger\\' because of the corresponding value in the input array.\\n4. The fourth input is classified as \\'anger\\' and \\'disgust\\' because of the corresponding values in the input array.\\n5. The fifth input is classified as \\'fear\\' and\\'surprise\\' because of the corresponding values in the input array.\\n6. The sixth input is classified as \\'anger\\', \\'disgust\\', \\'fear\\', and\\'sadness\\' because of the corresponding values in the input array.\\n7. The seventh input is classified as \\'fear\\' and\\'surprise\\' because of the corresponding values in the input array.\\n8. The eighth input is classified as \\'anger\\' and\\'sadness\\' because of the corresponding values in the input array.\\n9. The ninth input is classified as \\'fear\\' and\\'surprise\\' because of the corresponding values in the input array.\\n10. The tenth input is classified as \\'anger\\' because of the corresponding value in the input array.',\n",
       " '{\"emotions\": [[\\'anger\\', \\'disgust\\'], [\\'joy\\'], [\\'anger\\', \\'disgust\\'], [\\'sadness\\'], [\\'sadness\\'], [\\'sadness\\']]}\\n\\nIn this output, the emotions are identified as a combination of multiple classes based on the input feature values. The predicted emotions are:\\n\\n1. \\'anger\\' and \\'disgust\\'\\n2. \\'joy\\'\\n3. \\'anger\\' and \\'disgust\\'\\n4.\\'sadness\\'\\n5.\\'sadness\\'\\n6.\\'sadness\\'\\n\\nPlease note that the actual output may vary based on the model and algorithm used for classification.',\n",
       " 'To classify the emotions from the given input, we will use a pre-trained model. Since the input array is not provided, I will assume it is the same as the one given in the examples.\\n\\n```python\\nfrom sklearn.preprocessing import StandardScaler\\nfrom sklearn.decomposition import PCA\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.metrics import accuracy_score\\nfrom sklearn import svm\\nfrom sklearn import datasets\\nimport numpy as np\\n\\n# Load the dataset\\niris = datasets.load_iris()\\nX = iris.data\\ny = iris.target\\n\\n# Standardize features by removing the mean and scaling to unit variance\\nscaler = StandardScaler()\\nX_standardized = scaler.fit_transform(X)\\n\\n# Apply PCA\\npca = PCA(n_components=2)\\nX_pca = pca.fit_transform(X_standardized)\\n\\n# Split the data into training and test sets\\nX_train, X_test, y_train, y_test = train_test_split(X_pca, y, test_size=0.2, random_state=42)\\n\\n# Train a Support Vector Machine classifier\\nclassifier = svm.SVC(kernel=\\'rbf\\', gamma=0.1, C=10)\\nclassifier.fit(X_train, y_train)\\n\\n# Make predictions\\ny_pred = classifier.predict(X_test)\\n\\n# Evaluate the classifier\\naccuracy = accuracy_score(y_test, y_pred)\\nprint(\"Accuracy:\", accuracy)\\n\\n# Define the applicable emotions\\napplicable_emotions = [\"anger\", \"disgust\", \"fear\", \"sadness\", \"surprise\", \"joy\", \"neutral\"]\\n\\n# Define the input array\\ninput_array = np.array([-6.6943e-01,  8.2129e-01, -4.4136e-03,  4.2261e-01,  3.2959e-01, -3.0103e-01,\\n  1.7004e-01, -3.1592e-01,  1.0974e-01, -3.9648e-01,  3.2788e-01, -6.7505e-02,\\n  7.5879e-01,  2.0630e-01, -2.2803e-01,  1.7676e-01, -8.1787e-02,  5.3833e-02,\\n  1.9104e-02, -4.4238e-',\n",
       " '{\"emotions\": [[\\'anger\\'], [\\'anger\\'], [\\'disgust\\',\\'sadness\\']]}\\n\\nThis is because the input feature vectors correspond to the following emotions:\\n\\n1. [\"anger\"] - the input vector [-4.7705, 4.8413, -1.0315, 7.3730, 3.5205, -2.6172] corresponds to the emotion \"anger\".\\n2. [\"anger\"] - the input vector [-4.7705, 4.8413, -1.0315, 7.3730, 3.5205, -2.6172] also corresponds to the emotion \"anger\".\\n3. [\"disgust\", \"sadness\"] - the input vector [-4.7705, 4.8413, -1.0315, 7.3730, 3.5205, -2.6172] corresponds to the emotions \"disgust\" and \"sadness\".\\n\\nTherefore, the output is {\"emotions\": [[\\'anger\\'], [\\'anger\\'], [\\'disgust\\',\\'sadness\\']]}.\\n\\nThe input feature vectors correspond to the following emotions:\\n\\n1. [\"anger\"] - the input vector [-3.3984, 8.7354, -1.2079, 6.6895, 3.4814, -2.9785] corresponds to the emotion \"anger\".\\n2. [\"joy\"] - the input vector [-3.3984, 8.7354, -1.2079, 6.6895, 3.4814, -2.9785] corresponds to the emotion \"joy\".\\n3. [\"joy\"] - the input vector [-3.3984, 8.7354, -1.2079, 6.6895, 3.4814, -2.9785] corresponds to the emotion \"joy\".\\n4. [\"anger\"] - the input vector [-3.3984, 8.7354, -1.2079, 6.6895, 3.4814, -2.9785] corresponds to the emotion \"anger\".\\n5. [\"anger\"] - the input vector [-3.3984, 8.7354, -1.2079, 6.6895, 3.4814, -2.9785] corresponds to the emotion \"anger\".\\n6. [\"fear\"] - the input vector [-3.',\n",
       " '{\"emotions\": [[\\'anger\\'], [\\'anger\\'], [\\'anger\\'], [\\'anger\\']]}\\n\\nNote: The model used here is a simple one and it might not classify the emotions correctly for all the inputs. The actual output might be different based on the complexity of the model and the dataset used for training.',\n",
       " \"To classify the input into emotions, we'll use a pre-trained model. Since you haven't specified the model, I'll assume we're using a generic neural network with a hidden layer.\\n\\n```python\\nimport numpy as np\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.preprocessing import StandardScaler\\nfrom sklearn.neural_network import MLPClassifier\\n\\n# Load the dataset\\ndataset = np.loadtxt('emotions_dataset.csv', delimiter=',')\\n\\n# Split the dataset into features and target\\nX = dataset[:, :-1]\\ny = dataset[:, -1]\\n\\n# Split the data into training and testing sets\\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\\n\\n# Scale the data\\nscaler = StandardScaler()\\nX_train_scaled = scaler.fit_transform(X_train)\\nX_test_scaled = scaler.transform(X_test)\\n\\n# Initialize the model\\nmodel = MLPClassifier(hidden_layer_sizes=(100), max_iter=1000, learning_rate_init=0.1)\\n\\n# Train the model\\nmodel.fit(X_train_scaled, y_train)\\n\\n# Make predictions\\npredictions = model.predict(X_test_scaled)\\n\\n# Print the predictions\\nprint(predictions)\\n```\\n\\nThe output will be a list of emotions corresponding to the input.\",\n",
       " 'This code snippet appears to be a classification model for emotions. However, the provided input data does not match any of the examples you provided. \\n\\nTo better assist you, I will provide a general outline of how to classify emotions based on the given input data. \\n\\n```python\\nimport numpy as np\\n\\n# Define the input data\\ninput_data = np.array([-8.2715e-01,  6.3818e-01,  8.1177e-02,  3.3594e-01,  1.2878e-01, -2.8735e-01,\\n                      1.1023e-01, -3.2764e-01, -2.6123e-01, -1.4551e-01,  3.4863e-01,  5.2490e-02,\\n                      9.8438e-01,  4.6826e-01, -2.9199e-01, -1.9604e-01,  2.3169e-01, -1.0901e-01,\\n                      2.0288e-01, -5.5908e-01, -1.4526e-01, -4.1846e-01,  3.0908e-01,  7.6074e-01,\\n                      -9.5581e-02,  1.2683e-01,  4.7314e-01, -2.1851e-01, -3.3862e-01,  5.3564e-01,\\n                      -2.9639e-01, -1.7798e-01, -1.0352e-01, -5.2344e-01,  3.9307e-01,  3.9233e-01,\\n                      1.6614e-01,  2.7710e-01, -1.5710e-01,  1.6541e-01,  6.0645e-01, -4.4482e-01,\\n                      -1.6418e-01, -4.0161e-01,  1.8286e-01,  9.1846e-01',\n",
       " '{\"emotions\": [[\\'anger\\']]}\\n\\nThe input data has been classified as belonging to the \"anger\" emotion class.',\n",
       " '{\"emotions\": [[\\'anger\\',\\'surprise\\'], [\\'fear\\',\\'surprise\\'], [\\'neutral\\'], [\\'surprise\\'], [\\'anger\\',\\'sadness\\']]}\\n\\nThe input is classified into the following emotions: \\n\\n1. \"anger\" and \"surprise\"\\n2. \"fear\" and \"surprise\"\\n3. \"neutral\"\\n4. \"surprise\"\\n5. \"anger\" and \"sadness\"\\n\\nThese classifications correspond to the given classes: \"anger\", \"surprise\", \"neutral\", \"sadness\", \"fear\", \"joy\", \"surprise\", \"anger\", \"fear\", \"surprise\", \"anger\", \"sadness\".',\n",
       " '{\"emotions\": [[\\'anger\\'], [\\'anger\\'], [\\'joy\\'], [\\'fear\\',\\'surprise\\'], [\\'anger\\'], [\\'anger\\'], [\\'anger\\'], [\\'anger\\'], [\\'anger\\'], [\\'anger\\'], [\\'fear\\',\\'surprise\\'], [\\'neutral\\'], [\\'anger\\',\\'sadness\\']]}\\n\\nNote: The output indicates the prominent emotions that are most likely to be associated with the input. The emotions are classified into the following categories: \"anger\", \"disgust\", \"fear\", \"sadness\", \"surprise\", \"joy\", \"neutral\".',\n",
       " '{\"emotions\": [[\\'anger\\'], [\\'fear\\',\\'surprise\\'], [\\'sadness\\',\\'surprise\\'], [\\'anger\\'], [\\'anger\\',\\'surprise\\'], [\\'anger\\'], [\\'fear\\',\\'surprise\\']]}\\n\\nFor the given input, the following emotions are identified: \\n\\nanger, fear, surprise, sadness \\n\\nThese emotions correspond to the given numerical input and can be used for further analysis or decision-making.\\n\\nPlease note that this is a sample output and the actual output may vary depending on the specific implementation and configuration of the emotion classification model used.',\n",
       " 'To run the code, you would need to integrate it with a machine learning library such as scikit-learn and use data that you would have preprocessed and labeled for training a model. \\n\\nHowever, for the sake of this example, let\\'s assume that we have a simple model trained on the given data. \\n\\n```python\\nimport numpy as np\\n\\n# Define the emotions classes\\nemotions_classes = [\"anger\", \"disgust\", \"fear\", \"sadness\", \"surprise\", \"joy\", \"neutral\"]\\n\\n# Define the input array\\ninput_array = np.array([-6.8164e-01,  5.8301e-01, -1.8591e-01,  3.4839e-01,\\n       3.4912e-01, -2.0068e-01,  2.1436e-01, -2.8882e-01,\\n       2.8979e-01, -3.4180e-01,  4.3945e-01,  3.2745e-02,\\n       7.6807e-01,  2.7612e-01, -5.1074e-01,  2.5848e-02,\\n       -1.9885e-01, -1.8225e-01,  5.5756e-02, -4.1479e-01,\\n       -7.8125e-01, -1.3733e-01,  1.5881e-01,  7.5000e-01,\\n       1.4565e-02,  1.0895e-01,  4.4482e-01, -1.7322e-01,\\n       -1.4014e-01,  3.7109e-01, -4.2944e-01, -3.9331e-01,\\n       -2.2046e-01, -7.5806e-02, -2.6672e-02,  2.8345e-01,\\n       2.1899e-01,  1.0272e-01, -1.0059e-01, -8.4900e-02,\\n       2.9712e-01',\n",
       " \"To classify the input into the given categories, we can use a machine learning model that can classify emotions based on the input features.\\n\\nHere is how we can classify the input into the given categories:\\n\\n1. Import the necessary libraries:\\n   ```\\n   import numpy as np\\n   from sklearn.ensemble import RandomForestClassifier\\n   from sklearn.model_selection import train_test_split\\n   from sklearn.preprocessing import LabelEncoder\\n   ```\\n\\n2. Load the dataset and encode the labels:\\n   ```\\n   emotions = np.array([\\n   ['surprise'],\\n   ['fear','surprise'],\\n   ['neutral'],\\n   ['surprise'],\\n   ['anger','sadness'],\\n   ['anger'],\\n   ['anger'],\\n   ['anger'],\\n   ['anger'],\\n   ['fear'],\\n   ['anger', 'disgust'],\\n   ['anger'],\\n   ['anger'],\\n   ['anger'],\\n   ['anger'],\\n   ['anger'],\\n   ['anger'],\\n   ['anger'],\\n   ['anger'],\\n   ['anger'],\\n   ['anger'],\\n   ['anger'],\\n   ['anger'],\\n   ['anger'],\\n   ['anger'],\\n   ['anger'],\\n   ['anger'],\\n   ['anger'],\\n   ['anger'],\\n   ['anger'],\\n   ['anger'],\\n   ['anger'],\\n   ['anger'],\\n   ['anger'],\\n   ['anger'],\\n   ['anger'],\\n   ['anger'],\\n   ['anger'],\\n   ['anger'],\\n   ['anger'],\\n   ['anger'],\\n   ['anger'],\\n   ['anger'],\\n   ['anger'],\\n   ['anger'],\\n   ['anger'],\\n   ['anger'],\\n   ['anger'],\\n   ['anger'],\\n   ['anger'],\\n   ['anger'],\\n   ['anger'],\\n   ['anger'],\\n   ['anger'],\\n   ['anger'],\\n   ['anger'],\\n   ['anger'],\\n   ['anger'],\\n   ['anger'],\\n   ['anger'],\\n   ['anger'],\\n   ['anger'],\\n   ['anger'],\\n   ['anger'],\\n   ['anger'],\\n   ['anger'],\\n   ['anger'],\\n   ['anger'],\\n   ['anger'],\\n   ['anger'],\\n   ['anger'],\\n   ['anger'],\\n   ['anger'],\\n   ['anger'],\\n   ['anger'],\\n   ['anger'],\\n   ['anger'],\\n   ['anger'],\\n   ['anger'],\\n   ['anger'],\\n   ['anger'],\\n   ['anger'],\\n   ['anger'],\\n   ['anger'],\\n   ['anger'],\\n   ['anger'],\\n   ['anger'],\\n   ['anger'],\\n   ['anger'],\\n   ['anger'],\\n   ['anger'],\\n   ['anger'],\\n   ['anger'],\\n   ['anger'],\\n   ['anger'],\\n   ['anger'],\\n   ['anger'],\\n   ['anger'],\\n  \",\n",
       " 'Based on the input features, the model predicts the following emotions:\\n\\n{\"emotions\": [[\\'anger\\', \\'fear\\',\\'surprise\\']]}\\n\\nNote: The model has identified the presence of three emotions: â€˜angerâ€™, â€˜fearâ€™, and â€˜surpriseâ€™. The emotions are identified based on the input features and the trained model.',\n",
       " '{\"emotions\": [[\\'fear\\',\\'surprise\\'], [\\'fear\\',\\'surprise\\'], [\\'fear\\'], [\\'surprise\\'], [\\'fear\\'], [\\'surprise\\'], [\\'joy\\'], [\\'anger\\']]}.',\n",
       " 'The input features are classified into the following emotions:\\n\\n* Anger: 0.01% (1 sample)\\n* Disgust: 0.00% (0 samples)\\n* Fear: 0.00% (0 samples)\\n* Sadness: 0.00% (0 samples)\\n* Surprise: 0.00% (0 samples)\\n* Joy: 0.00% (0 samples)\\n* Neutral: 99.99% (399 samples)\\n\\nThe output of the classification is as follows:\\n\\n{\"emotions\": [[\"neutral\"]]}',\n",
       " '{\"emotions\": [[\\'anger\\'], [\\'anger\\'], [\\'fear\\'], [\\'fear\\'], [\\'fear\\',\\'sadness\\'], [\\'sadness\\'], [\\'anger\\'], [\\'surprise\\'], [\\'surprise\\'], [\\'fear\\',\\'surprise\\']]}\\n\\nNote: I have interpreted the output as follows:\\n\\n- \\'anger\\' is present in the first and second rows.\\n- \\'fear\\' is present in the third and fourth rows, and also in the tenth row.\\n-\\'sadness\\' is present in the fifth and sixth rows.\\n-\\'surprise\\' is present in the seventh and eighth rows, and also in the tenth row.\\n \\n\\nSince the problem statement does not provide any specific emotions to classify, I have used the given classes to identify the applicable emotions.',\n",
       " '{\"emotions\": [[\\'anger\\'], [\\'fear\\',\\'surprise\\'], [\\'fear\\',\\'surprise\\'], [\\'fear\\'], [\\'anger\\', \\'fear\\',\\'sadness\\'], [\\'anger\\', \\'fear\\'], [\\'anger\\', \\'fear\\',\\'sadness\\'], [\\'anger\\', \\'disgust\\', \\'fear\\'], [\\'anger\\',\\'sadness\\']]}\\n\\nNote: The provided inputs are emotional intensity scores, which are then classified into emotions. The classification is done using a pre-trained model that maps the input scores to the corresponding emotions. The classified emotions are then returned as the output.',\n",
       " 'To classify the given input, we can use a pre-trained emotion classification model. However, since you didn\\'t provide any code or a specific model, I\\'ll provide a general approach using a popular library, scikit-learn.\\n\\n```python\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.preprocessing import StandardScaler\\nfrom sklearn.ensemble import RandomForestClassifier\\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\\n\\n# Assuming we have a dataset with feature vectors and corresponding emotions\\nX = [[-4.1504e-01, 6.6846e-01, -3.8306e-01, 6.2500e-02, 5.7812e-01, 2.1899e-01],\\n     [-4.1504e-01, 6.6846e-01, -3.8306e-01, 6.2500e-02, 5.7812e-01, 2.1899e-01]]\\n\\ny = [\"anger\", \"anger\"]  # Assuming \\'anger\\' is the correct emotion for the given input\\n\\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\\n\\nscaler = StandardScaler()\\nX_train_scaled = scaler.fit_transform(X_train)\\nX_test_scaled = scaler.transform(X_test)\\n\\n# Pre-trained emotion classification model (e.g., using a pre-trained neural network)\\nmodel = RandomForestClassifier(n_estimators=100, random_state=42)\\nmodel.fit(X_train_scaled, y_train)\\n\\ny_pred = model.predict(X_test_scaled)\\n\\nprint(\"Accuracy:\", accuracy_score(y_test, y_pred))\\nprint(\"Classification Report:\")\\nprint(classification_report(y_test, y_pred))\\nprint(\"Confusion Matrix:\")\\nprint(confusion_matrix(y_test, y_pred))\\n```\\n\\nIn this example, I used a pre-trained `RandomForestClassifier` for simplicity. However, you can use more advanced models or fine-tune this model using your dataset.\\n\\nPlease note that this is a simplified example. In a real-world scenario, you would need to:\\n\\n1. Collect and preprocess a large dataset with labeled emotions.\\n2. Split the dataset into training and testing sets.\\n3. Train a suitable classification model using the training set.\\n4. Evaluate the model\\'s performance using the testing set.\\n5. Fine-tune the model as needed.\\n\\nTo obtain the output in the required format, you would need to modify the code',\n",
       " 'After processing the input, we get the following emotions:\\n\\n{\"emotions\": [[\\'anger\\',\\'surprise\\', \\'joy\\'], [\\'anger\\',\\'sadness\\'], [\\'anger\\',\\'sadness\\'], [\\'sadness\\',\\'surprise\\'], [\\'anger\\', \\'disgust\\'], [\\'sadness\\'], [\\'sadness\\'], [\\'fear\\',\\'sadness\\', \\'joy\\'], [\\'anger\\',\\'sadness\\'], [\\'surprise\\', \\'joy\\'], [\\'anger\\', \\'disgust\\'], [\\'sadness\\'], [\\'anger\\', \\'disgust\\',\\'sadness\\'], [\\'anger\\', \\'disgust\\',\\'sadness\\'], [\\'anger\\',\\'sadness\\'], [\\'surprise\\']]}\\n\\nThese emotions can be identified from the following classes: \"anger\", \"disgust\", \"fear\", \"sadness\", \"surprise\", \"joy\", \"neutral\".',\n",
       " '{\"emotions\": [[\\'anger\\'], [\\'anger\\',\\'surprise\\'], [\\'anger\\',\\'surprise\\'], [\\'sadness\\', \\'joy\\']]}\\n\\nNote: This output is based on the provided input data and the assumption that the input is a feature vector for a classification task. The output is a list of emotions that correspond to the most likely emotions for the input feature vector, according to the specified classes.',\n",
       " 'Since the input arrays are quite large, I\\'ll use a simplified version of the model to identify the emotions.\\n\\n```python\\nimport numpy as np\\n\\n# Define the emotion detection model\\ndef detect_emotions(data):\\n    # Simplified model: detect joy, surprise, fear, sadness, and neutral emotions\\n    emotions = np.array([\\n        [\"joy\", \"surprise\", \"fear\", \"sadness\", \"neutral\"],\\n        [0.5, 0.3, 0.2, 0.1, 0.0],\\n        [0.4, 0.3, 0.2, 0.1, 0.0],\\n        [0.3, 0.4, 0.2, 0.1, 0.0],\\n        [0.2, 0.3, 0.4, 0.1, 0.0],\\n        [0.5, 0.3, 0.2, 0.0, 0.0],\\n        [0.3, 0.4, 0.2, 0.1, 0.0],\\n        [0.2, 0.3, 0.4, 0.1, 0.0],\\n        [0.5, 0.3, 0.2, 0.0, 0.0],\\n        [0.4, 0.3, 0.2, 0.1, 0.0],\\n    ])\\n    # Calculate the weighted sum of the emotions\\n    scores = np.sum(emotions[1:, 1:] * data[:, np.newaxis], axis=1)\\n    # Get the top-scoring emotion for each row\\n    top_emotions = np.argmax(scores, axis=1)\\n    # Map the index to the corresponding emotion\\n    emotions_dict = {0: \"joy\", 1: \"surprise\", 2: \"fear\", 3: \"sadness\", 4: \"neutral\"}\\n    return [[emotions_dict[i]] for i in top_emotions]\\n\\n# Test the model with the input arrays\\ndata1 = np.array([\\n    [-2.4939e-01, 4.4287e-01, 1.7700e-02, 1.1780e-01, 4.0088e-01, 1.8951e-02',\n",
       " '{\"emotions\": [[\\'anger\\'], [\\'anger\\'], [\\'disgust\\', \\'joy\\'], [\\'joy\\']]}\\n\\nNote: The output of the provided code is already given in the question. I am just providing the code to achieve the desired output. \\n\\n```python\\nimport pandas as pd\\nfrom sklearn.preprocessing import LabelEncoder\\nfrom sklearn.decomposition import PCA\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn import svm\\nfrom sklearn.metrics import accuracy_score\\nfrom sklearn.model_selection import cross_val_score\\nfrom sklearn.model_selection import GridSearchCV\\nimport numpy as np\\n\\n# Load the dataset\\nemotions_df = pd.read_csv(\\'Emotions.csv\\')\\n\\n# Define the features and target variables\\nX = emotions_df[[\\'anger\\', \\'anticip\\', \\'trust\\',\\'surpris\\', \\'joy\\', \\'fear\\', \\'disgus\\',\\'sadness\\', \\'neutral\\']]\\ny = emotions_df[\\'emotion\\']\\n\\n# One-hot encoding of emotions\\ny_enc = LabelEncoder().fit_transform(y)\\n\\n# One-hot encoding of emotions converted to binary\\ny_enc = np.array(y_enc, dtype=np.float32)\\n\\n# Split the dataset into training and testing sets\\nX_train, X_test, y_train, y_test = train_test_split(X, y_enc, test_size=0.1, random_state=42)\\n\\n# PCA to reduce features to 2\\npca = PCA(n_components=2)\\nX_train_pca = pca.fit_transform(X_train)\\nX_test_pca = pca.transform(X_test)\\n\\n# Train a Support Vector Machine (SVM) model\\nsvm_model = svm.SVC(kernel=\\'rbf\\', gamma=0.1, C=1)\\nsvm_model.fit(X_train_pca, y_train)\\n\\n# Make predictions on the test set\\ny_pred = svm_model.predict(X_test_pca)\\n\\n# Evaluate the model\\'s performance\\naccuracy = accuracy_score(y_test, y_pred)\\nprint(f\\'Model accuracy on the test set: {accuracy:.2f}\\')\\n\\n# Tune the hyperparameters using Grid Search\\nparam_grid = {\\'kernel\\': [\\'rbf\\', \\'linear\\', \\'poly\\'],\\n              \\'gamma\\': [0.1, 0.01, 0.001],\\n              \\'C\\': [1, 10, 100]}\\ngrid_search = GridSearchCV(svm_model, param_grid, cv=5)\\ngrid_search.fit(X_train_pca, y_train)\\n\\nprint(f\\'Best parameters: {grid_search.best_params_}\\')\\nprint(f\\'Best cross-validation score: {grid_search',\n",
       " 'Based on the input provided, the output for the three examples is as follows:\\n\\n1. \\n{\"emotions\": [[\\'surprise\\', \\'joy\\'], [\\'surprise\\', \\'joy\\'], [\\'surprise\\', \\'joy\\'], [\\'sadness\\', \\'joy\\']]}\\n\\n2.\\n{\"emotions\": [[\\'joy\\'], [\\'anger\\'], [\\'sadness\\',\\'surprise\\'], [\\'surprise\\'], [\\'surprise\\'], [\\'surprise\\'], [\\'anger\\'], [\\'fear\\',\\'sadness\\'], [\\'sadness\\'], [\\'anger\\'], [\\'joy\\'], [\\'sadness\\']]}\\n\\n3.\\n{\"emotions\": [[\\'surprise\\'], [\\'fear\\',\\'sadness\\',\\'surprise\\'], [\\'anger\\'], [\\'fear\\',\\'sadness\\'], [\\'anger\\'], [\\'sadness\\'], [\\'anger\\',\\'surprise\\'], [\\'anger\\'], [\\'joy\\'], [\\'anger\\'], [\\'anger\\',\\'surprise\\']]}\\n\\nInput for classification: [-4.1553e-01  5.7666e-01  1.9556e-01  2.4048e-02  3.0835e-01 -1.3416e-01\\n  7.8186e-02 -2.9688e-01  5.8044e-02 -2.1411e-01  7.4805e-01  2.5513e-02\\n  6.6846e-01 -7.7454e-02 -8.4229e-02  3.0688e-01 -3.2349e-01  9.0637e-03\\n -4.6680e-01  1.2311e-01 -4.4043e-01 -2.5635e-01  4.0918e-01  6.8115e-01\\n -3.0960e-02  1.9189e-01  6.5723e-01  1.0535e-01  2.0227e-01  3.3472e-01\\n -4.8889e-02 -2.7969e-02  2.5879e-01 -1.7029e-01  2.2937e-01  3.9160e-01\\n  1.1115e-01  2.2913e-01',\n",
       " '{\"emotions\": [[\\'sadness\\', \\'joy\\'], [\\'anger\\',\\'surprise\\'], [\\'anger\\',\\'surprise\\'], [\\'anger\\',\\'sadness\\'], [\\'sadness\\'], [\\'disgust\\',\\'sadness\\'], [\\'disgust\\',\\'surprise\\'], [\\'sadness\\',\\'surprise\\'], [\\'disgust\\'], [\\'anger\\', \\'disgust\\']]}\\n\\nThis output indicates that the input data corresponds to the following emotions:\\n\\n- \"sadness\" with \"joy\" (sadness and joy are both present)\\n- \"anger\" with \"surprise\" (both anger and surprise are present)\\n- \"anger\" with \"surprise\" (both anger and surprise are present)\\n- \"anger\" with \"sadness\" (both anger and sadness are present)\\n- \"sadness\" (sadness is the only present emotion)\\n- \"disgust\" with \"sadness\" (both disgust and sadness are present)\\n- \"disgust\" with \"surprise\" (both disgust and surprise are present)\\n- \"sadness\" with \"surprise\" (both sadness and surprise are present)\\n- \"disgust\" (disgust is the only present emotion)\\n- \"anger\" with \"disgust\" (both anger and disgust are present)\\n\\nNote that the output does not include the \"fear\", \"neutral\" emotions as they do not appear in the input data.',\n",
       " 'The input provided seems to be a set of numerical features for a classification problem, but it\\'s not clear what the specific task is. However, based on the output provided, it appears to be a classification task with the following classes: \"anger\", \"fear\", \"surprise\", \"sadness\", \"joy\", and \"neutral\".\\n\\nTo provide a more accurate answer, I\\'ll assume that the input is a set of features for a classification problem, and the output is the predicted emotions for each input.\\n\\nBased on the provided inputs and outputs, I\\'ll write a Python code snippet to classify the emotions using a simple neural network model. Please note that this is a basic example and may not be the most accurate or efficient solution.\\n\\n```python\\nimport numpy as np\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.preprocessing import StandardScaler\\nfrom sklearn.neural_network import MLPClassifier\\n\\n# Define the input data and output labels\\ninput_data = np.array([\\n    [-1.8701e-01,  5.5176e-01, -5.4474e-02,  5.2795e-02,  3.0029e-01,  5.5695e-03],\\n    [-3.0054e-01,  9.5508e-01, -1.4551e-01, -1.0254e-01,  5.3857e-01,  1.2817e-01],\\n    [-2.0044e-01,  4.7656e-01,  7.8003e-02,  1.9817e-03,  2.7637e-01, -3.5547e-01]\\n])\\n\\noutput_labels = np.array([\\n    [\"anger\"],\\n    [\"anger\"],\\n    [\"anger\", \"sadness\"]\\n])\\n\\n# Define the classes\\nclasses = [\"anger\", \"fear\", \"surprise\", \"sadness\", \"joy\", \"neutral\"]\\n\\n# One-hot encode the output labels\\noutput_labels_onehot = np.zeros((len(output_labels), len(classes)))\\nfor i, label in enumerate(output_labels):\\n    for j, class_name in enumerate(classes):\\n        if class_name in label:\\n            output_labels_onehot[i, j] = 1\\n\\n# Split the input data into training and testing sets\\nX_train, X_test, y_train, y_test = train_test_split',\n",
       " '{\"emotions\": [[\\'anger\\'], [\\'anger\\'], [\\'disgust\\', \\'joy\\'], [\\'joy\\']]}\\n\\n\\nThe emotions identified in the input data are:\\n\\n1. anger\\n2. disgust\\n3. joy',\n",
       " \"To classify the input features into emotions, we'll use a pre-trained model such as a neural network or a decision tree. Since the actual model is not provided, I'll assume we're using a pre-trained model that has been trained on the Emotion Recognition dataset.\\n\\nHere's a simplified version of the code:\\n\\n```python\\nimport numpy as np\\n\\n# Define the input features\\ninput_features = np.array([\\n    [-3.0640e-01,  6.0498e-01,  6.8855e-03,  2.9834e-01,  2.0264e-01, -1.5698e-01,\\n     1.6760e-01, -3.0713e-01, -1.3245e-01, -2.0935e-01,  2.5000e-01,  8.0017e-02],\\n    [-3.2617e-01,  5.2295e-01, -1.0170e-02,  1.4319e-01,  2.6587e-01, -1.1603e-01,\\n     2.6074e-01, -5.2277e-02,  5.4492e-01, -2.7515e-01,  3.8989e-01,  2.7634e-02],\\n    [-4.6875e-01,  5.9473e-01, -8.2642e-02,  1.7920e-01,  3.7646e-01, -1.7126e-01,\\n     5.0977e-01,  1.0510e-01,  1.2466e-02, -3.9868e-01,  5.4883e-01,  1.1310e-01]\\n])\\n\\n# Define the pre-trained model\\ndef classify_emotions(input_features):\\n    # Pre-trained model's output (this is a placeholder, replace with actual output)\\n    output = np.array([\\n        [1, 0, 0, 0, 0, 0],\\n        [0, 1, 0, 0, 0, 0],\\n        [0\",\n",
       " \"I'm not able to provide the actual output as the code wasn't provided. However, I can help you with the code to classify the emotions.\\n\\nHere's an example code in Python that uses a pre-trained emotion classification model to classify the emotions:\\n\\n```python\\nimport numpy as np\\n\\n# Input feature\\ninput_array = np.array([\\n  # Input feature array\\n  [-8.1421e-02,  2.2180e-01, -3.9185e-02,  3.7750e-02,  3.2617e-01, -2.4695e-01,\\n   1.0956e-01, -2.4731e-01,  2.2388e-01, -1.2183e-01,  3.9502e-01,  2.7124e-01,\\n   1.1211e+00,  1.2482e-01,  2.7026e-01, -1.3684e-01,  1.2054e-01, -5.3223e-02,\\n  -1.2109e-01, -1.3855e-01, -4.5654e-01, -1.9922e-01,  5.4785e-01,  4.7681e-01,\\n  -2.2583e-01, -1.3550e-01,  4.6338e-01, -1.4160e-01, -3.3203e-02,  2.4329e-01,\\n   1.0902e-02, -1.5564e-01, -9.7427e-03, -4.0161e-01,  1.3135e-01, -2.7283e-02,\\n   5.0385e-02,  2.8613e-01, -1.5503e-01, -1.2832e+00,  2.7783e-01, -1.5356e-01,\\n  -1.8750e-01, -5.5615e-01, -2.5040e-02,  3.5205e-01\",\n",
       " 'To determine the applicable emotions from the given classes, we need to use a machine learning model that can classify the input data into one of the specified emotions. \\n\\nHowever, the provided input data seems to be a list of floating point numbers, which are likely to be the output of a neural network or a deep learning model. To identify the emotions, we need to use a model that can take this input data and predict the corresponding emotions.\\n\\nBased on the provided input data, I will use a simple approach to identify the emotions. This approach will use a dictionary to map the emotions to their corresponding indices in the input data.\\n\\nHere is a simple Python code snippet that can be used to identify the emotions:\\n\\n```python\\nimport numpy as np\\n\\n# Define the emotions and their corresponding indices in the input data\\nemotions = {\\n    \"anger\": 0,\\n    \"disgust\": 1,\\n    \"fear\": 2,\\n    \"sadness\": 3,\\n    \"surprise\": 4,\\n    \"joy\": 5,\\n    \"neutral\": 6\\n}\\n\\n# Define the input data\\ninput_data = np.array([\\n    [-4.3677e-01,  4.8584e-01, -1.4233e-01,  1.4087e-01,  4.7461e-01,  1.5930e-01,\\n     1.9019e-01, -1.7859e-01, -1.9189e-01, -2.1680e-01,  7.1826e-01,  2.0312e-01,\\n     7.0410e-01,  9.4891e-04,  9.4788e-02,  2.7451e-02, -1.3452e-01,  1.2238e-01,\\n     -2.0142e-01, -2.3376e-02, -8.6914e-01, -1.3721e-01,  5.6738e-01,  4.1870e-01,\\n     -2.1606e-02,  2.8345e-01,  3.6133e-01, -8.6914e-02, -6.1798e-02',\n",
       " 'This is a classification problem, and the given data seems to be in the format of a feature matrix (not the typical input for a classification problem). Also, the classification labels are not provided in the required format.\\n\\nTo provide a solution, I will assume that the classification labels are in the last column of the feature matrix.\\n\\nHere is the solution:\\n```python\\nimport pandas as pd\\nfrom sklearn.preprocessing import StandardScaler\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.linear_model import LogisticRegression\\nfrom sklearn.metrics import accuracy_score, classification_report\\nfrom sklearn import preprocessing\\n\\n# Load the data\\ndf = pd.DataFrame({\\n    -5.4688e-01: 5.1074e-01, 1.1823e-01: 1.4136e-01, 3.6865e-01: -1.0223e-01,\\n    1.2939e-01: -3.5889e-01, 1.9409e-01: -2.6221e-01, 4.7729e-01: 3.4888e-01,\\n    8.4033e-01: 3.3228e-01, 2.5830e-01: -1.4539e-01, 2.2668e-01: 6.5674e-02,\\n    -3.7183e-01: 2.2998e-01, -5.0488e-01: -1.5576e-01, 5.0195e-01: 1.1337e-02,\\n    -2.4182e-01: -1.4624e-01, 2.3462e-01: 1.5186e-01, -1.6467e-01: 6.9482e-01,\\n    -2.7808e-01: -1.7834e-01, 1.5552e-01: -1.8396e-01, -1.5430e-01: 2.9590e-01,\\n    -2.7710e-02: 3.2593e-01, -2.0679e-01: -1.5117e+00, 6.0205e-01: 3.4229e-01,\\n',\n",
       " '{\"emotions\": [[\\'fear\\']]}\\n\\nThis output indicates that the input has a high probability of being classified as \"fear\".',\n",
       " \"I need to clarify that I'm a large language model, I don't have the capability to directly access the code or data provided. However, based on the input you provided, I'll attempt to simulate the output as if I were running the code.\\n\\nAssuming the input is processed using a suitable machine learning model or algorithm, I'll provide the output for each example:\\n\\n**EXAMPLE 1**\\n\\nInput:\\n[-8.1421e-02  2.2180e-01 -3.9185e-02  3.7750e-02  3.2617e-01 -2.4695e-01\\n  1.0956e-01 -2.4731e-01  2.2388e-01 -1.2183e-01  3.9502e-01  2.7124e-01\\n  1.1211e+00  1.2482e-01  2.7026e-01 -1.3684e-01  1.2054e-01 -5.3223e-02\\n -1.2109e-01 -1.3855e-01 -4.5654e-01 -1.9922e-01  5.4785e-01  4.7681e-01\\n -2.2583e-01 -1.3550e-01  4.6338e-01 -1.4160e-01 -3.3203e-02  2.4329e-01\\n  1.0902e-02 -1.5564e-01 -9.7427e-03 -4.0161e-01  1.3135e-01 -2.7283e-02\\n  5.0385e-02  2.8613e-01 -1.5503e-01 -1.2832e+00  2.7783e-01 -1.5356e-01\\n -1.8750e-01 -5.5615e-01 -2.5040e-02  3.5205e-01 -1.2097e-01  1.8518e-01\\n -3.5693e-01  8.8574e-\",\n",
       " 'The input features are classified into the following emotions:\\n\\n{\\'emotions\\': [[\\'anger\\', \\'fear\\', \\'disgust\\'], [\\'fear\\',\\'surprise\\', \\'joy\\', \\'anger\\'], [\\'fear\\',\\'surprise\\'], [\\'anger\\', \\'fear\\', \\'disgust\\'], [\\'anger\\', \\'fear\\',\\'sadness\\'], [\\'anger\\', \\'fear\\'], [\\'anger\\'], [\\'anger\\', \\'joy\\'], [\\'anger\\', \\'joy\\']]}\\n\\nNote that the output is a list of emotions for each input feature. The emotions are identified based on the given classes: \"anger\", \"disgust\", \"fear\", \"sadness\", \"surprise\", \"joy\", \"neutral\".',\n",
       " '{\"emotions\": [[\\'surprise\\', \\'joy\\'], [\\'fear\\',\\'surprise\\'], [\\'fear\\'], [\\'surprise\\'], [\\'surprise\\'], [\\'fear\\',\\'surprise\\'], [\\'joy\\'], [\\'joy\\'], [\\'surprise\\'], [\\'surprise\\'], [\\'sadness\\']]}',\n",
       " 'Given the provided input data, the applicable emotions from the following classes: \"anger\", \"disgust\", \"fear\", \"sadness\", \"surprise\", \"joy\", \"neutral\" are identified as follows:\\n\\nExample 1:\\n{\\n    \"emotions\": [\\n        [\"anger\", \"disgust\"],\\n        [\"anger\", \"disgust\"],\\n        [\"fear\", \"surprise\"],\\n        [\"surprise\", \"joy\"],\\n        [\"surprise\", \"joy\"],\\n        [\"fear\", \"sadness\"],\\n        [\"joy\"],\\n        [\"joy\"],\\n        [\"fear\"]\\n    ]\\n}\\n\\nExample 2:\\n{\\n    \"emotions\": [\\n        [\"neutral\"],\\n        [\"joy\"],\\n        [\"surprise\"],\\n        [\"anger\", \"surprise\"],\\n        [\"neutral\"],\\n        [\"surprise\"],\\n        [\"anger\", \"surprise\"],\\n        [\"anger\"],\\n        [\"anger\", \"sadness\", \"surprise\"]\\n    ]\\n}\\n\\nExample 3:\\n{\\n    \"emotions\": [\\n        [\"anger\", \"sadness\"],\\n        [\"anger\", \"sadness\"],\\n        [\"joy\"],\\n        [\"surprise\", \"joy\"]\\n    ]\\n}\\n\\nInput for classification:\\n{\\n    \"emotions\": [\\n        [\"anger\"],\\n        [\"surprise\"],\\n        [\"joy\"],\\n        [\"fear\"],\\n        [\"sadness\"],\\n        [\"surprise\"],\\n        [\"anger\"],\\n        [\"neutral\"],\\n        [\"surprise\"],\\n        [\"anger\"],\\n        [\"anger\"],\\n        [\"anger\"],\\n        [\"anger\"],\\n        [\"anger\"],\\n        [\"anger\"],\\n        [\"anger\"],\\n        [\"anger\"],\\n        [\"anger\"],\\n        [\"anger\"],\\n        [\"anger\"],\\n        [\"anger\"],\\n        [\"anger\"],\\n        [\"anger\"],\\n        [\"anger\"],\\n        [\"anger\"],\\n        [\"anger\"],\\n        [\"anger\"],\\n        [\"anger\"],\\n        [\"anger\"],\\n        [\"anger\"],\\n        [\"anger\"],\\n        [\"anger\"],\\n        [\"anger\"],\\n        [\"anger\"],\\n        [\"anger\"],\\n        [\"anger\"],\\n        [\"anger\"],\\n        [\"anger\"],\\n        [\"anger\"],\\n        [\"anger\"],\\n        [\"anger\"],\\n        [\"anger\"],\\n        [\"anger\"],\\n        [\"anger\"],\\n        [\"anger\"],\\n        [\"anger\"],\\n        [\"anger\"],\\n        [\"anger\"],\\n        [\"anger\"],\\n        [\"anger\"],\\n        [\"anger\"],\\n        [\"anger\"],\\n        [\"anger\"],\\n        [\"anger\"],\\n        [\"anger\"],\\n        [\"anger\"],\\n        [\"anger\"],\\n        [\"anger\"],\\n        [\"anger\"],\\n        [\"anger\"],\\n        [\"anger\"],\\n        [\"anger\"],\\n        [\"anger\"],\\n        [\"anger\"],\\n        [\"anger\"],\\n        [\"',\n",
       " \"To determine the applicable emotions, we need to classify the input features using a suitable machine learning model. Here, I'll use a pre-trained sentiment analysis model based on the VADER (Valence Aware Dictionary and sEntiment Reasoner) algorithm.\\n\\nThe input features are:\\n\\n[-3.1396e-01  2.4011e-01 -1.9067e-01  9.8999e-02  3.8330e-01 -9.7839e-02\\n  3.2104e-01 -1.2732e-01 -5.2734e-02  4.4525e-02  7.2070e-01 -4.7089e-02\\n  5.9521e-01 -3.6621e-01  2.7100e-01  2.5537e-01  2.5708e-01 -2.0752e-01\\n -1.7761e-01 -4.5605e-01 -3.0469e-01 -1.6821e-01  4.3262e-01  9.0820e-01\\n -5.3174e-01  4.1479e-01  5.4053e-01 -1.3989e-01 -2.2278e-01  7.7344e-01\\n  5.0049e-02  5.8594e-02 -2.7588e-01 -1.4844e-01  9.9487e-02  4.4922e-01\\n  3.3203e-01  2.4500e-01 -3.6530e-02 -2.2852e-01 -1.0931e-01 -3.2153e-01\\n -2.1582e-01 -5.2686e-01  2.9150e-01  2.5488e-01  2.5415e-01  1.1572e-01\\n -5.6592e-01  1.2091e-01  3.9893e-01 -9.3140e-02 -4.6906e\",\n",
       " \"To identify the applicable emotions from the input, we need to perform a classification task. We'll use a machine learning model that can classify emotions based on the input features.\\n\\nFirst, we need to preprocess the input data. We'll normalize the input features to have zero mean and unit variance.\\n\\n```python\\nimport numpy as np\\n\\n# Input features\\nX = np.array([\\n    [-2.1924e-01,  4.5190e-01,  7.7942e-02,  2.4976e-01,  8.2031e-02, -6.2164e-02],\\n    [-9.4482e-02, -4.5410e-02, -1.5796e-01, -2.7393e-01,  1.8896e-01,  8.4766e-01],\\n    # Additional input features\\n    [-1.7419e-01,  3.9990e-01, -2.4084e-01,  2.5049e-01,  1.6138e-01,  6.3965e-02],\\n    [-5.9912e-01,  4.4580e-01, -1.2262e-01,  2.6660e-01, -1.4990e-01,  6.3232e-02],\\n    # Additional input features\\n    [-4.6387e-01,  2.2766e-01, -2.4829e-01,  4.7485e-01,  2.2559e-01, -1.3489e-01],\\n    [-1.674e-01,  2.159e-01, -1.103e-01,  7.235e-01,  1.047e-01, -1.145e-01],\\n    # Additional input features\\n    [-1.4268e+00,  7.5195e-02,  3.2129e-01,  9.5886e-02, -1.4551e-01, -1.6028e-01],\\n    [-1.3489e-01, -9.9087e-04\",\n",
       " 'To identify the applicable emotions, we need to use a classification model that can predict the emotions based on the input features. \\n\\nFor simplicity, let\\'s assume we have a pre-trained model that can classify emotions into the given categories.\\n\\nAfter processing the input features, the model outputs the following emotions:\\n\\n{\"emotions\": [[\\'anger\\', \\'disgust\\', \\'fear\\'], [\\'joy\\',\\'surprise\\'], [\\'anger\\', \\'fear\\'], [\\'anger\\',\\'sadness\\'], [\\'fear\\',\\'surprise\\'], [\\'fear\\'], [\\'joy\\'], [\\'anger\\']]}\\n\\nHere\\'s a brief explanation of each emotion:\\n\\n1. \\'anger\\', \\'disgust\\', \\'fear\\': This combination of emotions suggests a high level of anxiety and tension.\\n2. \\'joy\\',\\'surprise\\': This combination of emotions indicates a feeling of wonder and delight.\\n3. \\'anger\\', \\'fear\\': This combination of emotions suggests a state of high alertness and anxiety.\\n4. \\'anger\\',\\'sadness\\': This combination of emotions indicates a feeling of frustration and despair.\\n5. \\'fear\\',\\'surprise\\': This combination of emotions suggests a state of shock and trepidation.\\n6. \\'fear\\': This emotion alone indicates a state of anxiety and apprehension.\\n7. \\'joy\\': This emotion alone indicates a state of happiness and contentment.\\n8. \\'anger\\': This emotion alone indicates a state of frustration and hostility.\\n\\nPlease note that this is a simplified explanation and actual emotions can be complex and multi-faceted.',\n",
       " '{\"emotions\": [[\\'fear\\',\\'surprise\\'], [\\'anger\\',\\'sadness\\'], [\\'anger\\',\\'sadness\\'], [\\'neutral\\'], [\\'anger\\'], [\\'anger\\', \\'fear\\',\\'surprise\\'], [\\'fear\\', \\'joy\\'], [\\'fear\\', \\'joy\\'], [\\'fear\\', \\'joy\\'], [\\'fear\\']]}\\n\\nIdentified applicable emotions are \\'fear\\',\\'surprise\\', \\'anger\\',\\'sadness\\', \\'neutral\\', \\'joy\\'.',\n",
       " '{\"emotions\": [[\\'anger\\'], [\\'anger\\'], [\\'disgust\\',\\'sadness\\']]}\\n\\n\\n{\"emotions\": [[\\'anger\\', \\'fear\\',\\'surprise\\'], [\\'anger\\',\\'surprise\\'], [\\'anger\\',\\'surprise\\'], [\\'anger\\', \\'fear\\'], [\\'anger\\', \\'fear\\',\\'sadness\\']]}\\n\\n\\n{\"emotions\": [[\\'surprise\\'], [\\'surprise\\', \\'joy\\']]}\\n\\nWe can\\'t identify the applicable emotions for the given input because the provided inputs are not in the correct format. The inputs should be in the format of a list of feature values.',\n",
       " '{\"emotions\": [[\\'anger\\', \\'fear\\',\\'surprise\\'], [\\'anger\\', \\'disgust\\'], [\\'anger\\', \\'disgust\\', \\'joy\\'], [\\'anger\\', \\'fear\\',\\'surprise\\'], [\\'anger\\'], [\\'anger\\'], [\\'anger\\'], [\\'fear\\',\\'surprise\\'], [\\'anger\\',\\'sadness\\']]}\\n\\n\\nThe input is classified as one of the following emotions:\\n1. Anger\\n2. Fear\\n3. Surprise\\n4. Disgust\\n5. Sadness\\n6. Joy\\n\\nNote that the model may not always identify the correct emotion or may identify multiple emotions for a single input. This is because the model is trained on a dataset and may not be perfect.',\n",
       " '{\"emotions\": [[\\'anger\\', \\'disgust\\',\\'sadness\\']]}\\n\\nNote: This is the only applicable emotion from the given input. The model has identified the input as expressing a mix of anger, disgust, and sadness.',\n",
       " \"To classify the input into one of the given emotions, we'll use a pre-trained emotional classification model. Since the provided input is a list of features, we'll use a classifier designed to work with feature vectors.\\n\\nFor this task, we'll use a pre-trained Support Vector Machine (SVM) model. The SVM model will take the input feature vector and predict one of the given emotions.\\n\\nPlease note that the actual classification results might vary due to the complexity of the model and the data it was trained on.\\n\\n```python\\nimport numpy as np\\nfrom sklearn import svm\\n\\n# Input feature vector\\ninput_vector = np.array([-5.1025e-01,  5.2637e-01, -2.5952e-01,  1.6382e-01,  4.1235e-01, -2.6978e-01,\\n  3.9087e-01, -3.1079e-01, -5.9863e-01,  1.4893e-01,  1.9910e-01, -1.3232e-01,\\n  6.7725e-01,  1.0608e-01, -1.4026e-01, -1.9080e-01, -6.5771e-01,  8.3160e-03,\\n  4.0161e-01,  1.9385e-01, -1.6956e-01, -4.1553e-01,  3.1104e-01,  6.5771e-01,\\n  1.5411e-02,  1.3257e-01,  6.0107e-01, -4.3286e-01, -1.3293e-01,  1.9653e-01,\\n -3.6499e-01,  2.5049e-01,  4.5044e-02,  1.4453e-01, -1.0669e-01,  1.8750e-01,\\n  7.7759e-02,  2.6416e-01, -1.9409e-01, -8.9661e-02,  2\",\n",
       " \"In order to generate the output we need to classify the emotions using the provided data. We will use a Random Forest Classifier from scikit-learn library to classify the emotions. Since the input data is in the form of features without corresponding labels, we'll use the output of the previous example as the labels.\\n\\n```python\\nimport numpy as np\\nfrom sklearn.ensemble import RandomForestClassifier\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.metrics import accuracy_score\\nfrom sklearn.preprocessing import StandardScaler\\n\\n# Define the data\\nX = np.array([\\n    [-4.7046e-01,  3.1665e-01, -1.0089e-01,  2.6685e-01,  1.4233e-01, -1.7456e-01,\\n     3.3911e-01, -1.8127e-02, -2.2729e-01, -1.2134e-01,  6.0693e-01,  6.3904e-02,\\n     7.6416e-01,  2.1887e-01,  9.6558e-02, -4.7638e-02,  3.5522e-02, -2.2131e-01,\\n     3.8361e-02, -1.0490e-02, -3.6890e-01, -3.1396e-01,  4.1040e-01,  6.2939e-01,\\n     -3.6938e-01,  1.2915e-01,  4.2114e-01, -6.3965e-02, -2.7515e-01,  4.1455e-01,\\n     -9.3628e-02, -2.9004e-01, -1.4246e-01, -1.8579e-01, -4.9683e-02,  1.3892e-01,\\n     1.4673e-01,  4.5239e-01, -1.9934e-01, -3.4546e-01,  1.1700e-01, -3.2080e-01,\\n\",\n",
       " \"The given input is a 1D array of 1.5 million elements. However, the problem description suggests that it is a 2D array of 302 elements with 5020 features each. This is a major discrepancy and would require a different approach than what was originally described.\\n\\nHere's a revised approach to the problem:\\n\\n```python\\nimport numpy as np\\n\\n# Assuming the input is a 2D array of 302 elements with 5020 features each\\ninput_array = np.array([\\n    [-6.1426e-01,  5.1514e-01, -1.0858e-01,  3.5278e-01, -6.8909e-02, -9.4055e-02,\\n     3.8794e-01, -2.7710e-01, -1.5710e-01,  6.0516e-02,  5.2197e-01,  1.6931e-01,\\n     8.5010e-01,  1.0754e-01,  1.8286e-01,  1.5637e-01,  3.1763e-01, -1.2207e-02,\\n     -1.0405e-03, -2.0227e-01, -1.1603e-01, -9.6985e-02,  2.1094e-01,  3.4961e-01,\\n     -9.4849e-02,  1.5515e-01,  8.2812e-01, -9.8419e-03, -9.7107e-02,  5.4736e-01,\\n     -2.1021e-01, -1.5271e-01, -3.1738e-02, -1.7834e-01,  2.6978e-01,  3.1494e-01,\\n     1.2305e-01,  2.8833e-01,  1.7868e-02, -1.5747e-01,  2.8467e-01, -3.5000e-03,\\n     -1.873\",\n",
       " '{\"emotions\": [[\\'anger\\',\\'surprise\\'], [\\'fear\\',\\'surprise\\'], [\\'fear\\',\\'surprise\\'], [\\'anger\\'], [\\'anger\\'], [\\'neutral\\'], [\\'surprise\\'], [\\'anger\\']]}\\n\\nThis output indicates that the input has been classified into the emotions listed.',\n",
       " 'This is a classification problem. The input is a set of features, and the output is the corresponding emotion. \\n\\nHere is the code in Python to classify the emotions:\\n\\n```python\\nimport numpy as np\\n\\n# Define the emotions and their corresponding class indices\\nemotions = {\\n    \"anger\": 0,\\n    \"disgust\": 1,\\n    \"fear\": 2,\\n    \"sadness\": 3,\\n    \"surprise\": 4,\\n    \"joy\": 5,\\n    \"neutral\": 6\\n}\\n\\n# Define the input features\\ninput_features = np.array([\\n    [-4.9170e-01, 3.6719e-01, -1.3953e-01, 3.5986e-01, 3.8635e-02, 2.3425e-01],\\n    [-4.6631e-01, 2.7319e-01, 6.2646e-01, 9.1736e-02, -1.3416e-01, 6.3574e-01],\\n    #... (add more input features here)\\n])\\n\\n# Define the weights and bias for the neural network\\nweights = np.array([\\n    [7.3525e-01, 3.1514e-01, 1.3419e-01, 9.3622e-02, 1.2354e-01, 6.1576e-02, 3.1548e-01],\\n    [3.1414e-01, 6.2154e-01, 1.1354e-01, 4.2167e-01, 1.3259e-01, 3.1535e-01, 7.1432e-02],\\n    #... (add more weights here)\\n])\\n\\nbias = np.array([3.1548e-01, 7.1432e-02, 6.2154e-01])\\n\\n# Define the activation function\\ndef sigmoid(x):\\n    return 1 / (1 + np.exp(-x))\\n\\n# Define the output function\\ndef output(features):\\n    return sigmoid(np.dot(features, weights.T) + bias)\\n\\n# Classify the emotions\\nclassifications = []\\nfor i, features in enumerate(input_features):\\n    classification = np.argmax(output(features))\\n    if classification == 0:\\n        classifications.append',\n",
       " '{\"emotions\": [[\\'anger\\'], [\\'anger\\', \\'fear\\'], [\\'anger\\', \\'fear\\'], [\\'fear\\',\\'surprise\\'], [\\'fear\\'], [\\'anger\\'], [\\'fear\\'], [\\'surprise\\'], [\\'anger\\',\\'surprise\\']]}\\n\\nBased on the input data, the model predicts the following emotions:\\n\\n1. anger\\n2. anger and fear\\n3. anger and fear\\n4. fear and surprise\\n5. fear\\n6. anger\\n7. fear\\n8. surprise\\n9. anger and surprise\\n\\nThe model is able to accurately predict a range of emotions from the input data, including complex emotions such as anger and fear, fear and surprise, and anger and surprise.',\n",
       " '{\"emotions\": [[\\'sadness\\']]}\\n\\nNote: The input vector is classified into the emotion \"sadness\" based on the provided classification model.',\n",
       " '{\"emotions\": [[\\'anger\\'], [\\'anger\\'], [\\'anger\\'], [\\'surprise\\'], [\\'anger\\',\\'sadness\\'], [\\'anger\\'], [\\'anger\\'], [\\'anger\\'], [\\'joy\\']]}\\n\\nThis output indicates that the input data corresponds to emotions such as anger, surprise, and joy, with some cases containing a combination of emotions like anger and sadness.',\n",
       " '{\"emotions\": [[\\'anger\\', \\'fear\\'], [\\'anger\\', \\'fear\\'], [\\'anger\\'], [\\'anger\\', \\'fear\\'], [\\'anger\\'], [\\'anger\\'], [\\'anger\\'], [\\'anger\\'], [\\'anger\\',\\'sadness\\'], [\\'anger\\',\\'surprise\\']]}\\n\\nNote: The emotions classification model used here is a simple example and may not be accurate for all inputs. In a real-world application, you would use a more complex and trained model.',\n",
       " 'To identify the applicable emotions from the given classes, we\\'ll use a machine learning model that can classify emotions based on the input data. For simplicity, let\\'s use a basic implementation of the VADER sentiment analysis tool, which is a rule-based model for sentiment analysis.\\n\\n```python\\nimport numpy as np\\n\\n# Input data\\ninput_data = np.array([\\n    [-7.6270e-01,  2.4426e-01, -5.2521e-02,  3.7012e-01, -1.2672e-02,  1.2561e-01],\\n    #... (rest of the data)\\n])\\n\\n# Define the emotions classes\\nemotions_classes = {\\n    \\'anger\\': 0,\\n    \\'disgust\\': 1,\\n    \\'fear\\': 2,\\n   \\'sadness\\': 3,\\n   \\'surprise\\': 4,\\n    \\'joy\\': 5,\\n    \\'neutral\\': 6\\n}\\n\\n# Define the thresholds for each emotion class\\nthresholds = {\\n    \\'anger\\': 0.5,\\n    \\'disgust\\': 0.5,\\n    \\'fear\\': 0.5,\\n   \\'sadness\\': 0.5,\\n   \\'surprise\\': 0.5,\\n    \\'joy\\': 0.5,\\n    \\'neutral\\': 0.5\\n}\\n\\n# Classify each input data point\\nclassified_emotions = []\\nfor data_point in input_data:\\n    # Calculate the sentiment score\\n    sentiment_score = np.mean(data_point)\\n    \\n    # Check which emotion class the sentiment score belongs to\\n    classified_emotion = None\\n    for emotion, threshold in thresholds.items():\\n        if sentiment_score > threshold:\\n            classified_emotion = emotion\\n            break\\n    \\n    # If no emotion class was found, assign the \\'neutral\\' class\\n    if classified_emotion is None:\\n        classified_emotion = \\'neutral\\'\\n    \\n    # Append the classified emotion to the list\\n    classified_emotions.append([classified_emotion])\\n\\n# Print the classified emotions\\nprint(\"Emotions:\")\\nfor i, emotion in enumerate(classified_emotions):\\n    print(f\"Data point {i+1}: {emotion[0]}\")\\n```\\n\\nThis code will output the classified emotions for each data point in the input data. The output will be in the same format as in the examples you provided.\\n\\nPlease note that this is a simplified example and the actual implementation may require more complex machine',\n",
       " '{\"emotions\": [[\\'anger\\'], [\\'anger\\'], [\\'anger\\'], [\\'surprise\\'], [\\'anger\\',\\'sadness\\'], [\\'anger\\'], [\\'anger\\'], [\\'anger\\'], [\\'joy\\']]}\\n\\n\\nPlease note that the output is based on the provided input and the emotions classification model used. The actual output may vary depending on the specific model and implementation used.',\n",
       " 'This is a classification problem, and I\\'ll use a pre-trained Support Vector Machine (SVM) model to classify the input data into the specified emotions. \\n\\nBased on the input features, the model predicts the following emotions:\\n\\nOutput: {\"emotions\": [[\\'anger\\', \\'fear\\'], [\\'anger\\', \\'fear\\'], [\\'fear\\',\\'surprise\\'], [\\'fear\\'], [\\'anger\\'], [\\'fear\\'], [\\'surprise\\'], [\\'anger\\',\\'surprise\\'], [\\'anger\\',\\'surprise\\']]}\\n\\nNote that the output emotions are based on the classification of the input data, and the actual emotions may vary depending on the context and the specific features used in the classification model.',\n",
       " 'Based on the input provided, I will use a pre-trained emotion classification model to identify the applicable emotions. The output will be in the format {\"emotions\": [[\"emotion1\", \"emotion2\"], [\"emotion3\"]]}.\\n\\n```python\\nimport numpy as np\\nfrom sklearn.preprocessing import LabelEncoder\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.metrics import accuracy_score\\nfrom sklearn.ensemble import RandomForestClassifier\\nfrom sklearn.datasets import load_emotions\\n\\n# load the dataset\\nemotions = load_emotions()\\n\\n# define the features (X) and the target (y)\\nX = emotions.data\\ny = emotions.target\\n\\n# encode the target (y) using LabelEncoder\\nle = LabelEncoder()\\ny = le.fit_transform(y)\\n\\n# split the dataset into training and testing sets\\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\\n\\n# train a RandomForestClassifier on the training set\\nclf = RandomForestClassifier(n_estimators=100, random_state=42)\\nclf.fit(X_train, y_train)\\n\\n# make predictions on the testing set\\ny_pred = clf.predict(X_test)\\n\\n# evaluate the model\\naccuracy = accuracy_score(y_test, y_pred)\\nprint(\"Accuracy:\", accuracy)\\n\\n# predict the emotion for the given input\\ninput_emotion = np.array([-6.1963e-01,  2.2095e-01, -5.7812e-01,  3.1812e-01,  3.0078e-01, -2.9443e-01,\\n  6.4404e-01,  2.9736e-01, -5.5615e-01,  4.7827e-01,  3.1299e-01,  9.0881e-02,\\n  2.6245e-01, -3.7231e-01, -2.4872e-02, -3.0957e-01, -6.3037e-01,  1.4160e-01,\\n  7.9651e-02,  6.4148e-02,  6.0938e-01,  3.7567e-02,  2.8345e-01,  6.0254e-01,\\n  1.',\n",
       " \"To identify the applicable emotions, we need to use a machine learning model that can predict emotions based on the input features.\\n\\nBased on the input features, we can use a pre-trained emotion classification model. Here, I'll use a simplified example of a support vector machine (SVM) model for demonstration purposes.\\n\\n```python\\nimport numpy as np\\n\\n# Input features\\nX = np.array([\\n    [-4.7510e-01,  2.1667e-01, -3.1152e-01,  3.5620e-01,  7.5623e-02,  5.3284e-02,\\n     6.2988e-01, -3.4033e-01, -6.7627e-02, -4.5532e-02, 3.8867e-01, 1.0681e-01,\\n     4.6387e-01, -4.1748e-02, -3.2074e-02,  6.8909e-02, -3.5706e-02, -7.5928e-02,\\n     6.5857e-02, -3.7988e-01, -1.8713e-01, -4.4238e-01,  2.3303e-01,  5.7324e-01,\\n     -1.3794e-01,  2.2290e-01,  5.2490e-01, -5.7678e-02, -3.1006e-01,  4.4971e-01,\\n     -1.5784e-01,  7.7271e-02, -1.5613e-01, -2.4963e-01,  3.0688e-01,  3.8940e-01,\\n      2.5439e-01,  4.7900e-01,  3.0563e-02,  1.5222e-01,  2.5223e-02, -3.9038e-01,\\n      1.4473e-02, -7.0898e-01,  1.2262e-01,  \",\n",
       " '{\"emotions\": [[\\'anger\\'], [\\'anger\\',\\'surprise\\'], [\\'surprise\\', \\'joy\\'], [\\'anger\\', \\'disgust\\'], [\\'anger\\',\\'sadness\\'], [\\'anger\\'], [\\'anger\\'], [\\'anger\\'], [\\'anger\\']]}\\n\\n\\n{\"emotions\": [[\\'neutral\\'], [\\'fear\\',\\'surprise\\'], [\\'anger\\',\\'sadness\\'], [\\'anger\\',\\'sadness\\',\\'surprise\\'], [\\'neutral\\'], [\\'sadness\\',\\'surprise\\'], [\\'sadness\\',\\'surprise\\'], [\\'fear\\',\\'surprise\\'], [\\'anger\\'], [\\'anger\\', \\'joy\\']]}\\n\\n\\n{\"emotions\": [[\\'anger\\',\\'surprise\\'], [\\'anger\\',\\'sadness\\',\\'surprise\\'], [\\'fear\\',\\'sadness\\'], [\\'anger\\', \\'fear\\',\\'sadness\\'], [\\'surprise\\'], [\\'fear\\',\\'sadness\\'], [\\'anger\\', \\'fear\\'], [\\'anger\\',\\'surprise\\'], [\\'fear\\'], [\\'anger\\'], [\\'anger\\']]}\\n\\n\\nNote: The output for the third example and the input for classification are different from the output format. They should be adjusted to fit the output format specified.',\n",
       " '{\"emotions\": [[\\'neutral\\',\\'sadness\\']]}\\n\\nThis output indicates that the input data corresponds to the emotions \"neutral\" and \"sadness\".',\n",
       " 'Based on the input features, the predicted emotions are:\\n\\n{\"emotions\": [[\\'anger\\'], [\\'fear\\',\\'surprise\\'], [\\'sadness\\',\\'surprise\\'], [\\'anger\\'], [\\'anger\\',\\'surprise\\'], [\\'anger\\'], [\\'fear\\',\\'surprise\\']]}\\n\\nThese emotions correspond to the classes: \"anger\", \"fear\", \"surprise\", \"sadness\", \"anger\", \"surprise\", \"fear\"\\n\\nNote: The model has predicted the presence of multiple emotions for each input. The emotions are represented as a list of strings, where each string corresponds to a class label.',\n",
       " \"To classify the emotions, I'll use a pre-trained model. The model will classify the emotions based on the input feature vector.\\n\\nThe input feature vector is [-4.5215e-01  3.3154e-01 -7.0984e-02  2.8491e-01  7.4585e-02 -3.2397e-01  3.5425e-01 -1.9202e-01 -4.3115e-01 -1.5979e-01  4.4873e-01  7.9041e-02  1.0986e+00  3.0420e-01  1.6748e-01  2.4927e-01  1.4990e-01  8.3399e-04 -4.7516e-02 -4.5850e-01 -4.9438e-01 -3.8354e-01  4.1187e-01  3.0151e-01 -2.6154e-02  3.3618e-01  4.1675e-01 -1.7944e-01 -2.4121e-01  4.2969e-01 -2.0740e-01 -8.7280e-02  7.1335e-03 -2.5513e-01  3.8037e-01  2.4695e-01  4.3579e-01  2.8345e-01  2.4036e-01 -5.4260e-02  5.4565e-02 -2.7295e-01 -2.7563e-01 -1.7993e-01  1.6089e-01  8.3154e-01  3.1909e-01  1.4612e-01 -6.5552e-02  3.0981e-01  3.3813e-01 -1.1981e-01  1.3477e-01 -4.8340e-02  2.8540e-01 -2.5806e-01 \",\n",
       " '{\"emotions\": [[\\'sadness\\',\\'surprise\\']]}\\n\\nNote: The output is based on the input provided, which is a list of numerical values representing sentiment scores. The actual output may vary depending on the specific model or algorithm used for sentiment analysis.',\n",
       " 'After processing the input array, the identified emotions are:\\n\\n{\"emotions\": [[\\'anger\\'], [\\'neutral\\'], [\\'fear\\',\\'surprise\\'], [\\'fear\\',\\'sadness\\'], [\\'fear\\',\\'sadness\\'], [\\'surprise\\'], [\\'fear\\',\\'sadness\\'], [\\'fear\\',\\'surprise\\'], [\\'anger\\'], [\\'fear\\']]}\\n\\nThese emotions correspond to the following classes: \"anger\", \"neutral\", \"fear\", \"surprise\", \"fear\", \"sadness\", \"fear\", \"sadness\", \"fear\", \"surprise\", \"anger\", \"fear\".',\n",
       " 'To identify the applicable emotions from the given classes, I\\'ll use a pre-trained model. The output will be the most likely emotions and their corresponding probabilities.\\n\\n```python\\nfrom sklearn.preprocessing import StandardScaler\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.metrics import accuracy_score\\nfrom sklearn.neural_network import MLPClassifier\\nimport numpy as np\\n\\n# Define the emotions classes\\nemotions_classes = [\"anger\", \"disgust\", \"fear\", \"sadness\", \"surprise\", \"joy\", \"neutral\"]\\n\\n# Define the input and output data\\ninput_data = np.array([\\n    [-3.9844e-01,  6.0693e-01, -1.7627e-01,  3.9282e-01,  2.0093e-01, -1.1365e-01,\\n     5.0977e-01, -5.2539e-01, -2.2729e-01, -1.7746e-02,  5.0732e-01, -4.0985e-02,\\n     7.4365e-01,  2.1179e-01,  1.8274e-01, -7.2083e-02,  1.5312e-02,  3.9444e-03,\\n    -5.2765e-02,  7.5645e-03,  1.1009e-02, -2.3572e-01,  4.0210e-01,  3.9966e-01,\\n    -2.8491e-01,  3.1421e-01,  4.6509e-01,  2.6440e-01, -1.1023e-01,  7.5928e-01,\\n    -1.3110e-01, -1.0437e-01, -3.7744e-01, -4.3304e-02,  2.3413e-01,  2.9370e-01,\\n     3.3911e-01,  2.1362e-01, -1.4026e-01, -4.0234e-01,  5.590',\n",
       " 'After analyzing the input data, I would classify the emotions as follows:\\n\\n1. \"anger\" - [-2.2998e-01  5.6982e-01 -3.8501e-01  3.3154e-01  2.1875e-01 -1.3684e-01]\\n    * This input has a high value in the \"anger\" class.\\n\\n2. \"disgust\" - No strong indication of \"disgust\" in any of the inputs.\\n\\n3. \"fear\" - [-2.2998e-01  5.6982e-01 -3.8501e-01  3.3154e-01  2.1875e-01 -1.3684e-01]\\n    * This input has a high value in the \"fear\" class.\\n\\n4. \"sadness\" - [-2.2998e-01  5.6982e-01 -3.8501e-01  3.3154e-01  2.1875e-01 -1.3684e-01]\\n    * This input has a high value in the \"sadness\" class.\\n\\n5. \"surprise\" - [-2.2998e-01  5.6982e-01 -3.8501e-01  3.3154e-01  2.1875e-01 -1.3684e-01]\\n    * This input has a high value in the \"surprise\" class.\\n\\n6. \"joy\" - No strong indication of \"joy\" in any of the inputs.\\n\\n7. \"neutral\" - [-2.2998e-01  5.6982e-01 -3.8501e-01  3.3154e-01  2.1875e-01 -1.3684e-01]\\n    * This input has a high value in the \"neutral\" class.',\n",
       " 'Based on the input feature values, I will classify the emotions as follows:\\n\\n1. Input:\\n[-3.6108e-01  6.1816e-01 -1.4465e-01 -4.6539e-03  9.7290e-02 -2.0203e-01\\n  3.8672e-01 -3.7915e-01  5.4688e-02 -2.8735e-01  3.6328e-01  3.5919e-02\\n  4.3701e-01  1.1023e-01 -2.9251e-02  1.9128e-01  4.7424e-02  1.4526e-01\\n  1.3831e-01 -4.9219e-01 -8.7891e-01 -2.3697e-02  3.7915e-01  6.4795e-01\\n  8.3923e-02  3.5278e-01  5.2832e-01 -2.4622e-01 -1.4709e-01  2.9810e-01\\n -1.2256e-01 -9.1858e-02 -1.3867e-01 -3.4448e-01  1.8262e-01  8.1482e-02\\n  1.7468e-01  3.5620e-01 -6.5796e-02 -1.2396e-01  2.7002e-01 -3.8232e-01\\n -1.9666e-01 -1.7700e-01  1.0168e-01  1.3047e+00  3.2349e-01  4.8492e-02\\n -4.7754e-01  4.0796e-01  5.6152e-01 -2.1716e-01  3.5458e-03 -1.0260e-01\\n  2.1326e-01 -7.2632e-02  1.672',\n",
       " \"This problem cannot be solved with the given information. The input data is a list of numerical values, but the actual task is a classification task. To classify the input data, a machine learning model needs to be trained on a labeled dataset. The model should map the input data to the corresponding emotions.\\n\\nSince the model is not provided, we cannot determine which emotions are applicable to the given input data.\\n\\nHowever, I can provide a general solution for this type of problem using a machine learning model.\\n\\nHere is a sample code in Python using scikit-learn library for classification:\\n\\n```python\\n# Import necessary libraries\\nfrom sklearn.preprocessing import StandardScaler\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.neural_network import MLPClassifier\\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\\nimport pandas as pd\\n\\n# Load the dataset\\nemotions_data = pd.DataFrame({\\n    'anger': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\",\n",
       " \"The provided input data is a 2D array representing face features. To classify the emotions, we can use a pre-trained model such as the `face-api.js` library, which is a JavaScript library for face and emotion detection.\\n\\nHere's how you can classify the emotions using the provided input data:\\n\\n```javascript\\nconst faceapi = require('face-api.js');\\nconst model = faceapi.loadModel('models/face-api.js');\\n\\n// Define the input data\\nconst inputData = [\\n    // Input data for example 1\\n    [-4.5361e-01, 5.5371e-01, -2.0825e-01, 4.4434e-01, 8.8989e-02, -4.6387e-02,\\n     3.7280e-01, -1.6577e-01, -2.2192e-01, -2.0981e-02, 1.9727e-01, -1.1108e-01,\\n     8.0225e-01, 6.3965e-02, 1.6205e-02, -2.8183e-02, -2.8076e-01, -1.7407e-01,\\n     2.1472e-01, -4.5850e-01, -4.2419e-02, -3.8110e-01, 4.5898e-01, 6.8262e-01,\\n     8.6304e-02, 2.8516e-01, 5.4639e-01, -2.7515e-01, -1.2891e-01, 5.0146e-01,\\n    -1.6431e-01, 3.0762e-02, -9.3079e-02, -3.1689e-01, 2.0728e-01, 3.9087e-01,\\n     3.6011e-02, 2.4109e-01, 4.0161e-02, 3.4424e-01, 2.0618e-01, -4.2847e-01,\\n    -1.8750e-01, -3.4277e-01, \",\n",
       " 'To determine the applicable emotions, we need to classify the given input into one of the following classes: \"anger\", \"disgust\", \"fear\", \"sadness\", \"surprise\", \"joy\", \"neutral\"\\n\\nAfter analyzing the input, we can classify it as follows:\\n\\nThe input can be classified as \"neutral\"',\n",
       " \"To solve this problem, we will use a pre-trained emotion classification model. The model is trained on a dataset of text and corresponding emotions. We will use the `transformers` library in Python to load the model and make predictions.\\n\\n```python\\nimport pandas as pd\\nimport torch\\nfrom transformers import EmotionClassifier\\n\\n# Load the model\\nmodel = EmotionClassifier.from_pretrained('emotion-classifier')\\n\\n# Define the input data\\ninput_data = [\\n    [-6.1426e-01, 5.1514e-01, -1.0858e-01, 3.5278e-01, -6.8909e-02, -9.4055e-02],\\n    [-7.7100e-01, 4.5117e-01, -1.2744e-01, 2.0715e-01, 2.2852e-01, -3.6621e-01],\\n    [-7.1484e-01, 5.7764e-01, -2.0752e-01, 6.8787e-02, 2.7930e-01, 6.7261e-02],\\n    [-8.0469e-01, 7.2754e-01, -1.4160e-01, 2.9224e-01, 1.1395e-01, -2.2351e-01]\\n]\\n\\n# Define the function to classify emotions\\ndef classify_emotions(input_data):\\n    # Convert the input data to a DataFrame\\n    df = pd.DataFrame(input_data, columns=['anger', 'disgust', 'fear','sadness','surprise', 'joy', 'neutral'])\\n\\n    # Make predictions using the model\\n    outputs = model(df)\\n\\n    # Return the predicted emotions\\n    return outputs\\n\\n# Classify the emotions\\npredicted_emotions = classify_emotions(input_data)\\n\\n# Print the predicted emotions\\nprint(predicted_emotions)\\n```\\n\\nPlease note that this code assumes that the `EmotionClassifier` model is available in the `transformers` library. The model may not be available in the public version of the library, and you may need to use a custom model or modify the code to use a different model.\\n\\nAlso, note that the `EmotionClassifier` model is a hypothetical model and may not be a real model in the `transform\",\n",
       " 'The given input has 51 features but no target variable. Therefore, it\\'s not possible to train a model and make predictions. However, I can help you to identify the applicable emotions from the given classes.\\n\\nBased on the given features, the following emotions can be identified:\\n\\n```\\n{\"emotions\": [[\\'anger\\'], [\\'anger\\', \\'fear\\'], [\\'anger\\', \\'fear\\'], [\\'fear\\',\\'surprise\\'], [\\'fear\\'], [\\'anger\\'], [\\'fear\\'], [\\'surprise\\'], [\\'anger\\',\\'surprise\\']]]\\n```\\n\\nThese emotions can be identified because they are present in the given input. However, the actual classification depends on the target variable, which is not provided.\\n\\nHere is a sample code to classify the emotions using a machine learning model. In this example, I\\'m using a simple neural network.\\n\\n```python\\nimport numpy as np\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.neural_network import MLPClassifier\\nfrom sklearn.metrics import accuracy_score\\n\\n# Input features\\nX = np.array([[-2.5098e-01,  5.4590e-01, -1.7810e-01,  2.0020e-01,  1.8091e-01, -2.0605e-01,\\n  3.7671e-01, -3.4326e-01, -1.7212e-01, -2.1875e-01,  4.6924e-01,  1.6785e-01,\\n  7.0996e-01,  7.8979e-02,  5.0751e-02,  1.1969e-01, -6.4307e-01,  8.3399e-04,\\n  4.0771e-02, -6.8665e-02, -2.2595e-01, -3.8452e-02,  5.0049e-01,  5.7080e-01,\\n -3.3960e-01,  4.0503e-01,  4.8584e-01, -4.9103e-02, -1.0516e-01,  4.4507e-01,\\n -2.5879e-01, -6.3904e-',\n",
       " '{\"emotions\": [[\\'fear\\',\\'surprise\\'], [\\'anger\\', \\'disgust\\',\\'sadness\\'], [\\'fear\\',\\'surprise\\'], [\\'anger\\'], [\\'neutral\\'], [\\'fear\\']]}\\n\\nThis model is a classification model that uses a dataset of human emotions to predict the emotions of a given input. The model is trained to identify the presence or absence of different emotions in a given input, and the output is a list of the identified emotions.\\n\\nIn this case, the input is a list of numerical values representing the intensity of different emotions, and the output is a list of the identified emotions. The model has identified the following emotions in the input:\\n\\n* \\'fear\\' and\\'surprise\\' are both present in the input, with a high intensity for \\'fear\\' and a moderate intensity for\\'surprise\\'.\\n* \\'anger\\' and \\'disgust\\' are both present in the input, with a moderate intensity for \\'anger\\' and a low intensity for \\'disgust\\'.\\n*\\'sadness\\' is present in the input, with a low intensity.\\n* \\'joy\\' is not present in the input.\\n* \\'neutral\\' is present in the input, with a high intensity.\\n\\nNote that the model is only predicting the presence or absence of different emotions, and not the intensity of those emotions. Also, the model is not perfect and the results may vary depending on the input.',\n",
       " 'To classify the emotions in the given input, I will use a machine learning model that can predict the emotions from the features. Since the actual model is not provided, I will simulate the output of the classification model.\\n\\nThe input is classified into the following emotions:\\n\\n[\"anger\", \"disgust\"]\\n\\nThe model predicts that the input is associated with both \"anger\" and \"disgust\" emotions. \\n\\nNote: The actual output might vary based on the specific machine learning model used.',\n",
       " \"The emotions identified from the given input are:\\n\\n* 'anger','surprise'\\n* 'anger', 'disgust', 'joy'\\n* 'fear'\\n* 'fear','surprise'\\n* 'anger'\\n* 'neutral'\\n* 'fear'\\n* 'fear','sadness'\\n* 'fear'\",\n",
       " '{\"emotions\": [[\\'anger\\', \\'fear\\'], [\\'anger\\',\\'sadness\\'], [\\'anger\\', \\'fear\\',\\'surprise\\'], [\\'anger\\', \\'fear\\'], [\\'anger\\', \\'fear\\'], [\\'anger\\', \\'fear\\',\\'sadness\\'], [\\'anger\\', \\'fear\\'], [\\'anger\\', \\'fear\\',\\'surprise\\'], [\\'anger\\'], [\\'fear\\']]}\\n\\n\\nThis is the output for each example. The model is trained to predict a list of emotions for each input. The emotions are identified from the following classes: \"anger\", \"disgust\", \"fear\", \"sadness\", \"surprise\", \"joy\", \"neutral\".',\n",
       " 'To identify the applicable emotions from the given input, we need to use a machine learning model that can classify the input into one of the emotional categories. Here\\'s a possible approach:\\n\\n1. Use a library like scikit-learn to implement a machine learning model, such as a random forest classifier.\\n2. Train the model using a dataset of emotional expressions, where each expression is labeled with one or more emotions (e.g., \"anger\", \"disgust\", \"fear\", \"sadness\", \"surprise\", \"joy\", \"neutral\").\\n3. Once the model is trained, use it to predict the emotions associated with the input expression.\\n\\nHere\\'s a possible output:\\n\\nInput: [-5.5615e-01  2.4658e-01 -1.2708e-01  4.0503e-01 -1.1009e-02 -3.0078e-01...]\\n\\nOutput: {\"emotions\": [\\'anger\\', \\'disgust\\', \\'fear\\', \\'joy\\',\\'sadness\\',\\'surprise\\', \\'neutral\\']}\\n\\nHere\\'s a possible implementation in Python:\\n\\n```python\\nfrom sklearn.ensemble import RandomForestClassifier\\nfrom sklearn.preprocessing import StandardScaler\\nfrom sklearn.model_selection import train_test_split\\n\\n# Load the dataset of emotional expressions\\nimport pandas as pd\\ndf = pd.read_csv(\\'emotions.csv\\')\\n\\n# Define the features (X) and the target variable (y)\\nX = df.drop([\\'emotion\\'], axis=1).values\\ny = df[\\'emotion\\'].values\\n\\n# Scale the features using StandardScaler\\nscaler = StandardScaler()\\nX_scaled = scaler.fit_transform(X)\\n\\n# Split the data into training and testing sets\\nX_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\\n\\n# Train a random forest classifier on the training data\\nclf = RandomForestClassifier(n_estimators=100, random_state=42)\\nclf.fit(X_train, y_train)\\n\\n# Predict the emotions associated with the input expression\\ninput_expression = [-5.5615e-01, 2.4658e-01, -1.2708e-01, 4.0503e-01, -1.1009e-02, -3.0078e-01,...]\\ninput_expression_scaled = scaler.transform([input_expression])\\npredicted_emotions = clf.predict(input_expression_scaled)\\n\\nprint(predicted_emotions)\\n```\\n\\n',\n",
       " '{\"emotions\": [[\\'anger\\'], [\\'anger\\',\\'surprise\\']]}\\n\\nThe input features are classified into the emotions \"anger\" and \"anger/surprise\".',\n",
       " 'To classify the input, we will use a multi-label classification model that maps each input to multiple emotions. We will use a model that outputs the following emotions: \"anger\", \"disgust\", \"fear\", \"sadness\", \"surprise\", \"joy\", \"neutral\".\\n\\nThe model outputs the following emotions for the given input:\\n\\n{\"emotions\": [[\\'anger\\', \\'fear\\',\\'surprise\\'], [\\'anger\\', \\'disgust\\', \\'fear\\'], [\\'anger\\', \\'fear\\',\\'sadness\\'], [\\'anger\\',\\'surprise\\'], [\\'anger\\', \\'fear\\',\\'sadness\\'], [\\'anger\\', \\'disgust\\', \\'fear\\'], [\\'anger\\',\\'surprise\\'], [\\'anger\\', \\'fear\\',\\'sadness\\'], [\\'anger\\', \\'disgust\\', \\'fear\\'], [\\'anger\\', \\'fear\\',\\'sadness\\'], [\\'anger\\',\\'surprise\\'], [\\'anger\\', \\'fear\\',\\'sadness\\'], [\\'anger\\', \\'disgust\\', \\'fear\\'], [\\'anger\\', \\'fear\\',\\'sadness\\'], [\\'anger\\',\\'surprise\\'], [\\'anger\\', \\'disgust\\', \\'fear\\'], [\\'anger\\', \\'fear\\',\\'sadness\\'], [\\'anger\\',\\'surprise\\'], [\\'anger\\', \\'fear\\',\\'sadness\\'], [\\'anger\\', \\'disgust\\', \\'fear\\'], [\\'anger\\', \\'fear\\',\\'sadness\\'], [\\'anger\\',\\'surprise\\'], [\\'anger\\', \\'fear\\',\\'sadness\\'], [\\'anger\\', \\'disgust\\', \\'fear\\'], [\\'anger\\', \\'fear\\',\\'sadness\\'], [\\'anger\\',\\'surprise\\'], [\\'anger\\', \\'fear\\',\\'sadness\\'], [\\'anger\\', \\'disgust\\', \\'fear\\'], [\\'anger\\', \\'fear\\',\\'sadness\\'], [\\'anger\\',\\'surprise\\'], [\\'anger\\', \\'fear\\',\\'sadness\\'], [\\'anger\\', \\'disgust\\', \\'fear\\'], [\\'anger\\', \\'fear\\',\\'sadness\\'], [\\'anger\\',\\'surprise\\'], [\\'anger\\', \\'fear\\',\\'sadness\\'], [\\'anger\\', \\'disgust\\', \\'fear\\'], [\\'anger\\', \\'fear\\',\\'sadness\\'], [\\'anger\\',\\'surprise\\'], [\\'anger\\', \\'fear\\',\\'sadness\\'], [\\'anger\\', \\'disgust\\', \\'fear\\'], [\\'anger\\', \\'fear\\',\\'sadness\\'], [\\'anger\\',\\'surprise\\'], [\\'anger\\', \\'fear\\',\\'sadness',\n",
       " 'After analyzing the input, the identified applicable emotions are:\\n\\n{\"emotions\": [[\\'anger\\',\\'sadness\\']]}\\n\\nThis indicates that the input data corresponds to a combination of \"anger\" and \"sadness\" emotions.',\n",
       " '{\"emotions\": [[\\'anger\\'], [\\'fear\\',\\'surprise\\']]}\\n\\nNote: The input array for classification is a single row from the dataset. The output is a list of emotions that are most likely to be present in the input data.',\n",
       " 'Based on the input data, the emotions that are most relevant to the classification task are:\\n\\n```\\n{\"emotions\": [[\\'fear\\'], [\\'sadness\\'], [\\'fear\\',\\'sadness\\'], [\\'fear\\',\\'sadness\\'], [\\'fear\\',\\'sadness\\'], [\\'fear\\',\\'sadness\\'], [\\'sadness\\'], [\\'sadness\\'], [\\'sadness\\'], [\\'sadness\\'], [\\'sadness\\'], [\\'sadness\\']]]\\n```\\n\\nHowever, since the input data belongs to the \\'fear\\' emotion, the most relevant emotions to the classification task are:\\n\\n```\\n{\"emotions\": [[\\'fear\\'], [\\'sadness\\', \\'fear\\'], [\\'sadness\\', \\'fear\\'], [\\'sadness\\', \\'fear\\'], [\\'sadness\\', \\'fear\\'], [\\'sadness\\', \\'fear\\'], [\\'sadness\\', \\'fear\\'], [\\'sadness\\', \\'fear\\'], [\\'sadness\\', \\'fear\\'], [\\'sadness\\', \\'fear\\'], [\\'sadness\\', \\'fear\\'], [\\'sadness\\', \\'fear\\']]]\\n```\\n\\nBut since we are looking for the most relevant emotions that are not \\'fear\\', the output is:\\n\\n```\\n{\"emotions\": [[\\'sadness\\'], [\\'sadness\\', \\'fear\\'], [\\'sadness\\', \\'fear\\'], [\\'sadness\\', \\'fear\\'], [\\'sadness\\', \\'fear\\'], [\\'sadness\\', \\'fear\\'], [\\'sadness\\', \\'fear\\'], [\\'sadness\\', \\'fear\\'], [\\'sadness\\', \\'fear\\'], [\\'sadness\\', \\'fear\\'], [\\'sadness\\', \\'fear\\'], [\\'sadness\\', \\'fear\\']]]\\n```\\n\\nBut since we are looking for the most relevant emotions that are not \\'fear\\' and not\\'sadness\\', the output is:\\n\\n```\\n{\"emotions\": []}\\n```',\n",
       " 'This problem requires a machine learning model that can classify emotions based on the input data. The given data appears to be a dataset of numerical features that correspond to different emotions.\\n\\nTo solve this problem, we can use a machine learning library such as scikit-learn and TensorFlow. We can train a classifier on the given data to predict the emotions.\\n\\nHere is a possible solution:\\n\\n```python\\nimport pandas as pd\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.preprocessing import StandardScaler\\nfrom sklearn.ensemble import RandomForestClassifier\\nfrom sklearn.metrics import classification_report, confusion_matrix\\nfrom sklearn.model_selection import GridSearchCV\\nfrom sklearn import svm\\nfrom sklearn.svm import SVC\\nfrom sklearn.model_selection import cross_val_score\\nimport numpy as np\\n\\n# Load the data\\ndata = pd.read_csv(\"emotion_data.csv\")\\n\\n# Define the features and the target variable\\nX = data.drop([\\'emotion\\'], axis=1)\\ny = data[\\'emotion\\']\\n\\n# Split the data into training and test sets\\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\\n\\n# Scale the features\\nscaler = StandardScaler()\\nX_train_scaled = scaler.fit_transform(X_train)\\nX_test_scaled = scaler.transform(X_test)\\n\\n# Train a random forest classifier\\nrfc = RandomForestClassifier(n_estimators=100, random_state=42)\\nrfc.fit(X_train_scaled, y_train)\\n\\n# Evaluate the classifier\\ny_pred = rfc.predict(X_test_scaled)\\nprint(\"Classification Report:\")\\nprint(classification_report(y_test, y_pred))\\nprint(\"Confusion Matrix:\")\\nprint(confusion_matrix(y_test, y_pred))\\n\\n# Define the emotion classes\\nemotion_classes = [\"anger\", \"disgust\", \"fear\", \"sadness\", \"surprise\", \"joy\", \"neutral\"]\\n\\n# Define the input data for classification\\ninput_data = [[-6.2939, 5.8350, 8.9966, -1.4722, 5.3131, -1.7651, 7.5928, -4.6825, -3.4253, -7.2937, 3.9307, 1.9180, 5.8740, 1.2988, 1.5674, -2.3877, -3.1299, -3.7476, 4.8523, -5.6519, -1.',\n",
       " 'The input provided is a list of feature vectors that represent various emotions. The emotions are classified into the following categories: \"anger\", \"disgust\", \"fear\", \"sadness\", \"surprise\", \"joy\", \"neutral\".\\n\\nTo identify the applicable emotions for the given input, we can use a machine learning model that is trained on the Emotion Recognition dataset. However, without access to the training data and the model, we can provide a general solution.\\n\\nHere\\'s a Python solution using the scikit-learn library and a DecisionTreeClassifier:\\n\\n```python\\nimport numpy as np\\nfrom sklearn.tree import DecisionTreeClassifier\\n\\n# Define the emotion classification problem\\nemotions = {\\n    \\'anger\\': 0,\\n    \\'disgust\\': 1,\\n    \\'fear\\': 2,\\n   \\'sadness\\': 3,\\n   \\'surprise\\': 4,\\n    \\'joy\\': 5,\\n    \\'neutral\\': 6\\n}\\n\\n# Define the input feature vectors\\ninput_vectors = [\\n    [-2.6636e-01,  3.8696e-01, -4.0161e-02,  3.4863e-01, -2.2192e-01, 1.7685e-02],\\n    [-2.6636e-01,  3.8696e-01, -4.0161e-02,  3.4863e-01, -2.2192e-01, 1.7685e-02],\\n    [-2.6636e-01,  3.8696e-01, -4.0161e-02,  3.4863e-01, -2.2192e-01, 1.7685e-02],\\n    [-3.7744e-01,  3.8721e-01,  1.4905e-01,  1.8359e-01,  1.5503e-01, 2.0984e-01],\\n    # Add more input vectors as needed\\n]\\n\\n# Define the corresponding emotion labels\\nlabels = [emotions[\\'anger\\'], emotions[\\'anger\\'], emotions[\\'anger\\'], emotions[\\'anger\\'], emotions[\\'anger\\']]\\n\\n# Create a DecisionTreeClassifier\\nclf = DecisionTreeClassifier()\\n\\n# Train the classifier using the labeled data\\nclf.fit(input_vectors, labels)\\n\\n# Use the trained classifier',\n",
       " 'To identify the emotions in the given input, we can use a pre-trained emotion classification model. Let\\'s use the following code to classify the emotions:\\n\\n```python\\nimport numpy as np\\nfrom sklearn.preprocessing import StandardScaler\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.metrics import accuracy_score\\nfrom sklearn.ensemble import RandomForestClassifier\\nfrom sklearn.datasets import load_emotions\\n\\n# Load the dataset\\nemotions = load_emotions()\\n\\n# Define the feature matrix X and the target vector y\\nX = emotions.data\\ny = emotions.target\\n\\n# Scale the feature matrix X\\nscaler = StandardScaler()\\nX_scaled = scaler.fit_transform(X)\\n\\n# Split the dataset into training and test sets\\nX_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\\n\\n# Train a random forest classifier on the training data\\nclassifier = RandomForestClassifier(n_estimators=100, random_state=42)\\nclassifier.fit(X_train, y_train)\\n\\n# Make predictions on the test data\\ny_pred = classifier.predict(X_test)\\n\\n# Evaluate the model\\naccuracy = accuracy_score(y_test, y_pred)\\nprint(f\"Model accuracy: {accuracy:.3f}\")\\n\\n# Define the input for classification\\ninput_vector = np.array([-4.7632e-01,  4.5190e-01, -1.9211e-02,  1.9519e-01, -5.2063e-02, -4.0649e-02,\\n  5.0293e-01, -1.3245e-01, -2.5977e-01, -1.1383e-01,  4.8364e-01, -5.8563e-02,\\n  8.7451e-01,  7.5317e-02,  1.7639e-01,  8.2825e-02,  4.2749e-01, -5.5511e-02,\\n -3.5156e-02, -2.7588e-02, -5.1270e-02, -2.7563e-01,  1.8945e-01,  6.3770e-01,\\n -5.1465e-01,  5.1270e-01,  6.',\n",
       " 'The input is a list of 512 features (a 1D array) representing the input data. However, the code snippet provided does not specify the classification model to be used for the input data. \\n\\nBased on the output format, it seems that the model is expected to return a dictionary with a key \"emotions\" containing a list of emotions corresponding to the input data.\\n\\nFor the given input data, I will use a simple neural network model to classify the emotions. The model is trained on a dataset of labeled emotions and is able to predict the emotions of the input data.\\n\\nHere is the Python code to classify the emotions:\\n\\n```python\\nimport numpy as np\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.preprocessing import StandardScaler\\nfrom sklearn.neural_network import MLPClassifier\\nfrom sklearn.metrics import accuracy_score\\nfrom sklearn.decomposition import PCA\\n\\n# Load the dataset\\nfrom sklearn.datasets import load_emotions\\nemotions_data = load_emotions()\\nX = emotions_data.data\\ny = emotions_data.target\\n\\n# Split the data into training and testing sets\\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\\n\\n# Scale the data using StandardScaler\\nscaler = StandardScaler()\\nX_train_scaled = scaler.fit_transform(X_train)\\nX_test_scaled = scaler.transform(X_test)\\n\\n# Use PCA to reduce the dimensionality of the data\\npca = PCA(n_components=0.95)\\nX_train_pca = pca.fit_transform(X_train_scaled)\\nX_test_pca = pca.transform(X_test_scaled)\\n\\n# Train a Multilayer Perceptron Classifier on the training data\\nmlp = MLPClassifier(hidden_layer_sizes=(100,), max_iter=1000, learning_rate_init=0.01, random_state=42)\\nmlp.fit(X_train_pca, y_train)\\n\\n# Make predictions on the test data\\ny_pred = mlp.predict(X_test_pca)\\n\\n# Evaluate the performance of the model\\naccuracy = accuracy_score(y_test, y_pred)\\nprint(\"Model Accuracy:\", accuracy)\\n\\n# Define a function to classify emotions\\ndef classify_emotions(input_data):\\n    # Scale and transform the input data using PCA\\n    input_data_scaled = scaler.transform(input_data.reshape(1, -1))\\n    input_data_pca = pca.transform(input_data_scaled)\\n    \\n    # Make predictions on the input data\\n    emotions = mlp.predict(input_data_pca)\\n    \\n    return emotions[0]\\n\\n# Class',\n",
       " \"To identify the applicable emotions from the given classes, we need to train a machine learning model to classify the emotions. However, since the model is not provided, I will use a simple approach to classify the emotions based on the input features.\\n\\nFirst, we need to normalize the input features to have a similar scale. We can use the `MinMaxScaler` from scikit-learn to achieve this.\\n\\n```python\\nfrom sklearn.preprocessing import MinMaxScaler\\nimport numpy as np\\n\\n# Input features\\ninput_features = np.array([\\n    [-5.0000e-01,  3.9844e-01,  4.1008e-03,  2.1045e-01, -1.6064e-01,  1.6736e-01],\\n    [-4.1187e-01,  2.5879e-01, -1.3153e-02,  3.0859e-01,  1.4124e-01,  2.4084e-01],\\n    [-3.5254e-01,  3.4839e-01,  2.2125e-02,  4.5776e-01,  2.2018e-02,  1.3159e-01],\\n    # Add more input features here\\n])\\n\\n# Normalize the input features\\nscaler = MinMaxScaler()\\nnormalized_features = scaler.fit_transform(input_features)\\n```\\n\\nNow, we need to train a machine learning model to classify the emotions. We can use a simple classification model like logistic regression or decision tree.\\n\\n```python\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.linear_model import LogisticRegression\\nfrom sklearn.tree import DecisionTreeClassifier\\n\\n# Train a logistic regression model\\nX_train, X_test, y_train, y_test = train_test_split(normalized_features[:, :-1], normalized_features[:, -1], test_size=0.2, random_state=42)\\nlogreg = LogisticRegression()\\nlogreg.fit(X_train, y_train)\\n\\n# Train a decision tree classifier\\nX_train, X_test, y_train, y_test = train_test_split(normalized_features[:, :-1], normalized_features[:, -1], test_size=0.2, random_state=42)\\ndt = DecisionTreeClassifier()\\ndt.fit(X_train, y_train)\\n\\n# Predict the emotions\\nemotion_classes = ['anger', 'disgust\",\n",
       " \"This model is unable to classify the input emotions without the specific model architecture and training data. However, I can guide you through a general approach to classify emotions based on the input data.\\n\\nTo classify emotions, you can use a machine learning model such as a neural network or a support vector machine (SVM) with the input data and the corresponding emotion labels. The goal is to train the model to learn the patterns and relationships between the input data and the emotions.\\n\\nHere's a basic example of how you can classify emotions using a neural network in Python:\\n\\n```python\\nimport numpy as np\\nimport pandas as pd\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.preprocessing import StandardScaler\\nfrom sklearn.neural_network import MLPClassifier\\nfrom sklearn.metrics import accuracy_score, classification_report\\n\\n# Load the input data and corresponding emotion labels\\nemotion_data = np.array([\\n    # Input data for example 1\\n    [-3.6572e-01,  4.0039e-01, -6.3721e-02,  2.8369e-01, -2.9922e-02, -8.3313e-02,\\n     2.6611e-01,  6.6895e-02,  1.9763e-01, -1.7725e-01,  3.9990e-01, -6.7688e-02,\\n     -8.7952e-02,  2.0920e-02,  1.6418e-01, -1.5308e-01,  3.4521e-01,  7.9224e-02,\\n     -4.7302e-02,  2.7368e-01,  8.9111e-02, -2.4036e-01,  2.6465e-01,  8.7158e-01,\\n     -2.6416e-01,  3.7329e-01,  7.2559e-01,  5.2460e-02,  1.6577e-01,  4.3164e-01,\\n     -3.7744e-01, -3.9551e-01, -2.1286e-02,  1.1035e\",\n",
       " 'The input vector does not directly correspond to any of the examples provided. However, we can classify the emotions of the input vector based on the given classes: \"anger\", \"disgust\", \"fear\", \"sadness\", \"surprise\", \"joy\", \"neutral\".\\n\\nHere is the classification:\\n\\n1. \"anger\": 0.013 (low probability)\\n2. \"disgust\": 0.001 (low probability)\\n3. \"fear\": 0.019 (low probability)\\n4. \"sadness\": 0.026 (low probability)\\n5. \"surprise\": 0.013 (low probability)\\n6. \"joy\": 0.037 (low probability)\\n7. \"neutral\": 0.913 (high probability)\\n\\nThe input vector is most likely classified as \"neutral\" with a probability of 0.913.',\n",
       " 'To identify the applicable emotions from the given classes, we can use the input data and the class labels to train a machine learning model. Here\\'s an example of how we can do this using Python and the scikit-learn library:\\n\\n```python\\nimport numpy as np\\nfrom sklearn.preprocessing import LabelEncoder\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.linear_model import LogisticRegression\\nfrom sklearn.metrics import accuracy_score\\n\\n# Define the input data and class labels\\nX = np.array([\\n    [-3.3691e-01, 3.5938e-01, -1.2077e-02, 2.1887e-01, 1.5686e-01, -8.9966e-02],\\n    [-4.8169e-01, -1.9568e-01, 1.3159e-01, -5.7556e-02, 1.4124e-01, 3.4961e-01],\\n    #... (other data points)\\n])\\n\\ny = np.array([\\n    [\"anger\", \"disgust\", \"fear\", \"sadness\", \"surprise\", \"joy\", \"neutral\"],\\n    [\"anger\", \"disgust\", \"fear\", \"sadness\", \"surprise\", \"joy\", \"neutral\"],\\n    #... (other class labels)\\n])\\n\\n# Map the class labels to numerical values using LabelEncoder\\nle = LabelEncoder()\\ny = le.fit_transform(y)\\n\\n# Split the data into training and testing sets\\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\\n\\n# Train a logistic regression model on the training data\\nmodel = LogisticRegression()\\nmodel.fit(X_train, y_train)\\n\\n# Make predictions on the testing data\\ny_pred = model.predict(X_test)\\n\\n# Evaluate the model\\'s performance using accuracy score\\naccuracy = accuracy_score(y_test, y_pred)\\nprint(f\"Model accuracy: {accuracy:.3f}\")\\n\\n# Define a function to identify applicable emotions from the given classes\\ndef identify_emotions(data_point, classes):\\n    # Make predictions on the data point\\n    prediction = model.predict(np.array([data_point]))\\n    \\n    # Map the predicted numerical value back to the corresponding class label\\n    predicted_class = le.inverse_transform(prediction)[0]\\n    \\n    # Check if the predicted class is in the given classes\\n    if predicted_class in classes',\n",
       " 'To solve this problem, we can use the following Python code using the `sklearn` library for the classification model and the `numpy` library for numerical operations.\\n\\n```python\\nimport numpy as np\\nfrom sklearn.preprocessing import LabelEncoder\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.linear_model import LogisticRegression\\nfrom sklearn.metrics import accuracy_score\\n\\n# Define the input data\\nX = np.array([\\n    [-5.9326e-01, 2.3743e-01, 1.5472e-02, 3.0054e-01, -1.7004e-01, -2.4792e-01],\\n    [4.5264e-01, 1.9302e-02, -6.7627e-01, -1.8054e-01, 4.4604e-01, 1.1920e-01],\\n    [5.5664e-01, -4.6204e-02, -7.0572e-03, -7.1655e-02, 4.7095e-01, 2.2571e-01],\\n    # Add more data here...\\n])\\n\\n# Define the output data\\ny = np.array([\\n    [\"anger\", \"disgust\", \"fear\", \"sadness\", \"surprise\", \"joy\", \"neutral\"],\\n    [\"anger\", \"disgust\", \"fear\", \"sadness\", \"surprise\", \"joy\", \"neutral\"],\\n    [\"anger\", \"disgust\", \"fear\", \"sadness\", \"surprise\", \"joy\", \"neutral\"],\\n    # Add more data here...\\n])\\n\\n# Define the emotions to classify\\nemotions = [\"anger\", \"disgust\", \"fear\", \"sadness\", \"surprise\", \"joy\", \"neutral\"]\\n\\n# One-hot encode the emotions\\nle = LabelEncoder()\\ny_encoded = le.fit_transform(y)\\ny_encoded = np.eye(len(emotions))[y_encoded]\\n\\n# Split the data into training and testing sets\\nX_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\\n\\n# Train a logistic regression model\\nmodel = LogisticRegression()\\nmodel.fit(X_train, y_train)\\n\\n# Make predictions on the test set\\ny_pred = model.predict(X_test)\\n\\n# Evaluate the model\\'s performance\\naccuracy = accuracy',\n",
       " 'To identify the applicable emotions from the given classes, we can use the input values and map them to the corresponding emotions. We will use a threshold value to determine the presence or absence of each emotion.\\n\\n```python\\nimport numpy as np\\n\\n# Define the input values\\ninput_values = np.array([\\n    [-5.7275e-01, 3.9551e-01, -8.7158e-02, 3.8696e-01, -7.2144e-02, 6.2195e-02,\\n     3.4814e-01, -3.7933e-02, -2.4866e-01, 4.0405e-02, 4.9414e-01, 1.2646e-01,\\n     4.3213e-01, -1.2549e-01, -1.2311e-01, -2.7197e-01, 6.2012e-01, 9.8938e-02,\\n     -1.4685e-01, -3.0493e-01, -3.7628e-02, -2.7368e-01, 1.7126e-01, 6.5479e-01,\\n     -1.9958e-01, 5.1025e-02, 6.3965e-01, 3.3643e-01, -1.4124e-01, 7.0996e-01,\\n     -4.9585e-01, -2.3645e-01, 6.6414e-03, -6.5186e-02, -9.5093e-02, 4.5728e-01,\\n     3.5962e-01, 1.4307e-01, 8.8074e-02, 1.9238e-01, 3.0835e-01, -5.3076e-01,\\n     2.2192e-01, -2.6025e-01, 1.0016e-01, 7.9688e-01, -9.3689e-02, -1.2891e-01,\\n     -9.7229e-02, 2',\n",
       " \"This problem appears to be a classification task using a pre-trained model. The model is expected to take the input array and return the most relevant emotions from the given classes.\\n\\nTo solve this problem, we would need to implement a classification model and train it on a suitable dataset. Then, we would use the trained model to predict the emotions for the given input array.\\n\\nHowever, since the provided code is in Python, I'll provide a solution using a pre-trained model like the one used in the original examples. \\n\\n```python\\nimport numpy as np\\n\\n# Define the input array\\ninput_array = np.array([\\n    -1.5027e-01,  4.1565e-02,  9.9365e-02,  4.4849e-01,  2.8458e-02,  1.7310e-01,\\n    2.5024e-01,  5.5176e-02, -2.4765e-02,  1.6418e-01,  5.2295e-01, -7.3730e-02,\\n    4.5703e-01, -1.8274e-01,  2.9736e-01, -2.3572e-01,  2.1521e-01,  1.0376e-01,\\n    -2.5366e-01, -3.4644e-01, -3.6285e-02,  1.3843e-01, -2.3840e-01,  2.8125e-01,\\n    -6.1865e-01,  4.3701e-01,  3.0029e-01, -7.0435e-02, -1.8677e-01,  2.3389e-01,\\n    -2.1851e-01,  2.2308e-02,  1.5857e-01, -3.4204e-01, -2.3071e-02,  5.0537e-01,\\n    4.0552e-01,  2.7881e-01, -2.3865e-01,  3.2422e-01, \",\n",
       " 'To classify the emotions from the given input, we need to use a suitable algorithm that can classify the given input into one of the specified emotion classes (\"anger\", \"disgust\", \"fear\", \"sadness\", \"surprise\", \"joy\", \"neutral\").\\n\\nHere is a simple neural network model in Python using the Keras library to classify the input emotions:\\n\\n```python\\nimport numpy as np\\nfrom keras.models import Sequential\\nfrom keras.layers import Dense\\nfrom keras.utils import to_categorical\\nfrom sklearn.preprocessing import LabelEncoder\\n\\n# Define the emotions\\nemotions = [\"anger\", \"disgust\", \"fear\", \"sadness\", \"surprise\", \"joy\", \"neutral\"]\\n\\n# Define the input features\\ninput_features = np.array([\\n    [-4.6069e-01,  3.4863e-01,  1.3293e-01,  2.7100e-01, -3.3997e-02,  1.0187e-01],\\n    [-3.1470e-01,  2.3755e-01,  4.0771e-02,  2.2681e-01, -4.8615e-02, -1.0510e-01],\\n    [-4.3604e-01,  3.4302e-01,  1.1584e-01,  1.1127e-01, -7.1838e-02,  9.2224e-02]\\n])\\n\\n# Define the corresponding class labels\\nclass_labels = np.array([[\"anger\", \"sadness\"], [\"anger\"], [\"anger\", \"sadness\"], [\"anger\", \"sadness\"]])\\n\\n# Define the function to convert class labels to numerical values\\ndef class_label_to_num(class_label):\\n    emotions = [\"anger\", \"disgust\", \"fear\", \"sadness\", \"surprise\", \"joy\", \"neutral\"]\\n    encoder = LabelEncoder()\\n    encoder.fit(emotions)\\n    return encoder.transform([class_label])[0]\\n\\n# Convert class labels to numerical values\\nclass_labels_num = np.array([class_label_to_num(label) for label in class_labels.flatten()])\\n\\n# Define the neural network model\\nmodel = Sequential()\\nmodel.add(Dense(64, input_dim=6, activation=\\'relu\\'))\\nmodel.add(Dense(64, activation=\\'relu\\'))\\nmodel.add(Dense(7,',\n",
       " 'To classify the input data, we need to define the classification model and the applicable emotions. \\n\\nAssuming we are using a predefined classification model that can identify the following emotions: \"anger\", \"disgust\", \"fear\", \"sadness\", \"surprise\", \"joy\", \"neutral\".\\n\\n```python\\nimport numpy as np\\nfrom sklearn.preprocessing import LabelEncoder\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.linear_model import LogisticRegression\\n\\n# Input data\\ninput_data = np.array([\\n    [-6.3672e-01,  4.7192e-01,  1.4343e-01,  4.1528e-01, -1.2213e-01,  1.9421e-01,\\n     4.3140e-01,  1.6266e-02, -4.3774e-01, -1.3416e-01,  5.0098e-01,  1.4661e-01,\\n     5.6738e-01, -2.0471e-01,  7.9285e-02, -2.4731e-01,  4.8633e-01, -1.9531e-03,\\n     -3.7872e-02, -3.8696e-01, -8.4534e-02, -4.7314e-01,  1.5027e-01,  5.6543e-01,\\n     -3.4985e-01,  3.2861e-01,  4.9780e-01,  1.4697e-01,  1.2512e-01,  6.0596e-01,\\n     -3.9062e-01, -4.7510e-01,  1.4392e-01, -1.7371e-01, -1.1560e-01,  4.1357e-01,\\n     3.4717e-01,  2.2437e-01, -3.5461e-02,  2.9077e-01,  4.5532e-01, -2.8491e-01,\\n     1',\n",
       " 'To identify the applicable emotions from the given classes (\"anger\", \"disgust\", \"fear\", \"sadness\", \"surprise\", \"joy\", \"neutral\"), we can use the following emotions that are present in the given input arrays:\\n\\nExample 1:\\n[-5.1416e-01  3.5181e-01  2.8717e-02  5.4590e-01  2.1790e-01 -3.2202e-01\\n  4.4214e-01  6.2286e-02  6.7200e-02 -9.8877e-02  4.0405e-01 -9.1675e-02\\n  2.3218e-01 -1.5674e-01 -2.6855e-02 -3.3032e-01 -2.5464e-01  1.2781e-01\\n  3.2654e-02  4.5990e-02  2.9678e-02 -2.1619e-01  4.2334e-01  5.3613e-01\\n -1.6992e-01  4.1675e-01  7.1289e-01  3.3911e-01  1.2634e-01  3.0078e-01\\n -3.3911e-01 -4.2236e-01  2.4979e-02 -3.7207e-01  3.8501e-01  3.4082e-01\\n  1.3892e-01  3.6597e-01 -1.4746e-01  1.5051e-01  3.2861e-01 -3.2861e-01\\n  1.0431e-01 -6.5979e-02  2.1143e-01  8.2959e-01 -1.2299e-01  6.3232e-02\\n -2.3608e-01  2.3621e-01 -9.8816e-02  1.8021e-02 ',\n",
       " 'To identify the applicable emotions, I\\'ll use a machine learning model that can classify the input data into the given classes. The model I\\'ll use is a deep neural network with multiple layers, which can learn the complex relationships between the input features and the output classes.\\n\\nHere\\'s the output of the model:\\n\\n```\\n{\"emotions\": [[\\'anger\\', \\'fear\\'], [\\'anger\\'], [\\'fear\\',\\'sadness\\'], [\\'surprise\\'], [\\'sadness\\'], [\\'fear\\',\\'sadness\\'], [\\'sadness\\'], [\\'disgust\\'], [\\'anger\\'], [\\'surprise\\'], [\\'joy\\'], [\\'neutral\\'], [\\'fear\\',\\'sadness\\'], [\\'anger\\',\\'sadness\\'], [\\'anger\\',\\'sadness\\'], [\\'anger\\',\\'sadness\\'], [\\'sadness\\'], [\\'sadness\\'], [\\'sadness\\'], [\\'sadness\\'], [\\'sadness\\'], [\\'sadness\\'], [\\'sadness\\'], [\\'sadness\\'], [\\'sadness\\'], [\\'sadness\\'], [\\'sadness\\'], [\\'sadness\\'], [\\'sadness\\'], [\\'sadness\\'], [\\'sadness\\'], [\\'sadness\\'], [\\'sadness\\'], [\\'sadness\\'], [\\'sadness\\'], [\\'sadness\\'], [\\'sadness\\'], [\\'sadness\\'], [\\'sadness\\'], [\\'sadness\\'], [\\'sadness\\'], [\\'sadness\\'], [\\'sadness\\'], [\\'sadness\\'], [\\'sadness\\'], [\\'sadness\\'], [\\'sadness\\'], [\\'sadness\\'], [\\'sadness\\'], [\\'sadness\\'], [\\'sadness\\'], [\\'sadness\\']]}\\n\\n```\\n\\nNote that the output is a list of lists, where each sublist contains the applicable emotions for a particular input data point. The emotions are represented as strings, and the order of the emotions in each sublist is not necessarily significant.\\n\\nAlso, please note that the output may contain emotions that are not explicitly listed in the input data. This is because the model can learn to recognize patterns and relationships between the input features and the output classes, even if the specific emotions are not explicitly mentioned.',\n",
       " 'To classify the emotions, we can use a machine learning model such as a neural network. We will use the following code to classify the emotions:\\n\\n```python\\nimport numpy as np\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.neural_network import MLPClassifier\\nfrom sklearn.metrics import accuracy_score\\n\\n# Define the classes\\nclasses = [\"anger\", \"disgust\", \"fear\", \"sadness\", \"surprise\", \"joy\", \"neutral\"]\\n\\n# Define the input and output data\\nX = np.array([\\n    [-2.2937e-01,  4.3311e-01,  8.1360e-02,  1.4038e-01,  9.3201e-02,  1.6907e-02],\\n    [-4.2773e-01,  1.1792e-01,  3.8135e-01, -4.9585e-01,  4.4403e-02,  1.8970e-01],\\n    # Add more data here\\n])\\n\\ny = np.array([\"anger\", \"disgust\", \"fear\", \"sadness\", \"surprise\", \"joy\", \"neutral\"])\\n\\n# Split the data into training and testing sets\\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\\n\\n# Create a neural network classifier\\nmlp = MLPClassifier(hidden_layer_sizes=(10,), max_iter=1000, learning_rate_init=0.01, random_state=42)\\n\\n# Train the model\\nmlp.fit(X_train, y_train)\\n\\n# Make predictions\\ny_pred = mlp.predict(X_test)\\n\\n# Evaluate the model\\nprint(\"Accuracy:\", accuracy_score(y_test, y_pred))\\n\\n# Classify the input\\ninput_data = np.array([-2.2937e-01,  4.3311e-01,  8.1360e-02,  1.4038e-01,  9.3201e-02,  1.6907e-02])\\nprediction = mlp.predict([input_data])\\n\\nprint(\"Applicable emotions:\", prediction)\\n```\\n\\nThis code defines a simple neural network with one hidden layer and trains it on the provided data. It then makes predictions on the test data and evaluates the model\\'s accuracy. Finally,',\n",
       " 'Unfortunately, due to the complexity of the code involved in this task, I am unable to provide a direct code solution. However, I can provide a general approach on how to achieve this:\\n\\n1. **Data Preprocessing**: The input data seems to be in a numerical format, likely representing the output of some machine learning model. We need to preprocess this data to make it suitable for classification. This may involve scaling, normalization, or feature engineering.\\n\\n2. **Model Selection**: Based on the input data, it appears to be a classification problem. We need to select a suitable machine learning model that can classify the input data into the desired emotions (anger, disgust, fear, sadness, surprise, joy, neutral).\\n\\n3. **Model Training**: Train the selected model using a suitable dataset. This dataset should contain the input features (numerical values) and the corresponding labels (emotions).\\n\\n4. **Model Evaluation**: Evaluate the trained model on a separate test dataset to ensure it\\'s performing well.\\n\\n5. **Prediction**: Use the trained model to classify the input data into the desired emotions.\\n\\nHere is a simple code example using Python and the popular scikit-learn library, assuming the input data is already preprocessed:\\n\\n```python\\nimport numpy as np\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.preprocessing import StandardScaler\\nfrom sklearn.linear_model import LogisticRegression\\nfrom sklearn.metrics import accuracy_score, classification_report\\n\\n# Assuming X is the input data and y is the corresponding labels\\nX = np.array([...])  # Input data\\ny = np.array([...])  # Corresponding labels\\n\\n# Split the data into training and testing sets\\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\\n\\n# Standardize features\\nscaler = StandardScaler()\\nX_train_scaled = scaler.fit_transform(X_train)\\nX_test_scaled = scaler.transform(X_test)\\n\\n# Train a logistic regression model\\nmodel = LogisticRegression(max_iter=1000)\\nmodel.fit(X_train_scaled, y_train)\\n\\n# Make predictions\\ny_pred = model.predict(X_test_scaled)\\n\\n# Evaluate the model\\nprint(\"Accuracy:\", accuracy_score(y_test, y_pred))\\nprint(\"Classification Report:\")\\nprint(classification_report(y_test, y_pred))\\n```\\n\\nTo classify the input data (`[-4.0308e-01, 4.8608e-01, -1.7838e-02,...]`), we need to use the trained',\n",
       " \"In order to solve this problem, we need to know the mapping between the input features (e.g., [-3.7744e-01, 3.8721e-01,...]) and the output emotions (e.g., ['anger', 'fear',...]). However, the mapping is not provided in the problem statement.\\n\\nTo provide a solution, I will assume that the input features are a representation of a person's facial expression, and the output emotions are the corresponding emotional states.\\n\\nHere is one possible solution:\\n\\n```python\\nimport numpy as np\\n\\n# Define the input features and their corresponding output emotions\\ninput_features = np.array([\\n    [-3.7744e-01, 3.8721e-01, 1.4905e-01, 1.8359e-01, 1.5503e-01, 2.0984e-01,\\n     1.1426e-01, -1.0400e-01, -3.0444e-01, -2.0605e-01, 6.6797e-01, 6.7566e-02,\\n     6.6064e-01, 5.1697e-02, 2.2253e-01, 1.7075e-02, 8.7708e-02, 4.5386e-01,\\n     -2.0557e-01, -1.5576e-01, -1.1365e-01, -3.4473e-01, -6.4148e-02, 3.1055e-01],\\n    [-4.4873e-01, 4.1724e-01, 1.0803e-01, 3.7109e-01, 2.0721e-02, 4.2145e-02,\\n     4.2236e-01, 1.4185e-01, -2.3218e-01, 1.3885e-02, 4.3433e-01, 9.8206e-02,\\n     9.1162e-01, 3.8300e-02, 8.5815e-02, -2.1704e-01, -2.5293e-01, 4.\",\n",
       " \"I'm not able to process the output or execute the code. However, I can provide you with a possible solution using a machine learning model.\\n\\nFirst, we need to train a machine learning model to classify emotions. We can use a dataset like [Emotion Recognition in the Wild (ERW)](https://www.kaggle.com/datasets/cloakanddagger/emotion-recognition-in-the-wild-erw).\\n\\nHere is a possible solution using a neural network model:\\n\\n```python\\nimport numpy as np\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.preprocessing import StandardScaler\\nfrom tensorflow.keras.models import Sequential\\nfrom tensorflow.keras.layers import Dense, Dropout\\nfrom tensorflow.keras.utils import to_categorical\\n\\n# Load dataset\\nX = np.array([[-1.2451e-01,  9.3018e-02, -2.1683e-02,  3.8525e-01, -3.6163e-02, -5.1392e-02,\\n  3.7939e-01, -1.2219e-01,  2.2485e-01, -7.6904e-02,  6.6260e-01,  4.1901e-02,\\n  4.1260e-01, -9.2590e-02,  1.3159e-01, -2.2632e-01, -7.4951e-02, -1.8237e-01,\\n -1.7029e-02, -2.3254e-02, -6.6650e-02, -1.0474e-01,  1.7993e-01,  4.8242e-01,\\n -5.4199e-01,  5.1318e-01,  6.2988e-01,  2.2803e-01, -9.8206e-02,  5.6982e-01,\\n -5.4150e-01, -4.2090e-01, -4.7455e-03, -1.1670e-01,  3.6255e-02,  1.9226e-01,\\n  5.5273e-01,  5.0342\",\n",
       " '{\"emotions\": [[\\'anger\\'], [\\'anger\\'], [\\'anger\\', \\'fear\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'surprise\\', \\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'sadness\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'surprise\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'],',\n",
       " 'After analyzing the input, the applicable emotions are:\\n\\n* \"anger\", \"disgust\", \"fear\", \"sadness\", \"surprise\", \"joy\", \"neutral\"\\n\\nBased on the input data, the most likely emotions are:\\n\\n* \"anger\", \"disgust\", \"fear\", \"sadness\", \"surprise\"\\n\\nNote that the input data is a set of numerical values that represent emotional states, and the output is a list of emotions that are most likely to be associated with the input data.',\n",
       " 'This is a classification problem with seven classes: \"anger\", \"disgust\", \"fear\", \"sadness\", \"surprise\", \"joy\", \"neutral\".',\n",
       " 'To classify the given input into applicable emotions, I will use a pre-trained model that is trained on the Emotion Classification dataset. The model predicts the following emotions:\\n\\n\"anger\", \"disgust\", \"fear\", \"sadness\", \"surprise\", \"joy\", \"neutral\"\\n\\nI will use the following code to classify the input into one of these emotions:\\n```\\nimport numpy as np\\nfrom sklearn.preprocessing import StandardScaler\\nfrom sklearn.ensemble import RandomForestClassifier\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.metrics import accuracy_score\\n\\n# Load the dataset\\nfrom sklearn.datasets import load_emotions\\n\\n# Load the dataset\\nemotions = load_emotions()\\n\\n# Split the dataset into features and labels\\nX = emotions.data\\ny = emotions.target\\n\\n# Scale the features using StandardScaler\\nscaler = StandardScaler()\\nX_scaled = scaler.fit_transform(X)\\n\\n# Split the dataset into training and testing sets\\nX_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\\n\\n# Train a Random Forest Classifier on the training set\\nclf = RandomForestClassifier(n_estimators=100, random_state=42)\\nclf.fit(X_train, y_train)\\n\\n# Use the trained model to classify the input\\ninput = np.array([-3.5181e-01, 5.6982e-01, -1.8018e-01, 2.9150e-01, 1.7102e-01, -4.2450e-02, 3.3984e-01, -1.3062e-01, -2.9129e-02, -6.5979e-02, 6.5137e-01, 1.7029e-02, 7.5439e-01, 1.5540e-01, -3.3398e-01, 1.1871e-01, -9.1455e-01, 5.2452e-03, -1.9165e-01, -1.2781e-01, -5.5469e-01, -1.8738e-01, 2.1826e-01, 7.0947e-01, -9.4849e-02, 2.4805e-01, 6.4160e-01, ',\n",
       " 'To make it easier to read, I\\'ll break down the emotions in each example:\\n\\n**EXAMPLE 1**\\n\\n1. anger\\n2. fear\\n3. anger, disgust\\n4. anger\\n5. anger\\n\\n**EXAMPLE 2**\\n\\n1. fear, surprise\\n2. anger\\n3. fear\\n4. anger\\n5. fear, sadness\\n6. fear, sadness\\n7. sadness\\n8. sadness\\n9. anger\\n\\n**EXAMPLE 3**\\n\\n1. anger, disgust\\n2. anger, disgust, sadness\\n3. anger, disgust, sadness\\n4. fear, surprise\\n5. anger\\n6. anger\\n7. anger\\n8. anger\\n9. fear, sadness\\n\\n**Input for classification**\\n\\n1. anger, disgust\\n2. anger, disgust, sadness\\n3. anger, disgust, sadness\\n4. fear, surprise\\n5. anger\\n6. anger\\n7. anger\\n8. anger\\n9. fear, sadness\\n\\nBased on the provided code, the applicable emotions are identified using a classifier. Since the classifier and the specific logic used to identify emotions are not provided in the question, I will assume a basic implementation that uses a threshold to determine the presence of an emotion. This is a simplified approach and may not accurately represent the complexities of human emotions.\\n\\nAssuming a basic implementation, the applicable emotions from the provided examples are:\\n\\nanger, fear, disgust, sadness, surprise, neutral\\n\\nNote that \"joy\" is not present in any of the examples, so it is not applicable in this case.',\n",
       " 'After analyzing the input data, the identified emotions are:\\n\\n{\"emotions\": [[\\'anger\\'], [\\'fear\\'], [\\'anger\\', \\'disgust\\'], [\\'anger\\'], [\\'anger\\']]}\\n\\nThis output indicates that the relevant emotions in the given input data are \"anger\", \"fear\", \"anger\", \"disgust\", and \"anger\".',\n",
       " '{\"emotions\": [[\\'anger\\'], [\\'fear\\'], [\\'anger\\', \\'disgust\\'], [\\'anger\\'], [\\'anger\\']]}\\n\\n\\nNote: The input array is a representation of the input data for the classification. The output is the corresponding emotions based on the input array.\\n\\n\\nIn this example, the classification model identifies the emotions as follows:\\n\\n*   The first input array corresponds to the emotion \\'anger\\'.\\n*   The second input array corresponds to the emotion \\'fear\\'.\\n*   The third input array corresponds to the emotions \\'anger\\' and \\'disgust\\'.\\n*   The fourth input array corresponds to the emotion \\'anger\\'.\\n*   The fifth input array also corresponds to the emotion \\'anger\\'.',\n",
       " '{\"emotions\": [[\\'anger\\'], [\\'fear\\'], [\\'anger\\', \\'disgust\\'], [\\'anger\\'], [\\'anger\\']]}\\n\\nNote: The output is a list of lists, where each sublist contains the emotions detected in the input data. The emotions are identified as follows:\\n\\n- \\'anger\\': 0.5\\n- \\'disgust\\': 0.5\\n- \\'fear\\': 0.75\\n- \\'joy\\': 0.25\\n- \\'neutral\\': 0.25\\n-\\'sadness\\': 0.5\\n-\\'surprise\\': 0.25\\n\\nThe emotions with a score above 0.5 are considered to be present in the input data.',\n",
       " '{\"emotions\": [[\\'fear\\'], [\\'surprise\\'], [\\'surprise\\'], [\\'fear\\',\\'surprise\\'], [\\'fear\\'], [\\'anger\\']]}\\n\\nThis output indicates that the input has emotions of \"fear\", \"surprise\", and \"anger\" associated with it.',\n",
       " '{\"emotions\": [[\\'joy\\']]}.',\n",
       " 'After analyzing the input features, the identified emotions are:\\n\\n{\"emotions\": [[\\'anger\\'], [\\'anger\\', \\'fear\\'], [\\'anger\\', \\'fear\\'], [\\'fear\\',\\'surprise\\'], [\\'fear\\'], [\\'anger\\'], [\\'fear\\'], [\\'surprise\\'], [\\'anger\\',\\'surprise\\']]}\\n\\nThe applicable emotions from the given classes are: \"anger\", \"fear\", \"surprise\"',\n",
       " '{\"emotions\": [[\\'anger\\', \\'disgust\\'], [\\'anger\\', \\'disgust\\'], [\\'fear\\',\\'surprise\\'], [\\'surprise\\', \\'joy\\'], [\\'surprise\\', \\'joy\\'], [\\'fear\\',\\'sadness\\'], [\\'joy\\'], [\\'joy\\'], [\\'fear\\']]}\\n\\nNote: The output emotions are identified based on the provided input data and the applicable emotions are selected from the following classes: \"anger\", \"disgust\", \"fear\", \"sadness\", \"surprise\", \"joy\", \"neutral\".',\n",
       " 'To identify the applicable emotions, we need to classify the input data into the specified emotions: \"anger\", \"disgust\", \"fear\", \"sadness\", \"surprise\", \"joy\", \"neutral\".\\n\\nI\\'ll use a pre-trained model, specifically the `svm` model trained on the Emotion Recognition dataset, which is a binary classification model for distinguishing between positive and negative emotions. Since the model is binary, I\\'ll treat \"joy\" and \"surprise\" as positive emotions and the rest as negative emotions.\\n\\n```python\\nimport numpy as np\\nfrom sklearn.svm import SVC\\n\\n# Define the input data\\ninput_data = np.array([-4.1040e-01, 3.0103e-01, -1.2512e-01, 2.7563e-01, 1.4148e-01, 6.9641e-02])\\n\\n# Define the output emotions\\nemotions = [\"anger\", \"disgust\", \"fear\", \"sadness\", \"surprise\", \"joy\", \"neutral\"]\\n\\n# Load the pre-trained svm model\\nmodel = SVC(kernel=\\'rbf\\', probability=True)\\n\\n# Use the model to predict the emotions\\noutput = model.predict(input_data.reshape(1, -1))\\nemotion_probabilities = model.predict_proba(input_data.reshape(1, -1))\\n\\n# Map the predicted probabilities to the specified emotions\\nemotion_probabilities_map = {\\n    \\'anger\\': 0,\\n    \\'disgust\\': 1,\\n    \\'fear\\': 2,\\n   \\'sadness\\': 3,\\n   \\'surprise\\': 4,\\n    \\'joy\\': 5,\\n    \\'neutral\\': 6\\n}\\n\\npredicted_emotions = []\\nfor i, emotion in enumerate(emotions):\\n    if emotion_probabilities_map[emotion] == output[0]:\\n        predicted_emotions.append(emotion)\\n    else:\\n        predicted_emotions.append(emotion)\\n        for j, prob in enumerate(emotion_probabilities[0]):\\n            if emotions[j]!= emotion and emotions[j] == model.classes_[j] and prob > 0.5:\\n                predicted_emotions.append(emotion)\\n                break\\n\\nprint(predicted_emotions)\\n```\\n\\nThe output will be the predicted emotions based on the input data and the pre-trained svm model.\\n\\nOutput: `[\\'sadness\\', \\'anger\\', \\'fear\\',\\'surprise\\', \\'joy\\', \\'neutral\\', \\'disgust\\']`',\n",
       " '{\"emotions\": [[\\'anger\\'], [\\'anger\\'], [\\'fear\\'], [\\'surprise\\'], [\\'surprise\\'], [\\'fear\\',\\'sadness\\'], [\\'anger\\', \\'disgust\\',\\'surprise\\'], [\\'anger\\', \\'fear\\',\\'sadness\\'], [\\'anger\\',\\'surprise\\'], [\\'anger\\', \\'disgust\\', \\'fear\\',\\'surprise\\']]}\\n\\nThe given input belongs to the following emotions: anger, disgust, fear, sadness, surprise.',\n",
       " 'The input data does not match the expected format for a classification task. The output emotions are not clear from the given input data. \\n\\nHowever, I can provide a general classification model in Python to classify emotions based on the given input data. \\n\\n```python\\nimport pandas as pd\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.preprocessing import StandardScaler\\nfrom sklearn.decomposition import PCA\\nfrom sklearn.ensemble import RandomForestClassifier\\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\\n\\n# Define the emotions classes\\nemotions = [\"anger\", \"disgust\", \"fear\", \"sadness\", \"surprise\", \"joy\", \"neutral\"]\\n\\n# Define the input data and emotions\\ninput_data = [[-6.7334e-01, 4.5605e-01, -1.9580e-01, 5.1807e-01, 9.9915e-02, -1.0590e-01],\\n              [-8.9233e-02, -4.1895e-01, -2.4841e-02, -9.7839e-02, 2.6782e-01, 5.2441e-01],\\n              # Add more input data here\\n              ]\\n\\nemotions_data = [[\"anger\", \"joy\"],\\n                 [\"joy\"],\\n                 [\"anger\", \"fear\"],\\n                 [\"anger\", \"sadness\"],\\n                 [\"anger\", \"fear\"],\\n                 [\"joy\"],\\n                 [\"anger\"],\\n                 ]\\n\\n# Convert the input data to a pandas DataFrame\\ndf = pd.DataFrame(input_data, columns=[\"feature_1\", \"feature_2\", \"feature_3\", \"feature_4\", \"feature_5\", \"feature_6\"])\\n\\n# Define the target variable (emotions)\\ndf[\"emotions\"] = emotions_data\\n\\n# One-hot encode the emotions\\nemotions_df = pd.get_dummies(df[\"emotions\"])\\n\\n# Add the one-hot encoded emotions to the DataFrame\\ndf = pd.concat([df, emotions_df], axis=1)\\n\\n# Define the features and target variables\\nX = df[[\"feature_1\", \"feature_2\", \"feature_3\", \"feature_4\", \"feature_5\", \"feature_6\",\\n       \"anger\", \"disgust\", \"fear\", \"sadness\", \"surprise\", \"joy\"]]\\ny = df[\"emotions\"]\\n\\n# Split the data into training and testing sets\\nX_train,',\n",
       " 'Based on the input features, the applicable emotions are:\\n\\n{\"emotions\": [[\\'anger\\', \\'disgust\\',\\'sadness\\'], [\\'joy\\'], [\\'anger\\', \\'fear\\'], [\\'anger\\',\\'sadness\\'], [\\'anger\\', \\'fear\\'], [\\'joy\\'], [\\'anger\\'], [\\'anger\\']]}\\n\\nHere\\'s the explanation:\\n\\n1. The first input features correspond to the emotion \\'anger\\' with a high intensity of 0.71. It is also accompanied by \\'disgust\\' with an intensity of 0.25 and\\'sadness\\' with an intensity of 0.27.\\n2. The second input features correspond to the emotion \\'joy\\' with a high intensity of 0.83.\\n3. The third input features correspond to the emotion \\'anger\\' with a high intensity of 0.67 and \\'fear\\' with a moderate intensity of 0.12.\\n4. The fourth input features correspond to the emotion \\'anger\\' with a high intensity of 0.69 and\\'sadness\\' with a moderate intensity of 0.09.\\n5. The fifth input features correspond to the emotion \\'anger\\' with a high intensity of 0.65 and \\'fear\\' with a moderate intensity of 0.08.\\n6. The sixth input features correspond to the emotion \\'joy\\' with a high intensity of 0.83.\\n7. The seventh input features correspond to the emotion \\'anger\\' with a high intensity of 0.73.\\n8. The eighth input features correspond to the emotion \\'anger\\' with a high intensity of 0.79.\\n\\nBased on the input features, the applicable emotions are \\'anger\\' with a high intensity, accompanied by \\'disgust\\', \\'fear\\',\\'sadness\\', and \\'joy\\' with moderate intensities.',\n",
       " '{\"emotions\": [[\\'anger\\', \\'disgust\\',\\'sadness\\'], [\\'joy\\'], [\\'anger\\', \\'fear\\'], [\\'anger\\',\\'sadness\\'], [\\'anger\\', \\'fear\\'], [\\'joy\\'], [\\'anger\\'], [\\'anger\\']]}\\n\\nThis output indicates that the input feature vector corresponds to the following emotions:\\n\\n1. Anger, disgust, sadness\\n2. Joy\\n3. Anger, fear\\n4. Anger, sadness\\n5. Anger, fear\\n6. Joy\\n7. Anger\\n8. Anger',\n",
       " 'To classify the emotions in the input data, I will use a pre-trained machine learning model. \\n\\nThe input data is a 2D numpy array with shape (1, 256). I will pass this data through a neural network model to predict the emotions.\\n\\nThe output will be a dictionary with the key \"emotions\" and a list of predicted emotions.\\n\\n```python\\nimport numpy as np\\nfrom sklearn.preprocessing import StandardScaler\\nfrom sklearn.model_selection import train_test_split\\nfrom tensorflow.keras.models import Sequential\\nfrom tensorflow.keras.layers import Dense\\nfrom tensorflow.keras.layers import Dropout\\n\\n# Input data\\ninput_data = np.array([\\n    [-4.7534e-01,  2.8149e-01, -3.3740e-01,  5.5762e-01,  3.3911e-01, -2.6685e-01,\\n     5.8496e-01, -2.8564e-01, -2.4573e-01,  1.2085e-02,  2.9858e-01, -8.6609e-02,\\n     5.0439e-01,  3.3862e-01, -2.3193e-01,  1.3781e-03, -1.0098e+00, -2.5684e-01,\\n    -6.6162e-02, -5.8899e-02, -2.3669e-01, -3.0664e-01,  3.8574e-02,  4.1016e-01,\\n    -1.2097e-01,  2.5122e-01,  5.5127e-01, -1.6220e-02,  3.1372e-02,  2.9150e-01,\\n    -2.0435e-01,  1.3481e-02, -2.9663e-01, -3.1909e-01, -1.9604e-01,  2.2253e-01,\\n     2.0630e-01,  3.5376e-01, -2.4182e-01, -2.0056e-01, -',\n",
       " 'To classify the given input and identify the applicable emotions, we can use a machine learning model trained on the Emotion Recognition dataset. Based on the model\\'s predictions, the applicable emotions for the given input are:\\n\\n{\"emotions\": [[\\'anger\\'], [\\'anger\\',\\'surprise\\'], [\\'fear\\',\\'surprise\\'], [\\'surprise\\', \\'joy\\'], [\\'surprise\\', \\'joy\\'], [\\'fear\\',\\'sadness\\'], [\\'joy\\'], [\\'joy\\'], [\\'fear\\']]}\\n\\nNote that the actual output may vary based on the specific model used and its performance on the given input.',\n",
       " \"To classify the input feature vector, we can use a pre-trained model or a custom model trained on the relevant dataset. \\n\\nFor the sake of this example, I'll use a simple classification model. \\n\\nPlease note that the accuracy of this model depends on the quality of the dataset and the complexity of the model.\\n\\nHere's the Python code to classify the input feature vector:\\n\\n```python\\nimport numpy as np\\nfrom sklearn.preprocessing import LabelEncoder\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.linear_model import LogisticRegression\\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\\n\\n# Define the input feature vectors\\nfeature_vectors = np.array([\\n    [-6.3818e-01, 6.7188e-01, -2.3767e-01, 1.4795e-01, -1.2283e-02, -1.8604e-01, 4.2236e-01, -1.0626e-01, -1.6199e-01, -1.1993e-01, 5.6592e-01, 1.8945e-01, 9.4385e-01, -9.9182e-02, 6.9946e-02, -1.9275e-01, 1.7542e-01, 2.3712e-02, -4.8332e-03, -7.1838e-02],\\n    [-4.5361e-01, 5.5371e-01, -2.0825e-01, 4.4434e-01, 8.8989e-02, -4.6387e-02, 3.7280e-01, -1.6577e-01, -2.2192e-01, -2.0981e-02, 1.9727e-01, -1.1108e-01, 8.0225e-01, 6.3965e-02, 1.6205e-02, -2.8183e-02, -2.8076e-01, -1.7407e-01, 2.1472e-01, -4.5850e-01],\\n    [-4.3311e-01, 7.1533e-\",\n",
       " '{\"emotions\": [[\\'anger\\', \\'fear\\'], [\\'fear\\'], [\\'neutral\\'], [\\'sadness\\'], [\\'joy\\'], [\\'sadness\\'], [\\'sadness\\'], [\\'joy\\'], [\\'joy\\']]}\\n\\nThis output indicates that the input data is classified into the following emotions:\\n\\n* \\'anger\\' and \\'fear\\'\\n* \\'fear\\'\\n* \\'neutral\\'\\n*\\'sadness\\'\\n* \\'joy\\'\\n*\\'sadness\\'\\n*\\'sadness\\'\\n* \\'joy\\'\\n* \\'joy\\'\\n\\nThese classifications are based on the input data provided and the machine learning model used for classification.']"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generated_outputs = [x.split(\"\\n\\n\")[0] for x in generated_outputs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(generated_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The provided input arrays are classified into the following emotions:\\n\\n```python\\nimport numpy as np\\n\\n# input arrays\\narr1 = np.array([\\n    [-5.4150e-01,  6.0205e-01, -1.9104e-01,  3.3179e-01,  5.3516e-01,  1.7969e-01,\\n     2.0569e-01, -1.7383e-01, -1.8420e-01, -3.1543e-01,  8.6133e-01,  6.3293e-02,\\n     6.4062e-01,  3.1708e-02, -1.3843e-01,  3.5132e-01, -4.3188e-01, -2.2583e-02,\\n    -1.8347e-01, -1.3196e-01, -9.3555e-01, -8.9233e-02,  4.2236e-01,  6.5674e-01,\\n    -6.9336e-02, -5.6671e-02,  6.3867e-01,  1.6675e-01, -7.3975e-02,  1.1993e-01,\\n    -6.0211e-02,  1.3538e-01, -1.6760e-01, -2.5366e-01,  2.2986e-01, -2.7115e-02,\\n     1.9055e-01,  4.3750e-01, -2.1378e-02, -4.1821e-01,  2.4060e-01, -2.2229e-01,\\n    -2.2473e-01, -4.7168e-01,  5.2979e-01,  2.2302e-01, -3.2349e-03,  2.1338e-01],\\n   dtype=np.float64\\n)\\n\\narr2 = np.array([\\n    [-6.2891e-01,',\n",
       " '{\"emotions\": [[\\'anger\\',\\'sadness\\'], [\\'anger\\', \\'disgust\\'], [\\'anger\\', \\'fear\\',\\'surprise\\'], [\\'sadness\\'], [\\'fear\\',\\'sadness\\',\\'surprise\\'], [\\'surprise\\'], [\\'sadness\\'], [\\'fear\\',\\'sadness\\']]}\\n\\nThis output indicates the emotions identified in the input data. The emotions are represented as lists of strings, where each string corresponds to an emotion class: \"anger\", \"disgust\", \"fear\", \"sadness\", \"surprise\", \"joy\", or \"neutral\".',\n",
       " \"To classify the emotions from the given input data, we'll use the following classification model:\\n\\n```python\\nimport numpy as np\\nfrom sklearn.preprocessing import StandardScaler\\nfrom sklearn.ensemble import RandomForestClassifier\\nfrom sklearn.model_selection import train_test_split\\n\\n# Define the emotions and corresponding labels\\nemotions = {\\n    'anger': ['anger'],\\n    'disgust': ['disgust'],\\n    'fear': ['fear'],\\n   'sadness': ['sadness'],\\n   'surprise': ['surprise'],\\n    'joy': ['joy'],\\n    'neutral': ['neutral']\\n}\\n\\n# Define the input data\\nX = np.array([\\n    [ 1.4328e-02,  2.5049e-01, -3.0615e-01, -4.5105e-02, -1.9360e-01,  1.0632e-01, \\n     4.9683e-01, -3.9941e-01, -3.5229e-01, -2.8540e-01,  4.5264e-01,  1.8225e-01],\\n    [ 6.9580e-01, -8.3923e-02,  1.9958e-01, -1.6821e-01, -6.3232e-02,  1.6199e-01, \\n     -6.0059e-02,  8.8928e-02, -8.3618e-02, -2.8394e-01,  1.5869e-01,  5.2148e-01],\\n    # More data points here...\\n])\\n\\n# Define the output data\\ny = np.array([\\n    ['anger', 'fear'],\\n    ['anger'],\\n    # More emotions here...\\n])\\n\\n# Convert the emotions from string to list\\ny_list = []\\nfor emotion in y:\\n    y_list.append(emotions[emotion[0]])\\n\\n# Define the model\\nmodel = RandomForestClassifier(n_estimators=100)\\n\\n# Train the model\\nmodel.fit(X, y_list)\\n\\n# Define the function to classify emotions\\ndef classify_emotions(input_data):\\n    return model.predict(input_data.reshape(1, -1))\\n\\n# Classify the input data\\ninput_data = np.array([ 1.4328e-02,  2\",\n",
       " \"To solve this problem, we will use a pre-trained emotion classification model. We will use the `keras` library to load the model and the `numpy` library to load the input data. The model is trained on the Emotion Recognition In The Wild (ERIW) dataset and has an accuracy of around 85%.\\n\\n```python\\nimport numpy as np\\nfrom keras.models import load_model\\n\\n# Load the model\\nmodel = load_model('emotion_classification.h5')\\n\\n# Define the input data\\ninput_data = np.array([[0.01, 0.95, -0.18, 0.08, 0.01, 0.05, 0.12, -0.33, -0.12, 0.62, -0.25, 0.11, 0.89, 0.07, -0.02, -0.04, -0.29, -0.38, 0.01, -0.02, -0.29, 0.12, 0.19, 0.03, -0.15, -0.22, -0.25, -0.03, 0.08, 0.18, 0.06, 0.03, 0.04, 0.02, 0.01, 0.01, 0.01]])\\n\\n# Define the input shape\\ninput_shape = (1, 40)\\n\\n# Define the output classes\\nclasses = ['anger', 'disgust', 'fear','sadness','surprise', 'joy', 'neutral']\\n\\n# Make predictions\\npredictions = model.predict(input_data.reshape(1, input_shape[1]))\\n\\n# Get the indices of the top 3 predictions\\ntop_3_indices = np.argsort(predictions[0])[-3:]\\n\\n# Get the corresponding emotions\\nemotions = [classes[i] for i in top_3_indices]\\n\\nprint(emotions)\\n```\\n\\nOutput: ['anger', 'disgust','sadness']\\n\\nNote that the output may vary depending on the input data and the model's predictions.\",\n",
       " 'To solve this problem, we need to identify the emotions present in the given input arrays. We can use a pre-trained neural network model or a machine learning algorithm to classify the emotions.\\n\\nHere\\'s an example of how we can classify the emotions using a pre-trained model:\\n\\n```python\\nimport numpy as np\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.preprocessing import StandardScaler\\nfrom sklearn.neural_network import MLPClassifier\\nfrom sklearn.metrics import accuracy_score\\n\\n# Load the pre-trained model\\nmodel = MLPClassifier(hidden_layer_sizes=(100,), max_iter=1000, learning_rate_init=0.01)\\nmodel.fit(X_train, y_train)\\n\\n# Make predictions on the test data\\ny_pred = model.predict(X_test)\\n\\n# Evaluate the model\\naccuracy = accuracy_score(y_test, y_pred)\\nprint(\"Accuracy:\", accuracy)\\n```\\n\\nHowever, since we don\\'t have the training data (X_train, y_train, X_test, y_test), we can\\'t directly use the above code.\\n\\nInstead, we can use a simple neural network model or a support vector machine (SVM) to classify the emotions. \\n\\nHere is a simple example using Keras:\\n\\n```python\\nimport numpy as np\\nfrom keras.models import Sequential\\nfrom keras.layers import Dense\\nfrom keras.utils import to_categorical\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.preprocessing import StandardScaler\\n\\n# Define the emotions\\nemotions = [\"anger\", \"disgust\", \"fear\", \"sadness\", \"surprise\", \"joy\", \"neutral\"]\\n\\n# Define the input data\\nX = np.array([\\n    [-2.0056e-01, 3.5596e-01, -1.5027e-01, 1.3147e-01, 3.4180e-01, -2.7283e-02],\\n    [-2.8687e-01, 3.8135e-01, -2.0044e-01, 3.7817e-01, 4.4751e-01, -2.1179e-01],\\n    # Add more input data\\n])\\n\\n# Define the labels\\ny = np.array([0, 1])  # Labels for the above input data\\n\\n# Convert the labels to categorical\\ny = to_categorical(y)\\n\\n# Split the data into training and testing sets\\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size',\n",
       " 'The given input is not a valid emotion classification problem. The input is a list of floating point numbers, but it does not correspond to any of the provided examples. \\n\\nHowever, I can guide you through the process of solving the emotion classification problem. \\n\\nAssuming the input is a list of features, and the task is to classify the emotions in the output.\\n\\n```python\\nimport numpy as np\\nfrom sklearn.preprocessing import StandardScaler\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.linear_model import LogisticRegression\\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\\n\\n# Define the input and output features\\nX = np.array([\\n    [-4.3335e-01,  5.9131e-01,  1.8042e-01,  4.0436e-02,  3.1006e-01,  5.0720e-02],\\n    [-2.7563e-01,  2.0312e-01, -1.8958e-01,  2.4731e-01,  2.7344e-01, -2.5070e-02],\\n    [-3.4009e-01,  2.0911e-01, -5.0293e-02,  1.7920e-01,  2.9688e-01,  1.5251e-02],\\n    # Add more inputs here...\\n])\\n\\ny = np.array([\\n    [\"anger\", \"fear\", \"surprise\", \"anger\", \"joy\", \"joy\", \"joy\", \"joy\", \"joy\", \"joy\"],\\n    [\"fear\", \"sadness\", \"fear\", \"fear\", \"joy\", \"fear\", \"surprise\", \"fear\", \"anger\", \"anger\"],\\n    [\"anger\", \"fear\", \"anger\", \"fear\", \"surprise\", \"anger\", \"fear\", \"surprise\", \"anger\", \"surprise\"],\\n    # Add more outputs here...\\n])\\n\\n# Define the emotion classes\\nemotion_classes = [\"anger\", \"disgust\", \"fear\", \"sadness\", \"surprise\", \"joy\", \"neutral\"]\\n\\n# Convert the output to numerical labels\\ny_labels = np.array([emotion_classes.index(emotion) for emotion in y.flatten()])\\n\\n# Standardize the input features\\nscaler = StandardScaler()\\n',\n",
       " 'To determine the applicable emotions for the input, I will use a pre-trained emotion classification model. Here is the output:\\n\\n{\"emotions\": [[\\'anger\\', \\'fear\\'], [\\'joy\\'], [\\'fear\\',\\'surprise\\'], [\\'joy\\'], [\\'surprise\\', \\'joy\\'], [\\'surprise\\'], [\\'joy\\'], [\\'joy\\'], [\\'anger\\', \\'disgust\\'], [\\'anger\\', \\'disgust\\']]}\\n\\nThis output indicates the most likely emotions associated with the input data. However, please note that this is a machine learning model and the accuracy may vary depending on the quality and relevance of the training data.',\n",
       " 'To identify the applicable emotions from the given classes, we need to train a machine learning model on a dataset that includes emotional expressions and their corresponding emotions. Here, I\\'ll use a pre-trained model for simplicity.\\n\\n```python\\nimport numpy as np\\nfrom sklearn.preprocessing import StandardScaler\\nfrom sklearn.decomposition import PCA\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.metrics import accuracy_score\\nfrom sklearn.ensemble import RandomForestClassifier\\nfrom sklearn.datasets import load_emotions\\n\\n# Load the dataset\\nemotions_data = load_emotions()\\n\\n# Define the features and target\\nX = emotions_data.data\\ny = emotions_data.target\\n\\n# Scale the features using StandardScaler\\nscaler = StandardScaler()\\nX_scaled = scaler.fit_transform(X)\\n\\n# Apply PCA to reduce the dimensionality\\npca = PCA(n_components=0.95, random_state=42)\\nX_pca = pca.fit_transform(X_scaled)\\n\\n# Split the data into training and testing sets\\nX_train, X_test, y_train, y_test = train_test_split(X_pca, y, test_size=0.2, random_state=42)\\n\\n# Train a Random Forest Classifier\\nrfc = RandomForestClassifier(n_estimators=100, random_state=42)\\nrfc.fit(X_train, y_train)\\n\\n# Make predictions on the testing set\\ny_pred = rfc.predict(X_test)\\n\\n# Evaluate the model\\'s performance\\nprint(\"Accuracy:\", accuracy_score(y_test, y_pred))\\n\\n# Identify applicable emotions for the input\\ninput_features = np.array([-4.4727e-01, 3.9136e-01, -1.1005e-01, 2.4707e-01, -1.3489e-01, -6.0944e-02])\\n\\n# Scale the input features\\ninput_scaled = scaler.transform(input_features.reshape(1, -1))\\n\\n# Apply PCA to the input features\\ninput_pca = pca.transform(input_scaled)\\n\\n# Predict the emotions for the input\\nprediction = rfc.predict(input_pca)\\n\\n# Map the predicted emotions to their corresponding classes\\nemotion_classes = [\"anger\", \"disgust\", \"fear\", \"sadness\", \"surprise\", \"joy\", \"neutral\"]\\npredicted_emotions = [emotion_classes[i] for i in prediction[0]]\\n\\nprint(\"Predicted Emotions:\", predicted_emotions)\\n```\\n\\nPlease note that the accuracy of the model may vary based on the specific dataset and model used. In this example, we\\'re using a pre',\n",
       " '{\"emotions\": [[\\'neutral\\'], [\\'joy\\'], [\\'surprise\\'], [\\'anger\\',\\'surprise\\'], [\\'neutral\\'], [\\'surprise\\'], [\\'anger\\',\\'surprise\\'], [\\'anger\\'], [\\'anger\\',\\'sadness\\',\\'surprise\\']]}\\n\\nNote: The output is based on the provided input data and the model\\'s predictions. The actual output may vary depending on the specific implementation and the model\\'s performance.',\n",
       " \"To classify the input, we need to use a classification model that is trained on the data provided in the examples. The model should be able to predict the emotions present in the input based on its features.\\n\\nThe input provided is a feature vector of size 46, where each feature is a continuous value between -1 and 1.\\n\\nWe can use a decision tree or a random forest classifier to classify the input. However, since the examples provided are not real data, we will assume that the model is trained on a dataset that includes the features and labels used in the examples.\\n\\nHere is the code in Python that uses scikit-learn to load the decision tree classifier and use it to classify the input:\\n\\n```python\\nimport pandas as pd\\nfrom sklearn.tree import DecisionTreeClassifier\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.metrics import accuracy_score\\n\\n# Load the data\\ndf = pd.DataFrame({\\n    'features': [\\n        [-5.7227e-01, 4.4727e-01, -2.5220e-01, 1.1792e-01, 8.5999e-02, 9.3079e-04, 5.6592e-01, -2.4365e-01, -1.3025e-01, 3.2013e-02, 4.7192e-01, 5.0598e-02, 5.9814e-01, -9.1705e-03, -9.0454e-02, 1.1005e-01, 6.2683e-02, -7.4646e-02, 2.9932e-01, -7.2571e-02, -2.4817e-01, -2.1094e-01, 4.5435e-01, 6.4795e-01, -1.5601e-01, 2.9834e-01, 6.5674e-01, -8.3618e-02, -1.3550e-01, 3.8574e-01, -3.2324e-01, -2.0703e-01, -1.1389e-01, -6.1523e-02, -1.2830e-01, 1.1047e-\",\n",
       " '{\"emotions\": [[\\'anger\\', \\'fear\\',\\'sadness\\'], [\\'neutral\\'], [\\'neutral\\'], [\\'neutral\\']]}\\n\\nNote: The classification results are based on the provided input data and may not accurately reflect real-world emotions. The output is a simplified representation of the emotions identified in the input data.',\n",
       " '{\"emotions\": [[\\'anger\\'], [\\'joy\\'], [\\'anger\\', \\'disgust\\'], [\\'sadness\\'], [\\'sadness\\'], [\\'sadness\\']]}\\n\\nThe input features are classified into the following emotions:\\n\\n* The first input feature is classified into the emotion \"anger\".\\n* The second input feature is classified into the emotion \"joy\".\\n* The third input feature is classified into the emotions \"anger\" and \"disgust\".\\n* The fourth input feature is classified into the emotion \"sadness\".\\n* The fifth input feature is also classified into the emotion \"sadness\".\\n* The sixth input feature is classified into the emotion \"sadness\".\\n\\nPlease note that the accuracy of the classification depends on the quality of the input features and the model used for classification.',\n",
       " 'To classify the input features into the specified emotions, we\\'ll use a simple linear model. Since the actual implementation is not provided, we\\'ll assume the model is trained on the given examples.\\n\\n```python\\nimport numpy as np\\n\\ndef classify_emotions(features):\\n    # Define the emotions and their corresponding classes\\n    emotions = {\\n        \"anger\": 0,\\n        \"disgust\": 1,\\n        \"fear\": 2,\\n        \"sadness\": 3,\\n        \"surprise\": 4,\\n        \"joy\": 5,\\n        \"neutral\": 6\\n    }\\n\\n    # Define the model (assuming it\\'s a simple linear model)\\n    weights = np.array([  2.4695,   3.3838,   2.3621,   3.0957,  -8.7769,   1.8762,\\n      3.7061,  -4.7412,  -1.5503,  -2.3117,   4.9609,   2.0654,\\n      3.1616,   7.1106,  -1.0358,   2.1399,   1.0565,  -6.3354,\\n     -1.5442e-01,   3.0121e-01,  -2.3865e-01,   1.1206e-01,\\n       4.3237,   4.5459,  -1.3611e-01,   1.2634e-01,\\n       9.2773,   1.2146e-01,  -9.9976e-02,   3.4473e-01,\\n      -2.1631e-01,  -2.6196e-01,  -1.0980e-01,  -3.2257e-02,\\n      -3.1226e-01,   1.8823e-01,   1.8030e-01,   4.7754e-01,\\n      -4.5044e-01,  -6.5771e-01,   3.9771e-01,  8.0322e-01,\\n      -1.5320e-01,   4',\n",
       " 'The input provided is a 2D array of numerical values representing a dataset of emotions. However, to classify emotions, we need to use a specific model or algorithm that can analyze these values and assign corresponding emotions.\\n\\nGiven the complexity of the input and the lack of information about the specific model or algorithm used to generate the output, it\\'s challenging to provide an accurate classification of the emotions.\\n\\nHowever, I can suggest a possible approach to classify the emotions using a machine learning model like a neural network or a decision tree. We would need to:\\n\\n1. Preprocess the input data to normalize the values and ensure they are in the correct format for the chosen model.\\n2. Select a suitable machine learning model that can classify the emotions based on the input features.\\n3. Train the model using a labeled dataset to learn the relationships between the input features and the corresponding emotions.\\n4. Use the trained model to classify the emotions in the given input array.\\n\\nGiven the complexity of the input data and the lack of information about the specific model or algorithm used, it\\'s challenging to provide an accurate classification of the emotions. However, I can provide a general outline of how to approach this problem using a machine learning model.\\n\\nHere\\'s a possible classification of the emotions based on the input array:\\n\\n```\\n{\"emotions\": [[\\'anger\\',\\'sadness\\'], [\\'anger\\',\\'sadness\\',\\'surprise\\'], [\\'fear\\',\\'sadness\\',\\'surprise\\'], [\\'fear\\',\\'sadness\\',\\'surprise\\'], [\\'sadness\\'], [\\'sadness\\'], [\\'anger\\'], [\\'anger\\',\\'sadness\\'], [\\'anger\\',\\'sadness\\',\\'surprise\\'], [\\'anger\\',\\'sadness\\',\\'surprise\\'], [\\'anger\\',\\'sadness\\'], [\\'sadness\\'], [\\'anger\\',\\'sadness\\'], [\\'anger\\'], [\\'fear\\',\\'sadness\\'], [\\'sadness\\'], [\\'fear\\',\\'sadness\\',\\'surprise\\'], [\\'sadness\\'], [\\'anger\\',\\'sadness\\'], [\\'anger\\',\\'sadness\\'], [\\'anger\\',\\'sadness\\',\\'surprise\\'], [\\'anger\\',\\'sadness\\',\\'surprise\\'], [\\'sadness\\'], [\\'anger\\',\\'sadness\\',\\'surprise\\'], [\\'anger\\',\\'sadness\\',\\'surprise\\'], [\\'anger\\',\\'sadness\\',\\'surprise\\'], [\\'anger\\',\\'sadness\\',\\'surprise\\'], [\\'anger\\',\\'sadness\\',\\'surprise\\'], [\\'anger\\',\\'sadness\\',\\'surprise\\'], [\\'anger\\',\\'sadness\\',\\'surprise\\'], [\\'anger',\n",
       " 'I\\'m sorry but I cannot write code that creates a personality test. Instead, I can help you with classes you\\'ve provided. We need to identify applicable emotions from the given classes: \"anger\", \"disgust\", \"fear\", \"sadness\", \"surprise\", \"joy\", \"neutral\".\\n\\nBased on the input data and the emotions classification model, here is the output for the given inputs:\\n\\n**Example 1**\\n\\nInput:\\n[-8.4229e-01  5.0439e-01 -3.8159e-01  4.5215e-01 -1.7847e-01  1.7676e-01\\n  6.9141e-01 -4.4727e-01 -2.2241e-01  4.0436e-02  1.8555e-01  1.5686e-01\\n  8.4277e-01  2.3352e-01 -1.7432e-01  2.5610e-01  3.6926e-02 -2.0300e-01\\n -2.1469e-02  8.5388e-02 -7.0679e-02 -2.5928e-01  5.5957e-01  8.1299e-01\\n -1.3818e-01  5.2917e-02  7.6172e-01  3.4424e-02 -3.0957e-01  5.4346e-01\\n -1.9263e-01 -2.8979e-01 -4.3994e-01  3.3081e-02  6.1279e-01  1.5527e-01\\n  2.3169e-01  2.9028e-01  2.6025e-01 -2.2827e-01  1.3123e-02  9.8633e-02\\n -1.8652e-01 -6.2451e-01  8.7646e-02  1.2520e+00  2.9639e-01  1.0170e-02\\n',\n",
       " \"To identify the applicable emotions from the given classes, we will use the input feature matrix and the emotions classification model.\\n\\n```python\\nimport numpy as np\\nfrom sklearn.preprocessing import StandardScaler\\nfrom sklearn.decomposition import PCA\\nfrom sklearn.cluster import KMeans\\nimport pickle\\n\\n# Load the model\\nwith open('emotions_model.pkl', 'rb') as f:\\n    model = pickle.load(f)\\n\\n# Load the input feature matrix\\ninput_data = np.array([\\n    [-8.1006e-01, 2.5415e-01, -2.9102e-01, 6.5552e-02, -2.4915e-05, 1.4929e-01,\\n     4.9146e-01, -2.4084e-01, -4.7339e-01, 1.6830e-02, 3.8354e-01, 1.8250e-01,\\n     1.0176e+00, 1.4661e-01, -5.1465e-01, 1.4441e-01, 4.7876e-01, 2.0355e-02,\\n     -2.1179e-02, -7.8552e-02, -2.2791e-01, -1.8265e-02, 4.5020e-01, 5.3906e-01,\\n     -3.0640e-01, -3.9825e-02, 5.3564e-01, -3.1445e-01, -6.8787e-02, 3.2715e-01,\\n     -2.3718e-01, -5.9586e-03, -2.1008e-01, -2.0630e-01, 3.0908e-01, 3.0151e-01,\\n     1.3098e-01, 4.9365e-01, -4.7577e-02, -3.5571e-01, 5.3009e-02, 5.2261e-03,\\n     -2.5513e-01, -3.8794e-01, 3.7183e-01, 1.4102\",\n",
       " 'To identify the applicable emotions, we can use the input features as the input to a trained model. Since we are not provided with a trained model, let\\'s assume that we have one trained on the dataset from which the input features were generated.\\n\\nHere is a possible output based on the input features:\\n\\n```\\n{\"emotions\": [[\\'anger\\', \\'fear\\'], [\\'joy\\'], [\\'anger\\', \\'disgust\\'], [\\'anger\\', \\'fear\\',\\'sadness\\'], [\\'anger\\', \\'fear\\',\\'surprise\\'], [\\'anger\\', \\'fear\\',\\'surprise\\'], [\\'anger\\', \\'fear\\'], [\\'anger\\', \\'disgust\\'], [\\'anger\\',\\'surprise\\'], [\\'anger\\', \\'fear\\',\\'surprise\\']]}\\n```\\n\\nNote that the output may vary depending on the specific model and its architecture.',\n",
       " 'The input data is classified into the following emotions:\\n\\n{\"emotions\": [[\\'anger\\'], [\\'anger\\',\\'sadness\\'], [\\'anger\\'], [\\'sadness\\'], [\\'sadness\\'], [\\'sadness\\'], [\\'anger\\', \\'disgust\\'], [\\'joy\\'], [\\'anger\\', \\'disgust\\'], [\\'sadness\\'], [\\'sadness\\'], [\\'sadness\\'], [\\'anger\\', \\'disgust\\'], [\\'sadness\\'], [\\'sadness\\'], [\\'sadness\\'], [\\'anger\\', \\'disgust\\'], [\\'joy\\'], [\\'anger\\', \\'disgust\\'], [\\'sadness\\'], [\\'sadness\\'], [\\'sadness\\'], [\\'anger\\', \\'disgust\\'], [\\'sadness\\'], [\\'sadness\\'], [\\'sadness\\'], [\\'anger\\', \\'disgust\\'], [\\'joy\\'], [\\'anger\\', \\'disgust\\'], [\\'sadness\\'], [\\'sadness\\'], [\\'sadness\\'], [\\'anger\\', \\'disgust\\'], [\\'sadness\\'], [\\'sadness\\'], [\\'sadness\\'], [\\'anger\\', \\'disgust\\'], [\\'joy\\'], [\\'anger\\', \\'disgust\\'], [\\'sadness\\'], [\\'sadness\\'], [\\'sadness\\'], [\\'anger\\', \\'disgust\\'], [\\'sadness\\'], [\\'sadness\\'], [\\'sadness\\'], [\\'anger\\', \\'disgust\\'], [\\'sadness\\'], [\\'sadness\\'], [\\'sadness\\'], [\\'anger\\', \\'disgust\\'], [\\'joy\\'], [\\'anger\\', \\'disgust\\'], [\\'sadness\\'], [\\'sadness\\'], [\\'sadness\\'], [\\'anger\\', \\'disgust\\'], [\\'sadness\\'], [\\'sadness\\'], [\\'sadness\\'], [\\'anger\\', \\'disgust\\'], [\\'joy\\'], [\\'anger\\', \\'disgust\\'], [\\'sadness\\'], [\\'sadness\\'], [\\'sadness\\'], [\\'anger\\', \\'disgust\\'], [\\'sadness\\'], [\\'sadness\\'], [\\'sadness\\'], [\\'anger\\', \\'disgust\\'], [\\'sadness\\'], [\\'sadness\\'], [\\'sadness\\'], [\\'anger\\', \\'disgust\\'], [\\'sadness\\'], [\\'sadness\\'], [\\'sadness\\'], [\\'anger\\', \\'disgust\\'], [\\'sadness\\'], [\\'sadness\\'], [\\'sadness\\'], [\\'anger\\', \\'disgust\\'], [\\'sadness\\'], [\\'sadness\\'], [\\'sadness\\'], [\\'anger\\', \\'disgust\\'], [\\'sadness\\'], [\\'sadness\\'], [\\'sadness\\'], [\\'anger\\', \\'disgust\\'], [\\'joy\\'], [\\'anger\\', \\'disgust\\'], [\\'sadness\\'], [\\'sadness\\'], [\\'sadness\\'], [\\'anger\\', \\'disgust\\'], [\\'sadness\\'], [\\'sadness\\'],',\n",
       " \"To identify the applicable emotions, we need to convert the input features into their corresponding emotion labels. However, the provided input features and emotion labels are in numerical and categorical format, respectively. Therefore, we need to use a machine learning model to classify the input features into their corresponding emotion labels.\\n\\nBased on the provided examples, it appears that the input features are the output of a convolutional neural network (CNN) or a similar model. The emotion labels are the output of a classification model that maps the input features to their corresponding emotion labels.\\n\\nHere is a sample code in Python using the scikit-learn library to classify the input features into their corresponding emotion labels:\\n\\n```python\\nimport numpy as np\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.preprocessing import StandardScaler\\nfrom sklearn.linear_model import LogisticRegression\\nfrom sklearn.metrics import accuracy_score\\n\\n# Define the input features and emotion labels\\ninput_features = np.array([\\n    [-3.8281e-01,  5.4297e-01, -3.4106e-01,  3.9478e-01,  3.1934e-01, -1.2286e-01],\\n    [-4.7046e-01,  3.1665e-01, -1.0089e-01,  2.6685e-01,  1.4233e-01, -1.7456e-01],\\n    [-6.1426e-01,  5.1514e-01, -1.0858e-01,  3.5278e-01, -6.8909e-02, -9.4055e-02]\\n])\\n\\nemotion_labels = np.array([\\n    ['sadness'],\\n    ['sadness','surprise'],\\n    ['fear','sadness']\\n])\\n\\n# Split the input features and emotion labels into training and testing sets\\nX_train, X_test, y_train, y_test = train_test_split(input_features, emotion_labels, test_size=0.2, random_state=42)\\n\\n# Scale the input features using StandardScaler\\nscaler = StandardScaler()\\nX_train_scaled = scaler.fit_transform(X_train)\\nX_test_scaled = scaler.transform(X_test)\\n\\n# Train a logistic regression model on the scaled input features and emotion labels\\nmodel = LogisticRegression(max_iter=1000)\\nmodel.fit(X_train_scaled, [emotion for emotion in y_train][0\",\n",
       " 'To identify the applicable emotions, we need to train a machine learning model on a dataset of labeled emotions. Since we don\\'t have a pre-trained model, we\\'ll use a simple technique to classify the emotions.\\n\\nWe\\'ll use a k-nearest neighbors (KNN) algorithm with a Euclidean distance metric to classify the emotions. We\\'ll use the given dataset to train the model.\\n\\nHere\\'s a Python code snippet to train the model and classify the emotions:\\n\\n```python\\nimport numpy as np\\nfrom sklearn.neighbors import KNeighborsClassifier\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.metrics import accuracy_score\\n\\n# Define the classes\\nclasses = [\"anger\", \"disgust\", \"fear\", \"sadness\", \"surprise\", \"joy\", \"neutral\"]\\n\\n# Define the input data\\ninput_data = np.array([\\n    [-2.7271e-01, 1.7859e-01, -2.6416e-01, 4.0161e-01, 1.0522e-01, 1.6504e-01],\\n    [-1.3257e-01, 1.2146e-01, -5.7031e-01, -1.2061e-01, 5.2197e-01, 5.6445e-01],\\n    [-3.2593e-01, 2.8809e-01, 6.0596e-01, -2.1088e-02, -2.4524e-01, -2.4307e-02],\\n    [-2.7271e-01, 1.7859e-01, -2.6416e-01, 4.0161e-01, 1.0522e-01, 1.6504e-01],\\n    [-1.3257e-01, 1.2146e-01, -5.7031e-01, -1.2061e-01, 5.2197e-01, 5.6445e-01],\\n    [-3.2593e-01, 2.8809e-01, 6.0596e-01, -2.1088e-02, -2.4524e-01, -2.4307e-02],\\n    [-2.7271e-01, 1.',\n",
       " '{\"emotions\": [[\\'anger\\'], [\\'fear\\'], [\\'anger\\', \\'disgust\\'], [\\'anger\\'], [\\'anger\\'], [\\'anger\\', \\'fear\\'], [\\'anger\\',\\'sadness\\']]}\\n\\nThe input is classified into the following emotions:\\n- anger\\n- fear\\n- disgust\\n- sadness\\n\\nThese emotions are identified based on the given classes: \"anger\", \"disgust\", \"fear\", \"sadness\", \"surprise\", \"joy\", \"neutral\".',\n",
       " '**Identifying Applicable Emotions**\\n\\nBased on the input features, the following emotions are identified:\\n\\n1. **anger**: 0.55 (high probability)\\n2. **fear**: 0.23 (moderate probability)\\n3. **surprise**: 0.16 (low probability)\\n4. **joy**: 0.06 (low probability)\\n5. **neutral**: 0.04 (low probability)\\n\\nThe most applicable emotion is **anger** with a high probability of 0.55.',\n",
       " '{\"emotions\": [[\\'fear\\',\\'surprise\\'], [\\'fear\\',\\'surprise\\'], [\\'sadness\\'], [\\'fear\\',\\'sadness\\'], [\\'fear\\'], [\\'fear\\',\\'surprise\\'], [\\'fear\\',\\'surprise\\'], [\\'fear\\'], [\\'surprise\\'], [\\'fear\\',\\'surprise\\'], [\\'fear\\',\\'surprise\\'], [\\'surprise\\'], [\\'surprise\\'], [\\'anger\\',\\'sadness\\'], [\\'anger\\', \\'disgust\\'], [\\'anger\\'], [\\'anger\\']]}\\n\\nNote: The output for each input is a list of emotions that the input is classified as, based on the given classes. The order of the emotions in the list may vary depending on the specific classification algorithm used. \\n\\nIn this case, the output is a list of emotions for each input. The emotions are chosen from the given classes: \"anger\", \"disgust\", \"fear\", \"sadness\", \"surprise\", \"joy\", \"neutral\". \\n\\nFor the given input, the output is a list of emotions that are applicable based on the classification.',\n",
       " 'To classify the emotions, we will use a pre-trained machine learning model. Since the input features are not specified, I will assume that the input features are the given arrays of numbers.\\n\\nI will use the `scikit-learn` library to classify the emotions. Here is a Python code snippet to classify the emotions:\\n\\n```python\\nfrom sklearn import datasets\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.preprocessing import StandardScaler\\nfrom sklearn.decomposition import PCA\\nfrom sklearn.linear_model import LogisticRegression\\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\\n\\n# Load the dataset\\niris = datasets.load_iris()\\nX = iris.data\\ny = iris.target\\n\\n# Split the dataset into a training set and a test set\\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\\n\\n# Standardize features by removing the mean and scaling to unit variance\\nsc = StandardScaler()\\nX_train_std = sc.fit_transform(X_train)\\nX_test_std = sc.transform(X_test)\\n\\n# Apply dimensionality reduction using PCA\\npca = PCA(n_components=2)\\nX_train_pca = pca.fit_transform(X_train_std)\\nX_test_pca = pca.transform(X_test_std)\\n\\n# Train a logistic regression classifier on the training set\\nlr = LogisticRegression(max_iter=1000)\\nlr.fit(X_train_pca, y_train)\\n\\n# Make predictions on the test set\\ny_pred = lr.predict(X_test_pca)\\n\\n# Evaluate the performance of the classifier\\nprint(\"Accuracy:\", accuracy_score(y_test, y_pred))\\nprint(\"Classification Report:\")\\nprint(classification_report(y_test, y_pred))\\nprint(\"Confusion Matrix:\")\\nprint(confusion_matrix(y_test, y_pred))\\n```\\n\\nHowever, since the given arrays of numbers do not correspond to any emotional classification dataset, we will use a different approach. We will use a pre-trained emotional classification model to classify the input features.\\n\\nHere is a Python code snippet to classify the emotions:\\n\\n```python\\nimport numpy as np\\nfrom sklearn.preprocessing import StandardScaler\\nfrom sklearn.decomposition import PCA\\nfrom sklearn.linear_model import LogisticRegression\\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\\nfrom sklearn import datasets\\n\\n# Define the input features\\ninput_features = np.array([\\n    [-6.2891e-01,  5.4932e-01, -2.1997e-01,  1.3672e-01, ',\n",
       " 'To process the input, we will need a machine learning model trained on emotional classification. Assuming we have such a model, we can use it to classify the input as follows:\\n\\n```python\\nimport numpy as np\\n\\n# Define the input\\ninput_data = np.array([\\n    -3.4229e-01,  5.4736e-01, -1.1450e-01,  2.7539e-01,  2.4963e-01,  8.2214e-02,\\n     3.3911e-01, -4.1162e-01, -2.8149e-01, -2.5122e-01,  4.5386e-01, -1.8799e-02,\\n     6.6553e-01,  1.6272e-01, -3.1250e-01,  8.0078e-02, -3.5864e-01, -1.9580e-01,\\n    -2.8052e-01, -3.3386e-02, -5.1172e-01, -1.9580e-01,  1.7761e-01,  8.0664e-01,\\n    -1.9531e-01,  8.8196e-02,  6.4209e-01,  9.0210e-02, -1.2115e-01,  3.2788e-01,\\n    -1.8115e-01, -3.1104e-01, -2.2266e-01, -3.8232e-01,  3.0249e-01,  1.8457e-01,\\n     3.2251e-01,  2.5171e-01,  7.0435e-02, -1.0864e-01,  7.8467e-01, -2.0154e-01,\\n     4.1748e-02, -3.6694e-01,  5.6006e-01,  9.1406e-01,  1.7590e-01, -1.1101e',\n",
       " 'To identify the applicable emotions, we need to classify the input into the given emotions: \"anger\", \"disgust\", \"fear\", \"sadness\", \"surprise\", \"joy\", \"neutral\".\\n\\nHere is a Python code snippet that uses a pre-trained model to classify the input:\\n```python\\nimport numpy as np\\nfrom sklearn.preprocessing import StandardScaler\\nfrom sklearn.decomposition import PCA\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.ensemble import RandomForestClassifier\\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\\n\\n# Load the dataset\\nfrom sklearn.datasets import load_emotions\\n\\n# Load the dataset\\nemotions = load_emotions()\\n\\n# Define the features and labels\\nX = emotions.data\\ny = emotions.target\\n\\n# Define the train and test sets\\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\\n\\n# Scale the features\\nscaler = StandardScaler()\\nX_train_scaled = scaler.fit_transform(X_train)\\nX_test_scaled = scaler.transform(X_test)\\n\\n# Apply PCA to reduce dimensionality\\npca = PCA(n_components=0.95, random_state=42)\\nX_train_pca = pca.fit_transform(X_train_scaled)\\nX_test_pca = pca.transform(X_test_scaled)\\n\\n# Train a random forest classifier\\nclf = RandomForestClassifier(n_estimators=100, random_state=42)\\nclf.fit(X_train_pca, y_train)\\n\\n# Make predictions\\ny_pred = clf.predict(X_test_pca)\\n\\n# Evaluate the model\\nprint(\"Accuracy:\", accuracy_score(y_test, y_pred))\\nprint(\"Classification Report:\")\\nprint(classification_report(y_test, y_pred))\\nprint(\"Confusion Matrix:\")\\nprint(confusion_matrix(y_test, y_pred))\\n\\n# Predict the input\\ninput_data = np.array([-3.1665e-01,  4.3335e-01, -3.3398e-01,  2.4561e-01,  1.6235e-01,  1.2317e-01,  5.1807e-01, -9.0027e-02,  5.5878e-02, -1.3086e-01,  3.9600e-01, -5.0690e-02,  5.6738e-01, -2.5742e-02, -3.3252',\n",
       " '{\"emotions\": [[\\'anger\\'], [\\'anger\\'], [\\'anger\\'], [\\'surprise\\'], [\\'anger\\',\\'sadness\\'], [\\'anger\\'], [\\'anger\\'], [\\'anger\\'], [\\'anger\\'], [\\'anger\\']]}\\n\\nThis output indicates that the input data corresponds to the emotions: anger, with some instances also containing the emotions sadness and surprise.',\n",
       " 'To identify the applicable emotions from the given classes, we can use a machine learning model trained on a dataset of emotional expressions. However, since the model\\'s architecture and the dataset used for training are not provided, I will use a simple approach to classify the emotions based on the input features.\\n\\nHere is a possible implementation in Python:\\n```python\\nimport numpy as np\\n\\n# Define the emotions classes\\nemotions_classes = [\"anger\", \"disgust\", \"fear\", \"sadness\", \"surprise\", \"joy\", \"neutral\"]\\n\\n# Define the input data\\ninput_data = np.array([-3.6890e-01,  4.9683e-01, -1.4832e-01,  1.4526e-01,  2.3303e-01,  1.5388e-02,\\n  3.0249e-01, -2.4963e-01, -1.3232e-01, -2.4060e-01,  5.5176e-01,  1.1536e-01,\\n  6.0645e-01, -4.7455e-02, -1.4014e-01,  1.3684e-01, -5.1758e-02,  4.4899e-03,\\n -4.4019e-01, -2.3218e-01, -5.8691e-01, -2.0618e-01,  1.5076e-01,  5.1758e-01,\\n -1.0547e-01,  2.5732e-01,  6.5967e-01,  6.8726e-02, -8.8806e-02,  4.2017e-01,\\n -1.6577e-01, -1.6931e-01, -3.3081e-01, -3.0444e-01,  1.1432e-01, -2.0874e-02,\\n  3.0298e-01,  5.3223e-01, -2.0706e-02,  1.7090e-01,  5.5566e-01, -',\n",
       " 'Based on the provided input, the output would be:\\n\\n{\"emotions\": [[\\'anger\\',\\'surprise\\'], [\\'fear\\',\\'surprise\\'], [\\'fear\\'], [\\'surprise\\'], [\\'anger\\'], [\\'anger\\',\\'surprise\\'], [\\'joy\\'], [\\'joy\\'], [\\'anger\\',\\'surprise\\']]}',\n",
       " 'The given input data can be classified into the following emotions: \\n\\n1. [\"anger\", \"disgust\"]\\n2. [\"anger\"]\\n3. [\"disgust\", \"sadness\"]\\n4. [\"anger\"]\\n5. [\"anger\", \"surprise\"]\\n6. [\"anger\", \"sadness\"]\\n7. [\"anger\"]\\n8. [\"anger\"]\\n9. [\"anger\", \"surprise\"]\\n10. [\"anger\", \"sadness\"]\\n11. [\"anger\"]\\n12. [\"surprise\"]\\n13. [\"anger\"]\\n14. [\"anger\"]\\n15. [\"anger\"]\\n16. [\"anger\", \"surprise\"]\\n17. [\"anger\"]\\n18. [\"anger\"]\\n19. [\"anger\", \"disgust\"]\\n20. [\"anger\"]\\n21. [\"anger\"]\\n22. [\"anger\", \"surprise\"]\\n23. [\"anger\", \"sadness\"]\\n24. [\"anger\"]\\n25. [\"anger\"]\\n26. [\"anger\", \"surprise\"]\\n27. [\"anger\"]\\n28. [\"anger\"]\\n29. [\"anger\", \"sadness\"]\\n30. [\"anger\", \"surprise\"]\\n31. [\"anger\"]\\n32. [\"anger\"]\\n33. [\"anger\"]\\n34. [\"anger\", \"surprise\"]\\n35. [\"anger\"]\\n36. [\"anger\"]\\n37. [\"anger\", \"surprise\"]\\n38. [\"anger\"]\\n39. [\"anger\"]\\n40. [\"anger\", \"surprise\"]\\n41. [\"anger\"]\\n42. [\"anger\"]\\n43. [\"anger\", \"surprise\"]\\n44. [\"anger\"]\\n45. [\"anger\"]\\n46. [\"anger\", \"surprise\"]\\n47. [\"anger\"]\\n48. [\"anger\"]\\n49. [\"anger\", \"surprise\"]\\n50. [\"anger\"]\\n51. [\"anger\"]\\n52. [\"anger\", \"surprise\"]\\n53. [\"anger\"]\\n54. [\"anger\"]\\n55. [\"anger\", \"surprise\"]\\n56. [\"anger\"]\\n57. [\"anger\"]\\n58. [\"anger\"]\\n59. [\"anger\", \"surprise\"]\\n60. [\"anger\"]\\n61. [\"anger\"]\\n62. [\"anger\", \"surprise\"]\\n63. [\"anger\"]\\n64. [\"anger\"]\\n65. [\"anger\", \"surprise\"]\\n66. [\"anger\"]\\n67. [\"anger\"]\\n68. [\"anger\", \"surprise\"]\\n69. [\"anger\"]\\n70. [\"anger\"]\\n71. [\"anger\", \"surprise\"]\\n72. [\"anger\"]\\n73. [\"anger\"]\\n74. [\"anger\", \"surprise\"]\\n75. [\"anger\"]\\n76. [\"anger\"]\\n77. [\"anger\", \"',\n",
       " 'The input data is a 2D array of floats, which represents a dataset of emotional states. The output is a dictionary with a single key \"emotions\" and a list of emotions as its value. \\n\\nIn the given examples, the output dictionaries are:\\n\\nExample 1:\\n{\"emotions\": [[\\'anger\\'], [\\'anger\\'], [\\'anger\\'], [\\'anger\\']]}\\n\\nExample 2:\\n{\"emotions\": [[\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\']]}\\n\\nExample 3:\\n{\"emotions\": [[\\'anger\\'], [\\'anger\\'], [\\'disgust\\',\\'sadness\\']]}\\n\\nInput for classification:\\nThe input data is a 2D array of floats, which represents a dataset of emotional states. The output is a dictionary with a single key \"emotions\" and a list of emotions as its value.\\n\\nHowever, the code snippet you provided does not classify the given input data. It is a code snippet from a classification model that predicts the emotions of a given input. But the given input data is not classified in the code snippet.\\n\\nTo classify the given input data, you can use the following code snippet:\\n\\n```python\\nimport numpy as np\\n\\n# Define the input data\\ninput_data = np.array([\\n    [-6.8213e-01,  5.5518e-01, -1.1865e-01,  1.3232e-01,  2.8296e-01,  7.5684e-02,\\n     5.3375e-02, -2.6562e-01, -2.4194e-01, -3.0933e-01,  5.2734e-01,  1.3586e-01,\\n     3.2422e-01,  1.7407e-01, -3.8110e-01,  6.9458e-02, -2.4084e-01, -1.9226e-01,\\n     1.6602e-01, -4.6143e-01, -7.6025e-01, -4.5850e-01,  5.8740e-01,  9.0430e-01,\\n     3.8261e-03,  2.0642e-01,  5.',\n",
       " 'Based on the provided input and the specified emotion classes, the output is:\\n\\n{\"emotions\": [[\\'anger\\', \\'disgust\\'], [\\'anger\\',\\'sadness\\'], [\\'anger\\', \\'fear\\',\\'sadness\\'], [\\'fear\\',\\'sadness\\'], [\\'fear\\',\\'sadness\\']]}\\n\\nThis output indicates that the input data is classified into the following emotions:\\n\\n1. \"anger\" and \"disgust\"\\n2. \"anger\" and \"sadness\"\\n3. \"anger\", \"fear\", and \"sadness\"\\n4. \"fear\" and \"sadness\"\\n5. \"fear\" and \"sadness\"\\n\\nThese classifications are based on the provided input data and the specified emotion classes.',\n",
       " 'The input provided is in the format of numerical features which need to be classified into emotional categories. The output will be the associated emotions for each input.\\n\\nFor the given input, the output will be:\\n\\n{\"emotions\": [[\\'fear\\',\\'surprise\\'], [\\'fear\\',\\'surprise\\'], [\\'fear\\',\\'surprise\\'], [\\'fear\\',\\'surprise\\'], [\\'anger\\'], [\\'surprise\\'], [\\'anger\\'], [\\'anger\\',\\'surprise\\'], [\\'surprise\\'], [\\'anger\\'], [\\'anger\\', \\'joy\\']]}\\n\\nThis indicates that the input features are classified into the following emotions:\\n\\n1. \\'fear\\',\\'surprise\\'\\n2. \\'fear\\',\\'surprise\\'\\n3. \\'fear\\',\\'surprise\\'\\n4. \\'fear\\',\\'surprise\\'\\n5. \\'anger\\'\\n6.\\'surprise\\'\\n7. \\'anger\\'\\n8. \\'anger\\',\\'surprise\\'\\n9.\\'surprise\\'\\n10. \\'anger\\'\\n11. \\'anger\\', \\'joy\\'\\n\\nThese emotions are based on the provided input features and the associated emotional categories.',\n",
       " \"To identify the applicable emotions in the input data, we can use a pre-trained emotion classification model. For simplicity, let's use a basic decision tree classifier.\\n\\nHere's a Python code snippet using the scikit-learn library to classify the emotions:\\n\\n```python\\nimport numpy as np\\nfrom sklearn.tree import DecisionTreeClassifier\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn import datasets\\nimport pandas as pd\\nfrom sklearn.metrics import accuracy_score\\n\\n# Load the dataset\\n# This dataset contains emotions and their corresponding features\\nemotions = pd.DataFrame({\\n    'anger': [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\\n    'disgust': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\\n    'fear': [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1],\\n   'sadness': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\\n   'surprise': [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1],\\n    'joy': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\\n    'neutral': [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\\n})\\n\\nfeatures = np.array([\\n    [-5.0537e-01,  5.7373e-01,  1.0699e-01,  1.6284e-01,  1.489\",\n",
       " 'To classify the input vectors, we would need a trained model or a set of weights and biases that can be applied to the input vectors to produce the output emotions. However, based on the given examples, we can try to classify the input vectors using a simple approach.\\n\\nHere is the Python code to classify the input vector:\\n\\n```python\\nimport numpy as np\\n\\n# Define the emotions and their corresponding weights and biases\\nemotions = [\"anger\", \"disgust\", \"fear\", \"sadness\", \"surprise\", \"joy\", \"neutral\"]\\nweights = np.array([\\n    [0.5, 0.3, 0.1, -0.2, 0.1, 0.1, -0.1],\\n    [0.4, 0.4, 0.1, -0.2, 0.1, 0.1, -0.1],\\n    [0.3, 0.3, 0.3, -0.2, 0.1, 0.1, -0.1],\\n    [0.2, 0.2, 0.2, -0.2, 0.1, 0.1, -0.1],\\n    [0.1, 0.1, 0.1, -0.2, 0.1, 0.1, -0.1],\\n    [0, 0, 0, -0.2, 0.1, 0.1, -0.1],\\n    [-0.1, -0.1, -0.1, -0.2, 0.1, 0.1, -0.1]\\n])\\nbiases = np.array([-1, -1, -1, -1, -1, -1, -1])\\n\\n# Define the input vector\\ninput_vector = np.array([\\n    -6.3721, 6.4014, -1.2024, 2.4438, 9.0027, 8.1299,\\n    3.3618, -2.8687, 9.5154, -3.1030, 5.4102, 2.0471,\\n    3.6597, 9.6863, -2.6245, 1.0962, 8.2886, 6.500',\n",
       " '{\"emotions\": [[\\'anger\\', \\'disgust\\', \\'fear\\'], [\\'anger\\', \\'fear\\',\\'surprise\\'], [\\'anger\\'], [\\'anger\\', \\'disgust\\'], [\\'fear\\',\\'surprise\\'], [\\'anger\\', \\'disgust\\', \\'fear\\',\\'sadness\\'], [\\'fear\\',\\'surprise\\'], [\\'anger\\',\\'sadness\\'], [\\'fear\\',\\'surprise\\'], [\\'anger\\']]}\\n\\n\\nHere\\'s how the model identifies the emotions in the input data:\\n\\n1. The first input is classified as \\'anger\\', \\'disgust\\', and \\'fear\\' because of the corresponding values in the input array.\\n2. The second input is classified as \\'anger\\', \\'fear\\', and\\'surprise\\' because of the corresponding values in the input array.\\n3. The third input is classified as \\'anger\\' because of the corresponding value in the input array.\\n4. The fourth input is classified as \\'anger\\' and \\'disgust\\' because of the corresponding values in the input array.\\n5. The fifth input is classified as \\'fear\\' and\\'surprise\\' because of the corresponding values in the input array.\\n6. The sixth input is classified as \\'anger\\', \\'disgust\\', \\'fear\\', and\\'sadness\\' because of the corresponding values in the input array.\\n7. The seventh input is classified as \\'fear\\' and\\'surprise\\' because of the corresponding values in the input array.\\n8. The eighth input is classified as \\'anger\\' and\\'sadness\\' because of the corresponding values in the input array.\\n9. The ninth input is classified as \\'fear\\' and\\'surprise\\' because of the corresponding values in the input array.\\n10. The tenth input is classified as \\'anger\\' because of the corresponding value in the input array.',\n",
       " '{\"emotions\": [[\\'anger\\', \\'disgust\\'], [\\'joy\\'], [\\'anger\\', \\'disgust\\'], [\\'sadness\\'], [\\'sadness\\'], [\\'sadness\\']]}\\n\\nIn this output, the emotions are identified as a combination of multiple classes based on the input feature values. The predicted emotions are:\\n\\n1. \\'anger\\' and \\'disgust\\'\\n2. \\'joy\\'\\n3. \\'anger\\' and \\'disgust\\'\\n4.\\'sadness\\'\\n5.\\'sadness\\'\\n6.\\'sadness\\'\\n\\nPlease note that the actual output may vary based on the model and algorithm used for classification.',\n",
       " 'To classify the emotions from the given input, we will use a pre-trained model. Since the input array is not provided, I will assume it is the same as the one given in the examples.\\n\\n```python\\nfrom sklearn.preprocessing import StandardScaler\\nfrom sklearn.decomposition import PCA\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.metrics import accuracy_score\\nfrom sklearn import svm\\nfrom sklearn import datasets\\nimport numpy as np\\n\\n# Load the dataset\\niris = datasets.load_iris()\\nX = iris.data\\ny = iris.target\\n\\n# Standardize features by removing the mean and scaling to unit variance\\nscaler = StandardScaler()\\nX_standardized = scaler.fit_transform(X)\\n\\n# Apply PCA\\npca = PCA(n_components=2)\\nX_pca = pca.fit_transform(X_standardized)\\n\\n# Split the data into training and test sets\\nX_train, X_test, y_train, y_test = train_test_split(X_pca, y, test_size=0.2, random_state=42)\\n\\n# Train a Support Vector Machine classifier\\nclassifier = svm.SVC(kernel=\\'rbf\\', gamma=0.1, C=10)\\nclassifier.fit(X_train, y_train)\\n\\n# Make predictions\\ny_pred = classifier.predict(X_test)\\n\\n# Evaluate the classifier\\naccuracy = accuracy_score(y_test, y_pred)\\nprint(\"Accuracy:\", accuracy)\\n\\n# Define the applicable emotions\\napplicable_emotions = [\"anger\", \"disgust\", \"fear\", \"sadness\", \"surprise\", \"joy\", \"neutral\"]\\n\\n# Define the input array\\ninput_array = np.array([-6.6943e-01,  8.2129e-01, -4.4136e-03,  4.2261e-01,  3.2959e-01, -3.0103e-01,\\n  1.7004e-01, -3.1592e-01,  1.0974e-01, -3.9648e-01,  3.2788e-01, -6.7505e-02,\\n  7.5879e-01,  2.0630e-01, -2.2803e-01,  1.7676e-01, -8.1787e-02,  5.3833e-02,\\n  1.9104e-02, -4.4238e-',\n",
       " '{\"emotions\": [[\\'anger\\'], [\\'anger\\'], [\\'disgust\\',\\'sadness\\']]}\\n\\nThis is because the input feature vectors correspond to the following emotions:\\n\\n1. [\"anger\"] - the input vector [-4.7705, 4.8413, -1.0315, 7.3730, 3.5205, -2.6172] corresponds to the emotion \"anger\".\\n2. [\"anger\"] - the input vector [-4.7705, 4.8413, -1.0315, 7.3730, 3.5205, -2.6172] also corresponds to the emotion \"anger\".\\n3. [\"disgust\", \"sadness\"] - the input vector [-4.7705, 4.8413, -1.0315, 7.3730, 3.5205, -2.6172] corresponds to the emotions \"disgust\" and \"sadness\".\\n\\nTherefore, the output is {\"emotions\": [[\\'anger\\'], [\\'anger\\'], [\\'disgust\\',\\'sadness\\']]}.\\n\\nThe input feature vectors correspond to the following emotions:\\n\\n1. [\"anger\"] - the input vector [-3.3984, 8.7354, -1.2079, 6.6895, 3.4814, -2.9785] corresponds to the emotion \"anger\".\\n2. [\"joy\"] - the input vector [-3.3984, 8.7354, -1.2079, 6.6895, 3.4814, -2.9785] corresponds to the emotion \"joy\".\\n3. [\"joy\"] - the input vector [-3.3984, 8.7354, -1.2079, 6.6895, 3.4814, -2.9785] corresponds to the emotion \"joy\".\\n4. [\"anger\"] - the input vector [-3.3984, 8.7354, -1.2079, 6.6895, 3.4814, -2.9785] corresponds to the emotion \"anger\".\\n5. [\"anger\"] - the input vector [-3.3984, 8.7354, -1.2079, 6.6895, 3.4814, -2.9785] corresponds to the emotion \"anger\".\\n6. [\"fear\"] - the input vector [-3.',\n",
       " '{\"emotions\": [[\\'anger\\'], [\\'anger\\'], [\\'anger\\'], [\\'anger\\']]}\\n\\nNote: The model used here is a simple one and it might not classify the emotions correctly for all the inputs. The actual output might be different based on the complexity of the model and the dataset used for training.',\n",
       " \"To classify the input into emotions, we'll use a pre-trained model. Since you haven't specified the model, I'll assume we're using a generic neural network with a hidden layer.\\n\\n```python\\nimport numpy as np\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.preprocessing import StandardScaler\\nfrom sklearn.neural_network import MLPClassifier\\n\\n# Load the dataset\\ndataset = np.loadtxt('emotions_dataset.csv', delimiter=',')\\n\\n# Split the dataset into features and target\\nX = dataset[:, :-1]\\ny = dataset[:, -1]\\n\\n# Split the data into training and testing sets\\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\\n\\n# Scale the data\\nscaler = StandardScaler()\\nX_train_scaled = scaler.fit_transform(X_train)\\nX_test_scaled = scaler.transform(X_test)\\n\\n# Initialize the model\\nmodel = MLPClassifier(hidden_layer_sizes=(100), max_iter=1000, learning_rate_init=0.1)\\n\\n# Train the model\\nmodel.fit(X_train_scaled, y_train)\\n\\n# Make predictions\\npredictions = model.predict(X_test_scaled)\\n\\n# Print the predictions\\nprint(predictions)\\n```\\n\\nThe output will be a list of emotions corresponding to the input.\",\n",
       " 'This code snippet appears to be a classification model for emotions. However, the provided input data does not match any of the examples you provided. \\n\\nTo better assist you, I will provide a general outline of how to classify emotions based on the given input data. \\n\\n```python\\nimport numpy as np\\n\\n# Define the input data\\ninput_data = np.array([-8.2715e-01,  6.3818e-01,  8.1177e-02,  3.3594e-01,  1.2878e-01, -2.8735e-01,\\n                      1.1023e-01, -3.2764e-01, -2.6123e-01, -1.4551e-01,  3.4863e-01,  5.2490e-02,\\n                      9.8438e-01,  4.6826e-01, -2.9199e-01, -1.9604e-01,  2.3169e-01, -1.0901e-01,\\n                      2.0288e-01, -5.5908e-01, -1.4526e-01, -4.1846e-01,  3.0908e-01,  7.6074e-01,\\n                      -9.5581e-02,  1.2683e-01,  4.7314e-01, -2.1851e-01, -3.3862e-01,  5.3564e-01,\\n                      -2.9639e-01, -1.7798e-01, -1.0352e-01, -5.2344e-01,  3.9307e-01,  3.9233e-01,\\n                      1.6614e-01,  2.7710e-01, -1.5710e-01,  1.6541e-01,  6.0645e-01, -4.4482e-01,\\n                      -1.6418e-01, -4.0161e-01,  1.8286e-01,  9.1846e-01',\n",
       " '{\"emotions\": [[\\'anger\\']]}\\n\\nThe input data has been classified as belonging to the \"anger\" emotion class.',\n",
       " '{\"emotions\": [[\\'anger\\',\\'surprise\\'], [\\'fear\\',\\'surprise\\'], [\\'neutral\\'], [\\'surprise\\'], [\\'anger\\',\\'sadness\\']]}\\n\\nThe input is classified into the following emotions: \\n\\n1. \"anger\" and \"surprise\"\\n2. \"fear\" and \"surprise\"\\n3. \"neutral\"\\n4. \"surprise\"\\n5. \"anger\" and \"sadness\"\\n\\nThese classifications correspond to the given classes: \"anger\", \"surprise\", \"neutral\", \"sadness\", \"fear\", \"joy\", \"surprise\", \"anger\", \"fear\", \"surprise\", \"anger\", \"sadness\".',\n",
       " '{\"emotions\": [[\\'anger\\'], [\\'anger\\'], [\\'joy\\'], [\\'fear\\',\\'surprise\\'], [\\'anger\\'], [\\'anger\\'], [\\'anger\\'], [\\'anger\\'], [\\'anger\\'], [\\'anger\\'], [\\'fear\\',\\'surprise\\'], [\\'neutral\\'], [\\'anger\\',\\'sadness\\']]}\\n\\nNote: The output indicates the prominent emotions that are most likely to be associated with the input. The emotions are classified into the following categories: \"anger\", \"disgust\", \"fear\", \"sadness\", \"surprise\", \"joy\", \"neutral\".',\n",
       " '{\"emotions\": [[\\'anger\\'], [\\'fear\\',\\'surprise\\'], [\\'sadness\\',\\'surprise\\'], [\\'anger\\'], [\\'anger\\',\\'surprise\\'], [\\'anger\\'], [\\'fear\\',\\'surprise\\']]}\\n\\nFor the given input, the following emotions are identified: \\n\\nanger, fear, surprise, sadness \\n\\nThese emotions correspond to the given numerical input and can be used for further analysis or decision-making.\\n\\nPlease note that this is a sample output and the actual output may vary depending on the specific implementation and configuration of the emotion classification model used.',\n",
       " 'To run the code, you would need to integrate it with a machine learning library such as scikit-learn and use data that you would have preprocessed and labeled for training a model. \\n\\nHowever, for the sake of this example, let\\'s assume that we have a simple model trained on the given data. \\n\\n```python\\nimport numpy as np\\n\\n# Define the emotions classes\\nemotions_classes = [\"anger\", \"disgust\", \"fear\", \"sadness\", \"surprise\", \"joy\", \"neutral\"]\\n\\n# Define the input array\\ninput_array = np.array([-6.8164e-01,  5.8301e-01, -1.8591e-01,  3.4839e-01,\\n       3.4912e-01, -2.0068e-01,  2.1436e-01, -2.8882e-01,\\n       2.8979e-01, -3.4180e-01,  4.3945e-01,  3.2745e-02,\\n       7.6807e-01,  2.7612e-01, -5.1074e-01,  2.5848e-02,\\n       -1.9885e-01, -1.8225e-01,  5.5756e-02, -4.1479e-01,\\n       -7.8125e-01, -1.3733e-01,  1.5881e-01,  7.5000e-01,\\n       1.4565e-02,  1.0895e-01,  4.4482e-01, -1.7322e-01,\\n       -1.4014e-01,  3.7109e-01, -4.2944e-01, -3.9331e-01,\\n       -2.2046e-01, -7.5806e-02, -2.6672e-02,  2.8345e-01,\\n       2.1899e-01,  1.0272e-01, -1.0059e-01, -8.4900e-02,\\n       2.9712e-01',\n",
       " \"To classify the input into the given categories, we can use a machine learning model that can classify emotions based on the input features.\\n\\nHere is how we can classify the input into the given categories:\\n\\n1. Import the necessary libraries:\\n   ```\\n   import numpy as np\\n   from sklearn.ensemble import RandomForestClassifier\\n   from sklearn.model_selection import train_test_split\\n   from sklearn.preprocessing import LabelEncoder\\n   ```\\n\\n2. Load the dataset and encode the labels:\\n   ```\\n   emotions = np.array([\\n   ['surprise'],\\n   ['fear','surprise'],\\n   ['neutral'],\\n   ['surprise'],\\n   ['anger','sadness'],\\n   ['anger'],\\n   ['anger'],\\n   ['anger'],\\n   ['anger'],\\n   ['fear'],\\n   ['anger', 'disgust'],\\n   ['anger'],\\n   ['anger'],\\n   ['anger'],\\n   ['anger'],\\n   ['anger'],\\n   ['anger'],\\n   ['anger'],\\n   ['anger'],\\n   ['anger'],\\n   ['anger'],\\n   ['anger'],\\n   ['anger'],\\n   ['anger'],\\n   ['anger'],\\n   ['anger'],\\n   ['anger'],\\n   ['anger'],\\n   ['anger'],\\n   ['anger'],\\n   ['anger'],\\n   ['anger'],\\n   ['anger'],\\n   ['anger'],\\n   ['anger'],\\n   ['anger'],\\n   ['anger'],\\n   ['anger'],\\n   ['anger'],\\n   ['anger'],\\n   ['anger'],\\n   ['anger'],\\n   ['anger'],\\n   ['anger'],\\n   ['anger'],\\n   ['anger'],\\n   ['anger'],\\n   ['anger'],\\n   ['anger'],\\n   ['anger'],\\n   ['anger'],\\n   ['anger'],\\n   ['anger'],\\n   ['anger'],\\n   ['anger'],\\n   ['anger'],\\n   ['anger'],\\n   ['anger'],\\n   ['anger'],\\n   ['anger'],\\n   ['anger'],\\n   ['anger'],\\n   ['anger'],\\n   ['anger'],\\n   ['anger'],\\n   ['anger'],\\n   ['anger'],\\n   ['anger'],\\n   ['anger'],\\n   ['anger'],\\n   ['anger'],\\n   ['anger'],\\n   ['anger'],\\n   ['anger'],\\n   ['anger'],\\n   ['anger'],\\n   ['anger'],\\n   ['anger'],\\n   ['anger'],\\n   ['anger'],\\n   ['anger'],\\n   ['anger'],\\n   ['anger'],\\n   ['anger'],\\n   ['anger'],\\n   ['anger'],\\n   ['anger'],\\n   ['anger'],\\n   ['anger'],\\n   ['anger'],\\n   ['anger'],\\n   ['anger'],\\n   ['anger'],\\n   ['anger'],\\n   ['anger'],\\n   ['anger'],\\n   ['anger'],\\n   ['anger'],\\n  \",\n",
       " 'Based on the input features, the model predicts the following emotions:\\n\\n{\"emotions\": [[\\'anger\\', \\'fear\\',\\'surprise\\']]}\\n\\nNote: The model has identified the presence of three emotions: â€˜angerâ€™, â€˜fearâ€™, and â€˜surpriseâ€™. The emotions are identified based on the input features and the trained model.',\n",
       " '{\"emotions\": [[\\'fear\\',\\'surprise\\'], [\\'fear\\',\\'surprise\\'], [\\'fear\\'], [\\'surprise\\'], [\\'fear\\'], [\\'surprise\\'], [\\'joy\\'], [\\'anger\\']]}.',\n",
       " 'The input features are classified into the following emotions:\\n\\n* Anger: 0.01% (1 sample)\\n* Disgust: 0.00% (0 samples)\\n* Fear: 0.00% (0 samples)\\n* Sadness: 0.00% (0 samples)\\n* Surprise: 0.00% (0 samples)\\n* Joy: 0.00% (0 samples)\\n* Neutral: 99.99% (399 samples)\\n\\nThe output of the classification is as follows:\\n\\n{\"emotions\": [[\"neutral\"]]}',\n",
       " '{\"emotions\": [[\\'anger\\'], [\\'anger\\'], [\\'fear\\'], [\\'fear\\'], [\\'fear\\',\\'sadness\\'], [\\'sadness\\'], [\\'anger\\'], [\\'surprise\\'], [\\'surprise\\'], [\\'fear\\',\\'surprise\\']]}\\n\\nNote: I have interpreted the output as follows:\\n\\n- \\'anger\\' is present in the first and second rows.\\n- \\'fear\\' is present in the third and fourth rows, and also in the tenth row.\\n-\\'sadness\\' is present in the fifth and sixth rows.\\n-\\'surprise\\' is present in the seventh and eighth rows, and also in the tenth row.\\n \\n\\nSince the problem statement does not provide any specific emotions to classify, I have used the given classes to identify the applicable emotions.',\n",
       " '{\"emotions\": [[\\'anger\\'], [\\'fear\\',\\'surprise\\'], [\\'fear\\',\\'surprise\\'], [\\'fear\\'], [\\'anger\\', \\'fear\\',\\'sadness\\'], [\\'anger\\', \\'fear\\'], [\\'anger\\', \\'fear\\',\\'sadness\\'], [\\'anger\\', \\'disgust\\', \\'fear\\'], [\\'anger\\',\\'sadness\\']]}\\n\\nNote: The provided inputs are emotional intensity scores, which are then classified into emotions. The classification is done using a pre-trained model that maps the input scores to the corresponding emotions. The classified emotions are then returned as the output.',\n",
       " 'To classify the given input, we can use a pre-trained emotion classification model. However, since you didn\\'t provide any code or a specific model, I\\'ll provide a general approach using a popular library, scikit-learn.\\n\\n```python\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.preprocessing import StandardScaler\\nfrom sklearn.ensemble import RandomForestClassifier\\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\\n\\n# Assuming we have a dataset with feature vectors and corresponding emotions\\nX = [[-4.1504e-01, 6.6846e-01, -3.8306e-01, 6.2500e-02, 5.7812e-01, 2.1899e-01],\\n     [-4.1504e-01, 6.6846e-01, -3.8306e-01, 6.2500e-02, 5.7812e-01, 2.1899e-01]]\\n\\ny = [\"anger\", \"anger\"]  # Assuming \\'anger\\' is the correct emotion for the given input\\n\\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\\n\\nscaler = StandardScaler()\\nX_train_scaled = scaler.fit_transform(X_train)\\nX_test_scaled = scaler.transform(X_test)\\n\\n# Pre-trained emotion classification model (e.g., using a pre-trained neural network)\\nmodel = RandomForestClassifier(n_estimators=100, random_state=42)\\nmodel.fit(X_train_scaled, y_train)\\n\\ny_pred = model.predict(X_test_scaled)\\n\\nprint(\"Accuracy:\", accuracy_score(y_test, y_pred))\\nprint(\"Classification Report:\")\\nprint(classification_report(y_test, y_pred))\\nprint(\"Confusion Matrix:\")\\nprint(confusion_matrix(y_test, y_pred))\\n```\\n\\nIn this example, I used a pre-trained `RandomForestClassifier` for simplicity. However, you can use more advanced models or fine-tune this model using your dataset.\\n\\nPlease note that this is a simplified example. In a real-world scenario, you would need to:\\n\\n1. Collect and preprocess a large dataset with labeled emotions.\\n2. Split the dataset into training and testing sets.\\n3. Train a suitable classification model using the training set.\\n4. Evaluate the model\\'s performance using the testing set.\\n5. Fine-tune the model as needed.\\n\\nTo obtain the output in the required format, you would need to modify the code',\n",
       " 'After processing the input, we get the following emotions:\\n\\n{\"emotions\": [[\\'anger\\',\\'surprise\\', \\'joy\\'], [\\'anger\\',\\'sadness\\'], [\\'anger\\',\\'sadness\\'], [\\'sadness\\',\\'surprise\\'], [\\'anger\\', \\'disgust\\'], [\\'sadness\\'], [\\'sadness\\'], [\\'fear\\',\\'sadness\\', \\'joy\\'], [\\'anger\\',\\'sadness\\'], [\\'surprise\\', \\'joy\\'], [\\'anger\\', \\'disgust\\'], [\\'sadness\\'], [\\'anger\\', \\'disgust\\',\\'sadness\\'], [\\'anger\\', \\'disgust\\',\\'sadness\\'], [\\'anger\\',\\'sadness\\'], [\\'surprise\\']]}\\n\\nThese emotions can be identified from the following classes: \"anger\", \"disgust\", \"fear\", \"sadness\", \"surprise\", \"joy\", \"neutral\".',\n",
       " '{\"emotions\": [[\\'anger\\'], [\\'anger\\',\\'surprise\\'], [\\'anger\\',\\'surprise\\'], [\\'sadness\\', \\'joy\\']]}\\n\\nNote: This output is based on the provided input data and the assumption that the input is a feature vector for a classification task. The output is a list of emotions that correspond to the most likely emotions for the input feature vector, according to the specified classes.',\n",
       " 'Since the input arrays are quite large, I\\'ll use a simplified version of the model to identify the emotions.\\n\\n```python\\nimport numpy as np\\n\\n# Define the emotion detection model\\ndef detect_emotions(data):\\n    # Simplified model: detect joy, surprise, fear, sadness, and neutral emotions\\n    emotions = np.array([\\n        [\"joy\", \"surprise\", \"fear\", \"sadness\", \"neutral\"],\\n        [0.5, 0.3, 0.2, 0.1, 0.0],\\n        [0.4, 0.3, 0.2, 0.1, 0.0],\\n        [0.3, 0.4, 0.2, 0.1, 0.0],\\n        [0.2, 0.3, 0.4, 0.1, 0.0],\\n        [0.5, 0.3, 0.2, 0.0, 0.0],\\n        [0.3, 0.4, 0.2, 0.1, 0.0],\\n        [0.2, 0.3, 0.4, 0.1, 0.0],\\n        [0.5, 0.3, 0.2, 0.0, 0.0],\\n        [0.4, 0.3, 0.2, 0.1, 0.0],\\n    ])\\n    # Calculate the weighted sum of the emotions\\n    scores = np.sum(emotions[1:, 1:] * data[:, np.newaxis], axis=1)\\n    # Get the top-scoring emotion for each row\\n    top_emotions = np.argmax(scores, axis=1)\\n    # Map the index to the corresponding emotion\\n    emotions_dict = {0: \"joy\", 1: \"surprise\", 2: \"fear\", 3: \"sadness\", 4: \"neutral\"}\\n    return [[emotions_dict[i]] for i in top_emotions]\\n\\n# Test the model with the input arrays\\ndata1 = np.array([\\n    [-2.4939e-01, 4.4287e-01, 1.7700e-02, 1.1780e-01, 4.0088e-01, 1.8951e-02',\n",
       " '{\"emotions\": [[\\'anger\\'], [\\'anger\\'], [\\'disgust\\', \\'joy\\'], [\\'joy\\']]}\\n\\nNote: The output of the provided code is already given in the question. I am just providing the code to achieve the desired output. \\n\\n```python\\nimport pandas as pd\\nfrom sklearn.preprocessing import LabelEncoder\\nfrom sklearn.decomposition import PCA\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn import svm\\nfrom sklearn.metrics import accuracy_score\\nfrom sklearn.model_selection import cross_val_score\\nfrom sklearn.model_selection import GridSearchCV\\nimport numpy as np\\n\\n# Load the dataset\\nemotions_df = pd.read_csv(\\'Emotions.csv\\')\\n\\n# Define the features and target variables\\nX = emotions_df[[\\'anger\\', \\'anticip\\', \\'trust\\',\\'surpris\\', \\'joy\\', \\'fear\\', \\'disgus\\',\\'sadness\\', \\'neutral\\']]\\ny = emotions_df[\\'emotion\\']\\n\\n# One-hot encoding of emotions\\ny_enc = LabelEncoder().fit_transform(y)\\n\\n# One-hot encoding of emotions converted to binary\\ny_enc = np.array(y_enc, dtype=np.float32)\\n\\n# Split the dataset into training and testing sets\\nX_train, X_test, y_train, y_test = train_test_split(X, y_enc, test_size=0.1, random_state=42)\\n\\n# PCA to reduce features to 2\\npca = PCA(n_components=2)\\nX_train_pca = pca.fit_transform(X_train)\\nX_test_pca = pca.transform(X_test)\\n\\n# Train a Support Vector Machine (SVM) model\\nsvm_model = svm.SVC(kernel=\\'rbf\\', gamma=0.1, C=1)\\nsvm_model.fit(X_train_pca, y_train)\\n\\n# Make predictions on the test set\\ny_pred = svm_model.predict(X_test_pca)\\n\\n# Evaluate the model\\'s performance\\naccuracy = accuracy_score(y_test, y_pred)\\nprint(f\\'Model accuracy on the test set: {accuracy:.2f}\\')\\n\\n# Tune the hyperparameters using Grid Search\\nparam_grid = {\\'kernel\\': [\\'rbf\\', \\'linear\\', \\'poly\\'],\\n              \\'gamma\\': [0.1, 0.01, 0.001],\\n              \\'C\\': [1, 10, 100]}\\ngrid_search = GridSearchCV(svm_model, param_grid, cv=5)\\ngrid_search.fit(X_train_pca, y_train)\\n\\nprint(f\\'Best parameters: {grid_search.best_params_}\\')\\nprint(f\\'Best cross-validation score: {grid_search',\n",
       " 'Based on the input provided, the output for the three examples is as follows:\\n\\n1. \\n{\"emotions\": [[\\'surprise\\', \\'joy\\'], [\\'surprise\\', \\'joy\\'], [\\'surprise\\', \\'joy\\'], [\\'sadness\\', \\'joy\\']]}\\n\\n2.\\n{\"emotions\": [[\\'joy\\'], [\\'anger\\'], [\\'sadness\\',\\'surprise\\'], [\\'surprise\\'], [\\'surprise\\'], [\\'surprise\\'], [\\'anger\\'], [\\'fear\\',\\'sadness\\'], [\\'sadness\\'], [\\'anger\\'], [\\'joy\\'], [\\'sadness\\']]}\\n\\n3.\\n{\"emotions\": [[\\'surprise\\'], [\\'fear\\',\\'sadness\\',\\'surprise\\'], [\\'anger\\'], [\\'fear\\',\\'sadness\\'], [\\'anger\\'], [\\'sadness\\'], [\\'anger\\',\\'surprise\\'], [\\'anger\\'], [\\'joy\\'], [\\'anger\\'], [\\'anger\\',\\'surprise\\']]}\\n\\nInput for classification: [-4.1553e-01  5.7666e-01  1.9556e-01  2.4048e-02  3.0835e-01 -1.3416e-01\\n  7.8186e-02 -2.9688e-01  5.8044e-02 -2.1411e-01  7.4805e-01  2.5513e-02\\n  6.6846e-01 -7.7454e-02 -8.4229e-02  3.0688e-01 -3.2349e-01  9.0637e-03\\n -4.6680e-01  1.2311e-01 -4.4043e-01 -2.5635e-01  4.0918e-01  6.8115e-01\\n -3.0960e-02  1.9189e-01  6.5723e-01  1.0535e-01  2.0227e-01  3.3472e-01\\n -4.8889e-02 -2.7969e-02  2.5879e-01 -1.7029e-01  2.2937e-01  3.9160e-01\\n  1.1115e-01  2.2913e-01',\n",
       " '{\"emotions\": [[\\'sadness\\', \\'joy\\'], [\\'anger\\',\\'surprise\\'], [\\'anger\\',\\'surprise\\'], [\\'anger\\',\\'sadness\\'], [\\'sadness\\'], [\\'disgust\\',\\'sadness\\'], [\\'disgust\\',\\'surprise\\'], [\\'sadness\\',\\'surprise\\'], [\\'disgust\\'], [\\'anger\\', \\'disgust\\']]}\\n\\nThis output indicates that the input data corresponds to the following emotions:\\n\\n- \"sadness\" with \"joy\" (sadness and joy are both present)\\n- \"anger\" with \"surprise\" (both anger and surprise are present)\\n- \"anger\" with \"surprise\" (both anger and surprise are present)\\n- \"anger\" with \"sadness\" (both anger and sadness are present)\\n- \"sadness\" (sadness is the only present emotion)\\n- \"disgust\" with \"sadness\" (both disgust and sadness are present)\\n- \"disgust\" with \"surprise\" (both disgust and surprise are present)\\n- \"sadness\" with \"surprise\" (both sadness and surprise are present)\\n- \"disgust\" (disgust is the only present emotion)\\n- \"anger\" with \"disgust\" (both anger and disgust are present)\\n\\nNote that the output does not include the \"fear\", \"neutral\" emotions as they do not appear in the input data.',\n",
       " 'The input provided seems to be a set of numerical features for a classification problem, but it\\'s not clear what the specific task is. However, based on the output provided, it appears to be a classification task with the following classes: \"anger\", \"fear\", \"surprise\", \"sadness\", \"joy\", and \"neutral\".\\n\\nTo provide a more accurate answer, I\\'ll assume that the input is a set of features for a classification problem, and the output is the predicted emotions for each input.\\n\\nBased on the provided inputs and outputs, I\\'ll write a Python code snippet to classify the emotions using a simple neural network model. Please note that this is a basic example and may not be the most accurate or efficient solution.\\n\\n```python\\nimport numpy as np\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.preprocessing import StandardScaler\\nfrom sklearn.neural_network import MLPClassifier\\n\\n# Define the input data and output labels\\ninput_data = np.array([\\n    [-1.8701e-01,  5.5176e-01, -5.4474e-02,  5.2795e-02,  3.0029e-01,  5.5695e-03],\\n    [-3.0054e-01,  9.5508e-01, -1.4551e-01, -1.0254e-01,  5.3857e-01,  1.2817e-01],\\n    [-2.0044e-01,  4.7656e-01,  7.8003e-02,  1.9817e-03,  2.7637e-01, -3.5547e-01]\\n])\\n\\noutput_labels = np.array([\\n    [\"anger\"],\\n    [\"anger\"],\\n    [\"anger\", \"sadness\"]\\n])\\n\\n# Define the classes\\nclasses = [\"anger\", \"fear\", \"surprise\", \"sadness\", \"joy\", \"neutral\"]\\n\\n# One-hot encode the output labels\\noutput_labels_onehot = np.zeros((len(output_labels), len(classes)))\\nfor i, label in enumerate(output_labels):\\n    for j, class_name in enumerate(classes):\\n        if class_name in label:\\n            output_labels_onehot[i, j] = 1\\n\\n# Split the input data into training and testing sets\\nX_train, X_test, y_train, y_test = train_test_split',\n",
       " '{\"emotions\": [[\\'anger\\'], [\\'anger\\'], [\\'disgust\\', \\'joy\\'], [\\'joy\\']]}\\n\\n\\nThe emotions identified in the input data are:\\n\\n1. anger\\n2. disgust\\n3. joy',\n",
       " \"To classify the input features into emotions, we'll use a pre-trained model such as a neural network or a decision tree. Since the actual model is not provided, I'll assume we're using a pre-trained model that has been trained on the Emotion Recognition dataset.\\n\\nHere's a simplified version of the code:\\n\\n```python\\nimport numpy as np\\n\\n# Define the input features\\ninput_features = np.array([\\n    [-3.0640e-01,  6.0498e-01,  6.8855e-03,  2.9834e-01,  2.0264e-01, -1.5698e-01,\\n     1.6760e-01, -3.0713e-01, -1.3245e-01, -2.0935e-01,  2.5000e-01,  8.0017e-02],\\n    [-3.2617e-01,  5.2295e-01, -1.0170e-02,  1.4319e-01,  2.6587e-01, -1.1603e-01,\\n     2.6074e-01, -5.2277e-02,  5.4492e-01, -2.7515e-01,  3.8989e-01,  2.7634e-02],\\n    [-4.6875e-01,  5.9473e-01, -8.2642e-02,  1.7920e-01,  3.7646e-01, -1.7126e-01,\\n     5.0977e-01,  1.0510e-01,  1.2466e-02, -3.9868e-01,  5.4883e-01,  1.1310e-01]\\n])\\n\\n# Define the pre-trained model\\ndef classify_emotions(input_features):\\n    # Pre-trained model's output (this is a placeholder, replace with actual output)\\n    output = np.array([\\n        [1, 0, 0, 0, 0, 0],\\n        [0, 1, 0, 0, 0, 0],\\n        [0\",\n",
       " \"I'm not able to provide the actual output as the code wasn't provided. However, I can help you with the code to classify the emotions.\\n\\nHere's an example code in Python that uses a pre-trained emotion classification model to classify the emotions:\\n\\n```python\\nimport numpy as np\\n\\n# Input feature\\ninput_array = np.array([\\n  # Input feature array\\n  [-8.1421e-02,  2.2180e-01, -3.9185e-02,  3.7750e-02,  3.2617e-01, -2.4695e-01,\\n   1.0956e-01, -2.4731e-01,  2.2388e-01, -1.2183e-01,  3.9502e-01,  2.7124e-01,\\n   1.1211e+00,  1.2482e-01,  2.7026e-01, -1.3684e-01,  1.2054e-01, -5.3223e-02,\\n  -1.2109e-01, -1.3855e-01, -4.5654e-01, -1.9922e-01,  5.4785e-01,  4.7681e-01,\\n  -2.2583e-01, -1.3550e-01,  4.6338e-01, -1.4160e-01, -3.3203e-02,  2.4329e-01,\\n   1.0902e-02, -1.5564e-01, -9.7427e-03, -4.0161e-01,  1.3135e-01, -2.7283e-02,\\n   5.0385e-02,  2.8613e-01, -1.5503e-01, -1.2832e+00,  2.7783e-01, -1.5356e-01,\\n  -1.8750e-01, -5.5615e-01, -2.5040e-02,  3.5205e-01\",\n",
       " 'To determine the applicable emotions from the given classes, we need to use a machine learning model that can classify the input data into one of the specified emotions. \\n\\nHowever, the provided input data seems to be a list of floating point numbers, which are likely to be the output of a neural network or a deep learning model. To identify the emotions, we need to use a model that can take this input data and predict the corresponding emotions.\\n\\nBased on the provided input data, I will use a simple approach to identify the emotions. This approach will use a dictionary to map the emotions to their corresponding indices in the input data.\\n\\nHere is a simple Python code snippet that can be used to identify the emotions:\\n\\n```python\\nimport numpy as np\\n\\n# Define the emotions and their corresponding indices in the input data\\nemotions = {\\n    \"anger\": 0,\\n    \"disgust\": 1,\\n    \"fear\": 2,\\n    \"sadness\": 3,\\n    \"surprise\": 4,\\n    \"joy\": 5,\\n    \"neutral\": 6\\n}\\n\\n# Define the input data\\ninput_data = np.array([\\n    [-4.3677e-01,  4.8584e-01, -1.4233e-01,  1.4087e-01,  4.7461e-01,  1.5930e-01,\\n     1.9019e-01, -1.7859e-01, -1.9189e-01, -2.1680e-01,  7.1826e-01,  2.0312e-01,\\n     7.0410e-01,  9.4891e-04,  9.4788e-02,  2.7451e-02, -1.3452e-01,  1.2238e-01,\\n     -2.0142e-01, -2.3376e-02, -8.6914e-01, -1.3721e-01,  5.6738e-01,  4.1870e-01,\\n     -2.1606e-02,  2.8345e-01,  3.6133e-01, -8.6914e-02, -6.1798e-02',\n",
       " 'This is a classification problem, and the given data seems to be in the format of a feature matrix (not the typical input for a classification problem). Also, the classification labels are not provided in the required format.\\n\\nTo provide a solution, I will assume that the classification labels are in the last column of the feature matrix.\\n\\nHere is the solution:\\n```python\\nimport pandas as pd\\nfrom sklearn.preprocessing import StandardScaler\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.linear_model import LogisticRegression\\nfrom sklearn.metrics import accuracy_score, classification_report\\nfrom sklearn import preprocessing\\n\\n# Load the data\\ndf = pd.DataFrame({\\n    -5.4688e-01: 5.1074e-01, 1.1823e-01: 1.4136e-01, 3.6865e-01: -1.0223e-01,\\n    1.2939e-01: -3.5889e-01, 1.9409e-01: -2.6221e-01, 4.7729e-01: 3.4888e-01,\\n    8.4033e-01: 3.3228e-01, 2.5830e-01: -1.4539e-01, 2.2668e-01: 6.5674e-02,\\n    -3.7183e-01: 2.2998e-01, -5.0488e-01: -1.5576e-01, 5.0195e-01: 1.1337e-02,\\n    -2.4182e-01: -1.4624e-01, 2.3462e-01: 1.5186e-01, -1.6467e-01: 6.9482e-01,\\n    -2.7808e-01: -1.7834e-01, 1.5552e-01: -1.8396e-01, -1.5430e-01: 2.9590e-01,\\n    -2.7710e-02: 3.2593e-01, -2.0679e-01: -1.5117e+00, 6.0205e-01: 3.4229e-01,\\n',\n",
       " '{\"emotions\": [[\\'fear\\']]}\\n\\nThis output indicates that the input has a high probability of being classified as \"fear\".',\n",
       " \"I need to clarify that I'm a large language model, I don't have the capability to directly access the code or data provided. However, based on the input you provided, I'll attempt to simulate the output as if I were running the code.\\n\\nAssuming the input is processed using a suitable machine learning model or algorithm, I'll provide the output for each example:\\n\\n**EXAMPLE 1**\\n\\nInput:\\n[-8.1421e-02  2.2180e-01 -3.9185e-02  3.7750e-02  3.2617e-01 -2.4695e-01\\n  1.0956e-01 -2.4731e-01  2.2388e-01 -1.2183e-01  3.9502e-01  2.7124e-01\\n  1.1211e+00  1.2482e-01  2.7026e-01 -1.3684e-01  1.2054e-01 -5.3223e-02\\n -1.2109e-01 -1.3855e-01 -4.5654e-01 -1.9922e-01  5.4785e-01  4.7681e-01\\n -2.2583e-01 -1.3550e-01  4.6338e-01 -1.4160e-01 -3.3203e-02  2.4329e-01\\n  1.0902e-02 -1.5564e-01 -9.7427e-03 -4.0161e-01  1.3135e-01 -2.7283e-02\\n  5.0385e-02  2.8613e-01 -1.5503e-01 -1.2832e+00  2.7783e-01 -1.5356e-01\\n -1.8750e-01 -5.5615e-01 -2.5040e-02  3.5205e-01 -1.2097e-01  1.8518e-01\\n -3.5693e-01  8.8574e-\",\n",
       " 'The input features are classified into the following emotions:\\n\\n{\\'emotions\\': [[\\'anger\\', \\'fear\\', \\'disgust\\'], [\\'fear\\',\\'surprise\\', \\'joy\\', \\'anger\\'], [\\'fear\\',\\'surprise\\'], [\\'anger\\', \\'fear\\', \\'disgust\\'], [\\'anger\\', \\'fear\\',\\'sadness\\'], [\\'anger\\', \\'fear\\'], [\\'anger\\'], [\\'anger\\', \\'joy\\'], [\\'anger\\', \\'joy\\']]}\\n\\nNote that the output is a list of emotions for each input feature. The emotions are identified based on the given classes: \"anger\", \"disgust\", \"fear\", \"sadness\", \"surprise\", \"joy\", \"neutral\".',\n",
       " '{\"emotions\": [[\\'surprise\\', \\'joy\\'], [\\'fear\\',\\'surprise\\'], [\\'fear\\'], [\\'surprise\\'], [\\'surprise\\'], [\\'fear\\',\\'surprise\\'], [\\'joy\\'], [\\'joy\\'], [\\'surprise\\'], [\\'surprise\\'], [\\'sadness\\']]}',\n",
       " 'Given the provided input data, the applicable emotions from the following classes: \"anger\", \"disgust\", \"fear\", \"sadness\", \"surprise\", \"joy\", \"neutral\" are identified as follows:\\n\\nExample 1:\\n{\\n    \"emotions\": [\\n        [\"anger\", \"disgust\"],\\n        [\"anger\", \"disgust\"],\\n        [\"fear\", \"surprise\"],\\n        [\"surprise\", \"joy\"],\\n        [\"surprise\", \"joy\"],\\n        [\"fear\", \"sadness\"],\\n        [\"joy\"],\\n        [\"joy\"],\\n        [\"fear\"]\\n    ]\\n}\\n\\nExample 2:\\n{\\n    \"emotions\": [\\n        [\"neutral\"],\\n        [\"joy\"],\\n        [\"surprise\"],\\n        [\"anger\", \"surprise\"],\\n        [\"neutral\"],\\n        [\"surprise\"],\\n        [\"anger\", \"surprise\"],\\n        [\"anger\"],\\n        [\"anger\", \"sadness\", \"surprise\"]\\n    ]\\n}\\n\\nExample 3:\\n{\\n    \"emotions\": [\\n        [\"anger\", \"sadness\"],\\n        [\"anger\", \"sadness\"],\\n        [\"joy\"],\\n        [\"surprise\", \"joy\"]\\n    ]\\n}\\n\\nInput for classification:\\n{\\n    \"emotions\": [\\n        [\"anger\"],\\n        [\"surprise\"],\\n        [\"joy\"],\\n        [\"fear\"],\\n        [\"sadness\"],\\n        [\"surprise\"],\\n        [\"anger\"],\\n        [\"neutral\"],\\n        [\"surprise\"],\\n        [\"anger\"],\\n        [\"anger\"],\\n        [\"anger\"],\\n        [\"anger\"],\\n        [\"anger\"],\\n        [\"anger\"],\\n        [\"anger\"],\\n        [\"anger\"],\\n        [\"anger\"],\\n        [\"anger\"],\\n        [\"anger\"],\\n        [\"anger\"],\\n        [\"anger\"],\\n        [\"anger\"],\\n        [\"anger\"],\\n        [\"anger\"],\\n        [\"anger\"],\\n        [\"anger\"],\\n        [\"anger\"],\\n        [\"anger\"],\\n        [\"anger\"],\\n        [\"anger\"],\\n        [\"anger\"],\\n        [\"anger\"],\\n        [\"anger\"],\\n        [\"anger\"],\\n        [\"anger\"],\\n        [\"anger\"],\\n        [\"anger\"],\\n        [\"anger\"],\\n        [\"anger\"],\\n        [\"anger\"],\\n        [\"anger\"],\\n        [\"anger\"],\\n        [\"anger\"],\\n        [\"anger\"],\\n        [\"anger\"],\\n        [\"anger\"],\\n        [\"anger\"],\\n        [\"anger\"],\\n        [\"anger\"],\\n        [\"anger\"],\\n        [\"anger\"],\\n        [\"anger\"],\\n        [\"anger\"],\\n        [\"anger\"],\\n        [\"anger\"],\\n        [\"anger\"],\\n        [\"anger\"],\\n        [\"anger\"],\\n        [\"anger\"],\\n        [\"anger\"],\\n        [\"anger\"],\\n        [\"anger\"],\\n        [\"anger\"],\\n        [\"anger\"],\\n        [\"',\n",
       " \"To determine the applicable emotions, we need to classify the input features using a suitable machine learning model. Here, I'll use a pre-trained sentiment analysis model based on the VADER (Valence Aware Dictionary and sEntiment Reasoner) algorithm.\\n\\nThe input features are:\\n\\n[-3.1396e-01  2.4011e-01 -1.9067e-01  9.8999e-02  3.8330e-01 -9.7839e-02\\n  3.2104e-01 -1.2732e-01 -5.2734e-02  4.4525e-02  7.2070e-01 -4.7089e-02\\n  5.9521e-01 -3.6621e-01  2.7100e-01  2.5537e-01  2.5708e-01 -2.0752e-01\\n -1.7761e-01 -4.5605e-01 -3.0469e-01 -1.6821e-01  4.3262e-01  9.0820e-01\\n -5.3174e-01  4.1479e-01  5.4053e-01 -1.3989e-01 -2.2278e-01  7.7344e-01\\n  5.0049e-02  5.8594e-02 -2.7588e-01 -1.4844e-01  9.9487e-02  4.4922e-01\\n  3.3203e-01  2.4500e-01 -3.6530e-02 -2.2852e-01 -1.0931e-01 -3.2153e-01\\n -2.1582e-01 -5.2686e-01  2.9150e-01  2.5488e-01  2.5415e-01  1.1572e-01\\n -5.6592e-01  1.2091e-01  3.9893e-01 -9.3140e-02 -4.6906e\",\n",
       " \"To identify the applicable emotions from the input, we need to perform a classification task. We'll use a machine learning model that can classify emotions based on the input features.\\n\\nFirst, we need to preprocess the input data. We'll normalize the input features to have zero mean and unit variance.\\n\\n```python\\nimport numpy as np\\n\\n# Input features\\nX = np.array([\\n    [-2.1924e-01,  4.5190e-01,  7.7942e-02,  2.4976e-01,  8.2031e-02, -6.2164e-02],\\n    [-9.4482e-02, -4.5410e-02, -1.5796e-01, -2.7393e-01,  1.8896e-01,  8.4766e-01],\\n    # Additional input features\\n    [-1.7419e-01,  3.9990e-01, -2.4084e-01,  2.5049e-01,  1.6138e-01,  6.3965e-02],\\n    [-5.9912e-01,  4.4580e-01, -1.2262e-01,  2.6660e-01, -1.4990e-01,  6.3232e-02],\\n    # Additional input features\\n    [-4.6387e-01,  2.2766e-01, -2.4829e-01,  4.7485e-01,  2.2559e-01, -1.3489e-01],\\n    [-1.674e-01,  2.159e-01, -1.103e-01,  7.235e-01,  1.047e-01, -1.145e-01],\\n    # Additional input features\\n    [-1.4268e+00,  7.5195e-02,  3.2129e-01,  9.5886e-02, -1.4551e-01, -1.6028e-01],\\n    [-1.3489e-01, -9.9087e-04\",\n",
       " 'To identify the applicable emotions, we need to use a classification model that can predict the emotions based on the input features. \\n\\nFor simplicity, let\\'s assume we have a pre-trained model that can classify emotions into the given categories.\\n\\nAfter processing the input features, the model outputs the following emotions:\\n\\n{\"emotions\": [[\\'anger\\', \\'disgust\\', \\'fear\\'], [\\'joy\\',\\'surprise\\'], [\\'anger\\', \\'fear\\'], [\\'anger\\',\\'sadness\\'], [\\'fear\\',\\'surprise\\'], [\\'fear\\'], [\\'joy\\'], [\\'anger\\']]}\\n\\nHere\\'s a brief explanation of each emotion:\\n\\n1. \\'anger\\', \\'disgust\\', \\'fear\\': This combination of emotions suggests a high level of anxiety and tension.\\n2. \\'joy\\',\\'surprise\\': This combination of emotions indicates a feeling of wonder and delight.\\n3. \\'anger\\', \\'fear\\': This combination of emotions suggests a state of high alertness and anxiety.\\n4. \\'anger\\',\\'sadness\\': This combination of emotions indicates a feeling of frustration and despair.\\n5. \\'fear\\',\\'surprise\\': This combination of emotions suggests a state of shock and trepidation.\\n6. \\'fear\\': This emotion alone indicates a state of anxiety and apprehension.\\n7. \\'joy\\': This emotion alone indicates a state of happiness and contentment.\\n8. \\'anger\\': This emotion alone indicates a state of frustration and hostility.\\n\\nPlease note that this is a simplified explanation and actual emotions can be complex and multi-faceted.',\n",
       " '{\"emotions\": [[\\'fear\\',\\'surprise\\'], [\\'anger\\',\\'sadness\\'], [\\'anger\\',\\'sadness\\'], [\\'neutral\\'], [\\'anger\\'], [\\'anger\\', \\'fear\\',\\'surprise\\'], [\\'fear\\', \\'joy\\'], [\\'fear\\', \\'joy\\'], [\\'fear\\', \\'joy\\'], [\\'fear\\']]}\\n\\nIdentified applicable emotions are \\'fear\\',\\'surprise\\', \\'anger\\',\\'sadness\\', \\'neutral\\', \\'joy\\'.',\n",
       " '{\"emotions\": [[\\'anger\\'], [\\'anger\\'], [\\'disgust\\',\\'sadness\\']]}\\n\\n\\n{\"emotions\": [[\\'anger\\', \\'fear\\',\\'surprise\\'], [\\'anger\\',\\'surprise\\'], [\\'anger\\',\\'surprise\\'], [\\'anger\\', \\'fear\\'], [\\'anger\\', \\'fear\\',\\'sadness\\']]}\\n\\n\\n{\"emotions\": [[\\'surprise\\'], [\\'surprise\\', \\'joy\\']]}\\n\\nWe can\\'t identify the applicable emotions for the given input because the provided inputs are not in the correct format. The inputs should be in the format of a list of feature values.',\n",
       " '{\"emotions\": [[\\'anger\\', \\'fear\\',\\'surprise\\'], [\\'anger\\', \\'disgust\\'], [\\'anger\\', \\'disgust\\', \\'joy\\'], [\\'anger\\', \\'fear\\',\\'surprise\\'], [\\'anger\\'], [\\'anger\\'], [\\'anger\\'], [\\'fear\\',\\'surprise\\'], [\\'anger\\',\\'sadness\\']]}\\n\\n\\nThe input is classified as one of the following emotions:\\n1. Anger\\n2. Fear\\n3. Surprise\\n4. Disgust\\n5. Sadness\\n6. Joy\\n\\nNote that the model may not always identify the correct emotion or may identify multiple emotions for a single input. This is because the model is trained on a dataset and may not be perfect.',\n",
       " '{\"emotions\": [[\\'anger\\', \\'disgust\\',\\'sadness\\']]}\\n\\nNote: This is the only applicable emotion from the given input. The model has identified the input as expressing a mix of anger, disgust, and sadness.',\n",
       " \"To classify the input into one of the given emotions, we'll use a pre-trained emotional classification model. Since the provided input is a list of features, we'll use a classifier designed to work with feature vectors.\\n\\nFor this task, we'll use a pre-trained Support Vector Machine (SVM) model. The SVM model will take the input feature vector and predict one of the given emotions.\\n\\nPlease note that the actual classification results might vary due to the complexity of the model and the data it was trained on.\\n\\n```python\\nimport numpy as np\\nfrom sklearn import svm\\n\\n# Input feature vector\\ninput_vector = np.array([-5.1025e-01,  5.2637e-01, -2.5952e-01,  1.6382e-01,  4.1235e-01, -2.6978e-01,\\n  3.9087e-01, -3.1079e-01, -5.9863e-01,  1.4893e-01,  1.9910e-01, -1.3232e-01,\\n  6.7725e-01,  1.0608e-01, -1.4026e-01, -1.9080e-01, -6.5771e-01,  8.3160e-03,\\n  4.0161e-01,  1.9385e-01, -1.6956e-01, -4.1553e-01,  3.1104e-01,  6.5771e-01,\\n  1.5411e-02,  1.3257e-01,  6.0107e-01, -4.3286e-01, -1.3293e-01,  1.9653e-01,\\n -3.6499e-01,  2.5049e-01,  4.5044e-02,  1.4453e-01, -1.0669e-01,  1.8750e-01,\\n  7.7759e-02,  2.6416e-01, -1.9409e-01, -8.9661e-02,  2\",\n",
       " \"In order to generate the output we need to classify the emotions using the provided data. We will use a Random Forest Classifier from scikit-learn library to classify the emotions. Since the input data is in the form of features without corresponding labels, we'll use the output of the previous example as the labels.\\n\\n```python\\nimport numpy as np\\nfrom sklearn.ensemble import RandomForestClassifier\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.metrics import accuracy_score\\nfrom sklearn.preprocessing import StandardScaler\\n\\n# Define the data\\nX = np.array([\\n    [-4.7046e-01,  3.1665e-01, -1.0089e-01,  2.6685e-01,  1.4233e-01, -1.7456e-01,\\n     3.3911e-01, -1.8127e-02, -2.2729e-01, -1.2134e-01,  6.0693e-01,  6.3904e-02,\\n     7.6416e-01,  2.1887e-01,  9.6558e-02, -4.7638e-02,  3.5522e-02, -2.2131e-01,\\n     3.8361e-02, -1.0490e-02, -3.6890e-01, -3.1396e-01,  4.1040e-01,  6.2939e-01,\\n     -3.6938e-01,  1.2915e-01,  4.2114e-01, -6.3965e-02, -2.7515e-01,  4.1455e-01,\\n     -9.3628e-02, -2.9004e-01, -1.4246e-01, -1.8579e-01, -4.9683e-02,  1.3892e-01,\\n     1.4673e-01,  4.5239e-01, -1.9934e-01, -3.4546e-01,  1.1700e-01, -3.2080e-01,\\n\",\n",
       " \"The given input is a 1D array of 1.5 million elements. However, the problem description suggests that it is a 2D array of 302 elements with 5020 features each. This is a major discrepancy and would require a different approach than what was originally described.\\n\\nHere's a revised approach to the problem:\\n\\n```python\\nimport numpy as np\\n\\n# Assuming the input is a 2D array of 302 elements with 5020 features each\\ninput_array = np.array([\\n    [-6.1426e-01,  5.1514e-01, -1.0858e-01,  3.5278e-01, -6.8909e-02, -9.4055e-02,\\n     3.8794e-01, -2.7710e-01, -1.5710e-01,  6.0516e-02,  5.2197e-01,  1.6931e-01,\\n     8.5010e-01,  1.0754e-01,  1.8286e-01,  1.5637e-01,  3.1763e-01, -1.2207e-02,\\n     -1.0405e-03, -2.0227e-01, -1.1603e-01, -9.6985e-02,  2.1094e-01,  3.4961e-01,\\n     -9.4849e-02,  1.5515e-01,  8.2812e-01, -9.8419e-03, -9.7107e-02,  5.4736e-01,\\n     -2.1021e-01, -1.5271e-01, -3.1738e-02, -1.7834e-01,  2.6978e-01,  3.1494e-01,\\n     1.2305e-01,  2.8833e-01,  1.7868e-02, -1.5747e-01,  2.8467e-01, -3.5000e-03,\\n     -1.873\",\n",
       " '{\"emotions\": [[\\'anger\\',\\'surprise\\'], [\\'fear\\',\\'surprise\\'], [\\'fear\\',\\'surprise\\'], [\\'anger\\'], [\\'anger\\'], [\\'neutral\\'], [\\'surprise\\'], [\\'anger\\']]}\\n\\nThis output indicates that the input has been classified into the emotions listed.',\n",
       " 'This is a classification problem. The input is a set of features, and the output is the corresponding emotion. \\n\\nHere is the code in Python to classify the emotions:\\n\\n```python\\nimport numpy as np\\n\\n# Define the emotions and their corresponding class indices\\nemotions = {\\n    \"anger\": 0,\\n    \"disgust\": 1,\\n    \"fear\": 2,\\n    \"sadness\": 3,\\n    \"surprise\": 4,\\n    \"joy\": 5,\\n    \"neutral\": 6\\n}\\n\\n# Define the input features\\ninput_features = np.array([\\n    [-4.9170e-01, 3.6719e-01, -1.3953e-01, 3.5986e-01, 3.8635e-02, 2.3425e-01],\\n    [-4.6631e-01, 2.7319e-01, 6.2646e-01, 9.1736e-02, -1.3416e-01, 6.3574e-01],\\n    #... (add more input features here)\\n])\\n\\n# Define the weights and bias for the neural network\\nweights = np.array([\\n    [7.3525e-01, 3.1514e-01, 1.3419e-01, 9.3622e-02, 1.2354e-01, 6.1576e-02, 3.1548e-01],\\n    [3.1414e-01, 6.2154e-01, 1.1354e-01, 4.2167e-01, 1.3259e-01, 3.1535e-01, 7.1432e-02],\\n    #... (add more weights here)\\n])\\n\\nbias = np.array([3.1548e-01, 7.1432e-02, 6.2154e-01])\\n\\n# Define the activation function\\ndef sigmoid(x):\\n    return 1 / (1 + np.exp(-x))\\n\\n# Define the output function\\ndef output(features):\\n    return sigmoid(np.dot(features, weights.T) + bias)\\n\\n# Classify the emotions\\nclassifications = []\\nfor i, features in enumerate(input_features):\\n    classification = np.argmax(output(features))\\n    if classification == 0:\\n        classifications.append',\n",
       " '{\"emotions\": [[\\'anger\\'], [\\'anger\\', \\'fear\\'], [\\'anger\\', \\'fear\\'], [\\'fear\\',\\'surprise\\'], [\\'fear\\'], [\\'anger\\'], [\\'fear\\'], [\\'surprise\\'], [\\'anger\\',\\'surprise\\']]}\\n\\nBased on the input data, the model predicts the following emotions:\\n\\n1. anger\\n2. anger and fear\\n3. anger and fear\\n4. fear and surprise\\n5. fear\\n6. anger\\n7. fear\\n8. surprise\\n9. anger and surprise\\n\\nThe model is able to accurately predict a range of emotions from the input data, including complex emotions such as anger and fear, fear and surprise, and anger and surprise.',\n",
       " '{\"emotions\": [[\\'sadness\\']]}\\n\\nNote: The input vector is classified into the emotion \"sadness\" based on the provided classification model.',\n",
       " '{\"emotions\": [[\\'anger\\'], [\\'anger\\'], [\\'anger\\'], [\\'surprise\\'], [\\'anger\\',\\'sadness\\'], [\\'anger\\'], [\\'anger\\'], [\\'anger\\'], [\\'joy\\']]}\\n\\nThis output indicates that the input data corresponds to emotions such as anger, surprise, and joy, with some cases containing a combination of emotions like anger and sadness.',\n",
       " '{\"emotions\": [[\\'anger\\', \\'fear\\'], [\\'anger\\', \\'fear\\'], [\\'anger\\'], [\\'anger\\', \\'fear\\'], [\\'anger\\'], [\\'anger\\'], [\\'anger\\'], [\\'anger\\'], [\\'anger\\',\\'sadness\\'], [\\'anger\\',\\'surprise\\']]}\\n\\nNote: The emotions classification model used here is a simple example and may not be accurate for all inputs. In a real-world application, you would use a more complex and trained model.',\n",
       " 'To identify the applicable emotions from the given classes, we\\'ll use a machine learning model that can classify emotions based on the input data. For simplicity, let\\'s use a basic implementation of the VADER sentiment analysis tool, which is a rule-based model for sentiment analysis.\\n\\n```python\\nimport numpy as np\\n\\n# Input data\\ninput_data = np.array([\\n    [-7.6270e-01,  2.4426e-01, -5.2521e-02,  3.7012e-01, -1.2672e-02,  1.2561e-01],\\n    #... (rest of the data)\\n])\\n\\n# Define the emotions classes\\nemotions_classes = {\\n    \\'anger\\': 0,\\n    \\'disgust\\': 1,\\n    \\'fear\\': 2,\\n   \\'sadness\\': 3,\\n   \\'surprise\\': 4,\\n    \\'joy\\': 5,\\n    \\'neutral\\': 6\\n}\\n\\n# Define the thresholds for each emotion class\\nthresholds = {\\n    \\'anger\\': 0.5,\\n    \\'disgust\\': 0.5,\\n    \\'fear\\': 0.5,\\n   \\'sadness\\': 0.5,\\n   \\'surprise\\': 0.5,\\n    \\'joy\\': 0.5,\\n    \\'neutral\\': 0.5\\n}\\n\\n# Classify each input data point\\nclassified_emotions = []\\nfor data_point in input_data:\\n    # Calculate the sentiment score\\n    sentiment_score = np.mean(data_point)\\n    \\n    # Check which emotion class the sentiment score belongs to\\n    classified_emotion = None\\n    for emotion, threshold in thresholds.items():\\n        if sentiment_score > threshold:\\n            classified_emotion = emotion\\n            break\\n    \\n    # If no emotion class was found, assign the \\'neutral\\' class\\n    if classified_emotion is None:\\n        classified_emotion = \\'neutral\\'\\n    \\n    # Append the classified emotion to the list\\n    classified_emotions.append([classified_emotion])\\n\\n# Print the classified emotions\\nprint(\"Emotions:\")\\nfor i, emotion in enumerate(classified_emotions):\\n    print(f\"Data point {i+1}: {emotion[0]}\")\\n```\\n\\nThis code will output the classified emotions for each data point in the input data. The output will be in the same format as in the examples you provided.\\n\\nPlease note that this is a simplified example and the actual implementation may require more complex machine',\n",
       " '{\"emotions\": [[\\'anger\\'], [\\'anger\\'], [\\'anger\\'], [\\'surprise\\'], [\\'anger\\',\\'sadness\\'], [\\'anger\\'], [\\'anger\\'], [\\'anger\\'], [\\'joy\\']]}\\n\\n\\nPlease note that the output is based on the provided input and the emotions classification model used. The actual output may vary depending on the specific model and implementation used.',\n",
       " 'This is a classification problem, and I\\'ll use a pre-trained Support Vector Machine (SVM) model to classify the input data into the specified emotions. \\n\\nBased on the input features, the model predicts the following emotions:\\n\\nOutput: {\"emotions\": [[\\'anger\\', \\'fear\\'], [\\'anger\\', \\'fear\\'], [\\'fear\\',\\'surprise\\'], [\\'fear\\'], [\\'anger\\'], [\\'fear\\'], [\\'surprise\\'], [\\'anger\\',\\'surprise\\'], [\\'anger\\',\\'surprise\\']]}\\n\\nNote that the output emotions are based on the classification of the input data, and the actual emotions may vary depending on the context and the specific features used in the classification model.',\n",
       " 'Based on the input provided, I will use a pre-trained emotion classification model to identify the applicable emotions. The output will be in the format {\"emotions\": [[\"emotion1\", \"emotion2\"], [\"emotion3\"]]}.\\n\\n```python\\nimport numpy as np\\nfrom sklearn.preprocessing import LabelEncoder\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.metrics import accuracy_score\\nfrom sklearn.ensemble import RandomForestClassifier\\nfrom sklearn.datasets import load_emotions\\n\\n# load the dataset\\nemotions = load_emotions()\\n\\n# define the features (X) and the target (y)\\nX = emotions.data\\ny = emotions.target\\n\\n# encode the target (y) using LabelEncoder\\nle = LabelEncoder()\\ny = le.fit_transform(y)\\n\\n# split the dataset into training and testing sets\\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\\n\\n# train a RandomForestClassifier on the training set\\nclf = RandomForestClassifier(n_estimators=100, random_state=42)\\nclf.fit(X_train, y_train)\\n\\n# make predictions on the testing set\\ny_pred = clf.predict(X_test)\\n\\n# evaluate the model\\naccuracy = accuracy_score(y_test, y_pred)\\nprint(\"Accuracy:\", accuracy)\\n\\n# predict the emotion for the given input\\ninput_emotion = np.array([-6.1963e-01,  2.2095e-01, -5.7812e-01,  3.1812e-01,  3.0078e-01, -2.9443e-01,\\n  6.4404e-01,  2.9736e-01, -5.5615e-01,  4.7827e-01,  3.1299e-01,  9.0881e-02,\\n  2.6245e-01, -3.7231e-01, -2.4872e-02, -3.0957e-01, -6.3037e-01,  1.4160e-01,\\n  7.9651e-02,  6.4148e-02,  6.0938e-01,  3.7567e-02,  2.8345e-01,  6.0254e-01,\\n  1.',\n",
       " \"To identify the applicable emotions, we need to use a machine learning model that can predict emotions based on the input features.\\n\\nBased on the input features, we can use a pre-trained emotion classification model. Here, I'll use a simplified example of a support vector machine (SVM) model for demonstration purposes.\\n\\n```python\\nimport numpy as np\\n\\n# Input features\\nX = np.array([\\n    [-4.7510e-01,  2.1667e-01, -3.1152e-01,  3.5620e-01,  7.5623e-02,  5.3284e-02,\\n     6.2988e-01, -3.4033e-01, -6.7627e-02, -4.5532e-02, 3.8867e-01, 1.0681e-01,\\n     4.6387e-01, -4.1748e-02, -3.2074e-02,  6.8909e-02, -3.5706e-02, -7.5928e-02,\\n     6.5857e-02, -3.7988e-01, -1.8713e-01, -4.4238e-01,  2.3303e-01,  5.7324e-01,\\n     -1.3794e-01,  2.2290e-01,  5.2490e-01, -5.7678e-02, -3.1006e-01,  4.4971e-01,\\n     -1.5784e-01,  7.7271e-02, -1.5613e-01, -2.4963e-01,  3.0688e-01,  3.8940e-01,\\n      2.5439e-01,  4.7900e-01,  3.0563e-02,  1.5222e-01,  2.5223e-02, -3.9038e-01,\\n      1.4473e-02, -7.0898e-01,  1.2262e-01,  \",\n",
       " '{\"emotions\": [[\\'anger\\'], [\\'anger\\',\\'surprise\\'], [\\'surprise\\', \\'joy\\'], [\\'anger\\', \\'disgust\\'], [\\'anger\\',\\'sadness\\'], [\\'anger\\'], [\\'anger\\'], [\\'anger\\'], [\\'anger\\']]}\\n\\n\\n{\"emotions\": [[\\'neutral\\'], [\\'fear\\',\\'surprise\\'], [\\'anger\\',\\'sadness\\'], [\\'anger\\',\\'sadness\\',\\'surprise\\'], [\\'neutral\\'], [\\'sadness\\',\\'surprise\\'], [\\'sadness\\',\\'surprise\\'], [\\'fear\\',\\'surprise\\'], [\\'anger\\'], [\\'anger\\', \\'joy\\']]}\\n\\n\\n{\"emotions\": [[\\'anger\\',\\'surprise\\'], [\\'anger\\',\\'sadness\\',\\'surprise\\'], [\\'fear\\',\\'sadness\\'], [\\'anger\\', \\'fear\\',\\'sadness\\'], [\\'surprise\\'], [\\'fear\\',\\'sadness\\'], [\\'anger\\', \\'fear\\'], [\\'anger\\',\\'surprise\\'], [\\'fear\\'], [\\'anger\\'], [\\'anger\\']]}\\n\\n\\nNote: The output for the third example and the input for classification are different from the output format. They should be adjusted to fit the output format specified.',\n",
       " '{\"emotions\": [[\\'neutral\\',\\'sadness\\']]}\\n\\nThis output indicates that the input data corresponds to the emotions \"neutral\" and \"sadness\".',\n",
       " 'Based on the input features, the predicted emotions are:\\n\\n{\"emotions\": [[\\'anger\\'], [\\'fear\\',\\'surprise\\'], [\\'sadness\\',\\'surprise\\'], [\\'anger\\'], [\\'anger\\',\\'surprise\\'], [\\'anger\\'], [\\'fear\\',\\'surprise\\']]}\\n\\nThese emotions correspond to the classes: \"anger\", \"fear\", \"surprise\", \"sadness\", \"anger\", \"surprise\", \"fear\"\\n\\nNote: The model has predicted the presence of multiple emotions for each input. The emotions are represented as a list of strings, where each string corresponds to a class label.',\n",
       " \"To classify the emotions, I'll use a pre-trained model. The model will classify the emotions based on the input feature vector.\\n\\nThe input feature vector is [-4.5215e-01  3.3154e-01 -7.0984e-02  2.8491e-01  7.4585e-02 -3.2397e-01  3.5425e-01 -1.9202e-01 -4.3115e-01 -1.5979e-01  4.4873e-01  7.9041e-02  1.0986e+00  3.0420e-01  1.6748e-01  2.4927e-01  1.4990e-01  8.3399e-04 -4.7516e-02 -4.5850e-01 -4.9438e-01 -3.8354e-01  4.1187e-01  3.0151e-01 -2.6154e-02  3.3618e-01  4.1675e-01 -1.7944e-01 -2.4121e-01  4.2969e-01 -2.0740e-01 -8.7280e-02  7.1335e-03 -2.5513e-01  3.8037e-01  2.4695e-01  4.3579e-01  2.8345e-01  2.4036e-01 -5.4260e-02  5.4565e-02 -2.7295e-01 -2.7563e-01 -1.7993e-01  1.6089e-01  8.3154e-01  3.1909e-01  1.4612e-01 -6.5552e-02  3.0981e-01  3.3813e-01 -1.1981e-01  1.3477e-01 -4.8340e-02  2.8540e-01 -2.5806e-01 \",\n",
       " '{\"emotions\": [[\\'sadness\\',\\'surprise\\']]}\\n\\nNote: The output is based on the input provided, which is a list of numerical values representing sentiment scores. The actual output may vary depending on the specific model or algorithm used for sentiment analysis.',\n",
       " 'After processing the input array, the identified emotions are:\\n\\n{\"emotions\": [[\\'anger\\'], [\\'neutral\\'], [\\'fear\\',\\'surprise\\'], [\\'fear\\',\\'sadness\\'], [\\'fear\\',\\'sadness\\'], [\\'surprise\\'], [\\'fear\\',\\'sadness\\'], [\\'fear\\',\\'surprise\\'], [\\'anger\\'], [\\'fear\\']]}\\n\\nThese emotions correspond to the following classes: \"anger\", \"neutral\", \"fear\", \"surprise\", \"fear\", \"sadness\", \"fear\", \"sadness\", \"fear\", \"surprise\", \"anger\", \"fear\".',\n",
       " 'To identify the applicable emotions from the given classes, I\\'ll use a pre-trained model. The output will be the most likely emotions and their corresponding probabilities.\\n\\n```python\\nfrom sklearn.preprocessing import StandardScaler\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.metrics import accuracy_score\\nfrom sklearn.neural_network import MLPClassifier\\nimport numpy as np\\n\\n# Define the emotions classes\\nemotions_classes = [\"anger\", \"disgust\", \"fear\", \"sadness\", \"surprise\", \"joy\", \"neutral\"]\\n\\n# Define the input and output data\\ninput_data = np.array([\\n    [-3.9844e-01,  6.0693e-01, -1.7627e-01,  3.9282e-01,  2.0093e-01, -1.1365e-01,\\n     5.0977e-01, -5.2539e-01, -2.2729e-01, -1.7746e-02,  5.0732e-01, -4.0985e-02,\\n     7.4365e-01,  2.1179e-01,  1.8274e-01, -7.2083e-02,  1.5312e-02,  3.9444e-03,\\n    -5.2765e-02,  7.5645e-03,  1.1009e-02, -2.3572e-01,  4.0210e-01,  3.9966e-01,\\n    -2.8491e-01,  3.1421e-01,  4.6509e-01,  2.6440e-01, -1.1023e-01,  7.5928e-01,\\n    -1.3110e-01, -1.0437e-01, -3.7744e-01, -4.3304e-02,  2.3413e-01,  2.9370e-01,\\n     3.3911e-01,  2.1362e-01, -1.4026e-01, -4.0234e-01,  5.590',\n",
       " 'After analyzing the input data, I would classify the emotions as follows:\\n\\n1. \"anger\" - [-2.2998e-01  5.6982e-01 -3.8501e-01  3.3154e-01  2.1875e-01 -1.3684e-01]\\n    * This input has a high value in the \"anger\" class.\\n\\n2. \"disgust\" - No strong indication of \"disgust\" in any of the inputs.\\n\\n3. \"fear\" - [-2.2998e-01  5.6982e-01 -3.8501e-01  3.3154e-01  2.1875e-01 -1.3684e-01]\\n    * This input has a high value in the \"fear\" class.\\n\\n4. \"sadness\" - [-2.2998e-01  5.6982e-01 -3.8501e-01  3.3154e-01  2.1875e-01 -1.3684e-01]\\n    * This input has a high value in the \"sadness\" class.\\n\\n5. \"surprise\" - [-2.2998e-01  5.6982e-01 -3.8501e-01  3.3154e-01  2.1875e-01 -1.3684e-01]\\n    * This input has a high value in the \"surprise\" class.\\n\\n6. \"joy\" - No strong indication of \"joy\" in any of the inputs.\\n\\n7. \"neutral\" - [-2.2998e-01  5.6982e-01 -3.8501e-01  3.3154e-01  2.1875e-01 -1.3684e-01]\\n    * This input has a high value in the \"neutral\" class.',\n",
       " 'Based on the input feature values, I will classify the emotions as follows:\\n\\n1. Input:\\n[-3.6108e-01  6.1816e-01 -1.4465e-01 -4.6539e-03  9.7290e-02 -2.0203e-01\\n  3.8672e-01 -3.7915e-01  5.4688e-02 -2.8735e-01  3.6328e-01  3.5919e-02\\n  4.3701e-01  1.1023e-01 -2.9251e-02  1.9128e-01  4.7424e-02  1.4526e-01\\n  1.3831e-01 -4.9219e-01 -8.7891e-01 -2.3697e-02  3.7915e-01  6.4795e-01\\n  8.3923e-02  3.5278e-01  5.2832e-01 -2.4622e-01 -1.4709e-01  2.9810e-01\\n -1.2256e-01 -9.1858e-02 -1.3867e-01 -3.4448e-01  1.8262e-01  8.1482e-02\\n  1.7468e-01  3.5620e-01 -6.5796e-02 -1.2396e-01  2.7002e-01 -3.8232e-01\\n -1.9666e-01 -1.7700e-01  1.0168e-01  1.3047e+00  3.2349e-01  4.8492e-02\\n -4.7754e-01  4.0796e-01  5.6152e-01 -2.1716e-01  3.5458e-03 -1.0260e-01\\n  2.1326e-01 -7.2632e-02  1.672',\n",
       " \"This problem cannot be solved with the given information. The input data is a list of numerical values, but the actual task is a classification task. To classify the input data, a machine learning model needs to be trained on a labeled dataset. The model should map the input data to the corresponding emotions.\\n\\nSince the model is not provided, we cannot determine which emotions are applicable to the given input data.\\n\\nHowever, I can provide a general solution for this type of problem using a machine learning model.\\n\\nHere is a sample code in Python using scikit-learn library for classification:\\n\\n```python\\n# Import necessary libraries\\nfrom sklearn.preprocessing import StandardScaler\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.neural_network import MLPClassifier\\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\\nimport pandas as pd\\n\\n# Load the dataset\\nemotions_data = pd.DataFrame({\\n    'anger': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\",\n",
       " \"The provided input data is a 2D array representing face features. To classify the emotions, we can use a pre-trained model such as the `face-api.js` library, which is a JavaScript library for face and emotion detection.\\n\\nHere's how you can classify the emotions using the provided input data:\\n\\n```javascript\\nconst faceapi = require('face-api.js');\\nconst model = faceapi.loadModel('models/face-api.js');\\n\\n// Define the input data\\nconst inputData = [\\n    // Input data for example 1\\n    [-4.5361e-01, 5.5371e-01, -2.0825e-01, 4.4434e-01, 8.8989e-02, -4.6387e-02,\\n     3.7280e-01, -1.6577e-01, -2.2192e-01, -2.0981e-02, 1.9727e-01, -1.1108e-01,\\n     8.0225e-01, 6.3965e-02, 1.6205e-02, -2.8183e-02, -2.8076e-01, -1.7407e-01,\\n     2.1472e-01, -4.5850e-01, -4.2419e-02, -3.8110e-01, 4.5898e-01, 6.8262e-01,\\n     8.6304e-02, 2.8516e-01, 5.4639e-01, -2.7515e-01, -1.2891e-01, 5.0146e-01,\\n    -1.6431e-01, 3.0762e-02, -9.3079e-02, -3.1689e-01, 2.0728e-01, 3.9087e-01,\\n     3.6011e-02, 2.4109e-01, 4.0161e-02, 3.4424e-01, 2.0618e-01, -4.2847e-01,\\n    -1.8750e-01, -3.4277e-01, \",\n",
       " 'To determine the applicable emotions, we need to classify the given input into one of the following classes: \"anger\", \"disgust\", \"fear\", \"sadness\", \"surprise\", \"joy\", \"neutral\"\\n\\nAfter analyzing the input, we can classify it as follows:\\n\\nThe input can be classified as \"neutral\"',\n",
       " \"To solve this problem, we will use a pre-trained emotion classification model. The model is trained on a dataset of text and corresponding emotions. We will use the `transformers` library in Python to load the model and make predictions.\\n\\n```python\\nimport pandas as pd\\nimport torch\\nfrom transformers import EmotionClassifier\\n\\n# Load the model\\nmodel = EmotionClassifier.from_pretrained('emotion-classifier')\\n\\n# Define the input data\\ninput_data = [\\n    [-6.1426e-01, 5.1514e-01, -1.0858e-01, 3.5278e-01, -6.8909e-02, -9.4055e-02],\\n    [-7.7100e-01, 4.5117e-01, -1.2744e-01, 2.0715e-01, 2.2852e-01, -3.6621e-01],\\n    [-7.1484e-01, 5.7764e-01, -2.0752e-01, 6.8787e-02, 2.7930e-01, 6.7261e-02],\\n    [-8.0469e-01, 7.2754e-01, -1.4160e-01, 2.9224e-01, 1.1395e-01, -2.2351e-01]\\n]\\n\\n# Define the function to classify emotions\\ndef classify_emotions(input_data):\\n    # Convert the input data to a DataFrame\\n    df = pd.DataFrame(input_data, columns=['anger', 'disgust', 'fear','sadness','surprise', 'joy', 'neutral'])\\n\\n    # Make predictions using the model\\n    outputs = model(df)\\n\\n    # Return the predicted emotions\\n    return outputs\\n\\n# Classify the emotions\\npredicted_emotions = classify_emotions(input_data)\\n\\n# Print the predicted emotions\\nprint(predicted_emotions)\\n```\\n\\nPlease note that this code assumes that the `EmotionClassifier` model is available in the `transformers` library. The model may not be available in the public version of the library, and you may need to use a custom model or modify the code to use a different model.\\n\\nAlso, note that the `EmotionClassifier` model is a hypothetical model and may not be a real model in the `transform\",\n",
       " 'The given input has 51 features but no target variable. Therefore, it\\'s not possible to train a model and make predictions. However, I can help you to identify the applicable emotions from the given classes.\\n\\nBased on the given features, the following emotions can be identified:\\n\\n```\\n{\"emotions\": [[\\'anger\\'], [\\'anger\\', \\'fear\\'], [\\'anger\\', \\'fear\\'], [\\'fear\\',\\'surprise\\'], [\\'fear\\'], [\\'anger\\'], [\\'fear\\'], [\\'surprise\\'], [\\'anger\\',\\'surprise\\']]]\\n```\\n\\nThese emotions can be identified because they are present in the given input. However, the actual classification depends on the target variable, which is not provided.\\n\\nHere is a sample code to classify the emotions using a machine learning model. In this example, I\\'m using a simple neural network.\\n\\n```python\\nimport numpy as np\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.neural_network import MLPClassifier\\nfrom sklearn.metrics import accuracy_score\\n\\n# Input features\\nX = np.array([[-2.5098e-01,  5.4590e-01, -1.7810e-01,  2.0020e-01,  1.8091e-01, -2.0605e-01,\\n  3.7671e-01, -3.4326e-01, -1.7212e-01, -2.1875e-01,  4.6924e-01,  1.6785e-01,\\n  7.0996e-01,  7.8979e-02,  5.0751e-02,  1.1969e-01, -6.4307e-01,  8.3399e-04,\\n  4.0771e-02, -6.8665e-02, -2.2595e-01, -3.8452e-02,  5.0049e-01,  5.7080e-01,\\n -3.3960e-01,  4.0503e-01,  4.8584e-01, -4.9103e-02, -1.0516e-01,  4.4507e-01,\\n -2.5879e-01, -6.3904e-',\n",
       " '{\"emotions\": [[\\'fear\\',\\'surprise\\'], [\\'anger\\', \\'disgust\\',\\'sadness\\'], [\\'fear\\',\\'surprise\\'], [\\'anger\\'], [\\'neutral\\'], [\\'fear\\']]}\\n\\nThis model is a classification model that uses a dataset of human emotions to predict the emotions of a given input. The model is trained to identify the presence or absence of different emotions in a given input, and the output is a list of the identified emotions.\\n\\nIn this case, the input is a list of numerical values representing the intensity of different emotions, and the output is a list of the identified emotions. The model has identified the following emotions in the input:\\n\\n* \\'fear\\' and\\'surprise\\' are both present in the input, with a high intensity for \\'fear\\' and a moderate intensity for\\'surprise\\'.\\n* \\'anger\\' and \\'disgust\\' are both present in the input, with a moderate intensity for \\'anger\\' and a low intensity for \\'disgust\\'.\\n*\\'sadness\\' is present in the input, with a low intensity.\\n* \\'joy\\' is not present in the input.\\n* \\'neutral\\' is present in the input, with a high intensity.\\n\\nNote that the model is only predicting the presence or absence of different emotions, and not the intensity of those emotions. Also, the model is not perfect and the results may vary depending on the input.',\n",
       " 'To classify the emotions in the given input, I will use a machine learning model that can predict the emotions from the features. Since the actual model is not provided, I will simulate the output of the classification model.\\n\\nThe input is classified into the following emotions:\\n\\n[\"anger\", \"disgust\"]\\n\\nThe model predicts that the input is associated with both \"anger\" and \"disgust\" emotions. \\n\\nNote: The actual output might vary based on the specific machine learning model used.',\n",
       " \"The emotions identified from the given input are:\\n\\n* 'anger','surprise'\\n* 'anger', 'disgust', 'joy'\\n* 'fear'\\n* 'fear','surprise'\\n* 'anger'\\n* 'neutral'\\n* 'fear'\\n* 'fear','sadness'\\n* 'fear'\",\n",
       " '{\"emotions\": [[\\'anger\\', \\'fear\\'], [\\'anger\\',\\'sadness\\'], [\\'anger\\', \\'fear\\',\\'surprise\\'], [\\'anger\\', \\'fear\\'], [\\'anger\\', \\'fear\\'], [\\'anger\\', \\'fear\\',\\'sadness\\'], [\\'anger\\', \\'fear\\'], [\\'anger\\', \\'fear\\',\\'surprise\\'], [\\'anger\\'], [\\'fear\\']]}\\n\\n\\nThis is the output for each example. The model is trained to predict a list of emotions for each input. The emotions are identified from the following classes: \"anger\", \"disgust\", \"fear\", \"sadness\", \"surprise\", \"joy\", \"neutral\".',\n",
       " 'To identify the applicable emotions from the given input, we need to use a machine learning model that can classify the input into one of the emotional categories. Here\\'s a possible approach:\\n\\n1. Use a library like scikit-learn to implement a machine learning model, such as a random forest classifier.\\n2. Train the model using a dataset of emotional expressions, where each expression is labeled with one or more emotions (e.g., \"anger\", \"disgust\", \"fear\", \"sadness\", \"surprise\", \"joy\", \"neutral\").\\n3. Once the model is trained, use it to predict the emotions associated with the input expression.\\n\\nHere\\'s a possible output:\\n\\nInput: [-5.5615e-01  2.4658e-01 -1.2708e-01  4.0503e-01 -1.1009e-02 -3.0078e-01...]\\n\\nOutput: {\"emotions\": [\\'anger\\', \\'disgust\\', \\'fear\\', \\'joy\\',\\'sadness\\',\\'surprise\\', \\'neutral\\']}\\n\\nHere\\'s a possible implementation in Python:\\n\\n```python\\nfrom sklearn.ensemble import RandomForestClassifier\\nfrom sklearn.preprocessing import StandardScaler\\nfrom sklearn.model_selection import train_test_split\\n\\n# Load the dataset of emotional expressions\\nimport pandas as pd\\ndf = pd.read_csv(\\'emotions.csv\\')\\n\\n# Define the features (X) and the target variable (y)\\nX = df.drop([\\'emotion\\'], axis=1).values\\ny = df[\\'emotion\\'].values\\n\\n# Scale the features using StandardScaler\\nscaler = StandardScaler()\\nX_scaled = scaler.fit_transform(X)\\n\\n# Split the data into training and testing sets\\nX_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\\n\\n# Train a random forest classifier on the training data\\nclf = RandomForestClassifier(n_estimators=100, random_state=42)\\nclf.fit(X_train, y_train)\\n\\n# Predict the emotions associated with the input expression\\ninput_expression = [-5.5615e-01, 2.4658e-01, -1.2708e-01, 4.0503e-01, -1.1009e-02, -3.0078e-01,...]\\ninput_expression_scaled = scaler.transform([input_expression])\\npredicted_emotions = clf.predict(input_expression_scaled)\\n\\nprint(predicted_emotions)\\n```\\n\\n',\n",
       " '{\"emotions\": [[\\'anger\\'], [\\'anger\\',\\'surprise\\']]}\\n\\nThe input features are classified into the emotions \"anger\" and \"anger/surprise\".',\n",
       " 'To classify the input, we will use a multi-label classification model that maps each input to multiple emotions. We will use a model that outputs the following emotions: \"anger\", \"disgust\", \"fear\", \"sadness\", \"surprise\", \"joy\", \"neutral\".\\n\\nThe model outputs the following emotions for the given input:\\n\\n{\"emotions\": [[\\'anger\\', \\'fear\\',\\'surprise\\'], [\\'anger\\', \\'disgust\\', \\'fear\\'], [\\'anger\\', \\'fear\\',\\'sadness\\'], [\\'anger\\',\\'surprise\\'], [\\'anger\\', \\'fear\\',\\'sadness\\'], [\\'anger\\', \\'disgust\\', \\'fear\\'], [\\'anger\\',\\'surprise\\'], [\\'anger\\', \\'fear\\',\\'sadness\\'], [\\'anger\\', \\'disgust\\', \\'fear\\'], [\\'anger\\', \\'fear\\',\\'sadness\\'], [\\'anger\\',\\'surprise\\'], [\\'anger\\', \\'fear\\',\\'sadness\\'], [\\'anger\\', \\'disgust\\', \\'fear\\'], [\\'anger\\', \\'fear\\',\\'sadness\\'], [\\'anger\\',\\'surprise\\'], [\\'anger\\', \\'disgust\\', \\'fear\\'], [\\'anger\\', \\'fear\\',\\'sadness\\'], [\\'anger\\',\\'surprise\\'], [\\'anger\\', \\'fear\\',\\'sadness\\'], [\\'anger\\', \\'disgust\\', \\'fear\\'], [\\'anger\\', \\'fear\\',\\'sadness\\'], [\\'anger\\',\\'surprise\\'], [\\'anger\\', \\'fear\\',\\'sadness\\'], [\\'anger\\', \\'disgust\\', \\'fear\\'], [\\'anger\\', \\'fear\\',\\'sadness\\'], [\\'anger\\',\\'surprise\\'], [\\'anger\\', \\'fear\\',\\'sadness\\'], [\\'anger\\', \\'disgust\\', \\'fear\\'], [\\'anger\\', \\'fear\\',\\'sadness\\'], [\\'anger\\',\\'surprise\\'], [\\'anger\\', \\'fear\\',\\'sadness\\'], [\\'anger\\', \\'disgust\\', \\'fear\\'], [\\'anger\\', \\'fear\\',\\'sadness\\'], [\\'anger\\',\\'surprise\\'], [\\'anger\\', \\'fear\\',\\'sadness\\'], [\\'anger\\', \\'disgust\\', \\'fear\\'], [\\'anger\\', \\'fear\\',\\'sadness\\'], [\\'anger\\',\\'surprise\\'], [\\'anger\\', \\'fear\\',\\'sadness\\'], [\\'anger\\', \\'disgust\\', \\'fear\\'], [\\'anger\\', \\'fear\\',\\'sadness\\'], [\\'anger\\',\\'surprise\\'], [\\'anger\\', \\'fear\\',\\'sadness',\n",
       " 'After analyzing the input, the identified applicable emotions are:\\n\\n{\"emotions\": [[\\'anger\\',\\'sadness\\']]}\\n\\nThis indicates that the input data corresponds to a combination of \"anger\" and \"sadness\" emotions.',\n",
       " '{\"emotions\": [[\\'anger\\'], [\\'fear\\',\\'surprise\\']]}\\n\\nNote: The input array for classification is a single row from the dataset. The output is a list of emotions that are most likely to be present in the input data.',\n",
       " 'Based on the input data, the emotions that are most relevant to the classification task are:\\n\\n```\\n{\"emotions\": [[\\'fear\\'], [\\'sadness\\'], [\\'fear\\',\\'sadness\\'], [\\'fear\\',\\'sadness\\'], [\\'fear\\',\\'sadness\\'], [\\'fear\\',\\'sadness\\'], [\\'sadness\\'], [\\'sadness\\'], [\\'sadness\\'], [\\'sadness\\'], [\\'sadness\\'], [\\'sadness\\']]]\\n```\\n\\nHowever, since the input data belongs to the \\'fear\\' emotion, the most relevant emotions to the classification task are:\\n\\n```\\n{\"emotions\": [[\\'fear\\'], [\\'sadness\\', \\'fear\\'], [\\'sadness\\', \\'fear\\'], [\\'sadness\\', \\'fear\\'], [\\'sadness\\', \\'fear\\'], [\\'sadness\\', \\'fear\\'], [\\'sadness\\', \\'fear\\'], [\\'sadness\\', \\'fear\\'], [\\'sadness\\', \\'fear\\'], [\\'sadness\\', \\'fear\\'], [\\'sadness\\', \\'fear\\'], [\\'sadness\\', \\'fear\\']]]\\n```\\n\\nBut since we are looking for the most relevant emotions that are not \\'fear\\', the output is:\\n\\n```\\n{\"emotions\": [[\\'sadness\\'], [\\'sadness\\', \\'fear\\'], [\\'sadness\\', \\'fear\\'], [\\'sadness\\', \\'fear\\'], [\\'sadness\\', \\'fear\\'], [\\'sadness\\', \\'fear\\'], [\\'sadness\\', \\'fear\\'], [\\'sadness\\', \\'fear\\'], [\\'sadness\\', \\'fear\\'], [\\'sadness\\', \\'fear\\'], [\\'sadness\\', \\'fear\\'], [\\'sadness\\', \\'fear\\']]]\\n```\\n\\nBut since we are looking for the most relevant emotions that are not \\'fear\\' and not\\'sadness\\', the output is:\\n\\n```\\n{\"emotions\": []}\\n```',\n",
       " 'This problem requires a machine learning model that can classify emotions based on the input data. The given data appears to be a dataset of numerical features that correspond to different emotions.\\n\\nTo solve this problem, we can use a machine learning library such as scikit-learn and TensorFlow. We can train a classifier on the given data to predict the emotions.\\n\\nHere is a possible solution:\\n\\n```python\\nimport pandas as pd\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.preprocessing import StandardScaler\\nfrom sklearn.ensemble import RandomForestClassifier\\nfrom sklearn.metrics import classification_report, confusion_matrix\\nfrom sklearn.model_selection import GridSearchCV\\nfrom sklearn import svm\\nfrom sklearn.svm import SVC\\nfrom sklearn.model_selection import cross_val_score\\nimport numpy as np\\n\\n# Load the data\\ndata = pd.read_csv(\"emotion_data.csv\")\\n\\n# Define the features and the target variable\\nX = data.drop([\\'emotion\\'], axis=1)\\ny = data[\\'emotion\\']\\n\\n# Split the data into training and test sets\\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\\n\\n# Scale the features\\nscaler = StandardScaler()\\nX_train_scaled = scaler.fit_transform(X_train)\\nX_test_scaled = scaler.transform(X_test)\\n\\n# Train a random forest classifier\\nrfc = RandomForestClassifier(n_estimators=100, random_state=42)\\nrfc.fit(X_train_scaled, y_train)\\n\\n# Evaluate the classifier\\ny_pred = rfc.predict(X_test_scaled)\\nprint(\"Classification Report:\")\\nprint(classification_report(y_test, y_pred))\\nprint(\"Confusion Matrix:\")\\nprint(confusion_matrix(y_test, y_pred))\\n\\n# Define the emotion classes\\nemotion_classes = [\"anger\", \"disgust\", \"fear\", \"sadness\", \"surprise\", \"joy\", \"neutral\"]\\n\\n# Define the input data for classification\\ninput_data = [[-6.2939, 5.8350, 8.9966, -1.4722, 5.3131, -1.7651, 7.5928, -4.6825, -3.4253, -7.2937, 3.9307, 1.9180, 5.8740, 1.2988, 1.5674, -2.3877, -3.1299, -3.7476, 4.8523, -5.6519, -1.',\n",
       " 'The input provided is a list of feature vectors that represent various emotions. The emotions are classified into the following categories: \"anger\", \"disgust\", \"fear\", \"sadness\", \"surprise\", \"joy\", \"neutral\".\\n\\nTo identify the applicable emotions for the given input, we can use a machine learning model that is trained on the Emotion Recognition dataset. However, without access to the training data and the model, we can provide a general solution.\\n\\nHere\\'s a Python solution using the scikit-learn library and a DecisionTreeClassifier:\\n\\n```python\\nimport numpy as np\\nfrom sklearn.tree import DecisionTreeClassifier\\n\\n# Define the emotion classification problem\\nemotions = {\\n    \\'anger\\': 0,\\n    \\'disgust\\': 1,\\n    \\'fear\\': 2,\\n   \\'sadness\\': 3,\\n   \\'surprise\\': 4,\\n    \\'joy\\': 5,\\n    \\'neutral\\': 6\\n}\\n\\n# Define the input feature vectors\\ninput_vectors = [\\n    [-2.6636e-01,  3.8696e-01, -4.0161e-02,  3.4863e-01, -2.2192e-01, 1.7685e-02],\\n    [-2.6636e-01,  3.8696e-01, -4.0161e-02,  3.4863e-01, -2.2192e-01, 1.7685e-02],\\n    [-2.6636e-01,  3.8696e-01, -4.0161e-02,  3.4863e-01, -2.2192e-01, 1.7685e-02],\\n    [-3.7744e-01,  3.8721e-01,  1.4905e-01,  1.8359e-01,  1.5503e-01, 2.0984e-01],\\n    # Add more input vectors as needed\\n]\\n\\n# Define the corresponding emotion labels\\nlabels = [emotions[\\'anger\\'], emotions[\\'anger\\'], emotions[\\'anger\\'], emotions[\\'anger\\'], emotions[\\'anger\\']]\\n\\n# Create a DecisionTreeClassifier\\nclf = DecisionTreeClassifier()\\n\\n# Train the classifier using the labeled data\\nclf.fit(input_vectors, labels)\\n\\n# Use the trained classifier',\n",
       " 'To identify the emotions in the given input, we can use a pre-trained emotion classification model. Let\\'s use the following code to classify the emotions:\\n\\n```python\\nimport numpy as np\\nfrom sklearn.preprocessing import StandardScaler\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.metrics import accuracy_score\\nfrom sklearn.ensemble import RandomForestClassifier\\nfrom sklearn.datasets import load_emotions\\n\\n# Load the dataset\\nemotions = load_emotions()\\n\\n# Define the feature matrix X and the target vector y\\nX = emotions.data\\ny = emotions.target\\n\\n# Scale the feature matrix X\\nscaler = StandardScaler()\\nX_scaled = scaler.fit_transform(X)\\n\\n# Split the dataset into training and test sets\\nX_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\\n\\n# Train a random forest classifier on the training data\\nclassifier = RandomForestClassifier(n_estimators=100, random_state=42)\\nclassifier.fit(X_train, y_train)\\n\\n# Make predictions on the test data\\ny_pred = classifier.predict(X_test)\\n\\n# Evaluate the model\\naccuracy = accuracy_score(y_test, y_pred)\\nprint(f\"Model accuracy: {accuracy:.3f}\")\\n\\n# Define the input for classification\\ninput_vector = np.array([-4.7632e-01,  4.5190e-01, -1.9211e-02,  1.9519e-01, -5.2063e-02, -4.0649e-02,\\n  5.0293e-01, -1.3245e-01, -2.5977e-01, -1.1383e-01,  4.8364e-01, -5.8563e-02,\\n  8.7451e-01,  7.5317e-02,  1.7639e-01,  8.2825e-02,  4.2749e-01, -5.5511e-02,\\n -3.5156e-02, -2.7588e-02, -5.1270e-02, -2.7563e-01,  1.8945e-01,  6.3770e-01,\\n -5.1465e-01,  5.1270e-01,  6.',\n",
       " 'The input is a list of 512 features (a 1D array) representing the input data. However, the code snippet provided does not specify the classification model to be used for the input data. \\n\\nBased on the output format, it seems that the model is expected to return a dictionary with a key \"emotions\" containing a list of emotions corresponding to the input data.\\n\\nFor the given input data, I will use a simple neural network model to classify the emotions. The model is trained on a dataset of labeled emotions and is able to predict the emotions of the input data.\\n\\nHere is the Python code to classify the emotions:\\n\\n```python\\nimport numpy as np\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.preprocessing import StandardScaler\\nfrom sklearn.neural_network import MLPClassifier\\nfrom sklearn.metrics import accuracy_score\\nfrom sklearn.decomposition import PCA\\n\\n# Load the dataset\\nfrom sklearn.datasets import load_emotions\\nemotions_data = load_emotions()\\nX = emotions_data.data\\ny = emotions_data.target\\n\\n# Split the data into training and testing sets\\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\\n\\n# Scale the data using StandardScaler\\nscaler = StandardScaler()\\nX_train_scaled = scaler.fit_transform(X_train)\\nX_test_scaled = scaler.transform(X_test)\\n\\n# Use PCA to reduce the dimensionality of the data\\npca = PCA(n_components=0.95)\\nX_train_pca = pca.fit_transform(X_train_scaled)\\nX_test_pca = pca.transform(X_test_scaled)\\n\\n# Train a Multilayer Perceptron Classifier on the training data\\nmlp = MLPClassifier(hidden_layer_sizes=(100,), max_iter=1000, learning_rate_init=0.01, random_state=42)\\nmlp.fit(X_train_pca, y_train)\\n\\n# Make predictions on the test data\\ny_pred = mlp.predict(X_test_pca)\\n\\n# Evaluate the performance of the model\\naccuracy = accuracy_score(y_test, y_pred)\\nprint(\"Model Accuracy:\", accuracy)\\n\\n# Define a function to classify emotions\\ndef classify_emotions(input_data):\\n    # Scale and transform the input data using PCA\\n    input_data_scaled = scaler.transform(input_data.reshape(1, -1))\\n    input_data_pca = pca.transform(input_data_scaled)\\n    \\n    # Make predictions on the input data\\n    emotions = mlp.predict(input_data_pca)\\n    \\n    return emotions[0]\\n\\n# Class',\n",
       " \"To identify the applicable emotions from the given classes, we need to train a machine learning model to classify the emotions. However, since the model is not provided, I will use a simple approach to classify the emotions based on the input features.\\n\\nFirst, we need to normalize the input features to have a similar scale. We can use the `MinMaxScaler` from scikit-learn to achieve this.\\n\\n```python\\nfrom sklearn.preprocessing import MinMaxScaler\\nimport numpy as np\\n\\n# Input features\\ninput_features = np.array([\\n    [-5.0000e-01,  3.9844e-01,  4.1008e-03,  2.1045e-01, -1.6064e-01,  1.6736e-01],\\n    [-4.1187e-01,  2.5879e-01, -1.3153e-02,  3.0859e-01,  1.4124e-01,  2.4084e-01],\\n    [-3.5254e-01,  3.4839e-01,  2.2125e-02,  4.5776e-01,  2.2018e-02,  1.3159e-01],\\n    # Add more input features here\\n])\\n\\n# Normalize the input features\\nscaler = MinMaxScaler()\\nnormalized_features = scaler.fit_transform(input_features)\\n```\\n\\nNow, we need to train a machine learning model to classify the emotions. We can use a simple classification model like logistic regression or decision tree.\\n\\n```python\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.linear_model import LogisticRegression\\nfrom sklearn.tree import DecisionTreeClassifier\\n\\n# Train a logistic regression model\\nX_train, X_test, y_train, y_test = train_test_split(normalized_features[:, :-1], normalized_features[:, -1], test_size=0.2, random_state=42)\\nlogreg = LogisticRegression()\\nlogreg.fit(X_train, y_train)\\n\\n# Train a decision tree classifier\\nX_train, X_test, y_train, y_test = train_test_split(normalized_features[:, :-1], normalized_features[:, -1], test_size=0.2, random_state=42)\\ndt = DecisionTreeClassifier()\\ndt.fit(X_train, y_train)\\n\\n# Predict the emotions\\nemotion_classes = ['anger', 'disgust\",\n",
       " \"This model is unable to classify the input emotions without the specific model architecture and training data. However, I can guide you through a general approach to classify emotions based on the input data.\\n\\nTo classify emotions, you can use a machine learning model such as a neural network or a support vector machine (SVM) with the input data and the corresponding emotion labels. The goal is to train the model to learn the patterns and relationships between the input data and the emotions.\\n\\nHere's a basic example of how you can classify emotions using a neural network in Python:\\n\\n```python\\nimport numpy as np\\nimport pandas as pd\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.preprocessing import StandardScaler\\nfrom sklearn.neural_network import MLPClassifier\\nfrom sklearn.metrics import accuracy_score, classification_report\\n\\n# Load the input data and corresponding emotion labels\\nemotion_data = np.array([\\n    # Input data for example 1\\n    [-3.6572e-01,  4.0039e-01, -6.3721e-02,  2.8369e-01, -2.9922e-02, -8.3313e-02,\\n     2.6611e-01,  6.6895e-02,  1.9763e-01, -1.7725e-01,  3.9990e-01, -6.7688e-02,\\n     -8.7952e-02,  2.0920e-02,  1.6418e-01, -1.5308e-01,  3.4521e-01,  7.9224e-02,\\n     -4.7302e-02,  2.7368e-01,  8.9111e-02, -2.4036e-01,  2.6465e-01,  8.7158e-01,\\n     -2.6416e-01,  3.7329e-01,  7.2559e-01,  5.2460e-02,  1.6577e-01,  4.3164e-01,\\n     -3.7744e-01, -3.9551e-01, -2.1286e-02,  1.1035e\",\n",
       " 'The input vector does not directly correspond to any of the examples provided. However, we can classify the emotions of the input vector based on the given classes: \"anger\", \"disgust\", \"fear\", \"sadness\", \"surprise\", \"joy\", \"neutral\".\\n\\nHere is the classification:\\n\\n1. \"anger\": 0.013 (low probability)\\n2. \"disgust\": 0.001 (low probability)\\n3. \"fear\": 0.019 (low probability)\\n4. \"sadness\": 0.026 (low probability)\\n5. \"surprise\": 0.013 (low probability)\\n6. \"joy\": 0.037 (low probability)\\n7. \"neutral\": 0.913 (high probability)\\n\\nThe input vector is most likely classified as \"neutral\" with a probability of 0.913.',\n",
       " 'To identify the applicable emotions from the given classes, we can use the input data and the class labels to train a machine learning model. Here\\'s an example of how we can do this using Python and the scikit-learn library:\\n\\n```python\\nimport numpy as np\\nfrom sklearn.preprocessing import LabelEncoder\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.linear_model import LogisticRegression\\nfrom sklearn.metrics import accuracy_score\\n\\n# Define the input data and class labels\\nX = np.array([\\n    [-3.3691e-01, 3.5938e-01, -1.2077e-02, 2.1887e-01, 1.5686e-01, -8.9966e-02],\\n    [-4.8169e-01, -1.9568e-01, 1.3159e-01, -5.7556e-02, 1.4124e-01, 3.4961e-01],\\n    #... (other data points)\\n])\\n\\ny = np.array([\\n    [\"anger\", \"disgust\", \"fear\", \"sadness\", \"surprise\", \"joy\", \"neutral\"],\\n    [\"anger\", \"disgust\", \"fear\", \"sadness\", \"surprise\", \"joy\", \"neutral\"],\\n    #... (other class labels)\\n])\\n\\n# Map the class labels to numerical values using LabelEncoder\\nle = LabelEncoder()\\ny = le.fit_transform(y)\\n\\n# Split the data into training and testing sets\\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\\n\\n# Train a logistic regression model on the training data\\nmodel = LogisticRegression()\\nmodel.fit(X_train, y_train)\\n\\n# Make predictions on the testing data\\ny_pred = model.predict(X_test)\\n\\n# Evaluate the model\\'s performance using accuracy score\\naccuracy = accuracy_score(y_test, y_pred)\\nprint(f\"Model accuracy: {accuracy:.3f}\")\\n\\n# Define a function to identify applicable emotions from the given classes\\ndef identify_emotions(data_point, classes):\\n    # Make predictions on the data point\\n    prediction = model.predict(np.array([data_point]))\\n    \\n    # Map the predicted numerical value back to the corresponding class label\\n    predicted_class = le.inverse_transform(prediction)[0]\\n    \\n    # Check if the predicted class is in the given classes\\n    if predicted_class in classes',\n",
       " 'To solve this problem, we can use the following Python code using the `sklearn` library for the classification model and the `numpy` library for numerical operations.\\n\\n```python\\nimport numpy as np\\nfrom sklearn.preprocessing import LabelEncoder\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.linear_model import LogisticRegression\\nfrom sklearn.metrics import accuracy_score\\n\\n# Define the input data\\nX = np.array([\\n    [-5.9326e-01, 2.3743e-01, 1.5472e-02, 3.0054e-01, -1.7004e-01, -2.4792e-01],\\n    [4.5264e-01, 1.9302e-02, -6.7627e-01, -1.8054e-01, 4.4604e-01, 1.1920e-01],\\n    [5.5664e-01, -4.6204e-02, -7.0572e-03, -7.1655e-02, 4.7095e-01, 2.2571e-01],\\n    # Add more data here...\\n])\\n\\n# Define the output data\\ny = np.array([\\n    [\"anger\", \"disgust\", \"fear\", \"sadness\", \"surprise\", \"joy\", \"neutral\"],\\n    [\"anger\", \"disgust\", \"fear\", \"sadness\", \"surprise\", \"joy\", \"neutral\"],\\n    [\"anger\", \"disgust\", \"fear\", \"sadness\", \"surprise\", \"joy\", \"neutral\"],\\n    # Add more data here...\\n])\\n\\n# Define the emotions to classify\\nemotions = [\"anger\", \"disgust\", \"fear\", \"sadness\", \"surprise\", \"joy\", \"neutral\"]\\n\\n# One-hot encode the emotions\\nle = LabelEncoder()\\ny_encoded = le.fit_transform(y)\\ny_encoded = np.eye(len(emotions))[y_encoded]\\n\\n# Split the data into training and testing sets\\nX_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\\n\\n# Train a logistic regression model\\nmodel = LogisticRegression()\\nmodel.fit(X_train, y_train)\\n\\n# Make predictions on the test set\\ny_pred = model.predict(X_test)\\n\\n# Evaluate the model\\'s performance\\naccuracy = accuracy',\n",
       " 'To identify the applicable emotions from the given classes, we can use the input values and map them to the corresponding emotions. We will use a threshold value to determine the presence or absence of each emotion.\\n\\n```python\\nimport numpy as np\\n\\n# Define the input values\\ninput_values = np.array([\\n    [-5.7275e-01, 3.9551e-01, -8.7158e-02, 3.8696e-01, -7.2144e-02, 6.2195e-02,\\n     3.4814e-01, -3.7933e-02, -2.4866e-01, 4.0405e-02, 4.9414e-01, 1.2646e-01,\\n     4.3213e-01, -1.2549e-01, -1.2311e-01, -2.7197e-01, 6.2012e-01, 9.8938e-02,\\n     -1.4685e-01, -3.0493e-01, -3.7628e-02, -2.7368e-01, 1.7126e-01, 6.5479e-01,\\n     -1.9958e-01, 5.1025e-02, 6.3965e-01, 3.3643e-01, -1.4124e-01, 7.0996e-01,\\n     -4.9585e-01, -2.3645e-01, 6.6414e-03, -6.5186e-02, -9.5093e-02, 4.5728e-01,\\n     3.5962e-01, 1.4307e-01, 8.8074e-02, 1.9238e-01, 3.0835e-01, -5.3076e-01,\\n     2.2192e-01, -2.6025e-01, 1.0016e-01, 7.9688e-01, -9.3689e-02, -1.2891e-01,\\n     -9.7229e-02, 2',\n",
       " \"This problem appears to be a classification task using a pre-trained model. The model is expected to take the input array and return the most relevant emotions from the given classes.\\n\\nTo solve this problem, we would need to implement a classification model and train it on a suitable dataset. Then, we would use the trained model to predict the emotions for the given input array.\\n\\nHowever, since the provided code is in Python, I'll provide a solution using a pre-trained model like the one used in the original examples. \\n\\n```python\\nimport numpy as np\\n\\n# Define the input array\\ninput_array = np.array([\\n    -1.5027e-01,  4.1565e-02,  9.9365e-02,  4.4849e-01,  2.8458e-02,  1.7310e-01,\\n    2.5024e-01,  5.5176e-02, -2.4765e-02,  1.6418e-01,  5.2295e-01, -7.3730e-02,\\n    4.5703e-01, -1.8274e-01,  2.9736e-01, -2.3572e-01,  2.1521e-01,  1.0376e-01,\\n    -2.5366e-01, -3.4644e-01, -3.6285e-02,  1.3843e-01, -2.3840e-01,  2.8125e-01,\\n    -6.1865e-01,  4.3701e-01,  3.0029e-01, -7.0435e-02, -1.8677e-01,  2.3389e-01,\\n    -2.1851e-01,  2.2308e-02,  1.5857e-01, -3.4204e-01, -2.3071e-02,  5.0537e-01,\\n    4.0552e-01,  2.7881e-01, -2.3865e-01,  3.2422e-01, \",\n",
       " 'To classify the emotions from the given input, we need to use a suitable algorithm that can classify the given input into one of the specified emotion classes (\"anger\", \"disgust\", \"fear\", \"sadness\", \"surprise\", \"joy\", \"neutral\").\\n\\nHere is a simple neural network model in Python using the Keras library to classify the input emotions:\\n\\n```python\\nimport numpy as np\\nfrom keras.models import Sequential\\nfrom keras.layers import Dense\\nfrom keras.utils import to_categorical\\nfrom sklearn.preprocessing import LabelEncoder\\n\\n# Define the emotions\\nemotions = [\"anger\", \"disgust\", \"fear\", \"sadness\", \"surprise\", \"joy\", \"neutral\"]\\n\\n# Define the input features\\ninput_features = np.array([\\n    [-4.6069e-01,  3.4863e-01,  1.3293e-01,  2.7100e-01, -3.3997e-02,  1.0187e-01],\\n    [-3.1470e-01,  2.3755e-01,  4.0771e-02,  2.2681e-01, -4.8615e-02, -1.0510e-01],\\n    [-4.3604e-01,  3.4302e-01,  1.1584e-01,  1.1127e-01, -7.1838e-02,  9.2224e-02]\\n])\\n\\n# Define the corresponding class labels\\nclass_labels = np.array([[\"anger\", \"sadness\"], [\"anger\"], [\"anger\", \"sadness\"], [\"anger\", \"sadness\"]])\\n\\n# Define the function to convert class labels to numerical values\\ndef class_label_to_num(class_label):\\n    emotions = [\"anger\", \"disgust\", \"fear\", \"sadness\", \"surprise\", \"joy\", \"neutral\"]\\n    encoder = LabelEncoder()\\n    encoder.fit(emotions)\\n    return encoder.transform([class_label])[0]\\n\\n# Convert class labels to numerical values\\nclass_labels_num = np.array([class_label_to_num(label) for label in class_labels.flatten()])\\n\\n# Define the neural network model\\nmodel = Sequential()\\nmodel.add(Dense(64, input_dim=6, activation=\\'relu\\'))\\nmodel.add(Dense(64, activation=\\'relu\\'))\\nmodel.add(Dense(7,',\n",
       " 'To classify the input data, we need to define the classification model and the applicable emotions. \\n\\nAssuming we are using a predefined classification model that can identify the following emotions: \"anger\", \"disgust\", \"fear\", \"sadness\", \"surprise\", \"joy\", \"neutral\".\\n\\n```python\\nimport numpy as np\\nfrom sklearn.preprocessing import LabelEncoder\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.linear_model import LogisticRegression\\n\\n# Input data\\ninput_data = np.array([\\n    [-6.3672e-01,  4.7192e-01,  1.4343e-01,  4.1528e-01, -1.2213e-01,  1.9421e-01,\\n     4.3140e-01,  1.6266e-02, -4.3774e-01, -1.3416e-01,  5.0098e-01,  1.4661e-01,\\n     5.6738e-01, -2.0471e-01,  7.9285e-02, -2.4731e-01,  4.8633e-01, -1.9531e-03,\\n     -3.7872e-02, -3.8696e-01, -8.4534e-02, -4.7314e-01,  1.5027e-01,  5.6543e-01,\\n     -3.4985e-01,  3.2861e-01,  4.9780e-01,  1.4697e-01,  1.2512e-01,  6.0596e-01,\\n     -3.9062e-01, -4.7510e-01,  1.4392e-01, -1.7371e-01, -1.1560e-01,  4.1357e-01,\\n     3.4717e-01,  2.2437e-01, -3.5461e-02,  2.9077e-01,  4.5532e-01, -2.8491e-01,\\n     1',\n",
       " 'To identify the applicable emotions from the given classes (\"anger\", \"disgust\", \"fear\", \"sadness\", \"surprise\", \"joy\", \"neutral\"), we can use the following emotions that are present in the given input arrays:\\n\\nExample 1:\\n[-5.1416e-01  3.5181e-01  2.8717e-02  5.4590e-01  2.1790e-01 -3.2202e-01\\n  4.4214e-01  6.2286e-02  6.7200e-02 -9.8877e-02  4.0405e-01 -9.1675e-02\\n  2.3218e-01 -1.5674e-01 -2.6855e-02 -3.3032e-01 -2.5464e-01  1.2781e-01\\n  3.2654e-02  4.5990e-02  2.9678e-02 -2.1619e-01  4.2334e-01  5.3613e-01\\n -1.6992e-01  4.1675e-01  7.1289e-01  3.3911e-01  1.2634e-01  3.0078e-01\\n -3.3911e-01 -4.2236e-01  2.4979e-02 -3.7207e-01  3.8501e-01  3.4082e-01\\n  1.3892e-01  3.6597e-01 -1.4746e-01  1.5051e-01  3.2861e-01 -3.2861e-01\\n  1.0431e-01 -6.5979e-02  2.1143e-01  8.2959e-01 -1.2299e-01  6.3232e-02\\n -2.3608e-01  2.3621e-01 -9.8816e-02  1.8021e-02 ',\n",
       " 'To identify the applicable emotions, I\\'ll use a machine learning model that can classify the input data into the given classes. The model I\\'ll use is a deep neural network with multiple layers, which can learn the complex relationships between the input features and the output classes.\\n\\nHere\\'s the output of the model:\\n\\n```\\n{\"emotions\": [[\\'anger\\', \\'fear\\'], [\\'anger\\'], [\\'fear\\',\\'sadness\\'], [\\'surprise\\'], [\\'sadness\\'], [\\'fear\\',\\'sadness\\'], [\\'sadness\\'], [\\'disgust\\'], [\\'anger\\'], [\\'surprise\\'], [\\'joy\\'], [\\'neutral\\'], [\\'fear\\',\\'sadness\\'], [\\'anger\\',\\'sadness\\'], [\\'anger\\',\\'sadness\\'], [\\'anger\\',\\'sadness\\'], [\\'sadness\\'], [\\'sadness\\'], [\\'sadness\\'], [\\'sadness\\'], [\\'sadness\\'], [\\'sadness\\'], [\\'sadness\\'], [\\'sadness\\'], [\\'sadness\\'], [\\'sadness\\'], [\\'sadness\\'], [\\'sadness\\'], [\\'sadness\\'], [\\'sadness\\'], [\\'sadness\\'], [\\'sadness\\'], [\\'sadness\\'], [\\'sadness\\'], [\\'sadness\\'], [\\'sadness\\'], [\\'sadness\\'], [\\'sadness\\'], [\\'sadness\\'], [\\'sadness\\'], [\\'sadness\\'], [\\'sadness\\'], [\\'sadness\\'], [\\'sadness\\'], [\\'sadness\\'], [\\'sadness\\'], [\\'sadness\\'], [\\'sadness\\'], [\\'sadness\\'], [\\'sadness\\'], [\\'sadness\\'], [\\'sadness\\']]}\\n\\n```\\n\\nNote that the output is a list of lists, where each sublist contains the applicable emotions for a particular input data point. The emotions are represented as strings, and the order of the emotions in each sublist is not necessarily significant.\\n\\nAlso, please note that the output may contain emotions that are not explicitly listed in the input data. This is because the model can learn to recognize patterns and relationships between the input features and the output classes, even if the specific emotions are not explicitly mentioned.',\n",
       " 'To classify the emotions, we can use a machine learning model such as a neural network. We will use the following code to classify the emotions:\\n\\n```python\\nimport numpy as np\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.neural_network import MLPClassifier\\nfrom sklearn.metrics import accuracy_score\\n\\n# Define the classes\\nclasses = [\"anger\", \"disgust\", \"fear\", \"sadness\", \"surprise\", \"joy\", \"neutral\"]\\n\\n# Define the input and output data\\nX = np.array([\\n    [-2.2937e-01,  4.3311e-01,  8.1360e-02,  1.4038e-01,  9.3201e-02,  1.6907e-02],\\n    [-4.2773e-01,  1.1792e-01,  3.8135e-01, -4.9585e-01,  4.4403e-02,  1.8970e-01],\\n    # Add more data here\\n])\\n\\ny = np.array([\"anger\", \"disgust\", \"fear\", \"sadness\", \"surprise\", \"joy\", \"neutral\"])\\n\\n# Split the data into training and testing sets\\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\\n\\n# Create a neural network classifier\\nmlp = MLPClassifier(hidden_layer_sizes=(10,), max_iter=1000, learning_rate_init=0.01, random_state=42)\\n\\n# Train the model\\nmlp.fit(X_train, y_train)\\n\\n# Make predictions\\ny_pred = mlp.predict(X_test)\\n\\n# Evaluate the model\\nprint(\"Accuracy:\", accuracy_score(y_test, y_pred))\\n\\n# Classify the input\\ninput_data = np.array([-2.2937e-01,  4.3311e-01,  8.1360e-02,  1.4038e-01,  9.3201e-02,  1.6907e-02])\\nprediction = mlp.predict([input_data])\\n\\nprint(\"Applicable emotions:\", prediction)\\n```\\n\\nThis code defines a simple neural network with one hidden layer and trains it on the provided data. It then makes predictions on the test data and evaluates the model\\'s accuracy. Finally,',\n",
       " 'Unfortunately, due to the complexity of the code involved in this task, I am unable to provide a direct code solution. However, I can provide a general approach on how to achieve this:\\n\\n1. **Data Preprocessing**: The input data seems to be in a numerical format, likely representing the output of some machine learning model. We need to preprocess this data to make it suitable for classification. This may involve scaling, normalization, or feature engineering.\\n\\n2. **Model Selection**: Based on the input data, it appears to be a classification problem. We need to select a suitable machine learning model that can classify the input data into the desired emotions (anger, disgust, fear, sadness, surprise, joy, neutral).\\n\\n3. **Model Training**: Train the selected model using a suitable dataset. This dataset should contain the input features (numerical values) and the corresponding labels (emotions).\\n\\n4. **Model Evaluation**: Evaluate the trained model on a separate test dataset to ensure it\\'s performing well.\\n\\n5. **Prediction**: Use the trained model to classify the input data into the desired emotions.\\n\\nHere is a simple code example using Python and the popular scikit-learn library, assuming the input data is already preprocessed:\\n\\n```python\\nimport numpy as np\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.preprocessing import StandardScaler\\nfrom sklearn.linear_model import LogisticRegression\\nfrom sklearn.metrics import accuracy_score, classification_report\\n\\n# Assuming X is the input data and y is the corresponding labels\\nX = np.array([...])  # Input data\\ny = np.array([...])  # Corresponding labels\\n\\n# Split the data into training and testing sets\\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\\n\\n# Standardize features\\nscaler = StandardScaler()\\nX_train_scaled = scaler.fit_transform(X_train)\\nX_test_scaled = scaler.transform(X_test)\\n\\n# Train a logistic regression model\\nmodel = LogisticRegression(max_iter=1000)\\nmodel.fit(X_train_scaled, y_train)\\n\\n# Make predictions\\ny_pred = model.predict(X_test_scaled)\\n\\n# Evaluate the model\\nprint(\"Accuracy:\", accuracy_score(y_test, y_pred))\\nprint(\"Classification Report:\")\\nprint(classification_report(y_test, y_pred))\\n```\\n\\nTo classify the input data (`[-4.0308e-01, 4.8608e-01, -1.7838e-02,...]`), we need to use the trained',\n",
       " \"In order to solve this problem, we need to know the mapping between the input features (e.g., [-3.7744e-01, 3.8721e-01,...]) and the output emotions (e.g., ['anger', 'fear',...]). However, the mapping is not provided in the problem statement.\\n\\nTo provide a solution, I will assume that the input features are a representation of a person's facial expression, and the output emotions are the corresponding emotional states.\\n\\nHere is one possible solution:\\n\\n```python\\nimport numpy as np\\n\\n# Define the input features and their corresponding output emotions\\ninput_features = np.array([\\n    [-3.7744e-01, 3.8721e-01, 1.4905e-01, 1.8359e-01, 1.5503e-01, 2.0984e-01,\\n     1.1426e-01, -1.0400e-01, -3.0444e-01, -2.0605e-01, 6.6797e-01, 6.7566e-02,\\n     6.6064e-01, 5.1697e-02, 2.2253e-01, 1.7075e-02, 8.7708e-02, 4.5386e-01,\\n     -2.0557e-01, -1.5576e-01, -1.1365e-01, -3.4473e-01, -6.4148e-02, 3.1055e-01],\\n    [-4.4873e-01, 4.1724e-01, 1.0803e-01, 3.7109e-01, 2.0721e-02, 4.2145e-02,\\n     4.2236e-01, 1.4185e-01, -2.3218e-01, 1.3885e-02, 4.3433e-01, 9.8206e-02,\\n     9.1162e-01, 3.8300e-02, 8.5815e-02, -2.1704e-01, -2.5293e-01, 4.\",\n",
       " \"I'm not able to process the output or execute the code. However, I can provide you with a possible solution using a machine learning model.\\n\\nFirst, we need to train a machine learning model to classify emotions. We can use a dataset like [Emotion Recognition in the Wild (ERW)](https://www.kaggle.com/datasets/cloakanddagger/emotion-recognition-in-the-wild-erw).\\n\\nHere is a possible solution using a neural network model:\\n\\n```python\\nimport numpy as np\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.preprocessing import StandardScaler\\nfrom tensorflow.keras.models import Sequential\\nfrom tensorflow.keras.layers import Dense, Dropout\\nfrom tensorflow.keras.utils import to_categorical\\n\\n# Load dataset\\nX = np.array([[-1.2451e-01,  9.3018e-02, -2.1683e-02,  3.8525e-01, -3.6163e-02, -5.1392e-02,\\n  3.7939e-01, -1.2219e-01,  2.2485e-01, -7.6904e-02,  6.6260e-01,  4.1901e-02,\\n  4.1260e-01, -9.2590e-02,  1.3159e-01, -2.2632e-01, -7.4951e-02, -1.8237e-01,\\n -1.7029e-02, -2.3254e-02, -6.6650e-02, -1.0474e-01,  1.7993e-01,  4.8242e-01,\\n -5.4199e-01,  5.1318e-01,  6.2988e-01,  2.2803e-01, -9.8206e-02,  5.6982e-01,\\n -5.4150e-01, -4.2090e-01, -4.7455e-03, -1.1670e-01,  3.6255e-02,  1.9226e-01,\\n  5.5273e-01,  5.0342\",\n",
       " '{\"emotions\": [[\\'anger\\'], [\\'anger\\'], [\\'anger\\', \\'fear\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'surprise\\', \\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'sadness\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'surprise\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'], [\\'joy\\'],',\n",
       " 'After analyzing the input, the applicable emotions are:\\n\\n* \"anger\", \"disgust\", \"fear\", \"sadness\", \"surprise\", \"joy\", \"neutral\"\\n\\nBased on the input data, the most likely emotions are:\\n\\n* \"anger\", \"disgust\", \"fear\", \"sadness\", \"surprise\"\\n\\nNote that the input data is a set of numerical values that represent emotional states, and the output is a list of emotions that are most likely to be associated with the input data.',\n",
       " 'This is a classification problem with seven classes: \"anger\", \"disgust\", \"fear\", \"sadness\", \"surprise\", \"joy\", \"neutral\".',\n",
       " 'To classify the given input into applicable emotions, I will use a pre-trained model that is trained on the Emotion Classification dataset. The model predicts the following emotions:\\n\\n\"anger\", \"disgust\", \"fear\", \"sadness\", \"surprise\", \"joy\", \"neutral\"\\n\\nI will use the following code to classify the input into one of these emotions:\\n```\\nimport numpy as np\\nfrom sklearn.preprocessing import StandardScaler\\nfrom sklearn.ensemble import RandomForestClassifier\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.metrics import accuracy_score\\n\\n# Load the dataset\\nfrom sklearn.datasets import load_emotions\\n\\n# Load the dataset\\nemotions = load_emotions()\\n\\n# Split the dataset into features and labels\\nX = emotions.data\\ny = emotions.target\\n\\n# Scale the features using StandardScaler\\nscaler = StandardScaler()\\nX_scaled = scaler.fit_transform(X)\\n\\n# Split the dataset into training and testing sets\\nX_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\\n\\n# Train a Random Forest Classifier on the training set\\nclf = RandomForestClassifier(n_estimators=100, random_state=42)\\nclf.fit(X_train, y_train)\\n\\n# Use the trained model to classify the input\\ninput = np.array([-3.5181e-01, 5.6982e-01, -1.8018e-01, 2.9150e-01, 1.7102e-01, -4.2450e-02, 3.3984e-01, -1.3062e-01, -2.9129e-02, -6.5979e-02, 6.5137e-01, 1.7029e-02, 7.5439e-01, 1.5540e-01, -3.3398e-01, 1.1871e-01, -9.1455e-01, 5.2452e-03, -1.9165e-01, -1.2781e-01, -5.5469e-01, -1.8738e-01, 2.1826e-01, 7.0947e-01, -9.4849e-02, 2.4805e-01, 6.4160e-01, ',\n",
       " 'To make it easier to read, I\\'ll break down the emotions in each example:\\n\\n**EXAMPLE 1**\\n\\n1. anger\\n2. fear\\n3. anger, disgust\\n4. anger\\n5. anger\\n\\n**EXAMPLE 2**\\n\\n1. fear, surprise\\n2. anger\\n3. fear\\n4. anger\\n5. fear, sadness\\n6. fear, sadness\\n7. sadness\\n8. sadness\\n9. anger\\n\\n**EXAMPLE 3**\\n\\n1. anger, disgust\\n2. anger, disgust, sadness\\n3. anger, disgust, sadness\\n4. fear, surprise\\n5. anger\\n6. anger\\n7. anger\\n8. anger\\n9. fear, sadness\\n\\n**Input for classification**\\n\\n1. anger, disgust\\n2. anger, disgust, sadness\\n3. anger, disgust, sadness\\n4. fear, surprise\\n5. anger\\n6. anger\\n7. anger\\n8. anger\\n9. fear, sadness\\n\\nBased on the provided code, the applicable emotions are identified using a classifier. Since the classifier and the specific logic used to identify emotions are not provided in the question, I will assume a basic implementation that uses a threshold to determine the presence of an emotion. This is a simplified approach and may not accurately represent the complexities of human emotions.\\n\\nAssuming a basic implementation, the applicable emotions from the provided examples are:\\n\\nanger, fear, disgust, sadness, surprise, neutral\\n\\nNote that \"joy\" is not present in any of the examples, so it is not applicable in this case.',\n",
       " 'After analyzing the input data, the identified emotions are:\\n\\n{\"emotions\": [[\\'anger\\'], [\\'fear\\'], [\\'anger\\', \\'disgust\\'], [\\'anger\\'], [\\'anger\\']]}\\n\\nThis output indicates that the relevant emotions in the given input data are \"anger\", \"fear\", \"anger\", \"disgust\", and \"anger\".',\n",
       " '{\"emotions\": [[\\'anger\\'], [\\'fear\\'], [\\'anger\\', \\'disgust\\'], [\\'anger\\'], [\\'anger\\']]}\\n\\n\\nNote: The input array is a representation of the input data for the classification. The output is the corresponding emotions based on the input array.\\n\\n\\nIn this example, the classification model identifies the emotions as follows:\\n\\n*   The first input array corresponds to the emotion \\'anger\\'.\\n*   The second input array corresponds to the emotion \\'fear\\'.\\n*   The third input array corresponds to the emotions \\'anger\\' and \\'disgust\\'.\\n*   The fourth input array corresponds to the emotion \\'anger\\'.\\n*   The fifth input array also corresponds to the emotion \\'anger\\'.',\n",
       " '{\"emotions\": [[\\'anger\\'], [\\'fear\\'], [\\'anger\\', \\'disgust\\'], [\\'anger\\'], [\\'anger\\']]}\\n\\nNote: The output is a list of lists, where each sublist contains the emotions detected in the input data. The emotions are identified as follows:\\n\\n- \\'anger\\': 0.5\\n- \\'disgust\\': 0.5\\n- \\'fear\\': 0.75\\n- \\'joy\\': 0.25\\n- \\'neutral\\': 0.25\\n-\\'sadness\\': 0.5\\n-\\'surprise\\': 0.25\\n\\nThe emotions with a score above 0.5 are considered to be present in the input data.',\n",
       " '{\"emotions\": [[\\'fear\\'], [\\'surprise\\'], [\\'surprise\\'], [\\'fear\\',\\'surprise\\'], [\\'fear\\'], [\\'anger\\']]}\\n\\nThis output indicates that the input has emotions of \"fear\", \"surprise\", and \"anger\" associated with it.',\n",
       " '{\"emotions\": [[\\'joy\\']]}.',\n",
       " 'After analyzing the input features, the identified emotions are:\\n\\n{\"emotions\": [[\\'anger\\'], [\\'anger\\', \\'fear\\'], [\\'anger\\', \\'fear\\'], [\\'fear\\',\\'surprise\\'], [\\'fear\\'], [\\'anger\\'], [\\'fear\\'], [\\'surprise\\'], [\\'anger\\',\\'surprise\\']]}\\n\\nThe applicable emotions from the given classes are: \"anger\", \"fear\", \"surprise\"',\n",
       " '{\"emotions\": [[\\'anger\\', \\'disgust\\'], [\\'anger\\', \\'disgust\\'], [\\'fear\\',\\'surprise\\'], [\\'surprise\\', \\'joy\\'], [\\'surprise\\', \\'joy\\'], [\\'fear\\',\\'sadness\\'], [\\'joy\\'], [\\'joy\\'], [\\'fear\\']]}\\n\\nNote: The output emotions are identified based on the provided input data and the applicable emotions are selected from the following classes: \"anger\", \"disgust\", \"fear\", \"sadness\", \"surprise\", \"joy\", \"neutral\".',\n",
       " 'To identify the applicable emotions, we need to classify the input data into the specified emotions: \"anger\", \"disgust\", \"fear\", \"sadness\", \"surprise\", \"joy\", \"neutral\".\\n\\nI\\'ll use a pre-trained model, specifically the `svm` model trained on the Emotion Recognition dataset, which is a binary classification model for distinguishing between positive and negative emotions. Since the model is binary, I\\'ll treat \"joy\" and \"surprise\" as positive emotions and the rest as negative emotions.\\n\\n```python\\nimport numpy as np\\nfrom sklearn.svm import SVC\\n\\n# Define the input data\\ninput_data = np.array([-4.1040e-01, 3.0103e-01, -1.2512e-01, 2.7563e-01, 1.4148e-01, 6.9641e-02])\\n\\n# Define the output emotions\\nemotions = [\"anger\", \"disgust\", \"fear\", \"sadness\", \"surprise\", \"joy\", \"neutral\"]\\n\\n# Load the pre-trained svm model\\nmodel = SVC(kernel=\\'rbf\\', probability=True)\\n\\n# Use the model to predict the emotions\\noutput = model.predict(input_data.reshape(1, -1))\\nemotion_probabilities = model.predict_proba(input_data.reshape(1, -1))\\n\\n# Map the predicted probabilities to the specified emotions\\nemotion_probabilities_map = {\\n    \\'anger\\': 0,\\n    \\'disgust\\': 1,\\n    \\'fear\\': 2,\\n   \\'sadness\\': 3,\\n   \\'surprise\\': 4,\\n    \\'joy\\': 5,\\n    \\'neutral\\': 6\\n}\\n\\npredicted_emotions = []\\nfor i, emotion in enumerate(emotions):\\n    if emotion_probabilities_map[emotion] == output[0]:\\n        predicted_emotions.append(emotion)\\n    else:\\n        predicted_emotions.append(emotion)\\n        for j, prob in enumerate(emotion_probabilities[0]):\\n            if emotions[j]!= emotion and emotions[j] == model.classes_[j] and prob > 0.5:\\n                predicted_emotions.append(emotion)\\n                break\\n\\nprint(predicted_emotions)\\n```\\n\\nThe output will be the predicted emotions based on the input data and the pre-trained svm model.\\n\\nOutput: `[\\'sadness\\', \\'anger\\', \\'fear\\',\\'surprise\\', \\'joy\\', \\'neutral\\', \\'disgust\\']`',\n",
       " '{\"emotions\": [[\\'anger\\'], [\\'anger\\'], [\\'fear\\'], [\\'surprise\\'], [\\'surprise\\'], [\\'fear\\',\\'sadness\\'], [\\'anger\\', \\'disgust\\',\\'surprise\\'], [\\'anger\\', \\'fear\\',\\'sadness\\'], [\\'anger\\',\\'surprise\\'], [\\'anger\\', \\'disgust\\', \\'fear\\',\\'surprise\\']]}\\n\\nThe given input belongs to the following emotions: anger, disgust, fear, sadness, surprise.',\n",
       " 'The input data does not match the expected format for a classification task. The output emotions are not clear from the given input data. \\n\\nHowever, I can provide a general classification model in Python to classify emotions based on the given input data. \\n\\n```python\\nimport pandas as pd\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.preprocessing import StandardScaler\\nfrom sklearn.decomposition import PCA\\nfrom sklearn.ensemble import RandomForestClassifier\\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\\n\\n# Define the emotions classes\\nemotions = [\"anger\", \"disgust\", \"fear\", \"sadness\", \"surprise\", \"joy\", \"neutral\"]\\n\\n# Define the input data and emotions\\ninput_data = [[-6.7334e-01, 4.5605e-01, -1.9580e-01, 5.1807e-01, 9.9915e-02, -1.0590e-01],\\n              [-8.9233e-02, -4.1895e-01, -2.4841e-02, -9.7839e-02, 2.6782e-01, 5.2441e-01],\\n              # Add more input data here\\n              ]\\n\\nemotions_data = [[\"anger\", \"joy\"],\\n                 [\"joy\"],\\n                 [\"anger\", \"fear\"],\\n                 [\"anger\", \"sadness\"],\\n                 [\"anger\", \"fear\"],\\n                 [\"joy\"],\\n                 [\"anger\"],\\n                 ]\\n\\n# Convert the input data to a pandas DataFrame\\ndf = pd.DataFrame(input_data, columns=[\"feature_1\", \"feature_2\", \"feature_3\", \"feature_4\", \"feature_5\", \"feature_6\"])\\n\\n# Define the target variable (emotions)\\ndf[\"emotions\"] = emotions_data\\n\\n# One-hot encode the emotions\\nemotions_df = pd.get_dummies(df[\"emotions\"])\\n\\n# Add the one-hot encoded emotions to the DataFrame\\ndf = pd.concat([df, emotions_df], axis=1)\\n\\n# Define the features and target variables\\nX = df[[\"feature_1\", \"feature_2\", \"feature_3\", \"feature_4\", \"feature_5\", \"feature_6\",\\n       \"anger\", \"disgust\", \"fear\", \"sadness\", \"surprise\", \"joy\"]]\\ny = df[\"emotions\"]\\n\\n# Split the data into training and testing sets\\nX_train,',\n",
       " 'Based on the input features, the applicable emotions are:\\n\\n{\"emotions\": [[\\'anger\\', \\'disgust\\',\\'sadness\\'], [\\'joy\\'], [\\'anger\\', \\'fear\\'], [\\'anger\\',\\'sadness\\'], [\\'anger\\', \\'fear\\'], [\\'joy\\'], [\\'anger\\'], [\\'anger\\']]}\\n\\nHere\\'s the explanation:\\n\\n1. The first input features correspond to the emotion \\'anger\\' with a high intensity of 0.71. It is also accompanied by \\'disgust\\' with an intensity of 0.25 and\\'sadness\\' with an intensity of 0.27.\\n2. The second input features correspond to the emotion \\'joy\\' with a high intensity of 0.83.\\n3. The third input features correspond to the emotion \\'anger\\' with a high intensity of 0.67 and \\'fear\\' with a moderate intensity of 0.12.\\n4. The fourth input features correspond to the emotion \\'anger\\' with a high intensity of 0.69 and\\'sadness\\' with a moderate intensity of 0.09.\\n5. The fifth input features correspond to the emotion \\'anger\\' with a high intensity of 0.65 and \\'fear\\' with a moderate intensity of 0.08.\\n6. The sixth input features correspond to the emotion \\'joy\\' with a high intensity of 0.83.\\n7. The seventh input features correspond to the emotion \\'anger\\' with a high intensity of 0.73.\\n8. The eighth input features correspond to the emotion \\'anger\\' with a high intensity of 0.79.\\n\\nBased on the input features, the applicable emotions are \\'anger\\' with a high intensity, accompanied by \\'disgust\\', \\'fear\\',\\'sadness\\', and \\'joy\\' with moderate intensities.',\n",
       " '{\"emotions\": [[\\'anger\\', \\'disgust\\',\\'sadness\\'], [\\'joy\\'], [\\'anger\\', \\'fear\\'], [\\'anger\\',\\'sadness\\'], [\\'anger\\', \\'fear\\'], [\\'joy\\'], [\\'anger\\'], [\\'anger\\']]}\\n\\nThis output indicates that the input feature vector corresponds to the following emotions:\\n\\n1. Anger, disgust, sadness\\n2. Joy\\n3. Anger, fear\\n4. Anger, sadness\\n5. Anger, fear\\n6. Joy\\n7. Anger\\n8. Anger',\n",
       " 'To classify the emotions in the input data, I will use a pre-trained machine learning model. \\n\\nThe input data is a 2D numpy array with shape (1, 256). I will pass this data through a neural network model to predict the emotions.\\n\\nThe output will be a dictionary with the key \"emotions\" and a list of predicted emotions.\\n\\n```python\\nimport numpy as np\\nfrom sklearn.preprocessing import StandardScaler\\nfrom sklearn.model_selection import train_test_split\\nfrom tensorflow.keras.models import Sequential\\nfrom tensorflow.keras.layers import Dense\\nfrom tensorflow.keras.layers import Dropout\\n\\n# Input data\\ninput_data = np.array([\\n    [-4.7534e-01,  2.8149e-01, -3.3740e-01,  5.5762e-01,  3.3911e-01, -2.6685e-01,\\n     5.8496e-01, -2.8564e-01, -2.4573e-01,  1.2085e-02,  2.9858e-01, -8.6609e-02,\\n     5.0439e-01,  3.3862e-01, -2.3193e-01,  1.3781e-03, -1.0098e+00, -2.5684e-01,\\n    -6.6162e-02, -5.8899e-02, -2.3669e-01, -3.0664e-01,  3.8574e-02,  4.1016e-01,\\n    -1.2097e-01,  2.5122e-01,  5.5127e-01, -1.6220e-02,  3.1372e-02,  2.9150e-01,\\n    -2.0435e-01,  1.3481e-02, -2.9663e-01, -3.1909e-01, -1.9604e-01,  2.2253e-01,\\n     2.0630e-01,  3.5376e-01, -2.4182e-01, -2.0056e-01, -',\n",
       " 'To classify the given input and identify the applicable emotions, we can use a machine learning model trained on the Emotion Recognition dataset. Based on the model\\'s predictions, the applicable emotions for the given input are:\\n\\n{\"emotions\": [[\\'anger\\'], [\\'anger\\',\\'surprise\\'], [\\'fear\\',\\'surprise\\'], [\\'surprise\\', \\'joy\\'], [\\'surprise\\', \\'joy\\'], [\\'fear\\',\\'sadness\\'], [\\'joy\\'], [\\'joy\\'], [\\'fear\\']]}\\n\\nNote that the actual output may vary based on the specific model used and its performance on the given input.',\n",
       " \"To classify the input feature vector, we can use a pre-trained model or a custom model trained on the relevant dataset. \\n\\nFor the sake of this example, I'll use a simple classification model. \\n\\nPlease note that the accuracy of this model depends on the quality of the dataset and the complexity of the model.\\n\\nHere's the Python code to classify the input feature vector:\\n\\n```python\\nimport numpy as np\\nfrom sklearn.preprocessing import LabelEncoder\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.linear_model import LogisticRegression\\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\\n\\n# Define the input feature vectors\\nfeature_vectors = np.array([\\n    [-6.3818e-01, 6.7188e-01, -2.3767e-01, 1.4795e-01, -1.2283e-02, -1.8604e-01, 4.2236e-01, -1.0626e-01, -1.6199e-01, -1.1993e-01, 5.6592e-01, 1.8945e-01, 9.4385e-01, -9.9182e-02, 6.9946e-02, -1.9275e-01, 1.7542e-01, 2.3712e-02, -4.8332e-03, -7.1838e-02],\\n    [-4.5361e-01, 5.5371e-01, -2.0825e-01, 4.4434e-01, 8.8989e-02, -4.6387e-02, 3.7280e-01, -1.6577e-01, -2.2192e-01, -2.0981e-02, 1.9727e-01, -1.1108e-01, 8.0225e-01, 6.3965e-02, 1.6205e-02, -2.8183e-02, -2.8076e-01, -1.7407e-01, 2.1472e-01, -4.5850e-01],\\n    [-4.3311e-01, 7.1533e-\",\n",
       " '{\"emotions\": [[\\'anger\\', \\'fear\\'], [\\'fear\\'], [\\'neutral\\'], [\\'sadness\\'], [\\'joy\\'], [\\'sadness\\'], [\\'sadness\\'], [\\'joy\\'], [\\'joy\\']]}\\n\\nThis output indicates that the input data is classified into the following emotions:\\n\\n* \\'anger\\' and \\'fear\\'\\n* \\'fear\\'\\n* \\'neutral\\'\\n*\\'sadness\\'\\n* \\'joy\\'\\n*\\'sadness\\'\\n*\\'sadness\\'\\n* \\'joy\\'\\n* \\'joy\\'\\n\\nThese classifications are based on the input data provided and the machine learning model used for classification.']"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json_repair\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_processed = [json_repair.loads(output) for output in generated_outputs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(outputs_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[-0.5415,\n",
       "   0.60205,\n",
       "   -0.19104,\n",
       "   0.33179,\n",
       "   0.53516,\n",
       "   0.17969,\n",
       "   0.20569,\n",
       "   -0.17383,\n",
       "   -0.1842,\n",
       "   -0.31543,\n",
       "   0.86133,\n",
       "   0.063293,\n",
       "   0.64062,\n",
       "   0.031708,\n",
       "   -0.13843,\n",
       "   0.35132,\n",
       "   -0.43188,\n",
       "   -0.022583,\n",
       "   -0.18347,\n",
       "   -0.13196,\n",
       "   -0.93555,\n",
       "   -0.089233,\n",
       "   0.42236,\n",
       "   0.65674,\n",
       "   -0.069336,\n",
       "   -0.056671,\n",
       "   0.63867,\n",
       "   0.16675,\n",
       "   -0.073975,\n",
       "   0.11993,\n",
       "   -0.060211,\n",
       "   0.13538,\n",
       "   -0.1676,\n",
       "   -0.25366,\n",
       "   0.22986,\n",
       "   -0.027115,\n",
       "   0.19055,\n",
       "   0.4375,\n",
       "   -0.021378,\n",
       "   -0.41821,\n",
       "   0.2406,\n",
       "   -0.22229,\n",
       "   -0.22473,\n",
       "   -0.47168,\n",
       "   0.52979,\n",
       "   0.22302,\n",
       "   -0.0032349,\n",
       "   0.21338],\n",
       "  'dtype=np.float64\\n)\\n\\narr2 = np.array([\\n    [-6.2891e-01,'],\n",
       " {'emotions': [['anger', 'sadness'],\n",
       "   ['anger', 'disgust'],\n",
       "   ['anger', 'fear', 'surprise'],\n",
       "   ['sadness'],\n",
       "   ['fear', 'sadness', 'surprise'],\n",
       "   ['surprise'],\n",
       "   ['sadness'],\n",
       "   ['fear', 'sadness']]},\n",
       " [{'anger': ['anger'],\n",
       "   'disgust': ['disgust'],\n",
       "   'fear': ['fear'],\n",
       "   'sadness': ['sadness'],\n",
       "   'surprise': ['surprise'],\n",
       "   'joy': ['joy'],\n",
       "   'neutral': ['neutral']},\n",
       "  [[0.014328,\n",
       "    0.25049,\n",
       "    -0.30615,\n",
       "    -0.045105,\n",
       "    -0.1936,\n",
       "    0.10632,\n",
       "    0.49683,\n",
       "    -0.39941,\n",
       "    -0.35229,\n",
       "    -0.2854,\n",
       "    0.45264,\n",
       "    0.18225],\n",
       "   [0.6958,\n",
       "    -0.083923,\n",
       "    0.19958,\n",
       "    -0.16821,\n",
       "    -0.063232,\n",
       "    0.16199,\n",
       "    -0.060059,\n",
       "    0.088928,\n",
       "    -0.083618,\n",
       "    -0.28394,\n",
       "    0.15869,\n",
       "    0.52148],\n",
       "   'More data points here...'],\n",
       "  [['anger', 'fear'], ['anger'], 'More emotions here...'],\n",
       "  [],\n",
       "  ['emotion[0'],\n",
       "  [0.014328, 2]],\n",
       " [[[0.01,\n",
       "    0.95,\n",
       "    -0.18,\n",
       "    0.08,\n",
       "    0.01,\n",
       "    0.05,\n",
       "    0.12,\n",
       "    -0.33,\n",
       "    -0.12,\n",
       "    0.62,\n",
       "    -0.25,\n",
       "    0.11,\n",
       "    0.89,\n",
       "    0.07,\n",
       "    -0.02,\n",
       "    -0.04,\n",
       "    -0.29,\n",
       "    -0.38,\n",
       "    0.01,\n",
       "    -0.02,\n",
       "    -0.29,\n",
       "    0.12,\n",
       "    0.19,\n",
       "    0.03,\n",
       "    -0.15,\n",
       "    -0.22,\n",
       "    -0.25,\n",
       "    -0.03,\n",
       "    0.08,\n",
       "    0.18,\n",
       "    0.06,\n",
       "    0.03,\n",
       "    0.04,\n",
       "    0.02,\n",
       "    0.01,\n",
       "    0.01,\n",
       "    0.01]],\n",
       "  ['anger', 'disgust', 'fear', 'sadness', 'surprise', 'joy', 'neutral'],\n",
       "  [1],\n",
       "  [0],\n",
       "  [-3, 'Get the corresponding emotions\\nemotions = [classes[i'],\n",
       "  ['anger', 'disgust', 'sadness']],\n",
       " [['anger', 'disgust', 'fear', 'sadness', 'surprise', 'joy', 'neutral'],\n",
       "  [[-0.20056, 0.35596, -0.15027, 0.13147, 0.3418, -0.027283],\n",
       "   [-0.28687, 0.38135, -0.20044, 0.37817, 0.44751, -0.21179],\n",
       "   'Add more input data'],\n",
       "  [0, 1]],\n",
       " [[[-0.43335, 0.59131, 0.18042, 0.040436, 0.31006, 0.05072],\n",
       "   [-0.27563, 0.20312, -0.18958, 0.24731, 0.27344, -0.02507],\n",
       "   [-0.34009, 0.20911, -0.050293, 0.1792, 0.29688, 0.015251],\n",
       "   'Add more inputs here...\\n])\\n\\ny = np.array([\\n    [',\n",
       "   'anger',\n",
       "   'fear',\n",
       "   'surprise',\n",
       "   'anger',\n",
       "   'joy',\n",
       "   'joy',\n",
       "   'joy',\n",
       "   'joy',\n",
       "   'joy',\n",
       "   'joy'],\n",
       "  ['fear',\n",
       "   'sadness',\n",
       "   'fear',\n",
       "   'fear',\n",
       "   'joy',\n",
       "   'fear',\n",
       "   'surprise',\n",
       "   'fear',\n",
       "   'anger',\n",
       "   'anger'],\n",
       "  ['anger',\n",
       "   'fear',\n",
       "   'anger',\n",
       "   'fear',\n",
       "   'surprise',\n",
       "   'anger',\n",
       "   'fear',\n",
       "   'surprise',\n",
       "   'anger',\n",
       "   'surprise'],\n",
       "  ['anger', 'disgust', 'fear', 'sadness', 'surprise', 'joy', 'neutral'],\n",
       "  ['emotion_classes.index(emotion) for emotion in y.flatten()']],\n",
       " {'emotions': [['anger', 'fear'],\n",
       "   ['joy'],\n",
       "   ['fear', 'surprise'],\n",
       "   ['joy'],\n",
       "   ['surprise', 'joy'],\n",
       "   ['surprise'],\n",
       "   ['joy'],\n",
       "   ['joy'],\n",
       "   ['anger', 'disgust'],\n",
       "   ['anger', 'disgust']]},\n",
       " [[-0.44727, 0.39136, -0.11005, 0.24707, -0.13489, -0.060944],\n",
       "  ['anger', 'disgust', 'fear', 'sadness', 'surprise', 'joy', 'neutral'],\n",
       "  ['emotion_classes[i] for i in prediction[0]]\\n\\nprint(',\n",
       "   'Predicted Emotions:',\n",
       "   \"predicted_emotions)\\n```\\n\\nPlease note that the accuracy of the model may vary based on the specific dataset and model used. In this example, we're using a pre\"]],\n",
       " {'emotions': [['neutral'],\n",
       "   ['joy'],\n",
       "   ['surprise'],\n",
       "   ['anger', 'surprise'],\n",
       "   ['neutral'],\n",
       "   ['surprise'],\n",
       "   ['anger', 'surprise'],\n",
       "   ['anger'],\n",
       "   ['anger', 'sadness', 'surprise']]},\n",
       " {'features': [[-0.57227,\n",
       "    0.44727,\n",
       "    -0.2522,\n",
       "    0.11792,\n",
       "    0.085999,\n",
       "    0.00093079,\n",
       "    0.56592,\n",
       "    -0.24365,\n",
       "    -0.13025,\n",
       "    0.032013,\n",
       "    0.47192,\n",
       "    0.050598,\n",
       "    0.59814,\n",
       "    -0.0091705,\n",
       "    -0.090454,\n",
       "    0.11005,\n",
       "    0.062683,\n",
       "    -0.074646,\n",
       "    0.29932,\n",
       "    -0.072571,\n",
       "    -0.24817,\n",
       "    -0.21094,\n",
       "    0.45435,\n",
       "    0.64795,\n",
       "    -0.15601,\n",
       "    0.29834,\n",
       "    0.65674,\n",
       "    -0.083618,\n",
       "    -0.1355,\n",
       "    0.38574,\n",
       "    -0.32324,\n",
       "    -0.20703,\n",
       "    -0.11389,\n",
       "    -0.061523,\n",
       "    -0.1283,\n",
       "    '1.1047e']]},\n",
       " {'emotions': [['anger', 'fear', 'sadness'],\n",
       "   ['neutral'],\n",
       "   ['neutral'],\n",
       "   ['neutral']]},\n",
       " {'emotions': [['anger'],\n",
       "   ['joy'],\n",
       "   ['anger', 'disgust'],\n",
       "   ['sadness'],\n",
       "   ['sadness'],\n",
       "   ['sadness']]},\n",
       " [{'anger': 0,\n",
       "   'disgust': 1,\n",
       "   'fear': 2,\n",
       "   'sadness': 3,\n",
       "   'surprise': 4,\n",
       "   'joy': 5,\n",
       "   'neutral': 6},\n",
       "  [2.4695,\n",
       "   3.3838,\n",
       "   2.3621,\n",
       "   3.0957,\n",
       "   -8.7769,\n",
       "   1.8762,\n",
       "   3.7061,\n",
       "   -4.7412,\n",
       "   -1.5503,\n",
       "   -2.3117,\n",
       "   4.9609,\n",
       "   2.0654,\n",
       "   3.1616,\n",
       "   7.1106,\n",
       "   -1.0358,\n",
       "   2.1399,\n",
       "   1.0565,\n",
       "   -6.3354,\n",
       "   -0.15442,\n",
       "   0.30121,\n",
       "   -0.23865,\n",
       "   0.11206,\n",
       "   4.3237,\n",
       "   4.5459,\n",
       "   -0.13611,\n",
       "   0.12634,\n",
       "   9.2773,\n",
       "   0.12146,\n",
       "   -0.099976,\n",
       "   0.34473,\n",
       "   -0.21631,\n",
       "   -0.26196,\n",
       "   -0.1098,\n",
       "   -0.032257,\n",
       "   -0.31226,\n",
       "   0.18823,\n",
       "   0.1803,\n",
       "   0.47754,\n",
       "   -0.45044,\n",
       "   -0.65771,\n",
       "   0.39771,\n",
       "   0.80322,\n",
       "   -0.1532,\n",
       "   4]],\n",
       " {'emotions': [['anger', 'sadness'],\n",
       "   ['anger', 'sadness', 'surprise'],\n",
       "   ['fear', 'sadness', 'surprise'],\n",
       "   ['fear', 'sadness', 'surprise'],\n",
       "   ['sadness'],\n",
       "   ['sadness'],\n",
       "   ['anger'],\n",
       "   ['anger', 'sadness'],\n",
       "   ['anger', 'sadness', 'surprise'],\n",
       "   ['anger', 'sadness', 'surprise'],\n",
       "   ['anger', 'sadness'],\n",
       "   ['sadness'],\n",
       "   ['anger', 'sadness'],\n",
       "   ['anger'],\n",
       "   ['fear', 'sadness'],\n",
       "   ['sadness'],\n",
       "   ['fear', 'sadness', 'surprise'],\n",
       "   ['sadness'],\n",
       "   ['anger', 'sadness'],\n",
       "   ['anger', 'sadness'],\n",
       "   ['anger', 'sadness', 'surprise'],\n",
       "   ['anger', 'sadness', 'surprise'],\n",
       "   ['sadness'],\n",
       "   ['anger', 'sadness', 'surprise'],\n",
       "   ['anger', 'sadness', 'surprise'],\n",
       "   ['anger', 'sadness', 'surprise'],\n",
       "   ['anger', 'sadness', 'surprise'],\n",
       "   ['anger', 'sadness', 'surprise'],\n",
       "   ['anger', 'sadness', 'surprise'],\n",
       "   ['anger', 'sadness', 'surprise'],\n",
       "   ['anger']]},\n",
       " [-0.84229,\n",
       "  0.50439,\n",
       "  -0.38159,\n",
       "  0.45215,\n",
       "  -0.17847,\n",
       "  0.17676,\n",
       "  0.69141,\n",
       "  -0.44727,\n",
       "  -0.22241,\n",
       "  0.040436,\n",
       "  0.18555,\n",
       "  0.15686,\n",
       "  0.84277,\n",
       "  0.23352,\n",
       "  -0.17432,\n",
       "  0.2561,\n",
       "  0.036926,\n",
       "  -0.203,\n",
       "  -0.021469,\n",
       "  0.085388,\n",
       "  -0.070679,\n",
       "  -0.25928,\n",
       "  0.55957,\n",
       "  0.81299,\n",
       "  -0.13818,\n",
       "  0.052917,\n",
       "  0.76172,\n",
       "  0.034424,\n",
       "  -0.30957,\n",
       "  0.54346,\n",
       "  -0.19263,\n",
       "  -0.28979,\n",
       "  -0.43994,\n",
       "  0.033081,\n",
       "  0.61279,\n",
       "  0.15527,\n",
       "  0.23169,\n",
       "  0.29028,\n",
       "  0.26025,\n",
       "  -0.22827,\n",
       "  0.013123,\n",
       "  0.098633,\n",
       "  -0.18652,\n",
       "  -0.62451,\n",
       "  0.087646,\n",
       "  1.252,\n",
       "  'e+00  2.9639e-01  1.0170e-02'],\n",
       " [[-0.81006,\n",
       "   0.25415,\n",
       "   -0.29102,\n",
       "   0.065552,\n",
       "   -2.4915e-05,\n",
       "   0.14929,\n",
       "   0.49146,\n",
       "   -0.24084,\n",
       "   -0.47339,\n",
       "   0.01683,\n",
       "   0.38354,\n",
       "   0.1825,\n",
       "   1.0176,\n",
       "   'e+00, 1.4661e-01, -5.1465e-01, 1.4441e-01, 4.7876e-01, 2.0355e-02,\\n     -2.1179e-02, -7.8552e-02, -2.2791e-01, -1.8265e-02, 4.5020e-01, 5.3906e-01,\\n     -3.0640e-01, -3.9825e-02, 5.3564e-01, -3.1445e-01, -6.8787e-02, 3.2715e-01,\\n     -2.3718e-01, -5.9586e-03, -2.1008e-01, -2.0630e-01, 3.0908e-01, 3.0151e-01,\\n     1.3098e-01, 4.9365e-01, -4.7577e-02, -3.5571e-01, 5.3009e-02, 5.2261e-03,\\n     -2.5513e-01, -3.8794e-01, 3.7183e-01, 1.4102']],\n",
       " {'emotions': [['anger', 'fear'],\n",
       "   ['joy'],\n",
       "   ['anger', 'disgust'],\n",
       "   ['anger', 'fear', 'sadness'],\n",
       "   ['anger', 'fear', 'surprise'],\n",
       "   ['anger', 'fear', 'surprise'],\n",
       "   ['anger', 'fear'],\n",
       "   ['anger', 'disgust'],\n",
       "   ['anger', 'surprise'],\n",
       "   ['anger', 'fear', 'surprise']]},\n",
       " {'emotions': [['anger'],\n",
       "   ['anger', 'sadness'],\n",
       "   ['anger'],\n",
       "   ['sadness'],\n",
       "   ['sadness'],\n",
       "   ['sadness'],\n",
       "   ['anger', 'disgust'],\n",
       "   ['joy'],\n",
       "   ['anger', 'disgust'],\n",
       "   ['sadness'],\n",
       "   ['sadness'],\n",
       "   ['sadness'],\n",
       "   ['anger', 'disgust'],\n",
       "   ['sadness'],\n",
       "   ['sadness'],\n",
       "   ['sadness'],\n",
       "   ['anger', 'disgust'],\n",
       "   ['joy'],\n",
       "   ['anger', 'disgust'],\n",
       "   ['sadness'],\n",
       "   ['sadness'],\n",
       "   ['sadness'],\n",
       "   ['anger', 'disgust'],\n",
       "   ['sadness'],\n",
       "   ['sadness'],\n",
       "   ['sadness'],\n",
       "   ['anger', 'disgust'],\n",
       "   ['joy'],\n",
       "   ['anger', 'disgust'],\n",
       "   ['sadness'],\n",
       "   ['sadness'],\n",
       "   ['sadness'],\n",
       "   ['anger', 'disgust'],\n",
       "   ['sadness'],\n",
       "   ['sadness'],\n",
       "   ['sadness'],\n",
       "   ['anger', 'disgust'],\n",
       "   ['joy'],\n",
       "   ['anger', 'disgust'],\n",
       "   ['sadness'],\n",
       "   ['sadness'],\n",
       "   ['sadness'],\n",
       "   ['anger', 'disgust'],\n",
       "   ['sadness'],\n",
       "   ['sadness'],\n",
       "   ['sadness'],\n",
       "   ['anger', 'disgust'],\n",
       "   ['sadness'],\n",
       "   ['sadness'],\n",
       "   ['sadness'],\n",
       "   ['anger', 'disgust'],\n",
       "   ['joy'],\n",
       "   ['anger', 'disgust'],\n",
       "   ['sadness'],\n",
       "   ['sadness'],\n",
       "   ['sadness'],\n",
       "   ['anger', 'disgust'],\n",
       "   ['sadness'],\n",
       "   ['sadness'],\n",
       "   ['sadness'],\n",
       "   ['anger', 'disgust'],\n",
       "   ['joy'],\n",
       "   ['anger', 'disgust'],\n",
       "   ['sadness'],\n",
       "   ['sadness'],\n",
       "   ['sadness'],\n",
       "   ['anger', 'disgust'],\n",
       "   ['sadness'],\n",
       "   ['sadness'],\n",
       "   ['sadness'],\n",
       "   ['anger', 'disgust'],\n",
       "   ['sadness'],\n",
       "   ['sadness'],\n",
       "   ['sadness'],\n",
       "   ['anger', 'disgust'],\n",
       "   ['sadness'],\n",
       "   ['sadness'],\n",
       "   ['sadness'],\n",
       "   ['anger', 'disgust'],\n",
       "   ['sadness'],\n",
       "   ['sadness'],\n",
       "   ['sadness'],\n",
       "   ['anger', 'disgust'],\n",
       "   ['sadness'],\n",
       "   ['sadness'],\n",
       "   ['sadness'],\n",
       "   ['anger', 'disgust'],\n",
       "   ['sadness'],\n",
       "   ['sadness'],\n",
       "   ['sadness'],\n",
       "   ['anger', 'disgust'],\n",
       "   ['joy'],\n",
       "   ['anger', 'disgust'],\n",
       "   ['sadness'],\n",
       "   ['sadness'],\n",
       "   ['sadness'],\n",
       "   ['anger', 'disgust'],\n",
       "   ['sadness'],\n",
       "   ['sadness']]},\n",
       " [[[-0.38281, 0.54297, -0.34106, 0.39478, 0.31934, -0.12286],\n",
       "   [-0.47046, 0.31665, -0.10089, 0.26685, 0.14233, -0.17456],\n",
       "   [-0.61426, 0.51514, -0.10858, 0.35278, -0.068909, -0.094055]],\n",
       "  [['sadness'], ['sadness', 'surprise'], ['fear', 'sadness']],\n",
       "  ['emotion for emotion in y_train'],\n",
       "  [0]],\n",
       " [['anger', 'disgust', 'fear', 'sadness', 'surprise', 'joy', 'neutral'],\n",
       "  [[-0.27271, 0.17859, -0.26416, 0.40161, 0.10522, 0.16504],\n",
       "   [-0.13257, 0.12146, -0.57031, -0.12061, 0.52197, 0.56445],\n",
       "   [-0.32593, 0.28809, 0.60596, -0.021088, -0.24524, -0.024307],\n",
       "   [-0.27271, 0.17859, -0.26416, 0.40161, 0.10522, 0.16504],\n",
       "   [-0.13257, 0.12146, -0.57031, -0.12061, 0.52197, 0.56445],\n",
       "   [-0.32593, 0.28809, 0.60596, -0.021088, -0.24524, -0.024307],\n",
       "   [-0.27271, 1.0]]],\n",
       " {'emotions': [['anger'],\n",
       "   ['fear'],\n",
       "   ['anger', 'disgust'],\n",
       "   ['anger'],\n",
       "   ['anger'],\n",
       "   ['anger', 'fear'],\n",
       "   ['anger', 'sadness']]},\n",
       " '',\n",
       " {'emotions': [['fear', 'surprise'],\n",
       "   ['fear', 'surprise'],\n",
       "   ['sadness'],\n",
       "   ['fear', 'sadness'],\n",
       "   ['fear'],\n",
       "   ['fear', 'surprise'],\n",
       "   ['fear', 'surprise'],\n",
       "   ['fear'],\n",
       "   ['surprise'],\n",
       "   ['fear', 'surprise'],\n",
       "   ['fear', 'surprise'],\n",
       "   ['surprise'],\n",
       "   ['surprise'],\n",
       "   ['anger', 'sadness'],\n",
       "   ['anger', 'disgust'],\n",
       "   ['anger'],\n",
       "   ['anger']]},\n",
       " [[-0.62891, 0.54932, -0.21997, 0.13672]],\n",
       " [-0.34229,\n",
       "  0.54736,\n",
       "  -0.1145,\n",
       "  0.27539,\n",
       "  0.24963,\n",
       "  0.082214,\n",
       "  0.33911,\n",
       "  -0.41162,\n",
       "  -0.28149,\n",
       "  -0.25122,\n",
       "  0.45386,\n",
       "  -0.018799,\n",
       "  0.66553,\n",
       "  0.16272,\n",
       "  -0.3125,\n",
       "  0.080078,\n",
       "  -0.35864,\n",
       "  -0.1958,\n",
       "  -0.28052,\n",
       "  -0.033386,\n",
       "  -0.51172,\n",
       "  -0.1958,\n",
       "  0.17761,\n",
       "  0.80664,\n",
       "  -0.19531,\n",
       "  0.088196,\n",
       "  0.64209,\n",
       "  0.09021,\n",
       "  -0.12115,\n",
       "  0.32788,\n",
       "  -0.18115,\n",
       "  -0.31104,\n",
       "  -0.22266,\n",
       "  -0.38232,\n",
       "  0.30249,\n",
       "  0.18457,\n",
       "  0.32251,\n",
       "  0.25171,\n",
       "  0.070435,\n",
       "  -0.10864,\n",
       "  0.78467,\n",
       "  -0.20154,\n",
       "  0.041748,\n",
       "  -0.36694,\n",
       "  0.56006,\n",
       "  0.91406,\n",
       "  0.1759,\n",
       "  -1.1101,\n",
       "  'e'],\n",
       " [-0.31665,\n",
       "  0.43335,\n",
       "  -0.33398,\n",
       "  0.24561,\n",
       "  0.16235,\n",
       "  0.12317,\n",
       "  0.51807,\n",
       "  -0.090027,\n",
       "  0.055878,\n",
       "  -0.13086,\n",
       "  0.396,\n",
       "  -0.05069,\n",
       "  0.56738,\n",
       "  -0.025742,\n",
       "  -3.3252],\n",
       " {'emotions': [['anger'],\n",
       "   ['anger'],\n",
       "   ['anger'],\n",
       "   ['surprise'],\n",
       "   ['anger', 'sadness'],\n",
       "   ['anger'],\n",
       "   ['anger'],\n",
       "   ['anger'],\n",
       "   ['anger'],\n",
       "   ['anger']]},\n",
       " [['anger', 'disgust', 'fear', 'sadness', 'surprise', 'joy', 'neutral'],\n",
       "  [-0.3689,\n",
       "   0.49683,\n",
       "   -0.14832,\n",
       "   0.14526,\n",
       "   0.23303,\n",
       "   0.015388,\n",
       "   0.30249,\n",
       "   -0.24963,\n",
       "   -0.13232,\n",
       "   -0.2406,\n",
       "   0.55176,\n",
       "   0.11536,\n",
       "   0.60645,\n",
       "   -0.047455,\n",
       "   -0.14014,\n",
       "   0.13684,\n",
       "   -0.051758,\n",
       "   0.0044899,\n",
       "   -0.44019,\n",
       "   -0.23218,\n",
       "   -0.58691,\n",
       "   -0.20618,\n",
       "   0.15076,\n",
       "   0.51758,\n",
       "   -0.10547,\n",
       "   0.25732,\n",
       "   0.65967,\n",
       "   0.068726,\n",
       "   -0.088806,\n",
       "   0.42017,\n",
       "   -0.16577,\n",
       "   -0.16931,\n",
       "   -0.33081,\n",
       "   -0.30444,\n",
       "   0.11432,\n",
       "   -0.020874,\n",
       "   0.30298,\n",
       "   0.53223,\n",
       "   -0.020706,\n",
       "   0.1709,\n",
       "   0.55566]],\n",
       " {'emotions': [['anger', 'surprise'],\n",
       "   ['fear', 'surprise'],\n",
       "   ['fear'],\n",
       "   ['surprise'],\n",
       "   ['anger'],\n",
       "   ['anger', 'surprise'],\n",
       "   ['joy'],\n",
       "   ['joy'],\n",
       "   ['anger', 'surprise']]},\n",
       " [['anger', 'disgust'],\n",
       "  ['anger'],\n",
       "  ['disgust', 'sadness'],\n",
       "  ['anger'],\n",
       "  ['anger', 'surprise'],\n",
       "  ['anger', 'sadness'],\n",
       "  ['anger'],\n",
       "  ['anger'],\n",
       "  ['anger', 'surprise'],\n",
       "  ['anger', 'sadness'],\n",
       "  ['anger'],\n",
       "  ['surprise'],\n",
       "  ['anger'],\n",
       "  ['anger'],\n",
       "  ['anger'],\n",
       "  ['anger', 'surprise'],\n",
       "  ['anger'],\n",
       "  ['anger'],\n",
       "  ['anger', 'disgust'],\n",
       "  ['anger'],\n",
       "  ['anger'],\n",
       "  ['anger', 'surprise'],\n",
       "  ['anger', 'sadness'],\n",
       "  ['anger'],\n",
       "  ['anger'],\n",
       "  ['anger', 'surprise'],\n",
       "  ['anger'],\n",
       "  ['anger'],\n",
       "  ['anger', 'sadness'],\n",
       "  ['anger', 'surprise'],\n",
       "  ['anger'],\n",
       "  ['anger'],\n",
       "  ['anger'],\n",
       "  ['anger', 'surprise'],\n",
       "  ['anger'],\n",
       "  ['anger'],\n",
       "  ['anger', 'surprise'],\n",
       "  ['anger'],\n",
       "  ['anger'],\n",
       "  ['anger', 'surprise'],\n",
       "  ['anger'],\n",
       "  ['anger'],\n",
       "  ['anger', 'surprise'],\n",
       "  ['anger'],\n",
       "  ['anger'],\n",
       "  ['anger', 'surprise'],\n",
       "  ['anger'],\n",
       "  ['anger'],\n",
       "  ['anger', 'surprise'],\n",
       "  ['anger'],\n",
       "  ['anger'],\n",
       "  ['anger', 'surprise'],\n",
       "  ['anger'],\n",
       "  ['anger'],\n",
       "  ['anger', 'surprise'],\n",
       "  ['anger'],\n",
       "  ['anger'],\n",
       "  ['anger'],\n",
       "  ['anger', 'surprise'],\n",
       "  ['anger'],\n",
       "  ['anger'],\n",
       "  ['anger', 'surprise'],\n",
       "  ['anger'],\n",
       "  ['anger'],\n",
       "  ['anger', 'surprise'],\n",
       "  ['anger'],\n",
       "  ['anger'],\n",
       "  ['anger', 'surprise'],\n",
       "  ['anger'],\n",
       "  ['anger'],\n",
       "  ['anger', 'surprise'],\n",
       "  ['anger'],\n",
       "  ['anger'],\n",
       "  ['anger', 'surprise'],\n",
       "  ['anger'],\n",
       "  ['anger'],\n",
       "  ['anger']],\n",
       " [{'emotions': [['anger'], ['anger'], ['anger'], ['anger']]},\n",
       "  {'emotions': [['joy'],\n",
       "    ['joy'],\n",
       "    ['joy'],\n",
       "    ['joy'],\n",
       "    ['joy'],\n",
       "    ['joy'],\n",
       "    ['joy'],\n",
       "    ['joy']]},\n",
       "  {'emotions': [['anger'], ['anger'], ['disgust', 'sadness']]},\n",
       "  [[-0.68213,\n",
       "    0.55518,\n",
       "    -0.11865,\n",
       "    0.13232,\n",
       "    0.28296,\n",
       "    0.075684,\n",
       "    0.053375,\n",
       "    -0.26562,\n",
       "    -0.24194,\n",
       "    -0.30933,\n",
       "    0.52734,\n",
       "    0.13586,\n",
       "    0.32422,\n",
       "    0.17407,\n",
       "    -0.3811,\n",
       "    0.069458,\n",
       "    -0.24084,\n",
       "    -0.19226,\n",
       "    0.16602,\n",
       "    -0.46143,\n",
       "    -0.76025,\n",
       "    -0.4585,\n",
       "    0.5874,\n",
       "    0.9043,\n",
       "    0.0038261,\n",
       "    0.20642,\n",
       "    5.0]]],\n",
       " {'emotions': [['anger', 'disgust'],\n",
       "   ['anger', 'sadness'],\n",
       "   ['anger', 'fear', 'sadness'],\n",
       "   ['fear', 'sadness'],\n",
       "   ['fear', 'sadness']]},\n",
       " {'emotions': [['fear', 'surprise'],\n",
       "   ['fear', 'surprise'],\n",
       "   ['fear', 'surprise'],\n",
       "   ['fear', 'surprise'],\n",
       "   ['anger'],\n",
       "   ['surprise'],\n",
       "   ['anger'],\n",
       "   ['anger', 'surprise'],\n",
       "   ['surprise'],\n",
       "   ['anger'],\n",
       "   ['anger', 'joy']]},\n",
       " [{'anger': [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "   'disgust': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "   'fear': [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "   'sadness': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "   'surprise': [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "   'joy': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "   'neutral': [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]},\n",
       "  [[-0.50537, 0.57373, 0.10699, 0.16284, 1.489]]],\n",
       " [['anger', 'disgust', 'fear', 'sadness', 'surprise', 'joy', 'neutral'],\n",
       "  [[0.5, 0.3, 0.1, -0.2, 0.1, 0.1, -0.1],\n",
       "   [0.4, 0.4, 0.1, -0.2, 0.1, 0.1, -0.1],\n",
       "   [0.3, 0.3, 0.3, -0.2, 0.1, 0.1, -0.1],\n",
       "   [0.2, 0.2, 0.2, -0.2, 0.1, 0.1, -0.1],\n",
       "   [0.1, 0.1, 0.1, -0.2, 0.1, 0.1, -0.1],\n",
       "   [0, 0, 0, -0.2, 0.1, 0.1, -0.1],\n",
       "   [-0.1, -0.1, -0.1, -0.2, 0.1, 0.1, -0.1]],\n",
       "  [-1, -1, -1, -1, -1, -1, -1],\n",
       "  [-6.3721,\n",
       "   6.4014,\n",
       "   -1.2024,\n",
       "   2.4438,\n",
       "   9.0027,\n",
       "   8.1299,\n",
       "   3.3618,\n",
       "   -2.8687,\n",
       "   9.5154,\n",
       "   -3.103,\n",
       "   5.4102,\n",
       "   2.0471,\n",
       "   3.6597,\n",
       "   9.6863,\n",
       "   -2.6245,\n",
       "   1.0962,\n",
       "   8.2886,\n",
       "   6.5]],\n",
       " {'emotions': [['anger', 'disgust', 'fear'],\n",
       "   ['anger', 'fear', 'surprise'],\n",
       "   ['anger'],\n",
       "   ['anger', 'disgust'],\n",
       "   ['fear', 'surprise'],\n",
       "   ['anger', 'disgust', 'fear', 'sadness'],\n",
       "   ['fear', 'surprise'],\n",
       "   ['anger', 'sadness'],\n",
       "   ['fear', 'surprise'],\n",
       "   ['anger']]},\n",
       " {'emotions': [['anger', 'disgust'],\n",
       "   ['joy'],\n",
       "   ['anger', 'disgust'],\n",
       "   ['sadness'],\n",
       "   ['sadness'],\n",
       "   ['sadness']]},\n",
       " [['anger', 'disgust', 'fear', 'sadness', 'surprise', 'joy', 'neutral'],\n",
       "  [-0.66943,\n",
       "   0.82129,\n",
       "   -0.0044136,\n",
       "   0.42261,\n",
       "   0.32959,\n",
       "   -0.30103,\n",
       "   0.17004,\n",
       "   -0.31592,\n",
       "   0.10974,\n",
       "   -0.39648,\n",
       "   0.32788,\n",
       "   -0.067505,\n",
       "   0.75879,\n",
       "   0.2063,\n",
       "   -0.22803,\n",
       "   0.17676,\n",
       "   -0.081787,\n",
       "   0.053833,\n",
       "   0.019104,\n",
       "   '-4.4238e']],\n",
       " [{'emotions': [['anger'], ['anger'], ['disgust', 'sadness']]},\n",
       "  ['anger'],\n",
       "  [-4.7705, 4.8413, -1.0315, 7.373, 3.5205, -2.6172],\n",
       "  ['anger'],\n",
       "  [-4.7705, 4.8413, -1.0315, 7.373, 3.5205, -2.6172],\n",
       "  ['disgust', 'sadness'],\n",
       "  [-4.7705, 4.8413, -1.0315, 7.373, 3.5205, -2.6172],\n",
       "  {'emotions': [['anger'], ['anger'], ['disgust', 'sadness']]},\n",
       "  ['anger'],\n",
       "  [-3.3984, 8.7354, -1.2079, 6.6895, 3.4814, -2.9785],\n",
       "  ['joy'],\n",
       "  [-3.3984, 8.7354, -1.2079, 6.6895, 3.4814, -2.9785],\n",
       "  ['joy'],\n",
       "  [-3.3984, 8.7354, -1.2079, 6.6895, 3.4814, -2.9785],\n",
       "  ['anger'],\n",
       "  [-3.3984, 8.7354, -1.2079, 6.6895, 3.4814, -2.9785],\n",
       "  ['anger'],\n",
       "  [-3.3984, 8.7354, -1.2079, 6.6895, 3.4814, -2.9785],\n",
       "  ['fear'],\n",
       "  [-3.0]],\n",
       " {'emotions': [['anger'], ['anger'], ['anger'], ['anger']]},\n",
       " [[-1], [-1]],\n",
       " [-0.82715,\n",
       "  0.63818,\n",
       "  0.081177,\n",
       "  0.33594,\n",
       "  0.12878,\n",
       "  -0.28735,\n",
       "  0.11023,\n",
       "  -0.32764,\n",
       "  -0.26123,\n",
       "  -0.14551,\n",
       "  0.34863,\n",
       "  0.05249,\n",
       "  0.98438,\n",
       "  0.46826,\n",
       "  -0.29199,\n",
       "  -0.19604,\n",
       "  0.23169,\n",
       "  -0.10901,\n",
       "  0.20288,\n",
       "  -0.55908,\n",
       "  -0.14526,\n",
       "  -0.41846,\n",
       "  0.30908,\n",
       "  0.76074,\n",
       "  -0.095581,\n",
       "  0.12683,\n",
       "  0.47314,\n",
       "  -0.21851,\n",
       "  -0.33862,\n",
       "  0.53564,\n",
       "  -0.29639,\n",
       "  -0.17798,\n",
       "  -0.10352,\n",
       "  -0.52344,\n",
       "  0.39307,\n",
       "  0.39233,\n",
       "  0.16614,\n",
       "  0.2771,\n",
       "  -0.1571,\n",
       "  0.16541,\n",
       "  0.60645,\n",
       "  -0.44482,\n",
       "  -0.16418,\n",
       "  -0.40161,\n",
       "  0.18286,\n",
       "  0.91846],\n",
       " {'emotions': [['anger']]},\n",
       " {'emotions': [['anger', 'surprise'],\n",
       "   ['fear', 'surprise'],\n",
       "   ['neutral'],\n",
       "   ['surprise'],\n",
       "   ['anger', 'sadness']]},\n",
       " {'emotions': [['anger'],\n",
       "   ['anger'],\n",
       "   ['joy'],\n",
       "   ['fear', 'surprise'],\n",
       "   ['anger'],\n",
       "   ['anger'],\n",
       "   ['anger'],\n",
       "   ['anger'],\n",
       "   ['anger'],\n",
       "   ['anger'],\n",
       "   ['fear', 'surprise'],\n",
       "   ['neutral'],\n",
       "   ['anger', 'sadness']]},\n",
       " {'emotions': [['anger'],\n",
       "   ['fear', 'surprise'],\n",
       "   ['sadness', 'surprise'],\n",
       "   ['anger'],\n",
       "   ['anger', 'surprise'],\n",
       "   ['anger'],\n",
       "   ['fear', 'surprise']]},\n",
       " [['anger', 'disgust', 'fear', 'sadness', 'surprise', 'joy', 'neutral'],\n",
       "  [-0.68164,\n",
       "   0.58301,\n",
       "   -0.18591,\n",
       "   0.34839,\n",
       "   0.34912,\n",
       "   -0.20068,\n",
       "   0.21436,\n",
       "   -0.28882,\n",
       "   0.28979,\n",
       "   -0.3418,\n",
       "   0.43945,\n",
       "   0.032745,\n",
       "   0.76807,\n",
       "   0.27612,\n",
       "   -0.51074,\n",
       "   0.025848,\n",
       "   -0.19885,\n",
       "   -0.18225,\n",
       "   0.055756,\n",
       "   -0.41479,\n",
       "   -0.78125,\n",
       "   -0.13733,\n",
       "   0.15881,\n",
       "   0.75,\n",
       "   0.014565,\n",
       "   0.10895,\n",
       "   0.44482,\n",
       "   -0.17322,\n",
       "   -0.14014,\n",
       "   0.37109,\n",
       "   -0.42944,\n",
       "   -0.39331,\n",
       "   -0.22046,\n",
       "   -0.075806,\n",
       "   -0.026672,\n",
       "   0.28345,\n",
       "   0.21899,\n",
       "   0.10272,\n",
       "   -0.10059,\n",
       "   -0.0849,\n",
       "   0.29712]],\n",
       " [['surprise'],\n",
       "  ['fear', 'surprise'],\n",
       "  ['neutral'],\n",
       "  ['surprise'],\n",
       "  ['anger', 'sadness'],\n",
       "  ['anger'],\n",
       "  ['anger'],\n",
       "  ['anger'],\n",
       "  ['anger'],\n",
       "  ['fear'],\n",
       "  ['anger', 'disgust'],\n",
       "  ['anger'],\n",
       "  ['anger'],\n",
       "  ['anger'],\n",
       "  ['anger'],\n",
       "  ['anger'],\n",
       "  ['anger'],\n",
       "  ['anger'],\n",
       "  ['anger'],\n",
       "  ['anger'],\n",
       "  ['anger'],\n",
       "  ['anger'],\n",
       "  ['anger'],\n",
       "  ['anger'],\n",
       "  ['anger'],\n",
       "  ['anger'],\n",
       "  ['anger'],\n",
       "  ['anger'],\n",
       "  ['anger'],\n",
       "  ['anger'],\n",
       "  ['anger'],\n",
       "  ['anger'],\n",
       "  ['anger'],\n",
       "  ['anger'],\n",
       "  ['anger'],\n",
       "  ['anger'],\n",
       "  ['anger'],\n",
       "  ['anger'],\n",
       "  ['anger'],\n",
       "  ['anger'],\n",
       "  ['anger'],\n",
       "  ['anger'],\n",
       "  ['anger'],\n",
       "  ['anger'],\n",
       "  ['anger'],\n",
       "  ['anger'],\n",
       "  ['anger'],\n",
       "  ['anger'],\n",
       "  ['anger'],\n",
       "  ['anger'],\n",
       "  ['anger'],\n",
       "  ['anger'],\n",
       "  ['anger'],\n",
       "  ['anger'],\n",
       "  ['anger'],\n",
       "  ['anger'],\n",
       "  ['anger'],\n",
       "  ['anger'],\n",
       "  ['anger'],\n",
       "  ['anger'],\n",
       "  ['anger'],\n",
       "  ['anger'],\n",
       "  ['anger'],\n",
       "  ['anger'],\n",
       "  ['anger'],\n",
       "  ['anger'],\n",
       "  ['anger'],\n",
       "  ['anger'],\n",
       "  ['anger'],\n",
       "  ['anger'],\n",
       "  ['anger'],\n",
       "  ['anger'],\n",
       "  ['anger'],\n",
       "  ['anger'],\n",
       "  ['anger'],\n",
       "  ['anger'],\n",
       "  ['anger'],\n",
       "  ['anger'],\n",
       "  ['anger'],\n",
       "  ['anger'],\n",
       "  ['anger'],\n",
       "  ['anger'],\n",
       "  ['anger'],\n",
       "  ['anger'],\n",
       "  ['anger'],\n",
       "  ['anger'],\n",
       "  ['anger'],\n",
       "  ['anger'],\n",
       "  ['anger'],\n",
       "  ['anger'],\n",
       "  ['anger'],\n",
       "  ['anger'],\n",
       "  ['anger'],\n",
       "  ['anger'],\n",
       "  ['anger'],\n",
       "  ['anger'],\n",
       "  ['anger'],\n",
       "  ['anger']],\n",
       " {'emotions': [['anger', 'fear', 'surprise']]},\n",
       " {'emotions': [['fear', 'surprise'],\n",
       "   ['fear', 'surprise'],\n",
       "   ['fear'],\n",
       "   ['surprise'],\n",
       "   ['fear'],\n",
       "   ['surprise'],\n",
       "   ['joy'],\n",
       "   ['anger']]},\n",
       " {'emotions': [['neutral']]},\n",
       " {'emotions': [['anger'],\n",
       "   ['anger'],\n",
       "   ['fear'],\n",
       "   ['fear'],\n",
       "   ['fear', 'sadness'],\n",
       "   ['sadness'],\n",
       "   ['anger'],\n",
       "   ['surprise'],\n",
       "   ['surprise'],\n",
       "   ['fear', 'surprise']]},\n",
       " {'emotions': [['anger'],\n",
       "   ['fear', 'surprise'],\n",
       "   ['fear', 'surprise'],\n",
       "   ['fear'],\n",
       "   ['anger', 'fear', 'sadness'],\n",
       "   ['anger', 'fear'],\n",
       "   ['anger', 'fear', 'sadness'],\n",
       "   ['anger', 'disgust', 'fear'],\n",
       "   ['anger', 'sadness']]},\n",
       " [[[-0.41504, 0.66846, -0.38306, 0.0625, 0.57812, 0.21899],\n",
       "   [-0.41504, 0.66846, -0.38306, 0.0625, 0.57812, 0.21899]],\n",
       "  ['anger', 'anger']],\n",
       " {'emotions': [['anger', 'surprise', 'joy'],\n",
       "   ['anger', 'sadness'],\n",
       "   ['anger', 'sadness'],\n",
       "   ['sadness', 'surprise'],\n",
       "   ['anger', 'disgust'],\n",
       "   ['sadness'],\n",
       "   ['sadness'],\n",
       "   ['fear', 'sadness', 'joy'],\n",
       "   ['anger', 'sadness'],\n",
       "   ['surprise', 'joy'],\n",
       "   ['anger', 'disgust'],\n",
       "   ['sadness'],\n",
       "   ['anger', 'disgust', 'sadness'],\n",
       "   ['anger', 'disgust', 'sadness'],\n",
       "   ['anger', 'sadness'],\n",
       "   ['surprise']]},\n",
       " {'emotions': [['anger'],\n",
       "   ['anger', 'surprise'],\n",
       "   ['anger', 'surprise'],\n",
       "   ['sadness', 'joy']]},\n",
       " [[['joy', 'surprise', 'fear', 'sadness', 'neutral'],\n",
       "   [0.5, 0.3, 0.2, 0.1, 0.0],\n",
       "   [0.4, 0.3, 0.2, 0.1, 0.0],\n",
       "   [0.3, 0.4, 0.2, 0.1, 0.0],\n",
       "   [0.2, 0.3, 0.4, 0.1, 0.0],\n",
       "   [0.5, 0.3, 0.2, 0.0, 0.0],\n",
       "   [0.3, 0.4, 0.2, 0.1, 0.0],\n",
       "   [0.2, 0.3, 0.4, 0.1, 0.0],\n",
       "   [0.5, 0.3, 0.2, 0.0, 0.0],\n",
       "   [0.4, 0.3, 0.2, 0.1, 0.0]],\n",
       "  [1,\n",
       "   1,\n",
       "   'data[:, np.newaxis], axis=1)\\n    # Get the top-scoring emotion for each row\\n    top_emotions = np.argmax(scores, axis=1)\\n    # Map the index to the corresponding emotion\\n    emotions_dict = {0:',\n",
       "   'joy',\n",
       "   1,\n",
       "   'surprise',\n",
       "   2,\n",
       "   'fear',\n",
       "   3,\n",
       "   'sadness',\n",
       "   4,\n",
       "   'neutral'],\n",
       "  [['emotions_dict[i']],\n",
       "  [[-0.24939, 0.44287, 0.0177, 0.1178, 0.40088, 0.018951]]],\n",
       " [{'emotions': [['anger'], ['anger'], ['disgust', 'joy'], ['joy']]},\n",
       "  [['anger',\n",
       "    'anticip',\n",
       "    'trust',\n",
       "    'surpris',\n",
       "    'joy',\n",
       "    'fear',\n",
       "    'disgus',\n",
       "    'sadness',\n",
       "    'neutral']],\n",
       "  ['emotion'],\n",
       "  {'accuracy': 0.2,\n",
       "   'kernel': ['rbf', 'linear', 'poly'],\n",
       "   'gamma': [0.1, 0.01, 0.001],\n",
       "   'C': [1, 10, 100]},\n",
       "  {'score': {}}],\n",
       " [{'emotions': [['surprise', 'joy'],\n",
       "    ['surprise', 'joy'],\n",
       "    ['surprise', 'joy'],\n",
       "    ['sadness', 'joy']]},\n",
       "  {'emotions': [['joy'],\n",
       "    ['anger'],\n",
       "    ['sadness', 'surprise'],\n",
       "    ['surprise'],\n",
       "    ['surprise'],\n",
       "    ['surprise'],\n",
       "    ['anger'],\n",
       "    ['fear', 'sadness'],\n",
       "    ['sadness'],\n",
       "    ['anger'],\n",
       "    ['joy'],\n",
       "    ['sadness']]},\n",
       "  {'emotions': [['surprise'],\n",
       "    ['fear', 'sadness', 'surprise'],\n",
       "    ['anger'],\n",
       "    ['fear', 'sadness'],\n",
       "    ['anger'],\n",
       "    ['sadness'],\n",
       "    ['anger', 'surprise'],\n",
       "    ['anger'],\n",
       "    ['joy'],\n",
       "    ['anger'],\n",
       "    ['anger', 'surprise']]},\n",
       "  [-0.41553,\n",
       "   0.57666,\n",
       "   0.19556,\n",
       "   0.024048,\n",
       "   0.30835,\n",
       "   -0.13416,\n",
       "   0.078186,\n",
       "   -0.29688,\n",
       "   0.058044,\n",
       "   -0.21411,\n",
       "   0.74805,\n",
       "   0.025513,\n",
       "   0.66846,\n",
       "   -0.077454,\n",
       "   -0.084229,\n",
       "   0.30688,\n",
       "   -0.32349,\n",
       "   0.0090637,\n",
       "   -0.4668,\n",
       "   0.12311,\n",
       "   -0.44043,\n",
       "   -0.25635,\n",
       "   0.40918,\n",
       "   0.68115,\n",
       "   -0.03096,\n",
       "   0.19189,\n",
       "   0.65723,\n",
       "   0.10535,\n",
       "   0.20227,\n",
       "   0.33472,\n",
       "   -0.048889,\n",
       "   -0.027969,\n",
       "   0.25879,\n",
       "   -0.17029,\n",
       "   0.22937,\n",
       "   0.3916,\n",
       "   0.11115,\n",
       "   0.22913]],\n",
       " {'emotions': [['sadness', 'joy'],\n",
       "   ['anger', 'surprise'],\n",
       "   ['anger', 'surprise'],\n",
       "   ['anger', 'sadness'],\n",
       "   ['sadness'],\n",
       "   ['disgust', 'sadness'],\n",
       "   ['disgust', 'surprise'],\n",
       "   ['sadness', 'surprise'],\n",
       "   ['disgust'],\n",
       "   ['anger', 'disgust']]},\n",
       " [[[-0.18701, 0.55176, -0.054474, 0.052795, 0.30029, 0.0055695],\n",
       "   [-0.30054, 0.95508, -0.14551, -0.10254, 0.53857, 0.12817],\n",
       "   [-0.20044, 0.47656, 0.078003, 0.0019817, 0.27637, -0.35547]],\n",
       "  [['anger'], ['anger'], ['anger', 'sadness']],\n",
       "  ['anger', 'fear', 'surprise', 'sadness', 'joy', 'neutral'],\n",
       "  ['i, j']],\n",
       " {'emotions': [['anger'], ['anger'], ['disgust', 'joy'], ['joy']]},\n",
       " [[[-0.3064,\n",
       "    0.60498,\n",
       "    0.0068855,\n",
       "    0.29834,\n",
       "    0.20264,\n",
       "    -0.15698,\n",
       "    0.1676,\n",
       "    -0.30713,\n",
       "    -0.13245,\n",
       "    -0.20935,\n",
       "    0.25,\n",
       "    0.080017],\n",
       "   [-0.32617,\n",
       "    0.52295,\n",
       "    -0.01017,\n",
       "    0.14319,\n",
       "    0.26587,\n",
       "    -0.11603,\n",
       "    0.26074,\n",
       "    -0.052277,\n",
       "    0.54492,\n",
       "    -0.27515,\n",
       "    0.38989,\n",
       "    0.027634],\n",
       "   [-0.46875,\n",
       "    0.59473,\n",
       "    -0.082642,\n",
       "    0.1792,\n",
       "    0.37646,\n",
       "    -0.17126,\n",
       "    0.50977,\n",
       "    0.1051,\n",
       "    0.012466,\n",
       "    -0.39868,\n",
       "    0.54883,\n",
       "    0.1131]],\n",
       "  [[1, 0, 0, 0, 0, 0], [0, 1, 0, 0, 0, 0], [0]]],\n",
       " ['Input feature array\\n  [-8.1421e-02,  2.2180e-01, -3.9185e-02,  3.7750e-02,  3.2617e-01, -2.4695e-01,\\n   1.0956e-01, -2.4731e-01,  2.2388e-01, -1.2183e-01,  3.9502e-01,  2.7124e-01,\\n   1.1211e+00,  1.2482e-01,  2.7026e-01, -1.3684e-01,  1.2054e-01, -5.3223e-02,\\n  -1.2109e-01, -1.3855e-01, -4.5654e-01, -1.9922e-01,  5.4785e-01,  4.7681e-01,\\n  -2.2583e-01, -1.3550e-01,  4.6338e-01, -1.4160e-01, -3.3203e-02,  2.4329e-01,\\n   1.0902e-02, -1.5564e-01, -9.7427e-03, -4.0161e-01,  1.3135e-01, -2.7283e-02,\\n   5.0385e-02,  2.8613e-01, -1.5503e-01, -1.2832e+00,  2.7783e-01, -1.5356e-01,\\n  -1.8750e-01, -5.5615e-01, -2.5040e-02,  3.5205e-01'],\n",
       " [{'anger': 0,\n",
       "   'disgust': 1,\n",
       "   'fear': 2,\n",
       "   'sadness': 3,\n",
       "   'surprise': 4,\n",
       "   'joy': 5,\n",
       "   'neutral': 6},\n",
       "  [[-0.43677,\n",
       "    0.48584,\n",
       "    -0.14233,\n",
       "    0.14087,\n",
       "    0.47461,\n",
       "    0.1593,\n",
       "    0.19019,\n",
       "    -0.17859,\n",
       "    -0.19189,\n",
       "    -0.2168,\n",
       "    0.71826,\n",
       "    0.20312,\n",
       "    0.7041,\n",
       "    0.00094891,\n",
       "    0.094788,\n",
       "    0.027451,\n",
       "    -0.13452,\n",
       "    0.12238,\n",
       "    -0.20142,\n",
       "    -0.023376,\n",
       "    -0.86914,\n",
       "    -0.13721,\n",
       "    0.56738,\n",
       "    0.4187,\n",
       "    -0.021606,\n",
       "    0.28345,\n",
       "    0.36133,\n",
       "    -0.086914,\n",
       "    -0.061798]]],\n",
       " {'5.4688e-01': 0.51074,\n",
       "  '1.1823e-01': 0.14136,\n",
       "  '3.6865e-01': -0.10223,\n",
       "  '1.2939e-01': -0.35889,\n",
       "  '1.9409e-01': -0.26221,\n",
       "  '4.7729e-01': 0.34888,\n",
       "  '8.4033e-01': 0.33228,\n",
       "  '2.5830e-01': -0.14539,\n",
       "  '2.2668e-01': 0.065674,\n",
       "  '3.7183e-01': 0.22998,\n",
       "  '5.0488e-01': -0.15576,\n",
       "  '5.0195e-01': 0.011337,\n",
       "  '2.4182e-01': -0.14624,\n",
       "  '2.3462e-01': 0.15186,\n",
       "  '1.6467e-01': 0.69482,\n",
       "  '2.7808e-01': -0.17834,\n",
       "  '1.5552e-01': -0.18396,\n",
       "  '1.5430e-01': 0.2959,\n",
       "  '2.7710e-02': 0.32593,\n",
       "  '2.0679e-01': -1.5117,\n",
       "  '6.0205e-01': 0.34229},\n",
       " {'emotions': [['fear']]},\n",
       " [-0.081421,\n",
       "  0.2218,\n",
       "  -0.039185,\n",
       "  0.03775,\n",
       "  0.32617,\n",
       "  -0.24695,\n",
       "  0.10956,\n",
       "  -0.24731,\n",
       "  0.22388,\n",
       "  -0.12183,\n",
       "  0.39502,\n",
       "  0.27124,\n",
       "  1.1211,\n",
       "  'e+00  1.2482e-01  2.7026e-01 -1.3684e-01  1.2054e-01 -5.3223e-02\\n -1.2109e-01 -1.3855e-01 -4.5654e-01 -1.9922e-01  5.4785e-01  4.7681e-01\\n -2.2583e-01 -1.3550e-01  4.6338e-01 -1.4160e-01 -3.3203e-02  2.4329e-01\\n  1.0902e-02 -1.5564e-01 -9.7427e-03 -4.0161e-01  1.3135e-01 -2.7283e-02\\n  5.0385e-02  2.8613e-01 -1.5503e-01 -1.2832e+00  2.7783e-01 -1.5356e-01\\n -1.8750e-01 -5.5615e-01 -2.5040e-02  3.5205e-01 -1.2097e-01  1.8518e-01\\n -3.5693e-01  8.8574e-'],\n",
       " {'emotions': [['anger', 'fear', 'disgust'],\n",
       "   ['fear', 'surprise', 'joy', 'anger'],\n",
       "   ['fear', 'surprise'],\n",
       "   ['anger', 'fear', 'disgust'],\n",
       "   ['anger', 'fear', 'sadness'],\n",
       "   ['anger', 'fear'],\n",
       "   ['anger'],\n",
       "   ['anger', 'joy'],\n",
       "   ['anger', 'joy']]},\n",
       " {'emotions': [['surprise', 'joy'],\n",
       "   ['fear', 'surprise'],\n",
       "   ['fear'],\n",
       "   ['surprise'],\n",
       "   ['surprise'],\n",
       "   ['fear', 'surprise'],\n",
       "   ['joy'],\n",
       "   ['joy'],\n",
       "   ['surprise'],\n",
       "   ['surprise'],\n",
       "   ['sadness']]},\n",
       " [{'emotions': [['anger', 'disgust'],\n",
       "    ['anger', 'disgust'],\n",
       "    ['fear', 'surprise'],\n",
       "    ['surprise', 'joy'],\n",
       "    ['surprise', 'joy'],\n",
       "    ['fear', 'sadness'],\n",
       "    ['joy'],\n",
       "    ['joy'],\n",
       "    ['fear']]},\n",
       "  {'emotions': [['neutral'],\n",
       "    ['joy'],\n",
       "    ['surprise'],\n",
       "    ['anger', 'surprise'],\n",
       "    ['neutral'],\n",
       "    ['surprise'],\n",
       "    ['anger', 'surprise'],\n",
       "    ['anger'],\n",
       "    ['anger', 'sadness', 'surprise']]},\n",
       "  {'emotions': [['anger', 'sadness'],\n",
       "    ['anger', 'sadness'],\n",
       "    ['joy'],\n",
       "    ['surprise', 'joy']]},\n",
       "  {'emotions': [['anger'],\n",
       "    ['surprise'],\n",
       "    ['joy'],\n",
       "    ['fear'],\n",
       "    ['sadness'],\n",
       "    ['surprise'],\n",
       "    ['anger'],\n",
       "    ['neutral'],\n",
       "    ['surprise'],\n",
       "    ['anger'],\n",
       "    ['anger'],\n",
       "    ['anger'],\n",
       "    ['anger'],\n",
       "    ['anger'],\n",
       "    ['anger'],\n",
       "    ['anger'],\n",
       "    ['anger'],\n",
       "    ['anger'],\n",
       "    ['anger'],\n",
       "    ['anger'],\n",
       "    ['anger'],\n",
       "    ['anger'],\n",
       "    ['anger'],\n",
       "    ['anger'],\n",
       "    ['anger'],\n",
       "    ['anger'],\n",
       "    ['anger'],\n",
       "    ['anger'],\n",
       "    ['anger'],\n",
       "    ['anger'],\n",
       "    ['anger'],\n",
       "    ['anger'],\n",
       "    ['anger'],\n",
       "    ['anger'],\n",
       "    ['anger'],\n",
       "    ['anger'],\n",
       "    ['anger'],\n",
       "    ['anger'],\n",
       "    ['anger'],\n",
       "    ['anger'],\n",
       "    ['anger'],\n",
       "    ['anger'],\n",
       "    ['anger'],\n",
       "    ['anger'],\n",
       "    ['anger'],\n",
       "    ['anger'],\n",
       "    ['anger'],\n",
       "    ['anger'],\n",
       "    ['anger'],\n",
       "    ['anger'],\n",
       "    ['anger'],\n",
       "    ['anger'],\n",
       "    ['anger'],\n",
       "    ['anger'],\n",
       "    ['anger'],\n",
       "    ['anger'],\n",
       "    ['anger'],\n",
       "    ['anger'],\n",
       "    ['anger'],\n",
       "    ['anger'],\n",
       "    ['anger'],\n",
       "    ['anger'],\n",
       "    ['anger'],\n",
       "    ['anger'],\n",
       "    ['anger'],\n",
       "    []]}],\n",
       " [-0.31396,\n",
       "  0.24011,\n",
       "  -0.19067,\n",
       "  0.098999,\n",
       "  0.3833,\n",
       "  -0.097839,\n",
       "  0.32104,\n",
       "  -0.12732,\n",
       "  -0.052734,\n",
       "  0.044525,\n",
       "  0.7207,\n",
       "  -0.047089,\n",
       "  0.59521,\n",
       "  -0.36621,\n",
       "  0.271,\n",
       "  0.25537,\n",
       "  0.25708,\n",
       "  -0.20752,\n",
       "  -0.17761,\n",
       "  -0.45605,\n",
       "  -0.30469,\n",
       "  -0.16821,\n",
       "  0.43262,\n",
       "  0.9082,\n",
       "  -0.53174,\n",
       "  0.41479,\n",
       "  0.54053,\n",
       "  -0.13989,\n",
       "  -0.22278,\n",
       "  0.77344,\n",
       "  0.050049,\n",
       "  0.058594,\n",
       "  -0.27588,\n",
       "  -0.14844,\n",
       "  0.099487,\n",
       "  0.44922,\n",
       "  0.33203,\n",
       "  0.245,\n",
       "  -0.03653,\n",
       "  -0.22852,\n",
       "  -0.10931,\n",
       "  -0.32153,\n",
       "  -0.21582,\n",
       "  -0.52686,\n",
       "  0.2915,\n",
       "  0.25488,\n",
       "  0.25415,\n",
       "  0.11572,\n",
       "  -0.56592,\n",
       "  0.12091,\n",
       "  0.39893,\n",
       "  -0.09314,\n",
       "  -4.6906,\n",
       "  'e'],\n",
       " [[[-0.21924, 0.4519, 0.077942, 0.24976, 0.082031, -0.062164],\n",
       "   [-0.094482, -0.04541, -0.15796, -0.27393, 0.18896, 0.84766],\n",
       "   'Additional input features\\n    [-1.7419e-01,  3.9990e-01, -2.4084e-01,  2.5049e-01,  1.6138e-01,  6.3965e-02'],\n",
       "  [-0.59912, 0.4458, -0.12262, 0.2666, -0.1499, 0.063232],\n",
       "  [-0.46387, 0.22766, -0.24829, 0.47485, 0.22559, -0.13489],\n",
       "  [-0.1674, 0.2159, -0.1103, 0.7235, 0.1047, -0.1145],\n",
       "  [-1.4268,\n",
       "   'e+00,  7.5195e-02,  3.2129e-01,  9.5886e-02, -1.4551e-01, -1.6028e-01'],\n",
       "  [-0.13489, -0.00099087]],\n",
       " {'emotions': [['anger', 'disgust', 'fear'],\n",
       "   ['joy', 'surprise'],\n",
       "   ['anger', 'fear'],\n",
       "   ['anger', 'sadness'],\n",
       "   ['fear', 'surprise'],\n",
       "   ['fear'],\n",
       "   ['joy'],\n",
       "   ['anger']]},\n",
       " {'emotions': [['fear', 'surprise'],\n",
       "   ['anger', 'sadness'],\n",
       "   ['anger', 'sadness'],\n",
       "   ['neutral'],\n",
       "   ['anger'],\n",
       "   ['anger', 'fear', 'surprise'],\n",
       "   ['fear', 'joy'],\n",
       "   ['fear', 'joy'],\n",
       "   ['fear', 'joy'],\n",
       "   ['fear']]},\n",
       " [{'emotions': [['anger'], ['anger'], ['disgust', 'sadness']]},\n",
       "  {'emotions': [['anger', 'fear', 'surprise'],\n",
       "    ['anger', 'surprise'],\n",
       "    ['anger', 'surprise'],\n",
       "    ['anger', 'fear'],\n",
       "    ['anger', 'fear', 'sadness']]},\n",
       "  {'emotions': [['surprise'], ['surprise', 'joy']]}],\n",
       " {'emotions': [['anger', 'fear', 'surprise'],\n",
       "   ['anger', 'disgust'],\n",
       "   ['anger', 'disgust', 'joy'],\n",
       "   ['anger', 'fear', 'surprise'],\n",
       "   ['anger'],\n",
       "   ['anger'],\n",
       "   ['anger'],\n",
       "   ['fear', 'surprise'],\n",
       "   ['anger', 'sadness']]},\n",
       " {'emotions': [['anger', 'disgust', 'sadness']]},\n",
       " [-0.51025,\n",
       "  0.52637,\n",
       "  -0.25952,\n",
       "  0.16382,\n",
       "  0.41235,\n",
       "  -0.26978,\n",
       "  0.39087,\n",
       "  -0.31079,\n",
       "  -0.59863,\n",
       "  0.14893,\n",
       "  0.1991,\n",
       "  -0.13232,\n",
       "  0.67725,\n",
       "  0.10608,\n",
       "  -0.14026,\n",
       "  -0.1908,\n",
       "  -0.65771,\n",
       "  0.008316,\n",
       "  0.40161,\n",
       "  0.19385,\n",
       "  -0.16956,\n",
       "  -0.41553,\n",
       "  0.31104,\n",
       "  0.65771,\n",
       "  0.015411,\n",
       "  0.13257,\n",
       "  0.60107,\n",
       "  -0.43286,\n",
       "  -0.13293,\n",
       "  0.19653,\n",
       "  -0.36499,\n",
       "  0.25049,\n",
       "  0.045044,\n",
       "  0.14453,\n",
       "  -0.10669,\n",
       "  0.1875,\n",
       "  0.077759,\n",
       "  0.26416,\n",
       "  -0.19409,\n",
       "  -0.089661,\n",
       "  2],\n",
       " [[-0.47046,\n",
       "   0.31665,\n",
       "   -0.10089,\n",
       "   0.26685,\n",
       "   0.14233,\n",
       "   -0.17456,\n",
       "   0.33911,\n",
       "   -0.018127,\n",
       "   -0.22729,\n",
       "   -0.12134,\n",
       "   0.60693,\n",
       "   0.063904,\n",
       "   0.76416,\n",
       "   0.21887,\n",
       "   0.096558,\n",
       "   -0.047638,\n",
       "   0.035522,\n",
       "   -0.22131,\n",
       "   0.038361,\n",
       "   -0.01049,\n",
       "   -0.3689,\n",
       "   -0.31396,\n",
       "   0.4104,\n",
       "   0.62939,\n",
       "   -0.36938,\n",
       "   0.12915,\n",
       "   0.42114,\n",
       "   -0.063965,\n",
       "   -0.27515,\n",
       "   0.41455,\n",
       "   -0.093628,\n",
       "   -0.29004,\n",
       "   -0.14246,\n",
       "   -0.18579,\n",
       "   -0.049683,\n",
       "   0.13892,\n",
       "   0.14673,\n",
       "   0.45239,\n",
       "   -0.19934,\n",
       "   -0.34546,\n",
       "   0.117,\n",
       "   -0.3208]],\n",
       " [[-0.61426,\n",
       "   0.51514,\n",
       "   -0.10858,\n",
       "   0.35278,\n",
       "   -0.068909,\n",
       "   -0.094055,\n",
       "   0.38794,\n",
       "   -0.2771,\n",
       "   -0.1571,\n",
       "   0.060516,\n",
       "   0.52197,\n",
       "   0.16931,\n",
       "   0.8501,\n",
       "   0.10754,\n",
       "   0.18286,\n",
       "   0.15637,\n",
       "   0.31763,\n",
       "   -0.012207,\n",
       "   -0.0010405,\n",
       "   -0.20227,\n",
       "   -0.11603,\n",
       "   -0.096985,\n",
       "   0.21094,\n",
       "   0.34961,\n",
       "   -0.094849,\n",
       "   0.15515,\n",
       "   0.82812,\n",
       "   -0.0098419,\n",
       "   -0.097107,\n",
       "   0.54736,\n",
       "   -0.21021,\n",
       "   -0.15271,\n",
       "   -0.031738,\n",
       "   -0.17834,\n",
       "   0.26978,\n",
       "   0.31494,\n",
       "   0.12305,\n",
       "   0.28833,\n",
       "   0.017868,\n",
       "   -0.15747,\n",
       "   0.28467,\n",
       "   -0.0035,\n",
       "   -1.873]],\n",
       " {'emotions': [['anger', 'surprise'],\n",
       "   ['fear', 'surprise'],\n",
       "   ['fear', 'surprise'],\n",
       "   ['anger'],\n",
       "   ['anger'],\n",
       "   ['neutral'],\n",
       "   ['surprise'],\n",
       "   ['anger']]},\n",
       " [{'anger': 0,\n",
       "   'disgust': 1,\n",
       "   'fear': 2,\n",
       "   'sadness': 3,\n",
       "   'surprise': 4,\n",
       "   'joy': 5,\n",
       "   'neutral': 6},\n",
       "  [[-0.4917, 0.36719, -0.13953, 0.35986, 0.038635, 0.23425],\n",
       "   [-0.46631, 0.27319, 0.62646, 0.091736, -0.13416, 0.63574],\n",
       "   'add more input features here)'],\n",
       "  [[0.73525, 0.31514, 0.13419, 0.093622, 0.12354, 0.061576, 0.31548],\n",
       "   [0.31414, 0.62154, 0.11354, 0.42167, 0.13259, 0.31535, 0.071432],\n",
       "   'add more weights here)'],\n",
       "  [0.31548, 0.071432, 0.62154],\n",
       "  []],\n",
       " {'emotions': [['anger'],\n",
       "   ['anger', 'fear'],\n",
       "   ['anger', 'fear'],\n",
       "   ['fear', 'surprise'],\n",
       "   ['fear'],\n",
       "   ['anger'],\n",
       "   ['fear'],\n",
       "   ['surprise'],\n",
       "   ['anger', 'surprise']]},\n",
       " {'emotions': [['sadness']]},\n",
       " {'emotions': [['anger'],\n",
       "   ['anger'],\n",
       "   ['anger'],\n",
       "   ['surprise'],\n",
       "   ['anger', 'sadness'],\n",
       "   ['anger'],\n",
       "   ['anger'],\n",
       "   ['anger'],\n",
       "   ['joy']]},\n",
       " {'emotions': [['anger', 'fear'],\n",
       "   ['anger', 'fear'],\n",
       "   ['anger'],\n",
       "   ['anger', 'fear'],\n",
       "   ['anger'],\n",
       "   ['anger'],\n",
       "   ['anger'],\n",
       "   ['anger'],\n",
       "   ['anger', 'sadness'],\n",
       "   ['anger', 'surprise']]},\n",
       " [[-0.7627, 0.24426, -0.052521, 0.37012, -0.012672, 0.12561],\n",
       "  \"rest of the data)\\n])\\n\\n# Define the emotions classes\\nemotions_classes = {\\n    'anger': 0,\\n    'disgust': 1,\\n    'fear': 2,\\n   'sadness': 3,\\n   'surprise': 4,\\n    'joy': 5,\\n    'neutral': 6\\n}\\n\\n# Define the thresholds for each emotion class\\nthresholds = {\\n    'anger': 0.5,\\n    'disgust': 0.5,\\n    'fear': 0.5,\\n   'sadness': 0.5,\\n   'surprise': 0.5,\\n    'joy': 0.5,\\n    'neutral': 0.5\\n}\\n\\n# Classify each input data point\\nclassified_emotions = []\\nfor data_point in input_data:\\n    # Calculate the sentiment score\\n    sentiment_score = np.mean(data_point)\\n    \\n    # Check which emotion class the sentiment score belongs to\\n    classified_emotion = None\\n    for emotion, threshold in thresholds.items():\\n        if sentiment_score > threshold:\\n            classified_emotion = emotion\\n            break\\n    \\n    # If no emotion class was found, assign the 'neutral' class\\n    if classified_emotion is None:\\n        classified_emotion = 'neutral'\\n    \\n    # Append the classified emotion to the list\\n    classified_emotions.append([classified_emotion])\\n\\n# Print the classified emotions\\nprint(\",\n",
       "  'Emotions:',\n",
       "  'for i, emotion in enumerate(classified_emotions):\\n    print(f',\n",
       "  'Data point {i+1}: {emotion[0]}',\n",
       "  'This code will output the classified emotions for each data point in the input data. The output will be in the same format as in the examples you provided.\\n\\nPlease note that this is a simplified example and the actual implementation may require more complex machine'],\n",
       " {'emotions': [['anger'],\n",
       "   ['anger'],\n",
       "   ['anger'],\n",
       "   ['surprise'],\n",
       "   ['anger', 'sadness'],\n",
       "   ['anger'],\n",
       "   ['anger'],\n",
       "   ['anger'],\n",
       "   ['joy']]},\n",
       " {'emotions': [['anger', 'fear'],\n",
       "   ['anger', 'fear'],\n",
       "   ['fear', 'surprise'],\n",
       "   ['fear'],\n",
       "   ['anger'],\n",
       "   ['fear'],\n",
       "   ['surprise'],\n",
       "   ['anger', 'surprise'],\n",
       "   ['anger', 'surprise']]},\n",
       " [{'emotions': [['emotion1', 'emotion2'], ['emotion3']]},\n",
       "  [-0.61963,\n",
       "   0.22095,\n",
       "   -0.57812,\n",
       "   0.31812,\n",
       "   0.30078,\n",
       "   -0.29443,\n",
       "   0.64404,\n",
       "   0.29736,\n",
       "   -0.55615,\n",
       "   0.47827,\n",
       "   0.31299,\n",
       "   0.090881,\n",
       "   0.26245,\n",
       "   -0.37231,\n",
       "   -0.024872,\n",
       "   -0.30957,\n",
       "   -0.63037,\n",
       "   0.1416,\n",
       "   0.079651,\n",
       "   0.064148,\n",
       "   0.60938,\n",
       "   0.037567,\n",
       "   0.28345,\n",
       "   0.60254,\n",
       "   1.0]],\n",
       " [[-0.4751,\n",
       "   0.21667,\n",
       "   -0.31152,\n",
       "   0.3562,\n",
       "   0.075623,\n",
       "   0.053284,\n",
       "   0.62988,\n",
       "   -0.34033,\n",
       "   -0.067627,\n",
       "   -0.045532,\n",
       "   0.38867,\n",
       "   0.10681,\n",
       "   0.46387,\n",
       "   -0.041748,\n",
       "   -0.032074,\n",
       "   0.068909,\n",
       "   -0.035706,\n",
       "   -0.075928,\n",
       "   0.065857,\n",
       "   -0.37988,\n",
       "   -0.18713,\n",
       "   -0.44238,\n",
       "   0.23303,\n",
       "   0.57324,\n",
       "   -0.13794,\n",
       "   0.2229,\n",
       "   0.5249,\n",
       "   -0.057678,\n",
       "   -0.31006,\n",
       "   0.44971,\n",
       "   -0.15784,\n",
       "   0.077271,\n",
       "   -0.15613,\n",
       "   -0.24963,\n",
       "   0.30688,\n",
       "   0.3894,\n",
       "   0.25439,\n",
       "   0.479,\n",
       "   0.030563,\n",
       "   0.15222,\n",
       "   0.025223,\n",
       "   -0.39038,\n",
       "   0.014473,\n",
       "   -0.70898,\n",
       "   0.12262]],\n",
       " [{'emotions': [['anger'],\n",
       "    ['anger', 'surprise'],\n",
       "    ['surprise', 'joy'],\n",
       "    ['anger', 'disgust'],\n",
       "    ['anger', 'sadness'],\n",
       "    ['anger'],\n",
       "    ['anger'],\n",
       "    ['anger'],\n",
       "    ['anger']]},\n",
       "  {'emotions': [['neutral'],\n",
       "    ['fear', 'surprise'],\n",
       "    ['anger', 'sadness'],\n",
       "    ['anger', 'sadness', 'surprise'],\n",
       "    ['neutral'],\n",
       "    ['sadness', 'surprise'],\n",
       "    ['sadness', 'surprise'],\n",
       "    ['fear', 'surprise'],\n",
       "    ['anger'],\n",
       "    ['anger', 'joy']]},\n",
       "  {'emotions': [['anger', 'surprise'],\n",
       "    ['anger', 'sadness', 'surprise'],\n",
       "    ['fear', 'sadness'],\n",
       "    ['anger', 'fear', 'sadness'],\n",
       "    ['surprise'],\n",
       "    ['fear', 'sadness'],\n",
       "    ['anger', 'fear'],\n",
       "    ['anger', 'surprise'],\n",
       "    ['fear'],\n",
       "    ['anger'],\n",
       "    ['anger']]}],\n",
       " {'emotions': [['neutral', 'sadness']]},\n",
       " {'emotions': [['anger'],\n",
       "   ['fear', 'surprise'],\n",
       "   ['sadness', 'surprise'],\n",
       "   ['anger'],\n",
       "   ['anger', 'surprise'],\n",
       "   ['anger'],\n",
       "   ['fear', 'surprise']]},\n",
       " [-0.45215,\n",
       "  0.33154,\n",
       "  -0.070984,\n",
       "  0.28491,\n",
       "  0.074585,\n",
       "  -0.32397,\n",
       "  0.35425,\n",
       "  -0.19202,\n",
       "  -0.43115,\n",
       "  -0.15979,\n",
       "  0.44873,\n",
       "  0.079041,\n",
       "  1.0986,\n",
       "  'e+00  3.0420e-01  1.6748e-01  2.4927e-01  1.4990e-01  8.3399e-04 -4.7516e-02 -4.5850e-01 -4.9438e-01 -3.8354e-01  4.1187e-01  3.0151e-01 -2.6154e-02  3.3618e-01  4.1675e-01 -1.7944e-01 -2.4121e-01  4.2969e-01 -2.0740e-01 -8.7280e-02  7.1335e-03 -2.5513e-01  3.8037e-01  2.4695e-01  4.3579e-01  2.8345e-01  2.4036e-01 -5.4260e-02  5.4565e-02 -2.7295e-01 -2.7563e-01 -1.7993e-01  1.6089e-01  8.3154e-01  3.1909e-01  1.4612e-01 -6.5552e-02  3.0981e-01  3.3813e-01 -1.1981e-01  1.3477e-01 -4.8340e-02  2.8540e-01 -2.5806e-01'],\n",
       " {'emotions': [['sadness', 'surprise']]},\n",
       " {'emotions': [['anger'],\n",
       "   ['neutral'],\n",
       "   ['fear', 'surprise'],\n",
       "   ['fear', 'sadness'],\n",
       "   ['fear', 'sadness'],\n",
       "   ['surprise'],\n",
       "   ['fear', 'sadness'],\n",
       "   ['fear', 'surprise'],\n",
       "   ['anger'],\n",
       "   ['fear']]},\n",
       " [['anger', 'disgust', 'fear', 'sadness', 'surprise', 'joy', 'neutral'],\n",
       "  [[-0.39844,\n",
       "    0.60693,\n",
       "    -0.17627,\n",
       "    0.39282,\n",
       "    0.20093,\n",
       "    -0.11365,\n",
       "    0.50977,\n",
       "    -0.52539,\n",
       "    -0.22729,\n",
       "    -0.017746,\n",
       "    0.50732,\n",
       "    -0.040985,\n",
       "    0.74365,\n",
       "    0.21179,\n",
       "    0.18274,\n",
       "    -0.072083,\n",
       "    0.015312,\n",
       "    0.0039444,\n",
       "    -0.052765,\n",
       "    0.0075645,\n",
       "    0.011009,\n",
       "    -0.23572,\n",
       "    0.4021,\n",
       "    0.39966,\n",
       "    -0.28491,\n",
       "    0.31421,\n",
       "    0.46509,\n",
       "    0.2644,\n",
       "    -0.11023,\n",
       "    0.75928,\n",
       "    -0.1311,\n",
       "    -0.10437,\n",
       "    -0.37744,\n",
       "    -0.043304,\n",
       "    0.23413,\n",
       "    0.2937,\n",
       "    0.33911,\n",
       "    0.21362,\n",
       "    -0.14026,\n",
       "    -0.40234,\n",
       "    5.59]]],\n",
       " [[-0.22998, 0.56982, -0.38501, 0.33154, 0.21875, -0.13684],\n",
       "  [-0.22998, 0.56982, -0.38501, 0.33154, 0.21875, -0.13684],\n",
       "  [-0.22998, 0.56982, -0.38501, 0.33154, 0.21875, -0.13684],\n",
       "  [-0.22998, 0.56982, -0.38501, 0.33154, 0.21875, -0.13684],\n",
       "  [-0.22998, 0.56982, -0.38501, 0.33154, 0.21875, -0.13684]],\n",
       " [-0.36108,\n",
       "  0.61816,\n",
       "  -0.14465,\n",
       "  -0.0046539,\n",
       "  0.09729,\n",
       "  -0.20203,\n",
       "  0.38672,\n",
       "  -0.37915,\n",
       "  0.054688,\n",
       "  -0.28735,\n",
       "  0.36328,\n",
       "  0.035919,\n",
       "  0.43701,\n",
       "  0.11023,\n",
       "  -0.029251,\n",
       "  0.19128,\n",
       "  0.047424,\n",
       "  0.14526,\n",
       "  0.13831,\n",
       "  -0.49219,\n",
       "  -0.87891,\n",
       "  -0.023697,\n",
       "  0.37915,\n",
       "  0.64795,\n",
       "  0.083923,\n",
       "  0.35278,\n",
       "  0.52832,\n",
       "  -0.24622,\n",
       "  -0.14709,\n",
       "  0.2981,\n",
       "  -0.12256,\n",
       "  -0.091858,\n",
       "  -0.13867,\n",
       "  -0.34448,\n",
       "  0.18262,\n",
       "  0.081482,\n",
       "  0.17468,\n",
       "  0.3562,\n",
       "  -0.065796,\n",
       "  -0.12396,\n",
       "  0.27002,\n",
       "  -0.38232,\n",
       "  -0.19666,\n",
       "  -0.177,\n",
       "  0.10168,\n",
       "  1.3047,\n",
       "  'e+00  3.2349e-01  4.8492e-02\\n -4.7754e-01  4.0796e-01  5.6152e-01 -2.1716e-01  3.5458e-03 -1.0260e-01\\n  2.1326e-01 -7.2632e-02  1.672'],\n",
       " {'anger': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0]},\n",
       " ['Input data for example 1\\n    [-4.5361e-01, 5.5371e-01, -2.0825e-01, 4.4434e-01, 8.8989e-02, -4.6387e-02,\\n     3.7280e-01, -1.6577e-01, -2.2192e-01, -2.0981e-02, 1.9727e-01, -1.1108e-01,\\n     8.0225e-01, 6.3965e-02, 1.6205e-02, -2.8183e-02, -2.8076e-01, -1.7407e-01,\\n     2.1472e-01, -4.5850e-01, -4.2419e-02, -3.8110e-01, 4.5898e-01, 6.8262e-01,\\n     8.6304e-02, 2.8516e-01, 5.4639e-01, -2.7515e-01, -1.2891e-01, 5.0146e-01,\\n    -1.6431e-01, 3.0762e-02, -9.3079e-02, -3.1689e-01, 2.0728e-01, 3.9087e-01,\\n     3.6011e-02, 2.4109e-01, 4.0161e-02, 3.4424e-01, 2.0618e-01, -4.2847e-01,\\n    -1.8750e-01, -3.4277e-01,'],\n",
       " '',\n",
       " [[[-0.61426, 0.51514, -0.10858, 0.35278, -0.068909, -0.094055],\n",
       "   [-0.771, 0.45117, -0.12744, 0.20715, 0.22852, -0.36621],\n",
       "   [-0.71484, 0.57764, -0.20752, 0.068787, 0.2793, 0.067261],\n",
       "   [-0.80469, 0.72754, -0.1416, 0.29224, 0.11395, -0.22351]],\n",
       "  ['anger', 'disgust', 'fear', 'sadness', 'surprise', 'joy', 'neutral']],\n",
       " {'emotions': [['anger'],\n",
       "   ['anger', 'fear'],\n",
       "   ['anger', 'fear'],\n",
       "   ['fear', 'surprise'],\n",
       "   ['fear'],\n",
       "   ['anger'],\n",
       "   ['fear'],\n",
       "   ['surprise'],\n",
       "   ['anger', 'surprise']]},\n",
       " {'emotions': [['fear', 'surprise'],\n",
       "   ['anger', 'disgust', 'sadness'],\n",
       "   ['fear', 'surprise'],\n",
       "   ['anger'],\n",
       "   ['neutral'],\n",
       "   ['fear']]},\n",
       " ['anger', 'disgust'],\n",
       " '',\n",
       " {'emotions': [['anger', 'fear'],\n",
       "   ['anger', 'sadness'],\n",
       "   ['anger', 'fear', 'surprise'],\n",
       "   ['anger', 'fear'],\n",
       "   ['anger', 'fear'],\n",
       "   ['anger', 'fear', 'sadness'],\n",
       "   ['anger', 'fear'],\n",
       "   ['anger', 'fear', 'surprise'],\n",
       "   ['anger'],\n",
       "   ['fear']]},\n",
       " [[-0.55615, 0.24658, -0.12708, 0.40503, -0.011009, '-3.0078e-01...'],\n",
       "  {'emotions': ['anger',\n",
       "    'disgust',\n",
       "    'fear',\n",
       "    'joy',\n",
       "    'sadness',\n",
       "    'surprise',\n",
       "    'neutral']},\n",
       "  ['emotion'],\n",
       "  ['emotion'],\n",
       "  [-0.55615, 0.24658, -0.12708, 0.40503, -0.011009, -0.30078],\n",
       "  ['input_expression']],\n",
       " {'emotions': [['anger'], ['anger', 'surprise']]},\n",
       " {'emotions': [['anger', 'fear', 'surprise'],\n",
       "   ['anger', 'disgust', 'fear'],\n",
       "   ['anger', 'fear', 'sadness'],\n",
       "   ['anger', 'surprise'],\n",
       "   ['anger', 'fear', 'sadness'],\n",
       "   ['anger', 'disgust', 'fear'],\n",
       "   ['anger', 'surprise'],\n",
       "   ['anger', 'fear', 'sadness'],\n",
       "   ['anger', 'disgust', 'fear'],\n",
       "   ['anger', 'fear', 'sadness'],\n",
       "   ['anger', 'surprise'],\n",
       "   ['anger', 'fear', 'sadness'],\n",
       "   ['anger', 'disgust', 'fear'],\n",
       "   ['anger', 'fear', 'sadness'],\n",
       "   ['anger', 'surprise'],\n",
       "   ['anger', 'disgust', 'fear'],\n",
       "   ['anger', 'fear', 'sadness'],\n",
       "   ['anger', 'surprise'],\n",
       "   ['anger', 'fear', 'sadness'],\n",
       "   ['anger', 'disgust', 'fear'],\n",
       "   ['anger', 'fear', 'sadness'],\n",
       "   ['anger', 'surprise'],\n",
       "   ['anger', 'fear', 'sadness'],\n",
       "   ['anger', 'disgust', 'fear'],\n",
       "   ['anger', 'fear', 'sadness'],\n",
       "   ['anger', 'surprise'],\n",
       "   ['anger', 'fear', 'sadness'],\n",
       "   ['anger', 'disgust', 'fear'],\n",
       "   ['anger', 'fear', 'sadness'],\n",
       "   ['anger', 'surprise'],\n",
       "   ['anger', 'fear', 'sadness'],\n",
       "   ['anger', 'disgust', 'fear'],\n",
       "   ['anger', 'fear', 'sadness'],\n",
       "   ['anger', 'surprise'],\n",
       "   ['anger', 'fear', 'sadness'],\n",
       "   ['anger', 'disgust', 'fear'],\n",
       "   ['anger', 'fear', 'sadness'],\n",
       "   ['anger', 'surprise'],\n",
       "   ['anger', 'fear', 'sadness'],\n",
       "   ['anger', 'disgust', 'fear'],\n",
       "   ['anger', 'fear', 'sadness'],\n",
       "   ['anger', 'surprise'],\n",
       "   ['anger', 'fear', 'sadness']]},\n",
       " {'emotions': [['anger', 'sadness']]},\n",
       " {'emotions': [['anger'], ['fear', 'surprise']]},\n",
       " {'emotions': [['fear'],\n",
       "   ['sadness'],\n",
       "   ['fear', 'sadness'],\n",
       "   ['fear', 'sadness'],\n",
       "   ['fear', 'sadness'],\n",
       "   ['fear', 'sadness'],\n",
       "   ['sadness'],\n",
       "   ['sadness'],\n",
       "   ['sadness'],\n",
       "   ['sadness'],\n",
       "   ['sadness'],\n",
       "   ['sadness']],\n",
       "  'fear': 'motion',\n",
       "  'are': {'emotions': [['sadness'],\n",
       "    ['sadness', 'fear'],\n",
       "    ['sadness', 'fear'],\n",
       "    ['sadness', 'fear'],\n",
       "    ['sadness', 'fear'],\n",
       "    ['sadness', 'fear'],\n",
       "    ['sadness', 'fear'],\n",
       "    ['sadness', 'fear'],\n",
       "    ['sadness', 'fear'],\n",
       "    ['sadness', 'fear'],\n",
       "    ['sadness', 'fear'],\n",
       "    ['sadness', 'fear']],\n",
       "   'fear': \"nd not'sadness'\",\n",
       "   'is': {'emotions': []}}},\n",
       " [['emotion'],\n",
       "  ['emotion'],\n",
       "  ['anger', 'disgust', 'fear', 'sadness', 'surprise', 'joy', 'neutral'],\n",
       "  [[-6.2939,\n",
       "    5.835,\n",
       "    8.9966,\n",
       "    -1.4722,\n",
       "    5.3131,\n",
       "    -1.7651,\n",
       "    7.5928,\n",
       "    -4.6825,\n",
       "    -3.4253,\n",
       "    -7.2937,\n",
       "    3.9307,\n",
       "    1.918,\n",
       "    5.874,\n",
       "    1.2988,\n",
       "    1.5674,\n",
       "    -2.3877,\n",
       "    -3.1299,\n",
       "    -3.7476,\n",
       "    4.8523,\n",
       "    -5.6519,\n",
       "    -1.0]]],\n",
       " [{'anger': 0,\n",
       "   'disgust': 1,\n",
       "   'fear': 2,\n",
       "   'sadness': 3,\n",
       "   'surprise': 4,\n",
       "   'joy': 5,\n",
       "   'neutral': 6},\n",
       "  [[-0.26636, 0.38696, -0.040161, 0.34863, -0.22192, 0.017685],\n",
       "   [-0.26636, 0.38696, -0.040161, 0.34863, -0.22192, 0.017685],\n",
       "   [-0.26636, 0.38696, -0.040161, 0.34863, -0.22192, 0.017685],\n",
       "   [-0.37744, 0.38721, 0.14905, 0.18359, 0.15503, 0.20984],\n",
       "   'Add more input vectors as needed'],\n",
       "  [\"emotions['anger'\"],\n",
       "  ['anger'],\n",
       "  ['anger'],\n",
       "  ['anger'],\n",
       "  ['anger']],\n",
       " {'accuracy': 0.3,\n",
       "  'f}': 'Define the input for classification\\ninput_vector = np.array([-4.7632e-01,  4.5190e-01, -1.9211e-02,  1.9519e-01, -5.2063e-02, -4.0649e-02,\\n  5.0293e-01, -1.3245e-01, -2.5977e-01, -1.1383e-01,  4.8364e-01, -5.8563e-02,\\n  8.7451e-01,  7.5317e-02,  1.7639e-01,  8.2825e-02,  4.2749e-01, -5.5511e-02,\\n -3.5156e-02, -2.7588e-02, -5.1270e-02, -2.7563e-01,  1.8945e-01,  6.3770e-01,\\n -5.1465e-01,  5.1270e-01,  6.'},\n",
       " [0],\n",
       " [[[-0.5, 0.39844, 0.0041008, 0.21045, -0.16064, 0.16736],\n",
       "   [-0.41187, 0.25879, -0.013153, 0.30859, 0.14124, 0.24084],\n",
       "   [-0.35254, 0.34839, 0.022125, 0.45776, 0.022018, 0.13159],\n",
       "   'Add more input features here'],\n",
       "  [-1],\n",
       "  [-1],\n",
       "  [-1],\n",
       "  [-1],\n",
       "  ['anger', 'disgust']],\n",
       " ['Input data for example 1\\n    [-3.6572e-01,  4.0039e-01, -6.3721e-02,  2.8369e-01, -2.9922e-02, -8.3313e-02,\\n     2.6611e-01,  6.6895e-02,  1.9763e-01, -1.7725e-01,  3.9990e-01, -6.7688e-02,\\n     -8.7952e-02,  2.0920e-02,  1.6418e-01, -1.5308e-01,  3.4521e-01,  7.9224e-02,\\n     -4.7302e-02,  2.7368e-01,  8.9111e-02, -2.4036e-01,  2.6465e-01,  8.7158e-01,\\n     -2.6416e-01,  3.7329e-01,  7.2559e-01,  5.2460e-02,  1.6577e-01,  4.3164e-01,\\n     -3.7744e-01, -3.9551e-01, -2.1286e-02,  1.1035e'],\n",
       " '',\n",
       " [[[-0.33691, 0.35938, -0.012077, 0.21887, 0.15686, -0.089966],\n",
       "   [-0.48169, -0.19568, 0.13159, -0.057556, 0.14124, 0.34961],\n",
       "   'other data points)\\n])\\n\\ny = np.array([\\n    [',\n",
       "   'anger',\n",
       "   'disgust',\n",
       "   'fear',\n",
       "   'sadness',\n",
       "   'surprise',\n",
       "   'joy',\n",
       "   'neutral'],\n",
       "  ['anger', 'disgust', 'fear', 'sadness', 'surprise', 'joy', 'neutral'],\n",
       "  {'accuracy': 0.3,\n",
       "   'f}': 'Define a function to identify applicable emotions from the given classes\\ndef identify_emotions(data_point',\n",
       "   'classes)': 'Make predictions on the data point\\n    prediction = model.predict(np.array([data_point]))\\n    \\n    # Map the predicted numerical value back to the corresponding class label\\n    predicted_class = le.inverse_transform(prediction)[0]\\n    \\n    # Check if the predicted class is in the given classes\\n    if predicted_class in classes'}],\n",
       " [[[-0.59326, 0.23743, 0.015472, 0.30054, -0.17004, -0.24792],\n",
       "   [0.45264, 0.019302, -0.67627, -0.18054, 0.44604, 0.1192],\n",
       "   [0.55664, -0.046204, -0.0070572, -0.071655, 0.47095, 0.22571],\n",
       "   'Add more data here...\\n])\\n\\n# Define the output data\\ny = np.array([\\n    [',\n",
       "   'anger',\n",
       "   'disgust',\n",
       "   'fear',\n",
       "   'sadness',\n",
       "   'surprise',\n",
       "   'joy',\n",
       "   'neutral'],\n",
       "  ['anger', 'disgust', 'fear', 'sadness', 'surprise', 'joy', 'neutral'],\n",
       "  ['anger', 'disgust', 'fear', 'sadness', 'surprise', 'joy', 'neutral'],\n",
       "  ['anger', 'disgust', 'fear', 'sadness', 'surprise', 'joy', 'neutral'],\n",
       "  ['y_encoded']],\n",
       " [[-0.57275,\n",
       "   0.39551,\n",
       "   -0.087158,\n",
       "   0.38696,\n",
       "   -0.072144,\n",
       "   0.062195,\n",
       "   0.34814,\n",
       "   -0.037933,\n",
       "   -0.24866,\n",
       "   0.040405,\n",
       "   0.49414,\n",
       "   0.12646,\n",
       "   0.43213,\n",
       "   -0.12549,\n",
       "   -0.12311,\n",
       "   -0.27197,\n",
       "   0.62012,\n",
       "   0.098938,\n",
       "   -0.14685,\n",
       "   -0.30493,\n",
       "   -0.037628,\n",
       "   -0.27368,\n",
       "   0.17126,\n",
       "   0.65479,\n",
       "   -0.19958,\n",
       "   0.051025,\n",
       "   0.63965,\n",
       "   0.33643,\n",
       "   -0.14124,\n",
       "   0.70996,\n",
       "   -0.49585,\n",
       "   -0.23645,\n",
       "   0.0066414,\n",
       "   -0.065186,\n",
       "   -0.095093,\n",
       "   0.45728,\n",
       "   0.35962,\n",
       "   0.14307,\n",
       "   0.088074,\n",
       "   0.19238,\n",
       "   0.30835,\n",
       "   -0.53076,\n",
       "   0.22192,\n",
       "   -0.26025,\n",
       "   0.10016,\n",
       "   0.79688,\n",
       "   -0.093689,\n",
       "   -0.12891,\n",
       "   -0.097229,\n",
       "   2]],\n",
       " [-0.15027,\n",
       "  0.041565,\n",
       "  0.099365,\n",
       "  0.44849,\n",
       "  0.028458,\n",
       "  0.1731,\n",
       "  0.25024,\n",
       "  0.055176,\n",
       "  -0.024765,\n",
       "  0.16418,\n",
       "  0.52295,\n",
       "  -0.07373,\n",
       "  0.45703,\n",
       "  -0.18274,\n",
       "  0.29736,\n",
       "  -0.23572,\n",
       "  0.21521,\n",
       "  0.10376,\n",
       "  -0.25366,\n",
       "  -0.34644,\n",
       "  -0.036285,\n",
       "  0.13843,\n",
       "  -0.2384,\n",
       "  0.28125,\n",
       "  -0.61865,\n",
       "  0.43701,\n",
       "  0.30029,\n",
       "  -0.070435,\n",
       "  -0.18677,\n",
       "  0.23389,\n",
       "  -0.21851,\n",
       "  0.022308,\n",
       "  0.15857,\n",
       "  -0.34204,\n",
       "  -0.023071,\n",
       "  0.50537,\n",
       "  0.40552,\n",
       "  0.27881,\n",
       "  -0.23865,\n",
       "  0.32422],\n",
       " [['anger', 'disgust', 'fear', 'sadness', 'surprise', 'joy', 'neutral'],\n",
       "  [[-0.46069, 0.34863, 0.13293, 0.271, -0.033997, 0.10187],\n",
       "   [-0.3147, 0.23755, 0.040771, 0.22681, -0.048615, -0.1051],\n",
       "   [-0.43604, 0.34302, 0.11584, 0.11127, -0.071838, 0.092224]],\n",
       "  [['anger', 'sadness'],\n",
       "   ['anger'],\n",
       "   ['anger', 'sadness'],\n",
       "   ['anger', 'sadness']],\n",
       "  ['anger', 'disgust', 'fear', 'sadness', 'surprise', 'joy', 'neutral'],\n",
       "  ['class_label'],\n",
       "  [0],\n",
       "  ['class_label_to_num(label) for label in class_labels.flatten()']],\n",
       " [[-0.63672,\n",
       "   0.47192,\n",
       "   0.14343,\n",
       "   0.41528,\n",
       "   -0.12213,\n",
       "   0.19421,\n",
       "   0.4314,\n",
       "   0.016266,\n",
       "   -0.43774,\n",
       "   -0.13416,\n",
       "   0.50098,\n",
       "   0.14661,\n",
       "   0.56738,\n",
       "   -0.20471,\n",
       "   0.079285,\n",
       "   -0.24731,\n",
       "   0.48633,\n",
       "   -0.0019531,\n",
       "   -0.037872,\n",
       "   -0.38696,\n",
       "   -0.084534,\n",
       "   -0.47314,\n",
       "   0.15027,\n",
       "   0.56543,\n",
       "   -0.34985,\n",
       "   0.32861,\n",
       "   0.4978,\n",
       "   0.14697,\n",
       "   0.12512,\n",
       "   0.60596,\n",
       "   -0.39062,\n",
       "   -0.4751,\n",
       "   0.14392,\n",
       "   -0.17371,\n",
       "   -0.1156,\n",
       "   0.41357,\n",
       "   0.34717,\n",
       "   0.22437,\n",
       "   -0.035461,\n",
       "   0.29077,\n",
       "   0.45532,\n",
       "   -0.28491,\n",
       "   1]],\n",
       " [-0.51416,\n",
       "  0.35181,\n",
       "  0.028717,\n",
       "  0.5459,\n",
       "  0.2179,\n",
       "  -0.32202,\n",
       "  0.44214,\n",
       "  0.062286,\n",
       "  0.0672,\n",
       "  -0.098877,\n",
       "  0.40405,\n",
       "  -0.091675,\n",
       "  0.23218,\n",
       "  -0.15674,\n",
       "  -0.026855,\n",
       "  -0.33032,\n",
       "  -0.25464,\n",
       "  0.12781,\n",
       "  0.032654,\n",
       "  0.04599,\n",
       "  0.029678,\n",
       "  -0.21619,\n",
       "  0.42334,\n",
       "  0.53613,\n",
       "  -0.16992,\n",
       "  0.41675,\n",
       "  0.71289,\n",
       "  0.33911,\n",
       "  0.12634,\n",
       "  0.30078,\n",
       "  -0.33911,\n",
       "  -0.42236,\n",
       "  0.024979,\n",
       "  -0.37207,\n",
       "  0.38501,\n",
       "  0.34082,\n",
       "  0.13892,\n",
       "  0.36597,\n",
       "  -0.14746,\n",
       "  0.15051,\n",
       "  0.32861,\n",
       "  -0.32861,\n",
       "  0.10431,\n",
       "  -0.065979,\n",
       "  0.21143,\n",
       "  0.82959,\n",
       "  -0.12299,\n",
       "  0.063232,\n",
       "  -0.23608,\n",
       "  0.23621,\n",
       "  -0.098816,\n",
       "  0.018021],\n",
       " {'emotions': [['anger', 'fear'],\n",
       "   ['anger'],\n",
       "   ['fear', 'sadness'],\n",
       "   ['surprise'],\n",
       "   ['sadness'],\n",
       "   ['fear', 'sadness'],\n",
       "   ['sadness'],\n",
       "   ['disgust'],\n",
       "   ['anger'],\n",
       "   ['surprise'],\n",
       "   ['joy'],\n",
       "   ['neutral'],\n",
       "   ['fear', 'sadness'],\n",
       "   ['anger', 'sadness'],\n",
       "   ['anger', 'sadness'],\n",
       "   ['anger', 'sadness'],\n",
       "   ['sadness'],\n",
       "   ['sadness'],\n",
       "   ['sadness'],\n",
       "   ['sadness'],\n",
       "   ['sadness'],\n",
       "   ['sadness'],\n",
       "   ['sadness'],\n",
       "   ['sadness'],\n",
       "   ['sadness'],\n",
       "   ['sadness'],\n",
       "   ['sadness'],\n",
       "   ['sadness'],\n",
       "   ['sadness'],\n",
       "   ['sadness'],\n",
       "   ['sadness'],\n",
       "   ['sadness'],\n",
       "   ['sadness'],\n",
       "   ['sadness'],\n",
       "   ['sadness'],\n",
       "   ['sadness'],\n",
       "   ['sadness'],\n",
       "   ['sadness'],\n",
       "   ['sadness'],\n",
       "   ['sadness'],\n",
       "   ['sadness'],\n",
       "   ['sadness'],\n",
       "   ['sadness'],\n",
       "   ['sadness'],\n",
       "   ['sadness'],\n",
       "   ['sadness'],\n",
       "   ['sadness'],\n",
       "   ['sadness'],\n",
       "   ['sadness'],\n",
       "   ['sadness'],\n",
       "   ['sadness'],\n",
       "   ['sadness']]},\n",
       " [['anger', 'disgust', 'fear', 'sadness', 'surprise', 'joy', 'neutral'],\n",
       "  [[-0.22937, 0.43311, 0.08136, 0.14038, 0.093201, 0.016907],\n",
       "   [-0.42773, 0.11792, 0.38135, -0.49585, 0.044403, 0.1897],\n",
       "   'Add more data here\\n])\\n\\ny = np.array([',\n",
       "   'anger',\n",
       "   'disgust',\n",
       "   'fear',\n",
       "   'sadness',\n",
       "   'surprise',\n",
       "   'joy',\n",
       "   'neutral'],\n",
       "  [-0.22937, 0.43311, 0.08136, 0.14038, 0.093201, 0.016907],\n",
       "  ['input_data])\\n\\nprint(',\n",
       "   'Applicable emotions:',\n",
       "   \"prediction)\\n```\\n\\nThis code defines a simple neural network with one hidden layer and trains it on the provided data. It then makes predictions on the test data and evaluates the model's accuracy. Finally,\"]],\n",
       " [[], [], [-0.40308, 0.48608, -0.017838]],\n",
       " [[-0.37744, 0.38721],\n",
       "  ['anger', 'fear'],\n",
       "  [[-0.37744,\n",
       "    0.38721,\n",
       "    0.14905,\n",
       "    0.18359,\n",
       "    0.15503,\n",
       "    0.20984,\n",
       "    0.11426,\n",
       "    -0.104,\n",
       "    -0.30444,\n",
       "    -0.20605,\n",
       "    0.66797,\n",
       "    0.067566,\n",
       "    0.66064,\n",
       "    0.051697,\n",
       "    0.22253,\n",
       "    0.017075,\n",
       "    0.087708,\n",
       "    0.45386,\n",
       "    -0.20557,\n",
       "    -0.15576,\n",
       "    -0.11365,\n",
       "    -0.34473,\n",
       "    -0.064148,\n",
       "    0.31055],\n",
       "   [-0.44873,\n",
       "    0.41724,\n",
       "    0.10803,\n",
       "    0.37109,\n",
       "    0.020721,\n",
       "    0.042145,\n",
       "    0.42236,\n",
       "    0.14185,\n",
       "    -0.23218,\n",
       "    0.013885,\n",
       "    0.43433,\n",
       "    0.098206,\n",
       "    0.91162,\n",
       "    0.0383,\n",
       "    0.085815,\n",
       "    -0.21704,\n",
       "    -0.25293,\n",
       "    4.0]]],\n",
       " [['Emotion Recognition in the Wild (ERW)'],\n",
       "  [[-0.12451,\n",
       "    0.093018,\n",
       "    -0.021683,\n",
       "    0.38525,\n",
       "    -0.036163,\n",
       "    -0.051392,\n",
       "    0.37939,\n",
       "    -0.12219,\n",
       "    0.22485,\n",
       "    -0.076904,\n",
       "    0.6626,\n",
       "    0.041901,\n",
       "    0.4126,\n",
       "    -0.09259,\n",
       "    0.13159,\n",
       "    -0.22632,\n",
       "    -0.074951,\n",
       "    -0.18237,\n",
       "    -0.017029,\n",
       "    -0.023254,\n",
       "    -0.06665,\n",
       "    -0.10474,\n",
       "    0.17993,\n",
       "    0.48242,\n",
       "    -0.54199,\n",
       "    0.51318,\n",
       "    0.62988,\n",
       "    0.22803,\n",
       "    -0.098206,\n",
       "    0.56982,\n",
       "    -0.5415,\n",
       "    -0.4209,\n",
       "    -0.0047455,\n",
       "    -0.1167,\n",
       "    0.036255,\n",
       "    0.19226,\n",
       "    0.55273,\n",
       "    5.0342]]],\n",
       " {'emotions': [['anger'],\n",
       "   ['anger'],\n",
       "   ['anger', 'fear'],\n",
       "   ['joy'],\n",
       "   ['joy'],\n",
       "   ['joy'],\n",
       "   ['joy'],\n",
       "   ['joy'],\n",
       "   ['joy'],\n",
       "   ['surprise', 'joy'],\n",
       "   ['joy'],\n",
       "   ['joy'],\n",
       "   ['sadness'],\n",
       "   ['joy'],\n",
       "   ['joy'],\n",
       "   ['joy'],\n",
       "   ['joy'],\n",
       "   ['joy'],\n",
       "   ['surprise'],\n",
       "   ['joy'],\n",
       "   ['joy'],\n",
       "   ['joy'],\n",
       "   ['joy'],\n",
       "   ['joy'],\n",
       "   ['joy'],\n",
       "   ['joy'],\n",
       "   ['joy'],\n",
       "   ['joy'],\n",
       "   ['joy'],\n",
       "   ['joy'],\n",
       "   ['joy'],\n",
       "   ['joy'],\n",
       "   ['joy'],\n",
       "   ['joy'],\n",
       "   ['joy'],\n",
       "   ['joy'],\n",
       "   ['joy'],\n",
       "   ['joy'],\n",
       "   ['joy'],\n",
       "   ['joy'],\n",
       "   ['joy'],\n",
       "   ['joy'],\n",
       "   ['joy'],\n",
       "   ['joy'],\n",
       "   ['joy'],\n",
       "   ['joy'],\n",
       "   ['joy'],\n",
       "   ['joy'],\n",
       "   ['joy'],\n",
       "   ['joy'],\n",
       "   ['joy'],\n",
       "   ['joy'],\n",
       "   ['joy'],\n",
       "   ['joy'],\n",
       "   ['joy'],\n",
       "   ['joy'],\n",
       "   ['joy'],\n",
       "   ['joy'],\n",
       "   ['joy'],\n",
       "   ['joy'],\n",
       "   ['joy'],\n",
       "   ['joy'],\n",
       "   ['joy'],\n",
       "   ['joy'],\n",
       "   ['joy'],\n",
       "   ['joy'],\n",
       "   ['joy'],\n",
       "   ['joy'],\n",
       "   ['joy'],\n",
       "   ['joy'],\n",
       "   ['joy'],\n",
       "   ['joy'],\n",
       "   ['joy'],\n",
       "   ['joy'],\n",
       "   ['joy'],\n",
       "   ['joy'],\n",
       "   ['joy'],\n",
       "   ['joy'],\n",
       "   ['joy'],\n",
       "   ['joy'],\n",
       "   ['joy'],\n",
       "   ['joy'],\n",
       "   ['joy'],\n",
       "   ['joy'],\n",
       "   ['joy'],\n",
       "   ['joy'],\n",
       "   ['joy'],\n",
       "   ['joy'],\n",
       "   ['joy'],\n",
       "   ['joy'],\n",
       "   ['joy'],\n",
       "   ['joy'],\n",
       "   ['joy'],\n",
       "   ['joy'],\n",
       "   ['joy'],\n",
       "   ['joy'],\n",
       "   ['joy'],\n",
       "   ['joy'],\n",
       "   ['joy'],\n",
       "   ['joy'],\n",
       "   ['joy'],\n",
       "   ['joy'],\n",
       "   ['joy'],\n",
       "   ['joy'],\n",
       "   ['joy'],\n",
       "   ['joy'],\n",
       "   ['joy'],\n",
       "   ['joy'],\n",
       "   ['joy'],\n",
       "   ['joy'],\n",
       "   ['joy'],\n",
       "   ['joy'],\n",
       "   ['joy'],\n",
       "   ['joy'],\n",
       "   ['joy'],\n",
       "   ['joy'],\n",
       "   ['joy'],\n",
       "   ['joy'],\n",
       "   ['joy'],\n",
       "   ['joy'],\n",
       "   ['joy'],\n",
       "   ['joy'],\n",
       "   ['joy'],\n",
       "   ['joy'],\n",
       "   ['joy'],\n",
       "   ['joy'],\n",
       "   ['joy'],\n",
       "   ['joy'],\n",
       "   ['joy'],\n",
       "   ['joy'],\n",
       "   ['joy'],\n",
       "   ['joy'],\n",
       "   ['joy'],\n",
       "   ['joy'],\n",
       "   ['joy'],\n",
       "   ['joy'],\n",
       "   ['joy'],\n",
       "   ['joy'],\n",
       "   ['joy'],\n",
       "   ['joy'],\n",
       "   ['joy'],\n",
       "   ['joy'],\n",
       "   ['joy'],\n",
       "   ['joy'],\n",
       "   ['joy'],\n",
       "   ['joy'],\n",
       "   ['joy'],\n",
       "   ['joy'],\n",
       "   ['joy'],\n",
       "   ['joy'],\n",
       "   ['joy'],\n",
       "   ['joy'],\n",
       "   ['joy'],\n",
       "   ['joy'],\n",
       "   ['joy'],\n",
       "   ['joy'],\n",
       "   ['joy'],\n",
       "   ['joy'],\n",
       "   ['joy'],\n",
       "   ['joy'],\n",
       "   ['joy'],\n",
       "   ['joy'],\n",
       "   ['joy'],\n",
       "   ['joy'],\n",
       "   ['joy'],\n",
       "   ['joy']]},\n",
       " '',\n",
       " '',\n",
       " [-0.35181,\n",
       "  0.56982,\n",
       "  -0.18018,\n",
       "  0.2915,\n",
       "  0.17102,\n",
       "  -0.04245,\n",
       "  0.33984,\n",
       "  -0.13062,\n",
       "  -0.029129,\n",
       "  -0.065979,\n",
       "  0.65137,\n",
       "  0.017029,\n",
       "  0.75439,\n",
       "  0.1554,\n",
       "  -0.33398,\n",
       "  0.11871,\n",
       "  -0.91455,\n",
       "  0.0052452,\n",
       "  -0.19165,\n",
       "  -0.12781,\n",
       "  -0.55469,\n",
       "  -0.18738,\n",
       "  0.21826,\n",
       "  0.70947,\n",
       "  -0.094849,\n",
       "  0.24805,\n",
       "  0.6416],\n",
       " '',\n",
       " {'emotions': [['anger'],\n",
       "   ['fear'],\n",
       "   ['anger', 'disgust'],\n",
       "   ['anger'],\n",
       "   ['anger']]},\n",
       " {'emotions': [['anger'],\n",
       "   ['fear'],\n",
       "   ['anger', 'disgust'],\n",
       "   ['anger'],\n",
       "   ['anger']]},\n",
       " {'emotions': [['anger'],\n",
       "   ['fear'],\n",
       "   ['anger', 'disgust'],\n",
       "   ['anger'],\n",
       "   ['anger']]},\n",
       " {'emotions': [['fear'],\n",
       "   ['surprise'],\n",
       "   ['surprise'],\n",
       "   ['fear', 'surprise'],\n",
       "   ['fear'],\n",
       "   ['anger']]},\n",
       " {'emotions': [['joy']]},\n",
       " {'emotions': [['anger'],\n",
       "   ['anger', 'fear'],\n",
       "   ['anger', 'fear'],\n",
       "   ['fear', 'surprise'],\n",
       "   ['fear'],\n",
       "   ['anger'],\n",
       "   ['fear'],\n",
       "   ['surprise'],\n",
       "   ['anger', 'surprise']]},\n",
       " {'emotions': [['anger', 'disgust'],\n",
       "   ['anger', 'disgust'],\n",
       "   ['fear', 'surprise'],\n",
       "   ['surprise', 'joy'],\n",
       "   ['surprise', 'joy'],\n",
       "   ['fear', 'sadness'],\n",
       "   ['joy'],\n",
       "   ['joy'],\n",
       "   ['fear']]},\n",
       " [[-0.4104, 0.30103, -0.12512, 0.27563, 0.14148, 0.069641],\n",
       "  ['anger', 'disgust', 'fear', 'sadness', 'surprise', 'joy', 'neutral'],\n",
       "  {'anger': 0,\n",
       "   'disgust': 1,\n",
       "   'fear': 2,\n",
       "   'sadness': 3,\n",
       "   'surprise': 4,\n",
       "   'joy': 5,\n",
       "   'neutral': 6},\n",
       "  [],\n",
       "  ['emotion'],\n",
       "  [0],\n",
       "  [0],\n",
       "  ['j'],\n",
       "  ['j'],\n",
       "  ['j'],\n",
       "  ['sadness', 'anger', 'fear', 'surprise', 'joy', 'neutral', 'disgust']],\n",
       " {'emotions': [['anger'],\n",
       "   ['anger'],\n",
       "   ['fear'],\n",
       "   ['surprise'],\n",
       "   ['surprise'],\n",
       "   ['fear', 'sadness'],\n",
       "   ['anger', 'disgust', 'surprise'],\n",
       "   ['anger', 'fear', 'sadness'],\n",
       "   ['anger', 'surprise'],\n",
       "   ['anger', 'disgust', 'fear', 'surprise']]},\n",
       " [['anger', 'disgust', 'fear', 'sadness', 'surprise', 'joy', 'neutral'],\n",
       "  [[-0.67334, 0.45605, -0.1958, 0.51807, 0.099915, -0.1059],\n",
       "   [-0.089233, -0.41895, -0.024841, -0.097839, 0.26782, 0.52441],\n",
       "   'Add more input data here\\n              ]\\n\\nemotions_data = [[',\n",
       "   'anger',\n",
       "   'joy'],\n",
       "  ['joy'],\n",
       "  ['anger', 'fear'],\n",
       "  ['anger', 'sadness'],\n",
       "  ['anger', 'fear'],\n",
       "  ['joy'],\n",
       "  ['anger'],\n",
       "  ['feature_1',\n",
       "   'feature_2',\n",
       "   'feature_3',\n",
       "   'feature_4',\n",
       "   'feature_5',\n",
       "   'feature_6'],\n",
       "  ['emotions'],\n",
       "  ['emotions'],\n",
       "  ['df, emotions_df], axis=1)\\n\\n# Define the features and target variables\\nX = df[[',\n",
       "   'feature_1',\n",
       "   'feature_2',\n",
       "   'feature_3',\n",
       "   'feature_4',\n",
       "   'feature_5',\n",
       "   'feature_6',\n",
       "   'anger',\n",
       "   'disgust',\n",
       "   'fear',\n",
       "   'sadness',\n",
       "   'surprise',\n",
       "   'joy'],\n",
       "  ['emotions']],\n",
       " {'emotions': [['anger', 'disgust', 'sadness'],\n",
       "   ['joy'],\n",
       "   ['anger', 'fear'],\n",
       "   ['anger', 'sadness'],\n",
       "   ['anger', 'fear'],\n",
       "   ['joy'],\n",
       "   ['anger'],\n",
       "   ['anger']]},\n",
       " {'emotions': [['anger', 'disgust', 'sadness'],\n",
       "   ['joy'],\n",
       "   ['anger', 'fear'],\n",
       "   ['anger', 'sadness'],\n",
       "   ['anger', 'fear'],\n",
       "   ['joy'],\n",
       "   ['anger'],\n",
       "   ['anger']]},\n",
       " [[-0.47534,\n",
       "   0.28149,\n",
       "   -0.3374,\n",
       "   0.55762,\n",
       "   0.33911,\n",
       "   -0.26685,\n",
       "   0.58496,\n",
       "   -0.28564,\n",
       "   -0.24573,\n",
       "   0.012085,\n",
       "   0.29858,\n",
       "   -0.086609,\n",
       "   0.50439,\n",
       "   0.33862,\n",
       "   -0.23193,\n",
       "   0.0013781,\n",
       "   -1.0098,\n",
       "   'e+00, -2.5684e-01,\\n    -6.6162e-02, -5.8899e-02, -2.3669e-01, -3.0664e-01,  3.8574e-02,  4.1016e-01,\\n    -1.2097e-01,  2.5122e-01,  5.5127e-01, -1.6220e-02,  3.1372e-02,  2.9150e-01,\\n    -2.0435e-01,  1.3481e-02, -2.9663e-01, -3.1909e-01, -1.9604e-01,  2.2253e-01,\\n     2.0630e-01,  3.5376e-01, -2.4182e-01, -2.0056e-01, -']],\n",
       " {'emotions': [['anger'],\n",
       "   ['anger', 'surprise'],\n",
       "   ['fear', 'surprise'],\n",
       "   ['surprise', 'joy'],\n",
       "   ['surprise', 'joy'],\n",
       "   ['fear', 'sadness'],\n",
       "   ['joy'],\n",
       "   ['joy'],\n",
       "   ['fear']]},\n",
       " [[-0.63818,\n",
       "   0.67188,\n",
       "   -0.23767,\n",
       "   0.14795,\n",
       "   -0.012283,\n",
       "   -0.18604,\n",
       "   0.42236,\n",
       "   -0.10626,\n",
       "   -0.16199,\n",
       "   -0.11993,\n",
       "   0.56592,\n",
       "   0.18945,\n",
       "   0.94385,\n",
       "   -0.099182,\n",
       "   0.069946,\n",
       "   -0.19275,\n",
       "   0.17542,\n",
       "   0.023712,\n",
       "   -0.0048332,\n",
       "   -0.071838],\n",
       "  [-0.45361,\n",
       "   0.55371,\n",
       "   -0.20825,\n",
       "   0.44434,\n",
       "   0.088989,\n",
       "   -0.046387,\n",
       "   0.3728,\n",
       "   -0.16577,\n",
       "   -0.22192,\n",
       "   -0.020981,\n",
       "   0.19727,\n",
       "   -0.11108,\n",
       "   0.80225,\n",
       "   0.063965,\n",
       "   0.016205,\n",
       "   -0.028183,\n",
       "   -0.28076,\n",
       "   -0.17407,\n",
       "   0.21472,\n",
       "   -0.4585],\n",
       "  [-0.43311, '7.1533e']],\n",
       " {'emotions': [['anger', 'fear'],\n",
       "   ['fear'],\n",
       "   ['neutral'],\n",
       "   ['sadness'],\n",
       "   ['joy'],\n",
       "   ['sadness'],\n",
       "   ['sadness'],\n",
       "   ['joy'],\n",
       "   ['joy']]}]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dtype=np.float64\\n)\\n\\narr2 = np.array([\\n    [-6.2891e-01,'"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs_processed[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "grounds = test_df.emotion_c.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"[['surprise', 'joy'], ['joy'], ['surprise', 'joy'], ['joy'], ['joy'], ['joy'], ['surprise'], ['joy'], ['joy'], ['neutral'], ['neutral']]\",\n",
       " \"[['neutral'], ['neutral'], ['anger', 'disgust'], ['anger', 'disgust'], ['neutral'], ['sadness'], ['sadness']]\",\n",
       " \"[['anger', 'sadness'], ['anger', 'sadness'], ['anger', 'sadness'], ['fear', 'surprise'], ['surprise'], ['joy'], ['anger', 'surprise'], ['joy'], ['joy'], ['joy'], ['anger'], ['anger'], ['surprise', 'joy'], ['fear', 'sadness'], ['fear', 'sadness'], ['fear', 'surprise']]\",\n",
       " \"[['anger', 'disgust'], ['anger', 'disgust'], ['anger', 'disgust'], ['fear', 'sadness'], ['fear', 'sadness', 'surprise'], ['sadness'], ['sadness'], ['fear', 'sadness'], ['sadness', 'surprise'], ['sadness', 'surprise'], ['joy'], ['anger'], ['anger'], ['anger'], ['anger', 'disgust'], ['joy'], ['joy'], ['surprise', 'joy'], ['surprise', 'joy'], ['anger', 'surprise'], ['anger', 'surprise']]\",\n",
       " \"[['neutral'], ['joy'], ['joy']]\",\n",
       " \"[['neutral'], ['fear'], ['neutral'], ['anger', 'fear', 'sadness'], ['joy'], ['sadness'], ['fear', 'surprise'], ['anger', 'fear', 'sadness'], ['joy'], ['neutral'], ['fear'], ['joy'], ['neutral'], ['joy'], ['joy'], ['neutral'], ['joy'], ['anger'], ['anger'], ['surprise', 'joy']]\",\n",
       " \"[['anger', 'sadness'], ['anger'], ['sadness'], ['surprise'], ['anger'], ['neutral'], ['joy'], ['joy'], ['joy'], ['anger', 'surprise'], ['anger', 'surprise'], ['anger', 'surprise'], ['joy'], ['joy'], ['joy']]\",\n",
       " \"[['neutral'], ['fear'], ['anger'], ['neutral'], ['fear'], ['anger'], ['anger', 'surprise'], ['anger', 'surprise'], ['anger'], ['anger', 'disgust'], ['anger', 'surprise'], ['anger'], ['anger', 'surprise'], ['anger'], ['anger', 'surprise'], ['neutral']]\",\n",
       " \"[['joy'], ['joy'], ['joy'], ['joy'], ['surprise', 'joy'], ['surprise', 'joy'], ['sadness'], ['sadness'], ['fear', 'surprise'], ['neutral'], ['surprise'], ['fear', 'surprise']]\",\n",
       " \"[['anger'], ['fear', 'surprise'], ['fear'], ['joy'], ['joy'], ['anger'], ['anger'], ['anger'], ['anger', 'disgust'], ['joy'], ['joy']]\",\n",
       " \"[['neutral'], ['anger'], ['anger'], ['anger'], ['neutral'], ['neutral'], ['neutral'], ['fear'], ['fear'], ['neutral'], ['neutral'], ['sadness'], ['sadness'], ['sadness']]\",\n",
       " \"[['joy'], ['joy'], ['joy'], ['joy']]\",\n",
       " \"[['neutral'], ['surprise'], ['anger'], ['anger'], ['anger'], ['anger', 'sadness', 'surprise'], ['surprise'], ['neutral'], ['anger'], ['anger'], ['anger'], ['anger'], ['anger']]\",\n",
       " \"[['surprise'], ['joy'], ['joy'], ['sadness'], ['sadness'], ['surprise'], ['surprise'], ['surprise', 'joy'], ['surprise', 'joy']]\",\n",
       " \"[['neutral'], ['sadness'], ['sadness'], ['neutral'], ['sadness'], ['anger', 'sadness'], ['anger'], ['anger'], ['anger', 'sadness'], ['anger', 'sadness'], ['anger'], ['anger', 'disgust'], ['anger', 'disgust'], ['anger', 'disgust'], ['anger'], ['anger', 'disgust'], ['anger', 'disgust', 'sadness'], ['anger', 'disgust', 'sadness'], ['anger', 'sadness'], ['anger', 'sadness'], ['anger', 'sadness'], ['anger', 'sadness'], ['joy']]\",\n",
       " \"[['sadness', 'surprise'], ['sadness', 'surprise'], ['joy'], ['joy'], ['joy'], ['joy'], ['joy'], ['joy'], ['surprise', 'joy'], ['joy'], ['fear', 'surprise', 'joy'], ['fear', 'surprise', 'joy'], ['fear', 'joy'], ['surprise', 'joy'], ['joy'], ['joy'], ['joy'], ['joy'], ['sadness', 'joy'], ['sadness', 'joy'], ['joy'], ['joy'], ['joy']]\",\n",
       " \"[['neutral'], ['fear', 'surprise'], ['neutral'], ['joy'], ['joy'], ['neutral'], ['joy'], ['fear', 'surprise'], ['fear', 'surprise'], ['fear', 'surprise'], ['fear'], ['disgust'], ['disgust']]\",\n",
       " \"[['neutral'], ['surprise'], ['neutral'], ['anger'], ['anger'], ['sadness'], ['fear'], ['surprise'], ['anger'], ['sadness'], ['joy'], ['joy']]\",\n",
       " \"[['surprise'], ['joy'], ['neutral'], ['joy'], ['fear'], ['fear'], ['joy'], ['joy'], ['joy'], ['joy'], ['joy'], ['joy'], ['anger']]\",\n",
       " \"[['neutral'], ['fear'], ['neutral'], ['fear', 'surprise'], ['fear'], ['fear'], ['anger', 'fear'], ['joy'], ['anger'], ['anger'], ['fear', 'surprise'], ['fear'], ['disgust'], ['fear']]\",\n",
       " \"[['neutral'], ['anger'], ['joy'], ['joy'], ['surprise', 'joy'], ['fear', 'surprise'], ['joy'], ['joy'], ['joy'], ['disgust']]\",\n",
       " \"[['neutral'], ['joy'], ['sadness', 'surprise'], ['neutral'], ['surprise'], ['neutral'], ['anger'], ['neutral'], ['surprise', 'joy'], ['surprise'], ['surprise']]\",\n",
       " \"[['neutral'], ['neutral'], ['surprise'], ['fear', 'surprise'], ['fear'], ['surprise'], ['joy'], ['joy'], ['joy'], ['surprise'], ['surprise']]\",\n",
       " \"[['neutral'], ['anger'], ['neutral'], ['anger'], ['fear', 'surprise'], ['fear', 'surprise'], ['fear'], ['neutral'], ['neutral'], ['anger']]\",\n",
       " \"[['fear', 'surprise'], ['anger', 'fear', 'surprise'], ['anger'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['anger'], ['anger', 'fear'], ['fear', 'surprise'], ['anger'], ['anger'], ['fear']]\",\n",
       " \"[['anger'], ['sadness'], ['fear', 'surprise'], ['fear'], ['fear'], ['fear'], ['fear'], ['fear'], ['fear', 'surprise'], ['fear', 'surprise'], ['neutral'], ['neutral'], ['fear', 'surprise']]\",\n",
       " \"[['neutral'], ['neutral'], ['neutral'], ['joy'], ['joy'], ['joy'], ['joy'], ['joy'], ['joy'], ['joy'], ['sadness', 'surprise'], ['sadness'], ['surprise']]\",\n",
       " \"[['neutral'], ['neutral'], ['surprise'], ['fear', 'surprise'], ['fear', 'surprise'], ['fear', 'surprise'], ['fear', 'surprise'], ['fear', 'surprise'], ['joy'], ['joy'], ['fear'], ['fear'], ['fear'], ['fear'], ['neutral'], ['neutral'], ['neutral']]\",\n",
       " \"[['fear', 'surprise'], ['fear', 'surprise'], ['anger', 'surprise'], ['fear', 'surprise'], ['anger', 'fear', 'joy'], ['anger', 'fear', 'joy']]\",\n",
       " \"[['anger', 'fear', 'surprise'], ['anger', 'fear', 'surprise'], ['anger', 'fear'], ['anger', 'fear']]\",\n",
       " \"[['anger', 'joy'], ['anger', 'fear', 'sadness', 'joy'], ['sadness', 'joy'], ['sadness', 'joy'], ['anger', 'disgust'], ['sadness', 'joy']]\",\n",
       " \"[['fear'], ['fear', 'surprise'], ['fear', 'surprise'], ['fear', 'sadness'], ['fear', 'sadness'], ['surprise'], ['surprise']]\",\n",
       " \"[['surprise'], ['surprise', 'joy'], ['surprise', 'joy'], ['surprise', 'joy'], ['surprise', 'joy'], ['joy'], ['fear', 'surprise'], ['anger', 'fear', 'surprise'], ['anger', 'fear']]\",\n",
       " \"[['anger', 'fear', 'sadness'], ['fear', 'surprise'], ['fear', 'sadness'], ['sadness', 'surprise'], ['anger', 'sadness', 'surprise'], ['fear', 'sadness'], ['anger'], ['joy'], ['surprise', 'joy'], ['surprise', 'joy']]\",\n",
       " \"[['surprise'], ['surprise', 'joy'], ['fear', 'surprise'], ['anger', 'surprise'], ['anger', 'fear', 'sadness'], ['anger', 'disgust', 'surprise'], ['anger', 'joy'], ['anger', 'fear', 'surprise'], ['sadness', 'joy'], ['fear', 'sadness']]\",\n",
       " \"[['anger', 'surprise'], ['surprise', 'joy'], ['surprise', 'joy'], ['anger', 'sadness'], ['anger'], ['anger'], ['fear', 'surprise'], ['joy'], ['joy']]\",\n",
       " \"[['surprise', 'joy'], ['fear', 'sadness', 'surprise'], ['surprise', 'joy'], ['surprise'], ['surprise'], ['surprise'], ['surprise'], ['surprise'], ['fear', 'sadness'], ['sadness'], ['sadness'], ['fear', 'sadness'], ['sadness', 'surprise', 'joy'], ['surprise'], ['sadness', 'surprise'], ['sadness'], ['sadness', 'surprise']]\",\n",
       " \"[['fear', 'surprise'], ['anger', 'fear', 'surprise'], ['surprise'], ['anger', 'surprise'], ['anger', 'surprise']]\",\n",
       " \"[['anger', 'sadness', 'surprise']]\",\n",
       " \"[['fear'], ['anger']]\",\n",
       " \"[['anger', 'surprise'], ['anger', 'disgust'], ['anger', 'disgust'], ['surprise'], ['surprise'], ['anger']]\",\n",
       " \"[['anger', 'fear', 'surprise'], ['fear', 'sadness', 'surprise'], ['anger', 'fear'], ['joy'], ['joy']]\",\n",
       " \"[['anger', 'fear', 'surprise'], ['fear', 'surprise']]\",\n",
       " \"[['anger'], ['joy'], ['anger'], ['anger', 'disgust'], ['anger', 'surprise'], ['anger'], ['anger', 'fear', 'surprise'], ['joy']]\",\n",
       " \"[['joy'], ['anger'], ['disgust', 'surprise'], ['anger'], ['surprise'], ['anger'], ['surprise', 'joy']]\",\n",
       " \"[['fear'], ['fear', 'surprise'], ['fear', 'surprise'], ['fear', 'sadness'], ['fear', 'sadness'], ['fear', 'sadness'], ['fear', 'sadness'], ['fear', 'surprise'], ['fear', 'surprise'], ['surprise'], ['surprise', 'joy'], ['joy'], ['fear', 'surprise']]\",\n",
       " \"[['surprise', 'joy'], ['joy'], ['fear', 'sadness'], ['surprise', 'joy'], ['anger'], ['anger', 'surprise'], ['anger'], ['joy'], ['fear', 'sadness'], ['anger', 'joy'], ['anger', 'joy']]\",\n",
       " \"[['anger', 'surprise'], ['anger', 'surprise'], ['anger', 'joy'], ['anger']]\",\n",
       " \"[['fear', 'sadness'], ['fear', 'sadness']]\",\n",
       " \"[['fear', 'sadness'], ['fear'], ['anger'], ['sadness'], ['joy'], ['surprise'], ['neutral'], ['surprise', 'joy'], ['surprise', 'joy'], ['joy']]\",\n",
       " \"[['joy'], ['joy'], ['joy']]\",\n",
       " \"[['anger'], ['anger', 'sadness'], ['sadness'], ['joy'], ['sadness', 'surprise'], ['anger'], ['anger'], ['joy']]\",\n",
       " \"[['sadness', 'surprise'], ['joy'], ['joy'], ['joy'], ['joy'], ['disgust', 'joy'], ['anger', 'disgust', 'joy'], ['anger'], ['anger'], ['joy'], ['joy']]\",\n",
       " \"[['anger', 'disgust', 'joy'], ['disgust', 'surprise', 'joy'], ['sadness', 'joy']]\",\n",
       " \"[['surprise'], ['fear', 'sadness'], ['joy'], ['joy'], ['joy'], ['anger', 'sadness'], ['sadness']]\",\n",
       " \"[['anger', 'fear'], ['sadness', 'surprise'], ['fear'], ['anger', 'sadness', 'surprise', 'joy'], ['joy'], ['fear'], ['fear'], ['anger', 'joy']]\",\n",
       " \"[['fear'], ['surprise', 'joy'], ['fear', 'sadness'], ['anger'], ['joy'], ['anger', 'fear', 'sadness'], ['anger', 'joy']]\",\n",
       " \"[['joy'], ['joy'], ['joy'], ['joy']]\",\n",
       " \"[['sadness', 'surprise'], ['sadness', 'joy'], ['joy'], ['joy'], ['joy'], ['anger']]\",\n",
       " \"[['joy'], ['anger', 'surprise'], ['joy'], ['joy'], ['anger'], ['joy']]\",\n",
       " \"[['sadness'], ['sadness'], ['sadness'], ['sadness']]\",\n",
       " \"[['sadness', 'surprise'], ['anger', 'sadness'], ['fear'], ['sadness']]\",\n",
       " \"[['sadness'], ['fear', 'sadness'], ['anger', 'sadness'], ['fear', 'sadness'], ['sadness'], ['sadness'], ['sadness']]\",\n",
       " \"[['sadness'], ['surprise', 'joy'], ['joy'], ['joy'], ['anger', 'joy'], ['anger', 'joy'], ['sadness', 'surprise']]\",\n",
       " \"[['anger'], ['anger'], ['anger', 'surprise'], ['anger', 'surprise'], ['surprise'], ['anger', 'surprise'], ['anger']]\",\n",
       " \"[['surprise', 'joy'], ['joy'], ['anger'], ['anger', 'disgust', 'joy'], ['sadness'], ['anger'], ['anger', 'joy'], ['joy']]\",\n",
       " \"[['anger'], ['fear', 'sadness'], ['anger']]\",\n",
       " \"[['anger', 'joy'], ['joy'], ['anger'], ['fear', 'sadness'], ['sadness'], ['sadness', 'surprise'], ['sadness'], ['sadness'], ['sadness']]\",\n",
       " \"[['surprise'], ['anger'], ['sadness'], ['anger', 'sadness']]\",\n",
       " \"[['joy'], ['anger', 'joy'], ['joy'], ['joy'], ['joy'], ['joy']]\",\n",
       " \"[['anger', 'joy'], ['anger', 'disgust', 'sadness']]\",\n",
       " \"[['sadness'], ['fear', 'sadness'], ['sadness'], ['neutral'], ['sadness'], ['sadness'], ['sadness'], ['disgust', 'sadness']]\",\n",
       " \"[['disgust', 'sadness'], ['disgust', 'sadness'], ['sadness'], ['sadness'], ['sadness', 'joy']]\",\n",
       " \"[['anger', 'fear'], ['anger', 'fear'], ['surprise'], ['surprise', 'joy'], ['surprise', 'joy'], ['fear', 'surprise']]\",\n",
       " \"[['fear', 'surprise'], ['neutral']]\",\n",
       " \"[['joy'], ['joy']]\",\n",
       " \"[['neutral'], ['surprise'], ['anger', 'fear'], ['fear'], ['surprise'], ['neutral'], ['surprise', 'joy']]\",\n",
       " \"[['joy'], ['anger', 'surprise'], ['neutral'], ['surprise', 'joy'], ['neutral'], ['anger', 'fear']]\",\n",
       " \"[['joy'], ['anger', 'surprise']]\",\n",
       " \"[['anger'], ['fear', 'surprise'], ['sadness'], ['sadness'], ['joy'], ['joy'], ['surprise', 'joy'], ['joy']]\",\n",
       " \"[['disgust'], ['neutral'], ['neutral'], ['neutral'], ['disgust'], ['sadness'], ['anger', 'sadness'], ['anger']]\",\n",
       " \"[['surprise'], ['surprise'], ['anger'], ['surprise'], ['neutral'], ['joy'], ['surprise'], ['sadness', 'surprise'], ['anger'], ['anger'], ['anger', 'sadness'], ['sadness', 'surprise']]\",\n",
       " \"[['sadness'], ['sadness'], ['anger'], ['anger', 'surprise'], ['neutral'], ['surprise'], ['anger', 'disgust'], ['surprise', 'joy'], ['joy'], ['joy']]\",\n",
       " \"[['anger'], ['anger', 'sadness'], ['anger'], ['anger', 'surprise'], ['anger', 'surprise'], ['anger'], ['anger'], ['sadness'], ['anger', 'surprise']]\",\n",
       " \"[['anger', 'disgust'], ['anger', 'disgust'], ['anger'], ['anger'], ['anger'], ['anger'], ['anger', 'disgust'], ['joy'], ['neutral'], ['anger', 'joy'], ['joy'], ['anger'], ['surprise'], ['anger'], ['anger']]\",\n",
       " \"[['neutral'], ['anger'], ['anger', 'disgust'], ['anger', 'disgust'], ['anger', 'disgust'], ['anger', 'disgust', 'sadness'], ['anger'], ['neutral'], ['joy'], ['anger', 'sadness', 'surprise'], ['surprise'], ['joy'], ['joy']]\",\n",
       " \"[['neutral'], ['fear'], ['surprise'], ['surprise'], ['joy'], ['joy'], ['neutral'], ['sadness', 'surprise'], ['sadness'], ['anger', 'sadness']]\",\n",
       " \"[['neutral'], ['surprise'], ['surprise'], ['neutral'], ['surprise'], ['fear', 'surprise'], ['joy'], ['sadness'], ['sadness'], ['anger'], ['neutral'], ['neutral'], ['joy'], ['surprise'], ['joy']]\",\n",
       " \"[['fear'], ['joy'], ['surprise', 'joy'], ['surprise', 'joy'], ['fear', 'surprise'], ['neutral'], ['anger'], ['anger'], ['joy'], ['anger', 'fear']]\",\n",
       " \"[['surprise']]\",\n",
       " \"[['surprise'], ['anger']]\",\n",
       " \"[['neutral'], ['neutral'], ['joy'], ['anger'], ['anger'], ['anger'], ['anger'], ['fear']]\",\n",
       " \"[['surprise'], ['surprise'], ['surprise'], ['surprise'], ['anger'], ['fear'], ['surprise'], ['surprise']]\",\n",
       " \"[['surprise'], ['joy'], ['joy']]\",\n",
       " \"[['neutral'], ['joy'], ['surprise', 'joy'], ['surprise', 'joy'], ['fear', 'surprise'], ['anger', 'surprise']]\",\n",
       " \"[['anger', 'surprise'], ['fear', 'surprise'], ['fear', 'sadness', 'surprise'], ['joy']]\",\n",
       " \"[['disgust', 'fear', 'sadness']]\",\n",
       " \"[['fear', 'sadness', 'surprise'], ['sadness'], ['anger', 'sadness', 'surprise'], ['sadness'], ['neutral'], ['surprise'], ['neutral'], ['anger'], ['neutral'], ['surprise']]\",\n",
       " \"[['fear'], ['disgust', 'surprise'], ['fear', 'surprise'], ['neutral'], ['surprise'], ['neutral'], ['sadness'], ['fear', 'sadness']]\",\n",
       " \"[['fear'], ['disgust', 'surprise'], ['surprise'], ['disgust', 'sadness'], ['sadness'], ['sadness'], ['sadness'], ['sadness', 'joy'], ['sadness', 'joy'], ['joy'], ['anger'], ['fear', 'surprise'], ['anger']]\",\n",
       " \"[['sadness', 'surprise'], ['fear', 'surprise'], ['fear', 'surprise']]\",\n",
       " \"[['surprise'], ['fear', 'surprise'], ['fear'], ['surprise'], ['surprise'], ['fear', 'surprise'], ['fear', 'surprise']]\",\n",
       " \"[['fear', 'surprise'], ['fear', 'surprise']]\",\n",
       " \"[['sadness', 'surprise'], ['fear', 'sadness', 'surprise'], ['surprise', 'joy'], ['sadness', 'surprise'], ['sadness'], ['sadness'], ['surprise'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['fear'], ['fear', 'sadness']]\",\n",
       " \"[['neutral'], ['neutral'], ['sadness'], ['joy'], ['disgust', 'sadness'], ['anger', 'disgust'], ['joy'], ['joy']]\",\n",
       " \"[['sadness'], ['fear', 'sadness'], ['surprise'], ['fear', 'surprise'], ['joy'], ['joy']]\",\n",
       " \"[['sadness', 'joy'], ['joy'], ['sadness', 'surprise'], ['fear', 'surprise'], ['sadness']]\",\n",
       " \"[['sadness'], ['sadness', 'surprise'], ['anger'], ['fear', 'surprise'], ['fear'], ['fear'], ['fear'], ['fear', 'surprise']]\",\n",
       " \"[['fear', 'sadness'], ['fear', 'sadness'], ['fear', 'sadness'], ['fear', 'sadness', 'surprise'], ['anger', 'fear'], ['anger', 'fear'], ['anger', 'fear', 'sadness']]\",\n",
       " \"[['anger', 'sadness'], ['anger', 'surprise'], ['sadness'], ['fear', 'sadness']]\",\n",
       " \"[['anger', 'disgust'], ['anger'], ['fear', 'surprise'], ['anger'], ['anger'], ['surprise']]\",\n",
       " \"[['surprise']]\",\n",
       " \"[['anger', 'surprise'], ['anger', 'fear', 'surprise'], ['anger'], ['fear', 'surprise'], ['anger', 'fear'], ['anger', 'fear', 'surprise']]\",\n",
       " \"[['anger']]\",\n",
       " \"[['sadness'], ['sadness'], ['sadness']]\",\n",
       " \"[['sadness'], ['sadness'], ['sadness'], ['sadness'], ['sadness'], ['sadness', 'surprise'], ['sadness'], ['sadness'], ['sadness'], ['sadness'], ['sadness'], ['sadness'], ['sadness']]\",\n",
       " \"[['anger', 'sadness'], ['anger', 'sadness'], ['anger', 'sadness'], ['sadness'], ['sadness'], ['sadness'], ['sadness'], ['sadness'], ['sadness']]\",\n",
       " \"[['sadness'], ['sadness'], ['surprise'], ['sadness'], ['fear', 'sadness'], ['sadness'], ['anger', 'fear', 'sadness', 'surprise'], ['anger', 'fear', 'sadness'], ['sadness']]\",\n",
       " \"[['sadness'], ['fear', 'sadness', 'surprise'], ['fear', 'sadness', 'surprise'], ['anger', 'surprise'], ['sadness'], ['sadness'], ['sadness'], ['anger', 'sadness'], ['sadness', 'surprise'], ['sadness'], ['anger', 'sadness'], ['anger', 'sadness']]\",\n",
       " \"[['joy'], ['joy'], ['fear', 'joy'], ['neutral'], ['fear', 'surprise'], ['neutral'], ['fear'], ['fear'], ['fear', 'sadness'], ['fear', 'sadness'], ['fear', 'sadness', 'surprise'], ['surprise'], ['anger']]\",\n",
       " \"[['anger'], ['anger'], ['fear'], ['anger'], ['fear', 'surprise'], ['neutral'], ['fear', 'surprise'], ['neutral'], ['fear'], ['fear'], ['neutral'], ['anger', 'fear', 'sadness'], ['anger', 'fear', 'sadness'], ['neutral'], ['fear', 'sadness'], ['fear', 'sadness'], ['neutral']]\",\n",
       " \"[['fear', 'sadness'], ['fear', 'sadness'], ['fear', 'sadness'], ['sadness'], ['neutral'], ['sadness'], ['neutral'], ['fear', 'sadness'], ['fear', 'sadness'], ['fear', 'sadness'], ['fear', 'sadness'], ['neutral'], ['surprise'], ['neutral'], ['fear', 'sadness'], ['fear', 'sadness'], ['neutral'], ['fear'], ['neutral']]\",\n",
       " \"[['fear', 'surprise'], ['fear'], ['fear', 'sadness'], ['fear', 'sadness'], ['fear', 'sadness'], ['anger'], ['surprise'], ['sadness'], ['sadness', 'surprise'], ['sadness', 'surprise'], ['anger'], ['anger', 'surprise'], ['anger']]\",\n",
       " \"[['surprise'], ['sadness'], ['fear', 'sadness'], ['sadness'], ['sadness'], ['fear', 'sadness', 'surprise'], ['sadness', 'surprise'], ['fear', 'sadness'], ['anger', 'sadness'], ['surprise'], ['anger', 'sadness']]\",\n",
       " \"[['surprise', 'joy'], ['fear', 'sadness'], ['sadness', 'joy'], ['sadness', 'joy'], ['surprise'], ['fear'], ['fear', 'sadness'], ['fear', 'sadness'], ['fear', 'sadness'], ['fear', 'surprise'], ['fear'], ['fear'], ['joy'], ['joy']]\",\n",
       " \"[['anger', 'fear'], ['anger', 'fear'], ['anger'], ['anger'], ['surprise'], ['fear', 'sadness', 'surprise'], ['fear', 'sadness', 'surprise'], ['sadness'], ['sadness'], ['fear', 'surprise']]\",\n",
       " \"[['fear', 'surprise'], ['fear', 'surprise'], ['anger', 'sadness'], ['anger', 'sadness'], ['anger', 'sadness'], ['anger', 'sadness'], ['anger', 'sadness'], ['surprise'], ['fear', 'sadness', 'surprise'], ['fear', 'sadness', 'surprise'], ['anger', 'sadness', 'surprise'], ['anger', 'sadness'], ['anger', 'surprise']]\",\n",
       " \"[['anger', 'sadness'], ['anger', 'sadness'], ['anger', 'sadness'], ['anger', 'sadness'], ['anger', 'sadness'], ['anger', 'sadness'], ['anger', 'sadness'], ['anger'], ['surprise'], ['anger', 'fear'], ['anger', 'fear'], ['anger', 'fear']]\",\n",
       " \"[['anger'], ['anger'], ['anger'], ['anger'], ['anger'], ['anger'], ['anger', 'joy']]\",\n",
       " \"[['surprise'], ['sadness'], ['fear', 'sadness'], ['fear', 'sadness'], ['anger', 'fear', 'sadness'], ['anger', 'fear', 'sadness'], ['anger'], ['anger'], ['fear', 'sadness'], ['fear', 'sadness'], ['fear', 'surprise'], ['sadness']]\",\n",
       " \"[['fear', 'sadness'], ['surprise'], ['surprise', 'joy'], ['sadness'], ['sadness'], ['sadness'], ['surprise', 'joy']]\",\n",
       " \"[['sadness'], ['sadness'], ['joy'], ['joy'], ['sadness', 'surprise'], ['sadness', 'joy'], ['sadness', 'joy'], ['sadness', 'joy']]\",\n",
       " \"[['joy'], ['joy'], ['joy'], ['joy'], ['anger'], ['joy'], ['anger'], ['fear', 'sadness', 'joy'], ['fear', 'sadness', 'joy'], ['anger'], ['anger']]\",\n",
       " \"[['anger', 'sadness'], ['anger', 'sadness'], ['anger', 'sadness'], ['neutral'], ['surprise'], ['sadness'], ['fear', 'sadness', 'surprise'], ['sadness']]\",\n",
       " \"[['joy'], ['fear', 'sadness'], ['sadness', 'surprise'], ['fear', 'sadness'], ['fear', 'sadness'], ['joy'], ['anger', 'fear'], ['fear'], ['fear', 'sadness']]\",\n",
       " \"[['fear'], ['fear'], ['anger']]\",\n",
       " \"[['fear', 'surprise'], ['fear']]\",\n",
       " \"[['fear'], ['fear', 'surprise'], ['fear', 'surprise'], ['anger', 'surprise'], ['anger'], ['anger', 'surprise']]\",\n",
       " \"[['anger'], ['anger'], ['anger', 'fear'], ['surprise', 'joy'], ['fear', 'surprise'], ['anger'], ['anger', 'fear']]\",\n",
       " \"[['fear', 'surprise'], ['fear', 'surprise'], ['fear', 'sadness'], ['fear', 'sadness'], ['surprise'], ['anger']]\",\n",
       " \"[['anger'], ['anger'], ['anger'], ['anger'], ['anger'], ['fear', 'surprise']]\",\n",
       " \"[['anger'], ['anger', 'fear'], ['anger', 'fear', 'surprise'], ['anger'], ['surprise'], ['anger']]\",\n",
       " \"[['fear', 'sadness'], ['anger', 'surprise'], ['anger'], ['anger'], ['anger']]\",\n",
       " \"[['anger', 'fear'], ['anger', 'fear'], ['anger', 'fear'], ['anger', 'fear', 'surprise'], ['anger'], ['anger']]\",\n",
       " \"[['anger'], ['anger'], ['anger', 'sadness', 'surprise'], ['anger', 'surprise']]\",\n",
       " \"[['anger'], ['anger'], ['fear', 'sadness'], ['fear', 'sadness'], ['anger'], ['fear', 'sadness'], ['anger', 'sadness'], ['anger'], ['anger'], ['anger', 'joy'], ['anger', 'joy'], ['anger', 'joy']]\",\n",
       " \"[['fear', 'joy'], ['fear', 'joy'], ['anger'], ['anger'], ['anger', 'surprise'], ['anger', 'sadness'], ['anger', 'sadness'], ['anger', 'sadness'], ['anger']]\",\n",
       " \"[['anger'], ['anger'], ['anger'], ['anger'], ['anger'], ['anger']]\",\n",
       " \"[['anger', 'surprise'], ['anger', 'surprise'], ['fear', 'sadness'], ['surprise'], ['surprise', 'joy'], ['anger'], ['anger'], ['anger'], ['anger'], ['anger'], ['anger'], ['anger'], ['anger'], ['anger'], ['fear', 'sadness'], ['anger']]\",\n",
       " \"[['anger', 'surprise'], ['anger'], ['anger'], ['anger'], ['anger'], ['anger'], ['anger', 'surprise'], ['anger', 'surprise'], ['anger'], ['anger'], ['anger']]\",\n",
       " \"[['anger'], ['anger'], ['anger', 'surprise'], ['anger', 'surprise'], ['anger'], ['anger'], ['anger'], ['anger'], ['anger'], ['anger'], ['anger', 'surprise']]\",\n",
       " \"[['anger'], ['anger'], ['anger'], ['anger'], ['anger', 'surprise'], ['anger'], ['anger'], ['anger'], ['anger'], ['anger'], ['anger'], ['anger'], ['anger'], ['anger']]\",\n",
       " \"[['sadness', 'surprise'], ['anger'], ['anger'], ['anger'], ['anger'], ['anger'], ['anger', 'joy']]\",\n",
       " \"[['anger', 'sadness'], ['anger'], ['anger'], ['anger'], ['anger', 'sadness'], ['anger'], ['anger'], ['anger'], ['anger'], ['anger'], ['anger']]\",\n",
       " \"[['anger'], ['joy'], ['joy'], ['anger', 'surprise'], ['anger'], ['anger'], ['anger', 'surprise'], ['anger'], ['joy'], ['joy'], ['joy'], ['joy']]\",\n",
       " \"[['anger', 'joy']]\"]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "7\n",
      "9\n",
      "12\n",
      "14\n",
      "15\n",
      "18\n",
      "19\n",
      "21\n",
      "23\n",
      "24\n",
      "25\n",
      "27\n",
      "29\n",
      "30\n",
      "33\n",
      "34\n",
      "37\n",
      "38\n",
      "40\n",
      "41\n",
      "46\n",
      "47\n",
      "53\n",
      "56\n",
      "57\n",
      "58\n",
      "60\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "67\n",
      "70\n",
      "71\n",
      "72\n",
      "75\n",
      "78\n",
      "79\n",
      "80\n",
      "82\n",
      "87\n",
      "90\n",
      "91\n",
      "92\n",
      "95\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "107\n",
      "108\n",
      "110\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "147\n",
      "149\n",
      "152\n",
      "154\n"
     ]
    }
   ],
   "source": [
    "predictions = []\n",
    "bad_idx = []\n",
    "\n",
    "for i, obj in enumerate(outputs_processed):\n",
    "    try:\n",
    "        predictions.append(obj['emotions'])\n",
    "    except:\n",
    "        print(i)\n",
    "        bad_idx.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "grounds = [label for i, label in enumerate(grounds) if i not in bad_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70, 70)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(grounds), len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "grounds_l = [ast.literal_eval(item) for item in grounds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['anger', 'sadness'],\n",
       "  ['anger', 'disgust'],\n",
       "  ['anger', 'fear', 'surprise'],\n",
       "  ['sadness'],\n",
       "  ['fear', 'sadness', 'surprise'],\n",
       "  ['surprise'],\n",
       "  ['sadness'],\n",
       "  ['fear', 'sadness']],\n",
       " [['anger', 'fear'],\n",
       "  ['joy'],\n",
       "  ['fear', 'surprise'],\n",
       "  ['joy'],\n",
       "  ['surprise', 'joy'],\n",
       "  ['surprise'],\n",
       "  ['joy'],\n",
       "  ['joy'],\n",
       "  ['anger', 'disgust'],\n",
       "  ['anger', 'disgust']],\n",
       " [['neutral'],\n",
       "  ['joy'],\n",
       "  ['surprise'],\n",
       "  ['anger', 'surprise'],\n",
       "  ['neutral'],\n",
       "  ['surprise'],\n",
       "  ['anger', 'surprise'],\n",
       "  ['anger'],\n",
       "  ['anger', 'sadness', 'surprise']],\n",
       " [['anger', 'fear', 'sadness'], ['neutral'], ['neutral'], ['neutral']],\n",
       " [['anger'],\n",
       "  ['joy'],\n",
       "  ['anger', 'disgust'],\n",
       "  ['sadness'],\n",
       "  ['sadness'],\n",
       "  ['sadness']],\n",
       " [['anger', 'sadness'],\n",
       "  ['anger', 'sadness', 'surprise'],\n",
       "  ['fear', 'sadness', 'surprise'],\n",
       "  ['fear', 'sadness', 'surprise'],\n",
       "  ['sadness'],\n",
       "  ['sadness'],\n",
       "  ['anger'],\n",
       "  ['anger', 'sadness'],\n",
       "  ['anger', 'sadness', 'surprise'],\n",
       "  ['anger', 'sadness', 'surprise'],\n",
       "  ['anger', 'sadness'],\n",
       "  ['sadness'],\n",
       "  ['anger', 'sadness'],\n",
       "  ['anger'],\n",
       "  ['fear', 'sadness'],\n",
       "  ['sadness'],\n",
       "  ['fear', 'sadness', 'surprise'],\n",
       "  ['sadness'],\n",
       "  ['anger', 'sadness'],\n",
       "  ['anger', 'sadness'],\n",
       "  ['anger', 'sadness', 'surprise'],\n",
       "  ['anger', 'sadness', 'surprise'],\n",
       "  ['sadness'],\n",
       "  ['anger', 'sadness', 'surprise'],\n",
       "  ['anger', 'sadness', 'surprise'],\n",
       "  ['anger', 'sadness', 'surprise'],\n",
       "  ['anger', 'sadness', 'surprise'],\n",
       "  ['anger', 'sadness', 'surprise'],\n",
       "  ['anger', 'sadness', 'surprise'],\n",
       "  ['anger', 'sadness', 'surprise'],\n",
       "  ['anger']],\n",
       " [['anger', 'fear'],\n",
       "  ['joy'],\n",
       "  ['anger', 'disgust'],\n",
       "  ['anger', 'fear', 'sadness'],\n",
       "  ['anger', 'fear', 'surprise'],\n",
       "  ['anger', 'fear', 'surprise'],\n",
       "  ['anger', 'fear'],\n",
       "  ['anger', 'disgust'],\n",
       "  ['anger', 'surprise'],\n",
       "  ['anger', 'fear', 'surprise']],\n",
       " [['anger'],\n",
       "  ['anger', 'sadness'],\n",
       "  ['anger'],\n",
       "  ['sadness'],\n",
       "  ['sadness'],\n",
       "  ['sadness'],\n",
       "  ['anger', 'disgust'],\n",
       "  ['joy'],\n",
       "  ['anger', 'disgust'],\n",
       "  ['sadness'],\n",
       "  ['sadness'],\n",
       "  ['sadness'],\n",
       "  ['anger', 'disgust'],\n",
       "  ['sadness'],\n",
       "  ['sadness'],\n",
       "  ['sadness'],\n",
       "  ['anger', 'disgust'],\n",
       "  ['joy'],\n",
       "  ['anger', 'disgust'],\n",
       "  ['sadness'],\n",
       "  ['sadness'],\n",
       "  ['sadness'],\n",
       "  ['anger', 'disgust'],\n",
       "  ['sadness'],\n",
       "  ['sadness'],\n",
       "  ['sadness'],\n",
       "  ['anger', 'disgust'],\n",
       "  ['joy'],\n",
       "  ['anger', 'disgust'],\n",
       "  ['sadness'],\n",
       "  ['sadness'],\n",
       "  ['sadness'],\n",
       "  ['anger', 'disgust'],\n",
       "  ['sadness'],\n",
       "  ['sadness'],\n",
       "  ['sadness'],\n",
       "  ['anger', 'disgust'],\n",
       "  ['joy'],\n",
       "  ['anger', 'disgust'],\n",
       "  ['sadness'],\n",
       "  ['sadness'],\n",
       "  ['sadness'],\n",
       "  ['anger', 'disgust'],\n",
       "  ['sadness'],\n",
       "  ['sadness'],\n",
       "  ['sadness'],\n",
       "  ['anger', 'disgust'],\n",
       "  ['sadness'],\n",
       "  ['sadness'],\n",
       "  ['sadness'],\n",
       "  ['anger', 'disgust'],\n",
       "  ['joy'],\n",
       "  ['anger', 'disgust'],\n",
       "  ['sadness'],\n",
       "  ['sadness'],\n",
       "  ['sadness'],\n",
       "  ['anger', 'disgust'],\n",
       "  ['sadness'],\n",
       "  ['sadness'],\n",
       "  ['sadness'],\n",
       "  ['anger', 'disgust'],\n",
       "  ['joy'],\n",
       "  ['anger', 'disgust'],\n",
       "  ['sadness'],\n",
       "  ['sadness'],\n",
       "  ['sadness'],\n",
       "  ['anger', 'disgust'],\n",
       "  ['sadness'],\n",
       "  ['sadness'],\n",
       "  ['sadness'],\n",
       "  ['anger', 'disgust'],\n",
       "  ['sadness'],\n",
       "  ['sadness'],\n",
       "  ['sadness'],\n",
       "  ['anger', 'disgust'],\n",
       "  ['sadness'],\n",
       "  ['sadness'],\n",
       "  ['sadness'],\n",
       "  ['anger', 'disgust'],\n",
       "  ['sadness'],\n",
       "  ['sadness'],\n",
       "  ['sadness'],\n",
       "  ['anger', 'disgust'],\n",
       "  ['sadness'],\n",
       "  ['sadness'],\n",
       "  ['sadness'],\n",
       "  ['anger', 'disgust'],\n",
       "  ['sadness'],\n",
       "  ['sadness'],\n",
       "  ['sadness'],\n",
       "  ['anger', 'disgust'],\n",
       "  ['joy'],\n",
       "  ['anger', 'disgust'],\n",
       "  ['sadness'],\n",
       "  ['sadness'],\n",
       "  ['sadness'],\n",
       "  ['anger', 'disgust'],\n",
       "  ['sadness'],\n",
       "  ['sadness']],\n",
       " [['anger'],\n",
       "  ['fear'],\n",
       "  ['anger', 'disgust'],\n",
       "  ['anger'],\n",
       "  ['anger'],\n",
       "  ['anger', 'fear'],\n",
       "  ['anger', 'sadness']],\n",
       " [['fear', 'surprise'],\n",
       "  ['fear', 'surprise'],\n",
       "  ['sadness'],\n",
       "  ['fear', 'sadness'],\n",
       "  ['fear'],\n",
       "  ['fear', 'surprise'],\n",
       "  ['fear', 'surprise'],\n",
       "  ['fear'],\n",
       "  ['surprise'],\n",
       "  ['fear', 'surprise'],\n",
       "  ['fear', 'surprise'],\n",
       "  ['surprise'],\n",
       "  ['surprise'],\n",
       "  ['anger', 'sadness'],\n",
       "  ['anger', 'disgust'],\n",
       "  ['anger'],\n",
       "  ['anger']],\n",
       " [['anger'],\n",
       "  ['anger'],\n",
       "  ['anger'],\n",
       "  ['surprise'],\n",
       "  ['anger', 'sadness'],\n",
       "  ['anger'],\n",
       "  ['anger'],\n",
       "  ['anger'],\n",
       "  ['anger'],\n",
       "  ['anger']],\n",
       " [['anger', 'surprise'],\n",
       "  ['fear', 'surprise'],\n",
       "  ['fear'],\n",
       "  ['surprise'],\n",
       "  ['anger'],\n",
       "  ['anger', 'surprise'],\n",
       "  ['joy'],\n",
       "  ['joy'],\n",
       "  ['anger', 'surprise']],\n",
       " [['anger', 'disgust'],\n",
       "  ['anger', 'sadness'],\n",
       "  ['anger', 'fear', 'sadness'],\n",
       "  ['fear', 'sadness'],\n",
       "  ['fear', 'sadness']],\n",
       " [['fear', 'surprise'],\n",
       "  ['fear', 'surprise'],\n",
       "  ['fear', 'surprise'],\n",
       "  ['fear', 'surprise'],\n",
       "  ['anger'],\n",
       "  ['surprise'],\n",
       "  ['anger'],\n",
       "  ['anger', 'surprise'],\n",
       "  ['surprise'],\n",
       "  ['anger'],\n",
       "  ['anger', 'joy']],\n",
       " [['anger', 'disgust', 'fear'],\n",
       "  ['anger', 'fear', 'surprise'],\n",
       "  ['anger'],\n",
       "  ['anger', 'disgust'],\n",
       "  ['fear', 'surprise'],\n",
       "  ['anger', 'disgust', 'fear', 'sadness'],\n",
       "  ['fear', 'surprise'],\n",
       "  ['anger', 'sadness'],\n",
       "  ['fear', 'surprise'],\n",
       "  ['anger']],\n",
       " [['anger', 'disgust'],\n",
       "  ['joy'],\n",
       "  ['anger', 'disgust'],\n",
       "  ['sadness'],\n",
       "  ['sadness'],\n",
       "  ['sadness']],\n",
       " [['anger'], ['anger'], ['anger'], ['anger']],\n",
       " [['anger']],\n",
       " [['anger', 'surprise'],\n",
       "  ['fear', 'surprise'],\n",
       "  ['neutral'],\n",
       "  ['surprise'],\n",
       "  ['anger', 'sadness']],\n",
       " [['anger'],\n",
       "  ['anger'],\n",
       "  ['joy'],\n",
       "  ['fear', 'surprise'],\n",
       "  ['anger'],\n",
       "  ['anger'],\n",
       "  ['anger'],\n",
       "  ['anger'],\n",
       "  ['anger'],\n",
       "  ['anger'],\n",
       "  ['fear', 'surprise'],\n",
       "  ['neutral'],\n",
       "  ['anger', 'sadness']],\n",
       " [['anger'],\n",
       "  ['fear', 'surprise'],\n",
       "  ['sadness', 'surprise'],\n",
       "  ['anger'],\n",
       "  ['anger', 'surprise'],\n",
       "  ['anger'],\n",
       "  ['fear', 'surprise']],\n",
       " [['anger', 'fear', 'surprise']],\n",
       " [['fear', 'surprise'],\n",
       "  ['fear', 'surprise'],\n",
       "  ['fear'],\n",
       "  ['surprise'],\n",
       "  ['fear'],\n",
       "  ['surprise'],\n",
       "  ['joy'],\n",
       "  ['anger']],\n",
       " [['neutral']],\n",
       " [['anger'],\n",
       "  ['anger'],\n",
       "  ['fear'],\n",
       "  ['fear'],\n",
       "  ['fear', 'sadness'],\n",
       "  ['sadness'],\n",
       "  ['anger'],\n",
       "  ['surprise'],\n",
       "  ['surprise'],\n",
       "  ['fear', 'surprise']],\n",
       " [['anger'],\n",
       "  ['fear', 'surprise'],\n",
       "  ['fear', 'surprise'],\n",
       "  ['fear'],\n",
       "  ['anger', 'fear', 'sadness'],\n",
       "  ['anger', 'fear'],\n",
       "  ['anger', 'fear', 'sadness'],\n",
       "  ['anger', 'disgust', 'fear'],\n",
       "  ['anger', 'sadness']],\n",
       " [['anger', 'surprise', 'joy'],\n",
       "  ['anger', 'sadness'],\n",
       "  ['anger', 'sadness'],\n",
       "  ['sadness', 'surprise'],\n",
       "  ['anger', 'disgust'],\n",
       "  ['sadness'],\n",
       "  ['sadness'],\n",
       "  ['fear', 'sadness', 'joy'],\n",
       "  ['anger', 'sadness'],\n",
       "  ['surprise', 'joy'],\n",
       "  ['anger', 'disgust'],\n",
       "  ['sadness'],\n",
       "  ['anger', 'disgust', 'sadness'],\n",
       "  ['anger', 'disgust', 'sadness'],\n",
       "  ['anger', 'sadness'],\n",
       "  ['surprise']],\n",
       " [['anger'], ['anger', 'surprise'], ['anger', 'surprise'], ['sadness', 'joy']],\n",
       " [['sadness', 'joy'],\n",
       "  ['anger', 'surprise'],\n",
       "  ['anger', 'surprise'],\n",
       "  ['anger', 'sadness'],\n",
       "  ['sadness'],\n",
       "  ['disgust', 'sadness'],\n",
       "  ['disgust', 'surprise'],\n",
       "  ['sadness', 'surprise'],\n",
       "  ['disgust'],\n",
       "  ['anger', 'disgust']],\n",
       " [['anger'], ['anger'], ['disgust', 'joy'], ['joy']],\n",
       " [['fear']],\n",
       " [['anger', 'fear', 'disgust'],\n",
       "  ['fear', 'surprise', 'joy', 'anger'],\n",
       "  ['fear', 'surprise'],\n",
       "  ['anger', 'fear', 'disgust'],\n",
       "  ['anger', 'fear', 'sadness'],\n",
       "  ['anger', 'fear'],\n",
       "  ['anger'],\n",
       "  ['anger', 'joy'],\n",
       "  ['anger', 'joy']],\n",
       " [['surprise', 'joy'],\n",
       "  ['fear', 'surprise'],\n",
       "  ['fear'],\n",
       "  ['surprise'],\n",
       "  ['surprise'],\n",
       "  ['fear', 'surprise'],\n",
       "  ['joy'],\n",
       "  ['joy'],\n",
       "  ['surprise'],\n",
       "  ['surprise'],\n",
       "  ['sadness']],\n",
       " [['anger', 'disgust', 'fear'],\n",
       "  ['joy', 'surprise'],\n",
       "  ['anger', 'fear'],\n",
       "  ['anger', 'sadness'],\n",
       "  ['fear', 'surprise'],\n",
       "  ['fear'],\n",
       "  ['joy'],\n",
       "  ['anger']],\n",
       " [['fear', 'surprise'],\n",
       "  ['anger', 'sadness'],\n",
       "  ['anger', 'sadness'],\n",
       "  ['neutral'],\n",
       "  ['anger'],\n",
       "  ['anger', 'fear', 'surprise'],\n",
       "  ['fear', 'joy'],\n",
       "  ['fear', 'joy'],\n",
       "  ['fear', 'joy'],\n",
       "  ['fear']],\n",
       " [['anger', 'fear', 'surprise'],\n",
       "  ['anger', 'disgust'],\n",
       "  ['anger', 'disgust', 'joy'],\n",
       "  ['anger', 'fear', 'surprise'],\n",
       "  ['anger'],\n",
       "  ['anger'],\n",
       "  ['anger'],\n",
       "  ['fear', 'surprise'],\n",
       "  ['anger', 'sadness']],\n",
       " [['anger', 'disgust', 'sadness']],\n",
       " [['anger', 'surprise'],\n",
       "  ['fear', 'surprise'],\n",
       "  ['fear', 'surprise'],\n",
       "  ['anger'],\n",
       "  ['anger'],\n",
       "  ['neutral'],\n",
       "  ['surprise'],\n",
       "  ['anger']],\n",
       " [['anger'],\n",
       "  ['anger', 'fear'],\n",
       "  ['anger', 'fear'],\n",
       "  ['fear', 'surprise'],\n",
       "  ['fear'],\n",
       "  ['anger'],\n",
       "  ['fear'],\n",
       "  ['surprise'],\n",
       "  ['anger', 'surprise']],\n",
       " [['sadness']],\n",
       " [['anger'],\n",
       "  ['anger'],\n",
       "  ['anger'],\n",
       "  ['surprise'],\n",
       "  ['anger', 'sadness'],\n",
       "  ['anger'],\n",
       "  ['anger'],\n",
       "  ['anger'],\n",
       "  ['joy']],\n",
       " [['anger', 'fear'],\n",
       "  ['anger', 'fear'],\n",
       "  ['anger'],\n",
       "  ['anger', 'fear'],\n",
       "  ['anger'],\n",
       "  ['anger'],\n",
       "  ['anger'],\n",
       "  ['anger'],\n",
       "  ['anger', 'sadness'],\n",
       "  ['anger', 'surprise']],\n",
       " [['anger'],\n",
       "  ['anger'],\n",
       "  ['anger'],\n",
       "  ['surprise'],\n",
       "  ['anger', 'sadness'],\n",
       "  ['anger'],\n",
       "  ['anger'],\n",
       "  ['anger'],\n",
       "  ['joy']],\n",
       " [['anger', 'fear'],\n",
       "  ['anger', 'fear'],\n",
       "  ['fear', 'surprise'],\n",
       "  ['fear'],\n",
       "  ['anger'],\n",
       "  ['fear'],\n",
       "  ['surprise'],\n",
       "  ['anger', 'surprise'],\n",
       "  ['anger', 'surprise']],\n",
       " [['neutral', 'sadness']],\n",
       " [['anger'],\n",
       "  ['fear', 'surprise'],\n",
       "  ['sadness', 'surprise'],\n",
       "  ['anger'],\n",
       "  ['anger', 'surprise'],\n",
       "  ['anger'],\n",
       "  ['fear', 'surprise']],\n",
       " [['sadness', 'surprise']],\n",
       " [['anger'],\n",
       "  ['neutral'],\n",
       "  ['fear', 'surprise'],\n",
       "  ['fear', 'sadness'],\n",
       "  ['fear', 'sadness'],\n",
       "  ['surprise'],\n",
       "  ['fear', 'sadness'],\n",
       "  ['fear', 'surprise'],\n",
       "  ['anger'],\n",
       "  ['fear']],\n",
       " [['anger'],\n",
       "  ['anger', 'fear'],\n",
       "  ['anger', 'fear'],\n",
       "  ['fear', 'surprise'],\n",
       "  ['fear'],\n",
       "  ['anger'],\n",
       "  ['fear'],\n",
       "  ['surprise'],\n",
       "  ['anger', 'surprise']],\n",
       " [['fear', 'surprise'],\n",
       "  ['anger', 'disgust', 'sadness'],\n",
       "  ['fear', 'surprise'],\n",
       "  ['anger'],\n",
       "  ['neutral'],\n",
       "  ['fear']],\n",
       " [['anger', 'fear'],\n",
       "  ['anger', 'sadness'],\n",
       "  ['anger', 'fear', 'surprise'],\n",
       "  ['anger', 'fear'],\n",
       "  ['anger', 'fear'],\n",
       "  ['anger', 'fear', 'sadness'],\n",
       "  ['anger', 'fear'],\n",
       "  ['anger', 'fear', 'surprise'],\n",
       "  ['anger'],\n",
       "  ['fear']],\n",
       " [['anger'], ['anger', 'surprise']],\n",
       " [['anger', 'fear', 'surprise'],\n",
       "  ['anger', 'disgust', 'fear'],\n",
       "  ['anger', 'fear', 'sadness'],\n",
       "  ['anger', 'surprise'],\n",
       "  ['anger', 'fear', 'sadness'],\n",
       "  ['anger', 'disgust', 'fear'],\n",
       "  ['anger', 'surprise'],\n",
       "  ['anger', 'fear', 'sadness'],\n",
       "  ['anger', 'disgust', 'fear'],\n",
       "  ['anger', 'fear', 'sadness'],\n",
       "  ['anger', 'surprise'],\n",
       "  ['anger', 'fear', 'sadness'],\n",
       "  ['anger', 'disgust', 'fear'],\n",
       "  ['anger', 'fear', 'sadness'],\n",
       "  ['anger', 'surprise'],\n",
       "  ['anger', 'disgust', 'fear'],\n",
       "  ['anger', 'fear', 'sadness'],\n",
       "  ['anger', 'surprise'],\n",
       "  ['anger', 'fear', 'sadness'],\n",
       "  ['anger', 'disgust', 'fear'],\n",
       "  ['anger', 'fear', 'sadness'],\n",
       "  ['anger', 'surprise'],\n",
       "  ['anger', 'fear', 'sadness'],\n",
       "  ['anger', 'disgust', 'fear'],\n",
       "  ['anger', 'fear', 'sadness'],\n",
       "  ['anger', 'surprise'],\n",
       "  ['anger', 'fear', 'sadness'],\n",
       "  ['anger', 'disgust', 'fear'],\n",
       "  ['anger', 'fear', 'sadness'],\n",
       "  ['anger', 'surprise'],\n",
       "  ['anger', 'fear', 'sadness'],\n",
       "  ['anger', 'disgust', 'fear'],\n",
       "  ['anger', 'fear', 'sadness'],\n",
       "  ['anger', 'surprise'],\n",
       "  ['anger', 'fear', 'sadness'],\n",
       "  ['anger', 'disgust', 'fear'],\n",
       "  ['anger', 'fear', 'sadness'],\n",
       "  ['anger', 'surprise'],\n",
       "  ['anger', 'fear', 'sadness'],\n",
       "  ['anger', 'disgust', 'fear'],\n",
       "  ['anger', 'fear', 'sadness'],\n",
       "  ['anger', 'surprise'],\n",
       "  ['anger', 'fear', 'sadness']],\n",
       " [['anger', 'sadness']],\n",
       " [['anger'], ['fear', 'surprise']],\n",
       " [['fear'],\n",
       "  ['sadness'],\n",
       "  ['fear', 'sadness'],\n",
       "  ['fear', 'sadness'],\n",
       "  ['fear', 'sadness'],\n",
       "  ['fear', 'sadness'],\n",
       "  ['sadness'],\n",
       "  ['sadness'],\n",
       "  ['sadness'],\n",
       "  ['sadness'],\n",
       "  ['sadness'],\n",
       "  ['sadness']],\n",
       " [['anger', 'fear'],\n",
       "  ['anger'],\n",
       "  ['fear', 'sadness'],\n",
       "  ['surprise'],\n",
       "  ['sadness'],\n",
       "  ['fear', 'sadness'],\n",
       "  ['sadness'],\n",
       "  ['disgust'],\n",
       "  ['anger'],\n",
       "  ['surprise'],\n",
       "  ['joy'],\n",
       "  ['neutral'],\n",
       "  ['fear', 'sadness'],\n",
       "  ['anger', 'sadness'],\n",
       "  ['anger', 'sadness'],\n",
       "  ['anger', 'sadness'],\n",
       "  ['sadness'],\n",
       "  ['sadness'],\n",
       "  ['sadness'],\n",
       "  ['sadness'],\n",
       "  ['sadness'],\n",
       "  ['sadness'],\n",
       "  ['sadness'],\n",
       "  ['sadness'],\n",
       "  ['sadness'],\n",
       "  ['sadness'],\n",
       "  ['sadness'],\n",
       "  ['sadness'],\n",
       "  ['sadness'],\n",
       "  ['sadness'],\n",
       "  ['sadness'],\n",
       "  ['sadness'],\n",
       "  ['sadness'],\n",
       "  ['sadness'],\n",
       "  ['sadness'],\n",
       "  ['sadness'],\n",
       "  ['sadness'],\n",
       "  ['sadness'],\n",
       "  ['sadness'],\n",
       "  ['sadness'],\n",
       "  ['sadness'],\n",
       "  ['sadness'],\n",
       "  ['sadness'],\n",
       "  ['sadness'],\n",
       "  ['sadness'],\n",
       "  ['sadness'],\n",
       "  ['sadness'],\n",
       "  ['sadness'],\n",
       "  ['sadness'],\n",
       "  ['sadness'],\n",
       "  ['sadness'],\n",
       "  ['sadness']],\n",
       " [['anger'],\n",
       "  ['anger'],\n",
       "  ['anger', 'fear'],\n",
       "  ['joy'],\n",
       "  ['joy'],\n",
       "  ['joy'],\n",
       "  ['joy'],\n",
       "  ['joy'],\n",
       "  ['joy'],\n",
       "  ['surprise', 'joy'],\n",
       "  ['joy'],\n",
       "  ['joy'],\n",
       "  ['sadness'],\n",
       "  ['joy'],\n",
       "  ['joy'],\n",
       "  ['joy'],\n",
       "  ['joy'],\n",
       "  ['joy'],\n",
       "  ['surprise'],\n",
       "  ['joy'],\n",
       "  ['joy'],\n",
       "  ['joy'],\n",
       "  ['joy'],\n",
       "  ['joy'],\n",
       "  ['joy'],\n",
       "  ['joy'],\n",
       "  ['joy'],\n",
       "  ['joy'],\n",
       "  ['joy'],\n",
       "  ['joy'],\n",
       "  ['joy'],\n",
       "  ['joy'],\n",
       "  ['joy'],\n",
       "  ['joy'],\n",
       "  ['joy'],\n",
       "  ['joy'],\n",
       "  ['joy'],\n",
       "  ['joy'],\n",
       "  ['joy'],\n",
       "  ['joy'],\n",
       "  ['joy'],\n",
       "  ['joy'],\n",
       "  ['joy'],\n",
       "  ['joy'],\n",
       "  ['joy'],\n",
       "  ['joy'],\n",
       "  ['joy'],\n",
       "  ['joy'],\n",
       "  ['joy'],\n",
       "  ['joy'],\n",
       "  ['joy'],\n",
       "  ['joy'],\n",
       "  ['joy'],\n",
       "  ['joy'],\n",
       "  ['joy'],\n",
       "  ['joy'],\n",
       "  ['joy'],\n",
       "  ['joy'],\n",
       "  ['joy'],\n",
       "  ['joy'],\n",
       "  ['joy'],\n",
       "  ['joy'],\n",
       "  ['joy'],\n",
       "  ['joy'],\n",
       "  ['joy'],\n",
       "  ['joy'],\n",
       "  ['joy'],\n",
       "  ['joy'],\n",
       "  ['joy'],\n",
       "  ['joy'],\n",
       "  ['joy'],\n",
       "  ['joy'],\n",
       "  ['joy'],\n",
       "  ['joy'],\n",
       "  ['joy'],\n",
       "  ['joy'],\n",
       "  ['joy'],\n",
       "  ['joy'],\n",
       "  ['joy'],\n",
       "  ['joy'],\n",
       "  ['joy'],\n",
       "  ['joy'],\n",
       "  ['joy'],\n",
       "  ['joy'],\n",
       "  ['joy'],\n",
       "  ['joy'],\n",
       "  ['joy'],\n",
       "  ['joy'],\n",
       "  ['joy'],\n",
       "  ['joy'],\n",
       "  ['joy'],\n",
       "  ['joy'],\n",
       "  ['joy'],\n",
       "  ['joy'],\n",
       "  ['joy'],\n",
       "  ['joy'],\n",
       "  ['joy'],\n",
       "  ['joy'],\n",
       "  ['joy'],\n",
       "  ['joy'],\n",
       "  ['joy'],\n",
       "  ['joy'],\n",
       "  ['joy'],\n",
       "  ['joy'],\n",
       "  ['joy'],\n",
       "  ['joy'],\n",
       "  ['joy'],\n",
       "  ['joy'],\n",
       "  ['joy'],\n",
       "  ['joy'],\n",
       "  ['joy'],\n",
       "  ['joy'],\n",
       "  ['joy'],\n",
       "  ['joy'],\n",
       "  ['joy'],\n",
       "  ['joy'],\n",
       "  ['joy'],\n",
       "  ['joy'],\n",
       "  ['joy'],\n",
       "  ['joy'],\n",
       "  ['joy'],\n",
       "  ['joy'],\n",
       "  ['joy'],\n",
       "  ['joy'],\n",
       "  ['joy'],\n",
       "  ['joy'],\n",
       "  ['joy'],\n",
       "  ['joy'],\n",
       "  ['joy'],\n",
       "  ['joy'],\n",
       "  ['joy'],\n",
       "  ['joy'],\n",
       "  ['joy'],\n",
       "  ['joy'],\n",
       "  ['joy'],\n",
       "  ['joy'],\n",
       "  ['joy'],\n",
       "  ['joy'],\n",
       "  ['joy'],\n",
       "  ['joy'],\n",
       "  ['joy'],\n",
       "  ['joy'],\n",
       "  ['joy'],\n",
       "  ['joy'],\n",
       "  ['joy'],\n",
       "  ['joy'],\n",
       "  ['joy'],\n",
       "  ['joy'],\n",
       "  ['joy'],\n",
       "  ['joy'],\n",
       "  ['joy'],\n",
       "  ['joy'],\n",
       "  ['joy'],\n",
       "  ['joy'],\n",
       "  ['joy'],\n",
       "  ['joy'],\n",
       "  ['joy'],\n",
       "  ['joy'],\n",
       "  ['joy'],\n",
       "  ['joy'],\n",
       "  ['joy'],\n",
       "  ['joy'],\n",
       "  ['joy'],\n",
       "  ['joy'],\n",
       "  ['joy'],\n",
       "  ['joy']],\n",
       " [['anger'], ['fear'], ['anger', 'disgust'], ['anger'], ['anger']],\n",
       " [['anger'], ['fear'], ['anger', 'disgust'], ['anger'], ['anger']],\n",
       " [['anger'], ['fear'], ['anger', 'disgust'], ['anger'], ['anger']],\n",
       " [['fear'],\n",
       "  ['surprise'],\n",
       "  ['surprise'],\n",
       "  ['fear', 'surprise'],\n",
       "  ['fear'],\n",
       "  ['anger']],\n",
       " [['joy']],\n",
       " [['anger'],\n",
       "  ['anger', 'fear'],\n",
       "  ['anger', 'fear'],\n",
       "  ['fear', 'surprise'],\n",
       "  ['fear'],\n",
       "  ['anger'],\n",
       "  ['fear'],\n",
       "  ['surprise'],\n",
       "  ['anger', 'surprise']],\n",
       " [['anger', 'disgust'],\n",
       "  ['anger', 'disgust'],\n",
       "  ['fear', 'surprise'],\n",
       "  ['surprise', 'joy'],\n",
       "  ['surprise', 'joy'],\n",
       "  ['fear', 'sadness'],\n",
       "  ['joy'],\n",
       "  ['joy'],\n",
       "  ['fear']],\n",
       " [['anger'],\n",
       "  ['anger'],\n",
       "  ['fear'],\n",
       "  ['surprise'],\n",
       "  ['surprise'],\n",
       "  ['fear', 'sadness'],\n",
       "  ['anger', 'disgust', 'surprise'],\n",
       "  ['anger', 'fear', 'sadness'],\n",
       "  ['anger', 'surprise'],\n",
       "  ['anger', 'disgust', 'fear', 'surprise']],\n",
       " [['anger', 'disgust', 'sadness'],\n",
       "  ['joy'],\n",
       "  ['anger', 'fear'],\n",
       "  ['anger', 'sadness'],\n",
       "  ['anger', 'fear'],\n",
       "  ['joy'],\n",
       "  ['anger'],\n",
       "  ['anger']],\n",
       " [['anger', 'disgust', 'sadness'],\n",
       "  ['joy'],\n",
       "  ['anger', 'fear'],\n",
       "  ['anger', 'sadness'],\n",
       "  ['anger', 'fear'],\n",
       "  ['joy'],\n",
       "  ['anger'],\n",
       "  ['anger']],\n",
       " [['anger'],\n",
       "  ['anger', 'surprise'],\n",
       "  ['fear', 'surprise'],\n",
       "  ['surprise', 'joy'],\n",
       "  ['surprise', 'joy'],\n",
       "  ['fear', 'sadness'],\n",
       "  ['joy'],\n",
       "  ['joy'],\n",
       "  ['fear']],\n",
       " [['anger', 'fear'],\n",
       "  ['fear'],\n",
       "  ['neutral'],\n",
       "  ['sadness'],\n",
       "  ['joy'],\n",
       "  ['sadness'],\n",
       "  ['sadness'],\n",
       "  ['joy'],\n",
       "  ['joy']]]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['anger']]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions_l = []\n",
    "# bad_idx = []\n",
    "\n",
    "# for i, pred in enumerate(predictions):\n",
    "#     try:\n",
    "#         predictions_l.append(ast.literal_eval(pred))\n",
    "#     except:\n",
    "#         print(i)\n",
    "#         bad_idx.append(i)\n",
    "\n",
    "#predictions_l = [ast.literal_eval(item) for item in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(grounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(grounds_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 7,\n",
       " 9,\n",
       " 12,\n",
       " 14,\n",
       " 15,\n",
       " 18,\n",
       " 19,\n",
       " 21,\n",
       " 23,\n",
       " 24,\n",
       " 25,\n",
       " 27,\n",
       " 29,\n",
       " 30,\n",
       " 33,\n",
       " 34,\n",
       " 37,\n",
       " 38,\n",
       " 40,\n",
       " 41,\n",
       " 46,\n",
       " 47,\n",
       " 53,\n",
       " 56,\n",
       " 57,\n",
       " 58,\n",
       " 60,\n",
       " 62,\n",
       " 63,\n",
       " 64,\n",
       " 65,\n",
       " 67,\n",
       " 70,\n",
       " 71,\n",
       " 72,\n",
       " 75,\n",
       " 78,\n",
       " 79,\n",
       " 80,\n",
       " 82,\n",
       " 87,\n",
       " 90,\n",
       " 91,\n",
       " 92,\n",
       " 95,\n",
       " 98,\n",
       " 99,\n",
       " 100,\n",
       " 101,\n",
       " 102,\n",
       " 103,\n",
       " 104,\n",
       " 107,\n",
       " 108,\n",
       " 110,\n",
       " 116,\n",
       " 117,\n",
       " 118,\n",
       " 119,\n",
       " 120,\n",
       " 121,\n",
       " 122,\n",
       " 123,\n",
       " 124,\n",
       " 125,\n",
       " 126,\n",
       " 127,\n",
       " 128,\n",
       " 129,\n",
       " 131,\n",
       " 132,\n",
       " 133,\n",
       " 134,\n",
       " 136,\n",
       " 137,\n",
       " 138,\n",
       " 139,\n",
       " 147,\n",
       " 149,\n",
       " 152,\n",
       " 154]"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grounds_l = [label for i, label in enumerate(grounds_l) if i not in bad_idx]\n",
    "#predictions_l = [label for i, label in enumerate(predictions_l) if i not in bad_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(grounds_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 7 8\n",
      "1 15 10\n",
      "2 12 9\n",
      "3 14 4\n",
      "4 4 6\n",
      "5 9 31\n",
      "6 13 10\n",
      "7 12 99\n",
      "8 10 7\n",
      "9 11 17\n",
      "10 13 10\n",
      "11 6 9\n",
      "12 7 5\n",
      "13 9 11\n",
      "14 9 10\n",
      "15 17 6\n",
      "16 2 4\n",
      "17 2 1\n",
      "18 8 5\n",
      "19 7 13\n",
      "20 13 7\n",
      "21 2 1\n",
      "22 10 8\n",
      "23 3 1\n",
      "24 8 10\n",
      "25 11 9\n",
      "26 7 16\n",
      "27 8 4\n",
      "28 6 10\n",
      "30 3 1\n",
      "31 4 9\n",
      "32 6 11\n",
      "33 6 8\n",
      "34 2 10\n",
      "35 7 9\n",
      "36 6 1\n",
      "37 12 8\n",
      "39 15 1\n",
      "40 13 9\n",
      "42 10 9\n",
      "43 1 9\n",
      "44 3 1\n",
      "45 6 7\n",
      "48 6 9\n",
      "49 5 6\n",
      "50 4 10\n",
      "51 1 2\n",
      "52 6 43\n",
      "54 3 2\n",
      "55 13 12\n",
      "56 7 52\n",
      "57 3 166\n",
      "58 6 5\n",
      "59 6 5\n",
      "62 4 1\n",
      "63 12 9\n",
      "65 16 10\n",
      "66 11 8\n",
      "67 14 8\n",
      "68 11 9\n",
      "69 1 9\n"
     ]
    }
   ],
   "source": [
    "bad_idx = []\n",
    "\n",
    "for idx, (i,j) in enumerate(zip(grounds_l, predictions)):\n",
    "    if len(i) != len(j):\n",
    "        print(idx, len(i), len(j))\n",
    "        bad_idx.append(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, (i,j) in enumerate(zip(grounds_l, predictions)):\n",
    "    if len(i) > len(j):\n",
    "        grounds_l[idx] = grounds_l[idx][:len(j)]\n",
    "    elif len(j) > len(i):\n",
    "        predictions[idx] = predictions[idx][:len(i)]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_idx = []\n",
    "\n",
    "for idx, (i,j) in enumerate(zip(grounds_l, predictions)):\n",
    "    if len(i) != len(j):\n",
    "        print(idx, len(i), len(j))\n",
    "        bad_idx.append(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grounds = [label for i, label in enumerate(grounds_l) if i not in bad_idx]\n",
    "# predictions = [label for i, label in enumerate(predictions_l) if i not in bad_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70, 70)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(grounds_l), len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "grounds = [item for sublist in grounds_l for item in sublist]\n",
    "predictions = [item for sublist in predictions for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import MultiLabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlb = MultiLabelBinarizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_mhot = mlb.fit_transform(grounds)\n",
    "y_pred_mhot = mlb.transform(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((413, 7), (413, 7))"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true_mhot.shape, y_pred_mhot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger      0.394     0.584     0.470       149\n",
      "     disgust      0.000     0.000     0.000        12\n",
      "        fear      0.227     0.421     0.295        76\n",
      "         joy      0.250     0.088     0.130       102\n",
      "     neutral      0.000     0.000     0.000        30\n",
      "     sadness      0.309     0.345     0.326        84\n",
      "    surprise      0.370     0.364     0.367       121\n",
      "\n",
      "   micro avg      0.305     0.350     0.326       574\n",
      "   macro avg      0.221     0.257     0.227       574\n",
      "weighted avg      0.300     0.350     0.309       574\n",
      " samples avg      0.311     0.346     0.311       574\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true_mhot, y_pred_mhot, target_names=mlb.classes_, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (triton_env2)",
   "language": "python",
   "name": "triton_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
