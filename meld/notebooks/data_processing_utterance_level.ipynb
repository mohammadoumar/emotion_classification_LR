{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b20aa00d-c84a-4970-bc99-ffd9f8ed9776",
   "metadata": {},
   "source": [
    "# Data Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "640868d0-4cf7-4fb0-bfb3-3ed663372d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import json\n",
    "import random\n",
    "import pandas as pd # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f0c44be-8571-45e5-a85e-808d4990a707",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"comics_data_processed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dcf9f155-8e66-4a51-ae38-d0dd5f58006b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>index</th>\n",
       "      <th>file_name</th>\n",
       "      <th>page_nr</th>\n",
       "      <th>panel_nr</th>\n",
       "      <th>balloon_nr</th>\n",
       "      <th>utterance</th>\n",
       "      <th>raw_annotation</th>\n",
       "      <th>raw_emotion</th>\n",
       "      <th>raw_speaker_id</th>\n",
       "      <th>emotion</th>\n",
       "      <th>speaker_id</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>QC copy - 1500 - 04 Nightwing 19 _Nightwing 95...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>DID YOU HAVE TO ELECTROCUTE HER SO HARD?</td>\n",
       "      <td>2024-08-27 - aselermekova20\\nFeeling:AN0-DI0-F...</td>\n",
       "      <td>2024-08-27 - aselermekova20\\nFeeling:AN0-DI0-F...</td>\n",
       "      <td>2024-09-05 - aidaraliev12345\\nSpokenBy:ID-1</td>\n",
       "      <td>AN0-DI0-FE3-SA0-SU5-JO0</td>\n",
       "      <td>ID-1</td>\n",
       "      <td>TRAIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>QC copy - 1500 - 04 Nightwing 19 _Nightwing 95...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>IT'S NOT LIKE I HAVE DIFFERENT SETTINGS.</td>\n",
       "      <td>2024-08-27 - aselermekova20\\nFeeling:AN0-DI0-F...</td>\n",
       "      <td>2024-08-27 - aselermekova20\\nFeeling:AN0-DI0-F...</td>\n",
       "      <td>2024-09-05 - aidaraliev12345\\nSpokenBy:ID-2</td>\n",
       "      <td>AN0-DI0-FE0-SA0-SU5-JO0</td>\n",
       "      <td>ID-2</td>\n",
       "      <td>TRAIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>QC copy - 1500 - 04 Nightwing 19 _Nightwing 95...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>YOU'RE ELECTROCUTIONER. IT'S YOUR WHOLE THING....</td>\n",
       "      <td>2024-08-27 - aselermekova20\\nFeeling:AN0-DI0-F...</td>\n",
       "      <td>2024-08-27 - aselermekova20\\nFeeling:AN0-DI0-F...</td>\n",
       "      <td>2024-09-05 - aidaraliev12345\\nSpokenBy:ID-1</td>\n",
       "      <td>AN0-DI0-FE2-SA0-SU0-JO0</td>\n",
       "      <td>ID-1</td>\n",
       "      <td>TRAIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>QC copy - 1500 - 04 Nightwing 19 _Nightwing 95...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>OH, HEY. I THINK SHE'S AWAKE.</td>\n",
       "      <td>2024-08-27 - aselermekova20\\nFeeling:AN0-DI0-F...</td>\n",
       "      <td>2024-08-27 - aselermekova20\\nFeeling:AN0-DI0-F...</td>\n",
       "      <td>2024-09-05 - aidaraliev12345\\nSpokenBy:ID-2</td>\n",
       "      <td>AN0-DI0-FE0-SA0-SU4-JO0</td>\n",
       "      <td>ID-2</td>\n",
       "      <td>TRAIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>QC copy - 1500 - 04 Nightwing 19 _Nightwing 95...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>WELCOME BACK, MADAM MAYOR. BLOCKBUSTER IS PRET...</td>\n",
       "      <td>2024-08-27 - aselermekova20\\nFeeling:AN3-DI0-F...</td>\n",
       "      <td>2024-08-27 - aselermekova20\\nFeeling:AN3-DI0-F...</td>\n",
       "      <td>2024-09-05 - aidaraliev12345\\nSpokenBy:ID-1</td>\n",
       "      <td>AN3-DI0-FE0-SA0-SU0-JO0</td>\n",
       "      <td>ID-1</td>\n",
       "      <td>TRAIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5277</th>\n",
       "      <td>5277</td>\n",
       "      <td>5290</td>\n",
       "      <td>QC copy - 1499 - 58 ECC Co_mics 50 _The Jurass...</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>I KNOW THE BEINGS OF THIS WORLD ARE TRYING TO ...</td>\n",
       "      <td>2024-08-27 - aselermekova20\\nFeeling:AN5-DI0-F...</td>\n",
       "      <td>2024-08-27 - aselermekova20\\nFeeling:AN5-DI0-F...</td>\n",
       "      <td>2024-09-05 - aidaraliev12345\\nSpokenBy:BLACKMA...</td>\n",
       "      <td>AN5-DI0-FE0-SA0-SU0-JO0</td>\n",
       "      <td>BLACKMANTASAURUS</td>\n",
       "      <td>TEST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5278</th>\n",
       "      <td>5278</td>\n",
       "      <td>5291</td>\n",
       "      <td>QC copy - 1499 - 58 ECC Co_mics 50 _The Jurass...</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>… BUT I WILL CRUSH THEM IN DUE TIME!</td>\n",
       "      <td>2024-08-27 - aselermekova20\\nFeeling:AN5-DI0-F...</td>\n",
       "      <td>2024-08-27 - aselermekova20\\nFeeling:AN5-DI0-F...</td>\n",
       "      <td>2024-09-05 - aidaraliev12345\\nSpokenBy:BLACKMA...</td>\n",
       "      <td>AN5-DI0-FE0-SA0-SU0-JO0</td>\n",
       "      <td>BLACKMANTASAURUS</td>\n",
       "      <td>TEST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5279</th>\n",
       "      <td>5279</td>\n",
       "      <td>5292</td>\n",
       "      <td>QC copy - 1499 - 58 ECC Co_mics 50 _The Jurass...</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>FOR MY FIRST TASK...</td>\n",
       "      <td>2024-08-27 - aselermekova20\\nFeeling:AN5-DI0-F...</td>\n",
       "      <td>2024-08-27 - aselermekova20\\nFeeling:AN5-DI0-F...</td>\n",
       "      <td>2024-09-05 - aidaraliev12345\\nSpokenBy:BLACKMA...</td>\n",
       "      <td>AN5-DI0-FE0-SA0-SU0-JO0</td>\n",
       "      <td>BLACKMANTASAURUS</td>\n",
       "      <td>TEST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5280</th>\n",
       "      <td>5280</td>\n",
       "      <td>5293</td>\n",
       "      <td>QC copy - 1499 - 58 ECC Co_mics 50 _The Jurass...</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>… I MUST REMOVE THIS WORLD OF THEIR GODS!</td>\n",
       "      <td>2024-08-27 - aselermekova20\\nFeeling:AN5-DI0-F...</td>\n",
       "      <td>2024-08-27 - aselermekova20\\nFeeling:AN5-DI0-F...</td>\n",
       "      <td>2024-09-05 - aidaraliev12345\\nSpokenBy:BLACKMA...</td>\n",
       "      <td>AN5-DI0-FE0-SA0-SU0-JO5</td>\n",
       "      <td>BLACKMANTASAURUS</td>\n",
       "      <td>TEST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5281</th>\n",
       "      <td>5281</td>\n",
       "      <td>5294</td>\n",
       "      <td>QC copy - 1499 - 58 ECC Co_mics 50 _The Jurass...</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>TRIMYSCIRA! DARKYLOSEID IS COMING FOR YOU!</td>\n",
       "      <td>2024-08-27 - aselermekova20\\nFeeling:AN5-DI0-F...</td>\n",
       "      <td>2024-08-27 - aselermekova20\\nFeeling:AN5-DI0-F...</td>\n",
       "      <td>2024-08-27 - aselermekova20\\nSpokenBy:BLACKMAN...</td>\n",
       "      <td>AN5-DI0-FE0-SA0-SU0-JO0</td>\n",
       "      <td>BLACKMANTASAURUS</td>\n",
       "      <td>TEST</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5282 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0  index                                          file_name  \\\n",
       "0              0      0  QC copy - 1500 - 04 Nightwing 19 _Nightwing 95...   \n",
       "1              1      1  QC copy - 1500 - 04 Nightwing 19 _Nightwing 95...   \n",
       "2              2      2  QC copy - 1500 - 04 Nightwing 19 _Nightwing 95...   \n",
       "3              3      3  QC copy - 1500 - 04 Nightwing 19 _Nightwing 95...   \n",
       "4              4      4  QC copy - 1500 - 04 Nightwing 19 _Nightwing 95...   \n",
       "...          ...    ...                                                ...   \n",
       "5277        5277   5290  QC copy - 1499 - 58 ECC Co_mics 50 _The Jurass...   \n",
       "5278        5278   5291  QC copy - 1499 - 58 ECC Co_mics 50 _The Jurass...   \n",
       "5279        5279   5292  QC copy - 1499 - 58 ECC Co_mics 50 _The Jurass...   \n",
       "5280        5280   5293  QC copy - 1499 - 58 ECC Co_mics 50 _The Jurass...   \n",
       "5281        5281   5294  QC copy - 1499 - 58 ECC Co_mics 50 _The Jurass...   \n",
       "\n",
       "      page_nr  panel_nr  balloon_nr  \\\n",
       "0           1         2           1   \n",
       "1           1         2           2   \n",
       "2           1         2           3   \n",
       "3           1         3           1   \n",
       "4           1         4           1   \n",
       "...       ...       ...         ...   \n",
       "5277       20         1           1   \n",
       "5278       20         1           2   \n",
       "5279       20         2           1   \n",
       "5280       20         2           2   \n",
       "5281       20         2           3   \n",
       "\n",
       "                                              utterance  \\\n",
       "0              DID YOU HAVE TO ELECTROCUTE HER SO HARD?   \n",
       "1              IT'S NOT LIKE I HAVE DIFFERENT SETTINGS.   \n",
       "2     YOU'RE ELECTROCUTIONER. IT'S YOUR WHOLE THING....   \n",
       "3                         OH, HEY. I THINK SHE'S AWAKE.   \n",
       "4     WELCOME BACK, MADAM MAYOR. BLOCKBUSTER IS PRET...   \n",
       "...                                                 ...   \n",
       "5277  I KNOW THE BEINGS OF THIS WORLD ARE TRYING TO ...   \n",
       "5278               … BUT I WILL CRUSH THEM IN DUE TIME!   \n",
       "5279                               FOR MY FIRST TASK...   \n",
       "5280          … I MUST REMOVE THIS WORLD OF THEIR GODS!   \n",
       "5281         TRIMYSCIRA! DARKYLOSEID IS COMING FOR YOU!   \n",
       "\n",
       "                                         raw_annotation  \\\n",
       "0     2024-08-27 - aselermekova20\\nFeeling:AN0-DI0-F...   \n",
       "1     2024-08-27 - aselermekova20\\nFeeling:AN0-DI0-F...   \n",
       "2     2024-08-27 - aselermekova20\\nFeeling:AN0-DI0-F...   \n",
       "3     2024-08-27 - aselermekova20\\nFeeling:AN0-DI0-F...   \n",
       "4     2024-08-27 - aselermekova20\\nFeeling:AN3-DI0-F...   \n",
       "...                                                 ...   \n",
       "5277  2024-08-27 - aselermekova20\\nFeeling:AN5-DI0-F...   \n",
       "5278  2024-08-27 - aselermekova20\\nFeeling:AN5-DI0-F...   \n",
       "5279  2024-08-27 - aselermekova20\\nFeeling:AN5-DI0-F...   \n",
       "5280  2024-08-27 - aselermekova20\\nFeeling:AN5-DI0-F...   \n",
       "5281  2024-08-27 - aselermekova20\\nFeeling:AN5-DI0-F...   \n",
       "\n",
       "                                            raw_emotion  \\\n",
       "0     2024-08-27 - aselermekova20\\nFeeling:AN0-DI0-F...   \n",
       "1     2024-08-27 - aselermekova20\\nFeeling:AN0-DI0-F...   \n",
       "2     2024-08-27 - aselermekova20\\nFeeling:AN0-DI0-F...   \n",
       "3     2024-08-27 - aselermekova20\\nFeeling:AN0-DI0-F...   \n",
       "4     2024-08-27 - aselermekova20\\nFeeling:AN3-DI0-F...   \n",
       "...                                                 ...   \n",
       "5277  2024-08-27 - aselermekova20\\nFeeling:AN5-DI0-F...   \n",
       "5278  2024-08-27 - aselermekova20\\nFeeling:AN5-DI0-F...   \n",
       "5279  2024-08-27 - aselermekova20\\nFeeling:AN5-DI0-F...   \n",
       "5280  2024-08-27 - aselermekova20\\nFeeling:AN5-DI0-F...   \n",
       "5281  2024-08-27 - aselermekova20\\nFeeling:AN5-DI0-F...   \n",
       "\n",
       "                                         raw_speaker_id  \\\n",
       "0           2024-09-05 - aidaraliev12345\\nSpokenBy:ID-1   \n",
       "1           2024-09-05 - aidaraliev12345\\nSpokenBy:ID-2   \n",
       "2           2024-09-05 - aidaraliev12345\\nSpokenBy:ID-1   \n",
       "3           2024-09-05 - aidaraliev12345\\nSpokenBy:ID-2   \n",
       "4           2024-09-05 - aidaraliev12345\\nSpokenBy:ID-1   \n",
       "...                                                 ...   \n",
       "5277  2024-09-05 - aidaraliev12345\\nSpokenBy:BLACKMA...   \n",
       "5278  2024-09-05 - aidaraliev12345\\nSpokenBy:BLACKMA...   \n",
       "5279  2024-09-05 - aidaraliev12345\\nSpokenBy:BLACKMA...   \n",
       "5280  2024-09-05 - aidaraliev12345\\nSpokenBy:BLACKMA...   \n",
       "5281  2024-08-27 - aselermekova20\\nSpokenBy:BLACKMAN...   \n",
       "\n",
       "                      emotion        speaker_id  split  \n",
       "0     AN0-DI0-FE3-SA0-SU5-JO0              ID-1  TRAIN  \n",
       "1     AN0-DI0-FE0-SA0-SU5-JO0              ID-2  TRAIN  \n",
       "2     AN0-DI0-FE2-SA0-SU0-JO0              ID-1  TRAIN  \n",
       "3     AN0-DI0-FE0-SA0-SU4-JO0              ID-2  TRAIN  \n",
       "4     AN3-DI0-FE0-SA0-SU0-JO0              ID-1  TRAIN  \n",
       "...                       ...               ...    ...  \n",
       "5277  AN5-DI0-FE0-SA0-SU0-JO0  BLACKMANTASAURUS   TEST  \n",
       "5278  AN5-DI0-FE0-SA0-SU0-JO0  BLACKMANTASAURUS   TEST  \n",
       "5279  AN5-DI0-FE0-SA0-SU0-JO0  BLACKMANTASAURUS   TEST  \n",
       "5280  AN5-DI0-FE0-SA0-SU0-JO5  BLACKMANTASAURUS   TEST  \n",
       "5281  AN5-DI0-FE0-SA0-SU0-JO0  BLACKMANTASAURUS   TEST  \n",
       "\n",
       "[5282 rows x 13 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99bccfe7-ba71-4732-ba8d-5fe9d13eee57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "split\n",
       "TRAIN    3506\n",
       "TEST     1776\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.split.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d0ad38-7fc1-494b-b194-26dda0dfc415",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "e8f654b2-a65e-4d91-8dc3-88980aaac27f",
   "metadata": {},
   "source": [
    "current_dir = os.getcwd()\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "data_dir = os.path.join(parent_dir, \"data_files\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7ad1908e-0759-4836-941c-24db9770685f",
   "metadata": {},
   "source": [
    "### Read files into a dataframe"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6043fa6b-a48b-4c35-9962-95d45133b5ae",
   "metadata": {},
   "source": [
    "file_paths = glob.glob(os.path.join(data_dir, '*.xlsx'))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e7636f60-b77b-49f1-8f1d-71fc0c375cd8",
   "metadata": {},
   "source": [
    "df_list = []\n",
    "\n",
    "for file_path in file_paths:\n",
    "\n",
    "    df = pd.read_excel(file_path)\n",
    "    df['file_name'] = os.path.basename(file_path)\n",
    "    df_list.append(df)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ffa10570-96fa-4958-bb90-03a47c93ec80",
   "metadata": {},
   "source": [
    "df = pd.concat(df_list, ignore_index=True)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c48efe92-92e7-454f-92a8-edac098c9734",
   "metadata": {},
   "source": [
    "### Process dataframe"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fa7acb86-d464-4741-8d52-18cf5dcefc97",
   "metadata": {},
   "source": [
    "df = df[df['Annotations'].notna()].reset_index()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fa87426c-ccab-482d-9e74-0b54cffad22c",
   "metadata": {},
   "source": [
    "df[['raw_emotion', 'raw_speaker_id']] = df['Annotations'].str.split('\\n\\n', expand=True, n=1)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ee138e1b-31c8-40d2-930f-c536c1fdb029",
   "metadata": {},
   "source": [
    "def process_emotion(x):\n",
    "\n",
    "    raw_emotion = x.raw_emotion\n",
    "    try:\n",
    "        emotion = raw_emotion.split(\"\\n\")[1].split(\":\")[1]\n",
    "    except:\n",
    "        emotion = \"no annotation\"\n",
    "\n",
    "    return emotion"
   ]
  },
  {
   "cell_type": "raw",
   "id": "419c11f0-da0c-43f8-be68-1ec142ef648a",
   "metadata": {},
   "source": [
    "df['emotion'] = df.apply(lambda x: process_emotion(x), axis=1)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c7fc16d6-dde5-4ce5-a112-8da476d95aa7",
   "metadata": {},
   "source": [
    "def process_speaker(x):\n",
    "\n",
    "    raw_speaker_id = x.raw_speaker_id\n",
    "    \n",
    "    try:\n",
    "        if 'SpokenBy:' in raw_speaker_id.split(\"\\n\")[0]:\n",
    "            speaker_id = raw_speaker_id.split(\"\\n\")[0].split(\":\")[1]\n",
    "            \n",
    "        elif 'SpokenBy:' in raw_speaker_id.split(\"\\n\")[1]:            \n",
    "            speaker_id = raw_speaker_id.split(\"\\n\")[1].split(\":\")[1]\n",
    "            \n",
    "        elif 'SpokenBy:' in raw_speaker_id.split(\"\\n\")[2]:            \n",
    "            speaker_id = raw_speaker_id.split(\"\\n\")[2].split(\":\")[1]\n",
    "\n",
    "        return speaker_id\n",
    "            \n",
    "    except:\n",
    "        \n",
    "        speaker_id = \"no annotation\"\n",
    "\n",
    "        return speaker_id"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bcad10dc-2ae7-442d-9112-afc646094d8a",
   "metadata": {},
   "source": [
    "df['speaker_id'] = df.apply(lambda x: process_speaker(x), axis=1)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9cf0cfbb-2efc-46c7-b3c9-108b1225e286",
   "metadata": {},
   "source": [
    "df = df.drop(columns=['index', 'Translated text in Spanish; Castilian', 'Number of words.1', 'Signs with spaces.1', 'Signs without spaces.1'])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "285a4afa-3e07-4743-9a36-fd54b6251132",
   "metadata": {},
   "source": [
    "df = df.rename(columns={'Source text in English': 'utterance', 'Annotations': 'raw_annotation'})"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ad210f9e-c573-40fa-9e14-ce57480d51b9",
   "metadata": {},
   "source": [
    "df = df.drop(columns=['Number of words', 'Signs with spaces', 'Signs without spaces'])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "986d1996-d362-44c2-8c4d-0a58834ad2ee",
   "metadata": {},
   "source": [
    "df = df.rename(columns={'Page': 'page_nr', 'Panel': 'panel_nr', 'Balloon': 'balloon_nr'})"
   ]
  },
  {
   "cell_type": "raw",
   "id": "06b18eea-2360-4749-a8eb-474e85580504",
   "metadata": {},
   "source": [
    "df = df[['file_name', 'page_nr', 'panel_nr', 'balloon_nr', 'utterance', 'raw_annotation', 'raw_emotion', 'raw_speaker_id', 'emotion', 'speaker_id']]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1395b65b-de47-454f-97f7-eb78bdc766fb",
   "metadata": {},
   "source": [
    "### train-test-split"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9738d917-318e-4c5d-9f57-bf76173fbc0c",
   "metadata": {},
   "source": [
    "titles_list = list(df.file_name.unique())\n",
    "num_train = int(len(titles_list) * 0.7)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2f73f881-4353-4546-aba1-4a53383e3187",
   "metadata": {},
   "source": [
    "train_titles = random.sample(titles_list, num_train)\n",
    "test_titles = [title for title in titles_list if title not in train_titles]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e017fd14-b744-49ab-b29f-7909292c7f53",
   "metadata": {},
   "source": [
    "df['split'] = df['file_name'].apply(lambda x: 'TRAIN' if x in train_titles else ('TEST' if x in test_titles else 'UNKNOWN'))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e5477b81-f121-4e90-9732-0357631061b1",
   "metadata": {},
   "source": [
    "#### clean dataframe"
   ]
  },
  {
   "cell_type": "raw",
   "id": "dd608937-ff7d-44c4-8e82-8cc68a1dfdaa",
   "metadata": {},
   "source": [
    "wrong_idx = [1093, 26, 1447]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "82a56ed3-917f-41ea-82fb-9f3f134b4c94",
   "metadata": {},
   "source": [
    "df = df.drop(df.index[wrong_idx]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1a27101b-68cd-473f-861d-d21d639d1f99",
   "metadata": {},
   "source": [
    "speaker = df.iloc[1129]['raw_annotation'].split(\"\\n\\n\")[0].split(\":\")[1]\n",
    "emotion = df.iloc[1129]['raw_annotation'].split(\"\\n\\n\")[1].split(\":\")[1]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "51768703-78a4-4ff8-b3ed-4a109c7cee14",
   "metadata": {},
   "source": [
    "df.iloc[1129, 8] = emotion\n",
    "df.iloc[1129, 9] = speaker"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5f97acc2-bfd0-44f6-bc8b-a1a4389277c0",
   "metadata": {},
   "source": [
    "speaker = df.iloc[1411]['raw_annotation'].split(\"\\n\\n\")[0].split(\":\")[1]\n",
    "emotion = df.iloc[1411]['raw_annotation'].split(\"\\n\\n\")[1].split(\":\")[1]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "dccd6de8-6d6e-4211-b5de-c55c961062e6",
   "metadata": {},
   "source": [
    "df.iloc[1411, 8] = emotion\n",
    "df.iloc[1411, 9] = speaker"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3efb2cf1-434f-46c8-944a-6d0f3cb6ee72",
   "metadata": {},
   "source": [
    "df = df[df.emotion != \"no annotation\"].reset_index()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2e8e8473-7a70-4ed4-a2c9-7040b58a3675",
   "metadata": {},
   "source": [
    "df.to_csv(\"comics_data_processed.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7faa0984-9f2f-4ffc-8a66-2c207881942c",
   "metadata": {},
   "source": [
    "### dataframe grouped by titles"
   ]
  },
  {
   "cell_type": "raw",
   "id": "14b533e7-a75e-4f5e-9291-2189777c132b",
   "metadata": {},
   "source": [
    "df_by_title = df.groupby('file_name').agg({'utterance': list, 'emotion': list, 'split': set}).reset_index()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "56ab124c-aa11-4303-8ba3-cf6b5aa9146e",
   "metadata": {},
   "source": [
    "def get_full_title_text(x):\n",
    "\n",
    "    list_utterances = x.utterance\n",
    "    full_title_text = ' '.join(list_utterances)\n",
    "\n",
    "    return full_title_text"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8a9ac937-0853-41b6-9111-a196ef4ce719",
   "metadata": {},
   "source": [
    "df_by_title['full_title_text'] = df_by_title.apply(lambda x: get_full_title_text(x), axis=1)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f54b81c5-c153-4dd2-b915-8dee4cb43d9b",
   "metadata": {},
   "source": [
    "df_by_title = df_by_title.rename(columns={'utterance': 'utterances_l', 'emotion': 'emotions_l'})"
   ]
  },
  {
   "cell_type": "raw",
   "id": "16149b7a-e5a4-4ef4-a0ab-16a6bd5c723b",
   "metadata": {},
   "source": [
    "def process_split(x):\n",
    "\n",
    "    return list(x.split)[0]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6a9ed0e9-c581-457a-bd16-4daac27cba0f",
   "metadata": {},
   "source": [
    "df_by_title['split'] = df_by_title.apply(lambda x: process_split(x), axis=1)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2c6b1156-f57d-469d-944c-e33cf48ee70c",
   "metadata": {},
   "source": [
    "def find_utterance_indices(row):\n",
    "\n",
    "    title_text = row.full_title_text\n",
    "    utterances_l = row.utterances_l\n",
    "\n",
    "    start_indices = []\n",
    "    end_indices = []\n",
    "    \n",
    "    for utterance in utterances_l:\n",
    "        start = title_text.find(utterance)\n",
    "        if start != -1:\n",
    "            # Append the start index and calculate the end index\n",
    "            start_indices.append(start)\n",
    "            end_indices.append(start + len(utterance))\n",
    "        else:\n",
    "            # If substring not found, append -1 to both lists\n",
    "            start_indices.append(-1)\n",
    "            end_indices.append(-1)\n",
    "    \n",
    "    return start_indices, end_indices"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b98d9c86-9518-4cb0-9acc-de8e6185536c",
   "metadata": {},
   "source": [
    "df_by_title['start_indices', 'end_indices'] = df_by_title.apply(lambda row: find_utterance_indices(row), axis=1)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fbffa338-d4bf-4968-a716-32e3c3e22d35",
   "metadata": {},
   "source": [
    "df_by_title[['start_indices', 'end_indices']] = pd.DataFrame(df_by_title[('start_indices', 'end_indices')].tolist(), index=df_by_title.index)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f2ac3737-85cc-49c4-8ce2-91f2e957c112",
   "metadata": {},
   "source": [
    "df_by_title.to_csv(\"comics_data_by_title.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f2fa22-35d5-41aa-abf1-5a9987ee0b08",
   "metadata": {},
   "source": [
    "### Prepare prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3fd57164",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Formatting Fx\n",
    "# Build questoin\n",
    "# Build answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb67bd9e-9e45-4e9c-8e5d-bc18bbb4f617",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'index', 'file_name', 'page_nr', 'panel_nr', 'balloon_nr',\n",
       "       'utterance', 'raw_annotation', 'raw_emotion', 'raw_speaker_id',\n",
       "       'emotion', 'speaker_id', 'split'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "608f81e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def formatting_fct(instruction=\"\", input=\"\", output=\"\"):\n",
    "    \n",
    "    prompt_d ={\n",
    "            \n",
    "        \"instruction\": f\"\"\"{instruction}\"\"\",\n",
    "        \"input\": f\"\"\"{input}\"\"\",\n",
    "        \"output\": f\"\"\"{output}\"\"\"\n",
    "            \n",
    "        }\n",
    "    \n",
    "    return prompt_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b107f77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_instruction():\n",
    "\n",
    "    #results = json.dumps([\"emotion_class (str)\"] * nr_utterances)\n",
    "\n",
    "    instruction = f\"\"\"### You are an expert in Emotion Analysis. You are given an utternace from a comic book enclosed by <UT></UT> tags. Your task is to classify each utterance as one or more the following emotion classes: \"Anger\" (AN), \"Disgust\" (DI), \"Fear\" (FE), \"Sadness\" (SA), \"Surprise\" (SU) or \"Joy\" (JO). You must return a list of emotion classes in following JSON format: {{\"list_emotion_classes\": [\"emotion_class (str)\", \"emotion_class (str)\" ... \"emotion_class (str)\"]}} where each element \"emotion_classes (str)\" is replaced by one ore more of the following abbreviated emotion class labels: \"AN\", \"DI\", \"FE\", \"SA\", \"SU\" or \"JO\". \n",
    "\"\"\"    \n",
    "    return instruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1144129e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def build_tagged_text(text, start_indices, end_indices):\n",
    "\n",
    "#     offset = 0\n",
    "\n",
    "#     for i, (start_i, end_i) in enumerate(zip(start_indices, end_indices)):\n",
    "            \n",
    "#         start_tag = \"<UT\" + str(i+1) + \">\"\n",
    "#         end_tag = \"</UT\" + str(i+1) + \">\"\n",
    "        \n",
    "#         start_idx = start_i + offset\n",
    "#         end_idx = end_i + offset\n",
    "\n",
    "#         offset = offset + (len(start_tag)  + len(end_tag))\n",
    "        \n",
    "#         text_r = text[start_idx:end_idx]\n",
    "#         new_text = start_tag + text_r + end_tag\n",
    "#         text = text.replace(text_r, new_text)\n",
    "\n",
    "#         question = f\"\"\"### Here is the comic transcript: {text}\"\"\"\n",
    "\n",
    "#     return question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "44e9dbd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_tagged_text(utterance):\n",
    "\n",
    "    # tagged_utterances_l = []\n",
    "\n",
    "    # for idx, utterance in enumerate(utterances_l):\n",
    "        \n",
    "    #     start_tag = \"<UT\" + str(idx+1) + \">\"\n",
    "    #     end_tag = \"</UT\" + str(idx+1) + \">\"\n",
    "    #     tagged_utterance = start_tag + utterance + end_tag\n",
    "    #     tagged_utterances_l.append(tagged_utterance)\n",
    "        \n",
    "    # tagged_title_text = ''.join(tagged_utterances_l)\n",
    "    \n",
    "    tagged_utterance = \"<UT>\" + utterance + \"</UT>\"\n",
    "    question = f\"\"\"### Here is the utterance from a comic book: {tagged_utterance}\"\"\"\n",
    "\n",
    "    return question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "539b6d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_answer(utterance_emotions):\n",
    "\n",
    "    utterance_emotions_l = []\n",
    "    emotion_class_labels = [\"Anger\", \"Disgust\", \"Fear\", \"Sadness\", \"Surprise\", \"Joy\"]\n",
    "\n",
    "    if utterance_emotions == 'Neutral':\n",
    "        \n",
    "        utterance_emotions_l.append([utterance_emotions])\n",
    "    \n",
    "    else:\n",
    "        utterance_emotions = utterance_emotions.split(\"-\")\n",
    "       \n",
    "        #emotion_annotation_l = []\n",
    "\n",
    "        for idx, emotion_annotation in enumerate(utterance_emotions):\n",
    "\n",
    "            if '0' not in emotion_annotation:\n",
    "         \n",
    "                #emotion_annotation_l.append(emotion_class_labels[idx])\n",
    "                utterance_emotions_l.append(emotion_annotation[:-1])\n",
    "            \n",
    "        #title_emotions_l.append(emotion_annotation_l)\n",
    "                \n",
    "\n",
    "    return json.dumps({\"list_emotion_classes\": utterance_emotions_l})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd67b57",
   "metadata": {},
   "source": [
    "### Build Data Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "85fd7584",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df[df.split == 'TRAIN'].reset_index()\n",
    "\n",
    "data_file_train = []\n",
    "\n",
    "for index, _ in df_train.iterrows():\n",
    "    \n",
    "    i = index\n",
    "\n",
    "    instruction = build_instruction()\n",
    "    question = build_tagged_text(df_train.iloc[i].utterance)\n",
    "    answer = build_answer(df_train.iloc[i].emotion)\n",
    "    \n",
    "    data_file_train.append( formatting_fct(instruction, question, answer) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "181fe00c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3506"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_file_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f7a42377",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'instruction': '### You are an expert in Emotion Analysis. You are given an utternace from a comic book enclosed by <UT></UT> tags. Your task is to classify each utterance as one or more the following emotion classes: \"Anger\" (AN), \"Disgust\" (DI), \"Fear\" (FE), \"Sadness\" (SA), \"Surprise\" (SU) or \"Joy\" (JO). You must return a list of emotion classes in following JSON format: {\"list_emotion_classes\": [\"emotion_class (str)\", \"emotion_class (str)\" ... \"emotion_class (str)\"]} where each element \"emotion_classes (str)\" is replaced by one ore more of the following abbreviated emotion class labels: \"AN\", \"DI\", \"FE\", \"SA\", \"SU\" or \"JO\". \\n', 'input': '### Here is the utterance from a comic book: <UT>DID YOU HAVE TO ELECTROCUTE HER SO HARD?</UT>', 'output': '{\"list_emotion_classes\": [\"FE\", \"SU\"]}'}\n",
      "{'instruction': '### You are an expert in Emotion Analysis. You are given an utternace from a comic book enclosed by <UT></UT> tags. Your task is to classify each utterance as one or more the following emotion classes: \"Anger\" (AN), \"Disgust\" (DI), \"Fear\" (FE), \"Sadness\" (SA), \"Surprise\" (SU) or \"Joy\" (JO). You must return a list of emotion classes in following JSON format: {\"list_emotion_classes\": [\"emotion_class (str)\", \"emotion_class (str)\" ... \"emotion_class (str)\"]} where each element \"emotion_classes (str)\" is replaced by one ore more of the following abbreviated emotion class labels: \"AN\", \"DI\", \"FE\", \"SA\", \"SU\" or \"JO\". \\n', 'input': \"### Here is the utterance from a comic book: <UT>IT'S NOT LIKE I HAVE DIFFERENT SETTINGS.</UT>\", 'output': '{\"list_emotion_classes\": [\"SU\"]}'}\n",
      "{'instruction': '### You are an expert in Emotion Analysis. You are given an utternace from a comic book enclosed by <UT></UT> tags. Your task is to classify each utterance as one or more the following emotion classes: \"Anger\" (AN), \"Disgust\" (DI), \"Fear\" (FE), \"Sadness\" (SA), \"Surprise\" (SU) or \"Joy\" (JO). You must return a list of emotion classes in following JSON format: {\"list_emotion_classes\": [\"emotion_class (str)\", \"emotion_class (str)\" ... \"emotion_class (str)\"]} where each element \"emotion_classes (str)\" is replaced by one ore more of the following abbreviated emotion class labels: \"AN\", \"DI\", \"FE\", \"SA\", \"SU\" or \"JO\". \\n', 'input': \"### Here is the utterance from a comic book: <UT>YOU'RE ELECTROCUTIONER. IT'S YOUR WHOLE THING. YOU'D THINK YOU'D HAVE SOME DEGREE OF CONTROL?</UT>\", 'output': '{\"list_emotion_classes\": [\"FE\"]}'}\n",
      "{'instruction': '### You are an expert in Emotion Analysis. You are given an utternace from a comic book enclosed by <UT></UT> tags. Your task is to classify each utterance as one or more the following emotion classes: \"Anger\" (AN), \"Disgust\" (DI), \"Fear\" (FE), \"Sadness\" (SA), \"Surprise\" (SU) or \"Joy\" (JO). You must return a list of emotion classes in following JSON format: {\"list_emotion_classes\": [\"emotion_class (str)\", \"emotion_class (str)\" ... \"emotion_class (str)\"]} where each element \"emotion_classes (str)\" is replaced by one ore more of the following abbreviated emotion class labels: \"AN\", \"DI\", \"FE\", \"SA\", \"SU\" or \"JO\". \\n', 'input': \"### Here is the utterance from a comic book: <UT>OH, HEY. I THINK SHE'S AWAKE.</UT>\", 'output': '{\"list_emotion_classes\": [\"SU\"]}'}\n",
      "{'instruction': '### You are an expert in Emotion Analysis. You are given an utternace from a comic book enclosed by <UT></UT> tags. Your task is to classify each utterance as one or more the following emotion classes: \"Anger\" (AN), \"Disgust\" (DI), \"Fear\" (FE), \"Sadness\" (SA), \"Surprise\" (SU) or \"Joy\" (JO). You must return a list of emotion classes in following JSON format: {\"list_emotion_classes\": [\"emotion_class (str)\", \"emotion_class (str)\" ... \"emotion_class (str)\"]} where each element \"emotion_classes (str)\" is replaced by one ore more of the following abbreviated emotion class labels: \"AN\", \"DI\", \"FE\", \"SA\", \"SU\" or \"JO\". \\n', 'input': '### Here is the utterance from a comic book: <UT>WELCOME BACK, MADAM MAYOR. BLOCKBUSTER IS PRETTY PISSED WITH YOU.</UT>', 'output': '{\"list_emotion_classes\": [\"AN\"]}'}\n",
      "{'instruction': '### You are an expert in Emotion Analysis. You are given an utternace from a comic book enclosed by <UT></UT> tags. Your task is to classify each utterance as one or more the following emotion classes: \"Anger\" (AN), \"Disgust\" (DI), \"Fear\" (FE), \"Sadness\" (SA), \"Surprise\" (SU) or \"Joy\" (JO). You must return a list of emotion classes in following JSON format: {\"list_emotion_classes\": [\"emotion_class (str)\", \"emotion_class (str)\" ... \"emotion_class (str)\"]} where each element \"emotion_classes (str)\" is replaced by one ore more of the following abbreviated emotion class labels: \"AN\", \"DI\", \"FE\", \"SA\", \"SU\" or \"JO\". \\n', 'input': \"### Here is the utterance from a comic book: <UT>HE KNOWS YOU'RE WORKING WITH DICK GRAYSON.</UT>\", 'output': '{\"list_emotion_classes\": [\"AN\", \"SU\"]}'}\n",
      "{'instruction': '### You are an expert in Emotion Analysis. You are given an utternace from a comic book enclosed by <UT></UT> tags. Your task is to classify each utterance as one or more the following emotion classes: \"Anger\" (AN), \"Disgust\" (DI), \"Fear\" (FE), \"Sadness\" (SA), \"Surprise\" (SU) or \"Joy\" (JO). You must return a list of emotion classes in following JSON format: {\"list_emotion_classes\": [\"emotion_class (str)\", \"emotion_class (str)\" ... \"emotion_class (str)\"]} where each element \"emotion_classes (str)\" is replaced by one ore more of the following abbreviated emotion class labels: \"AN\", \"DI\", \"FE\", \"SA\", \"SU\" or \"JO\". \\n', 'input': '### Here is the utterance from a comic book: <UT>HE WANTS ME TO GET INFORMATION OUT OF YOU.</UT>', 'output': '{\"list_emotion_classes\": [\"JO\"]}'}\n",
      "{'instruction': '### You are an expert in Emotion Analysis. You are given an utternace from a comic book enclosed by <UT></UT> tags. Your task is to classify each utterance as one or more the following emotion classes: \"Anger\" (AN), \"Disgust\" (DI), \"Fear\" (FE), \"Sadness\" (SA), \"Surprise\" (SU) or \"Joy\" (JO). You must return a list of emotion classes in following JSON format: {\"list_emotion_classes\": [\"emotion_class (str)\", \"emotion_class (str)\" ... \"emotion_class (str)\"]} where each element \"emotion_classes (str)\" is replaced by one ore more of the following abbreviated emotion class labels: \"AN\", \"DI\", \"FE\", \"SA\", \"SU\" or \"JO\". \\n', 'input': \"### Here is the utterance from a comic book: <UT>SHE'S AWAKE, BOSS. SHE--</UT>\", 'output': '{\"list_emotion_classes\": [\"JO\"]}'}\n",
      "{'instruction': '### You are an expert in Emotion Analysis. You are given an utternace from a comic book enclosed by <UT></UT> tags. Your task is to classify each utterance as one or more the following emotion classes: \"Anger\" (AN), \"Disgust\" (DI), \"Fear\" (FE), \"Sadness\" (SA), \"Surprise\" (SU) or \"Joy\" (JO). You must return a list of emotion classes in following JSON format: {\"list_emotion_classes\": [\"emotion_class (str)\", \"emotion_class (str)\" ... \"emotion_class (str)\"]} where each element \"emotion_classes (str)\" is replaced by one ore more of the following abbreviated emotion class labels: \"AN\", \"DI\", \"FE\", \"SA\", \"SU\" or \"JO\". \\n', 'input': '### Here is the utterance from a comic book: <UT>CAN YOU WALK?</UT>', 'output': '{\"list_emotion_classes\": [\"FE\"]}'}\n",
      "{'instruction': '### You are an expert in Emotion Analysis. You are given an utternace from a comic book enclosed by <UT></UT> tags. Your task is to classify each utterance as one or more the following emotion classes: \"Anger\" (AN), \"Disgust\" (DI), \"Fear\" (FE), \"Sadness\" (SA), \"Surprise\" (SU) or \"Joy\" (JO). You must return a list of emotion classes in following JSON format: {\"list_emotion_classes\": [\"emotion_class (str)\", \"emotion_class (str)\" ... \"emotion_class (str)\"]} where each element \"emotion_classes (str)\" is replaced by one ore more of the following abbreviated emotion class labels: \"AN\", \"DI\", \"FE\", \"SA\", \"SU\" or \"JO\". \\n', 'input': '### Here is the utterance from a comic book: <UT>HOW DID YOU FIND ME?</UT>', 'output': '{\"list_emotion_classes\": [\"SU\"]}'}\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(data_file_train[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "91becc82",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df[df.split == 'TEST'].reset_index()\n",
    "\n",
    "data_file_test = []\n",
    "\n",
    "for index, _ in df_test.iterrows():\n",
    "    \n",
    "    i = index\n",
    "\n",
    "    instruction = build_instruction()\n",
    "    question = build_tagged_text(df_test.iloc[i].utterance)\n",
    "    answer = build_answer(df_test.iloc[i].emotion)\n",
    "    \n",
    "    data_file_test.append( formatting_fct(instruction, question, answer) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "96669b4f-b279-48ba-8b9b-d04f91d49c67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1776"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6e2c531d-d86d-4289-8f3d-d00fd56d0051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'instruction': '### You are an expert in Emotion Analysis. You are given an utternace from a comic book enclosed by <UT></UT> tags. Your task is to classify each utterance as one or more the following emotion classes: \"Anger\" (AN), \"Disgust\" (DI), \"Fear\" (FE), \"Sadness\" (SA), \"Surprise\" (SU) or \"Joy\" (JO). You must return a list of emotion classes in following JSON format: {\"list_emotion_classes\": [\"emotion_class (str)\", \"emotion_class (str)\" ... \"emotion_class (str)\"]} where each element \"emotion_classes (str)\" is replaced by one ore more of the following abbreviated emotion class labels: \"AN\", \"DI\", \"FE\", \"SA\", \"SU\" or \"JO\". \\n', 'input': \"### Here is the utterance from a comic book: <UT>HOW'S IT GOING?</UT>\", 'output': '{\"list_emotion_classes\": [\"SU\", \"JO\"]}'}\n",
      "{'instruction': '### You are an expert in Emotion Analysis. You are given an utternace from a comic book enclosed by <UT></UT> tags. Your task is to classify each utterance as one or more the following emotion classes: \"Anger\" (AN), \"Disgust\" (DI), \"Fear\" (FE), \"Sadness\" (SA), \"Surprise\" (SU) or \"Joy\" (JO). You must return a list of emotion classes in following JSON format: {\"list_emotion_classes\": [\"emotion_class (str)\", \"emotion_class (str)\" ... \"emotion_class (str)\"]} where each element \"emotion_classes (str)\" is replaced by one ore more of the following abbreviated emotion class labels: \"AN\", \"DI\", \"FE\", \"SA\", \"SU\" or \"JO\". \\n', 'input': '### Here is the utterance from a comic book: <UT>HEY.</UT>', 'output': '{\"list_emotion_classes\": [\"JO\"]}'}\n",
      "{'instruction': '### You are an expert in Emotion Analysis. You are given an utternace from a comic book enclosed by <UT></UT> tags. Your task is to classify each utterance as one or more the following emotion classes: \"Anger\" (AN), \"Disgust\" (DI), \"Fear\" (FE), \"Sadness\" (SA), \"Surprise\" (SU) or \"Joy\" (JO). You must return a list of emotion classes in following JSON format: {\"list_emotion_classes\": [\"emotion_class (str)\", \"emotion_class (str)\" ... \"emotion_class (str)\"]} where each element \"emotion_classes (str)\" is replaced by one ore more of the following abbreviated emotion class labels: \"AN\", \"DI\", \"FE\", \"SA\", \"SU\" or \"JO\". \\n', 'input': '### Here is the utterance from a comic book: <UT>CAN I GET YOU ANYTHING?</UT>', 'output': '{\"list_emotion_classes\": [\"SU\", \"JO\"]}'}\n",
      "{'instruction': '### You are an expert in Emotion Analysis. You are given an utternace from a comic book enclosed by <UT></UT> tags. Your task is to classify each utterance as one or more the following emotion classes: \"Anger\" (AN), \"Disgust\" (DI), \"Fear\" (FE), \"Sadness\" (SA), \"Surprise\" (SU) or \"Joy\" (JO). You must return a list of emotion classes in following JSON format: {\"list_emotion_classes\": [\"emotion_class (str)\", \"emotion_class (str)\" ... \"emotion_class (str)\"]} where each element \"emotion_classes (str)\" is replaced by one ore more of the following abbreviated emotion class labels: \"AN\", \"DI\", \"FE\", \"SA\", \"SU\" or \"JO\". \\n', 'input': '### Here is the utterance from a comic book: <UT>JUST A COKE.</UT>', 'output': '{\"list_emotion_classes\": [\"JO\"]}'}\n",
      "{'instruction': '### You are an expert in Emotion Analysis. You are given an utternace from a comic book enclosed by <UT></UT> tags. Your task is to classify each utterance as one or more the following emotion classes: \"Anger\" (AN), \"Disgust\" (DI), \"Fear\" (FE), \"Sadness\" (SA), \"Surprise\" (SU) or \"Joy\" (JO). You must return a list of emotion classes in following JSON format: {\"list_emotion_classes\": [\"emotion_class (str)\", \"emotion_class (str)\" ... \"emotion_class (str)\"]} where each element \"emotion_classes (str)\" is replaced by one ore more of the following abbreviated emotion class labels: \"AN\", \"DI\", \"FE\", \"SA\", \"SU\" or \"JO\". \\n', 'input': '### Here is the utterance from a comic book: <UT>OKAY. COMING UP.</UT>', 'output': '{\"list_emotion_classes\": [\"JO\"]}'}\n",
      "{'instruction': '### You are an expert in Emotion Analysis. You are given an utternace from a comic book enclosed by <UT></UT> tags. Your task is to classify each utterance as one or more the following emotion classes: \"Anger\" (AN), \"Disgust\" (DI), \"Fear\" (FE), \"Sadness\" (SA), \"Surprise\" (SU) or \"Joy\" (JO). You must return a list of emotion classes in following JSON format: {\"list_emotion_classes\": [\"emotion_class (str)\", \"emotion_class (str)\" ... \"emotion_class (str)\"]} where each element \"emotion_classes (str)\" is replaced by one ore more of the following abbreviated emotion class labels: \"AN\", \"DI\", \"FE\", \"SA\", \"SU\" or \"JO\". \\n', 'input': '### Here is the utterance from a comic book: <UT>THANKS.</UT>', 'output': '{\"list_emotion_classes\": [\"JO\"]}'}\n",
      "{'instruction': '### You are an expert in Emotion Analysis. You are given an utternace from a comic book enclosed by <UT></UT> tags. Your task is to classify each utterance as one or more the following emotion classes: \"Anger\" (AN), \"Disgust\" (DI), \"Fear\" (FE), \"Sadness\" (SA), \"Surprise\" (SU) or \"Joy\" (JO). You must return a list of emotion classes in following JSON format: {\"list_emotion_classes\": [\"emotion_class (str)\", \"emotion_class (str)\" ... \"emotion_class (str)\"]} where each element \"emotion_classes (str)\" is replaced by one ore more of the following abbreviated emotion class labels: \"AN\", \"DI\", \"FE\", \"SA\", \"SU\" or \"JO\". \\n', 'input': '### Here is the utterance from a comic book: <UT>HOW IS IT OUT THERE? GETTING HOT?</UT>', 'output': '{\"list_emotion_classes\": [\"SU\"]}'}\n",
      "{'instruction': '### You are an expert in Emotion Analysis. You are given an utternace from a comic book enclosed by <UT></UT> tags. Your task is to classify each utterance as one or more the following emotion classes: \"Anger\" (AN), \"Disgust\" (DI), \"Fear\" (FE), \"Sadness\" (SA), \"Surprise\" (SU) or \"Joy\" (JO). You must return a list of emotion classes in following JSON format: {\"list_emotion_classes\": [\"emotion_class (str)\", \"emotion_class (str)\" ... \"emotion_class (str)\"]} where each element \"emotion_classes (str)\" is replaced by one ore more of the following abbreviated emotion class labels: \"AN\", \"DI\", \"FE\", \"SA\", \"SU\" or \"JO\". \\n', 'input': \"### Here is the utterance from a comic book: <UT>IT'S ALL RIGHT.</UT>\", 'output': '{\"list_emotion_classes\": [\"JO\"]}'}\n",
      "{'instruction': '### You are an expert in Emotion Analysis. You are given an utternace from a comic book enclosed by <UT></UT> tags. Your task is to classify each utterance as one or more the following emotion classes: \"Anger\" (AN), \"Disgust\" (DI), \"Fear\" (FE), \"Sadness\" (SA), \"Surprise\" (SU) or \"Joy\" (JO). You must return a list of emotion classes in following JSON format: {\"list_emotion_classes\": [\"emotion_class (str)\", \"emotion_class (str)\" ... \"emotion_class (str)\"]} where each element \"emotion_classes (str)\" is replaced by one ore more of the following abbreviated emotion class labels: \"AN\", \"DI\", \"FE\", \"SA\", \"SU\" or \"JO\". \\n', 'input': '### Here is the utterance from a comic book: <UT>ONE COKE. ENJOY.</UT>', 'output': '{\"list_emotion_classes\": [\"JO\"]}'}\n",
      "{'instruction': '### You are an expert in Emotion Analysis. You are given an utternace from a comic book enclosed by <UT></UT> tags. Your task is to classify each utterance as one or more the following emotion classes: \"Anger\" (AN), \"Disgust\" (DI), \"Fear\" (FE), \"Sadness\" (SA), \"Surprise\" (SU) or \"Joy\" (JO). You must return a list of emotion classes in following JSON format: {\"list_emotion_classes\": [\"emotion_class (str)\", \"emotion_class (str)\" ... \"emotion_class (str)\"]} where each element \"emotion_classes (str)\" is replaced by one ore more of the following abbreviated emotion class labels: \"AN\", \"DI\", \"FE\", \"SA\", \"SU\" or \"JO\". \\n', 'input': '### Here is the utterance from a comic book: <UT>@ONCE UPON A TIME…</UT>', 'output': '{\"list_emotion_classes\": [[\"Neutral\"]]}'}\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(data_file_test[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb35781",
   "metadata": {},
   "source": [
    "### Create and save JSON files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "01306b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = os.path.join(os.getcwd(), \"../datasets/comics_utterance_train.json\")\n",
    "\n",
    "with open(file_path, 'w') as file:\n",
    "    \n",
    "    json.dump(data_file_train, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9b6f5885",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = os.path.join(os.getcwd(), \"../datasets/comics_utterance_test.json\")\n",
    "\n",
    "with open(file_path, 'w') as file:\n",
    "    \n",
    "    json.dump(data_file_test, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f7e522",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
