{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d48c7115",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 3,
     "id": "db736e14-03fb-4438-938d-c705d6786666",
     "kernelId": "5ae81875-6bf9-4a4d-b9d2-28830bffd5f4"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "# import pandas as pd\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import transformers\n",
    "from transformers import Trainer\n",
    "from transformers import BertTokenizer\n",
    "from transformers import BertForSequenceClassification\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers.data.data_collator import DataCollatorWithPadding\n",
    "\n",
    "import datasets\n",
    "from datasets import Dataset\n",
    "from datasets import ClassLabel\n",
    "from datasets import load_metric\n",
    "\n",
    "import evaluate # type: ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b0d459f",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "37286c02-6bf4-41f5-ab70-51515a054e7b",
     "kernelId": "5ae81875-6bf9-4a4d-b9d2-28830bffd5f4"
    }
   },
   "source": [
    "## Global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d2e73f1",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 2,
     "id": "0c699094-439f-4dda-85a9-815e7948540c",
     "kernelId": "5ae81875-6bf9-4a4d-b9d2-28830bffd5f4"
    }
   },
   "outputs": [],
   "source": [
    "DATASET_FOLDER = Path('emotion_analysis_comics/dataset_files')\n",
    "# DATA_FILE = 'emotion_analysis_comics/bert/datasets/comics_dataset_35.pt'\n",
    "RESULTS_FOLDER = 'emotion_analysis_comics/bert/outputs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25cd7cc9",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 3,
     "id": "35aada91-232a-421e-a28f-94b359c6d65d",
     "kernelId": "5ae81875-6bf9-4a4d-b9d2-28830bffd5f4"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f26bac23",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 4,
     "id": "dc52e71e-65fa-4946-acdf-e4fffe9d0f79",
     "kernelId": "5ae81875-6bf9-4a4d-b9d2-28830bffd5f4"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fbd7f91",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "013a6d64-65e7-4189-a468-40ecfd8a6736",
     "kernelId": "5ae81875-6bf9-4a4d-b9d2-28830bffd5f4"
    }
   },
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16553ed1",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 5,
     "id": "626737f9-ff56-4992-b72b-60750375e455",
     "kernelId": "5ae81875-6bf9-4a4d-b9d2-28830bffd5f4"
    }
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(DATASET_FOLDER / \"comics_dataset_train.csv\")\n",
    "test_df = pd.read_csv(DATASET_FOLDER / \"comics_dataset_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65621b2b",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 6,
     "id": "4fbfcc7b-55fb-456e-ab02-2ae975803046",
     "kernelId": "5ae81875-6bf9-4a4d-b9d2-28830bffd5f4"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5803, 11), (1326, 11))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dfafb58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_map = {\n",
    "    'AN': 'anger',\n",
    "    'DI': 'disgust',\n",
    "    'FE': 'fear',\n",
    "    'SA': 'sadness',\n",
    "    'SU': 'surprise',\n",
    "    'JO': 'joy'\n",
    "}\n",
    "\n",
    "def extract_emotions(row):\n",
    "\n",
    "    emotion_str = row.emotion\n",
    "\n",
    "    if emotion_str == 'Neutral':\n",
    "        return ['neutral']\n",
    "\n",
    "    emotions = emotion_str.split('-')\n",
    "    tags = []\n",
    "\n",
    "    for emotion in emotions:\n",
    "        abbrev = emotion[:2]  # Get the abbreviation\n",
    "        value_part = emotion[2:]  # Get the value part\n",
    "        \n",
    "        # Ensure that the value part is a valid integer and abbrev is in the emotion_map\n",
    "        if abbrev in emotion_map and value_part.isdigit():\n",
    "            value = int(value_part)\n",
    "            if value > 0:\n",
    "                tag = emotion_map[abbrev].lower() + \":\" + str(value)\n",
    "                #tags.append(emotion_map[abbrev].lower())\n",
    "                tags.append(tag)\n",
    "        else:\n",
    "            print(f\"Warning: Skipping invalid emotion entry: '{emotion}'\")\n",
    "    return tags  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "27985d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['utterance_emotion'] = train_df.apply(lambda row: extract_emotions(row), axis=1)\n",
    "test_df['utterance_emotion'] = test_df.apply(lambda row: extract_emotions(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3611469f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_emotions_only(row):\n",
    "\n",
    "    emotion_l = []\n",
    "\n",
    "    for emotion in row.utterance_emotion:\n",
    "\n",
    "        if emotion == 'neutral':\n",
    "            emotion_l.append('neutral')\n",
    "        else:\n",
    "            emotion_l.append(emotion.split(\":\")[0])\n",
    "\n",
    "    return emotion_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c288e65c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['emotion_only'] = train_df.apply(lambda row: get_emotions_only(row), axis=1)\n",
    "test_df['emotion_only'] = test_df.apply(lambda row: get_emotions_only(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "af5da0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "\n",
    "mlb = MultiLabelBinarizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0410f65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['binarized_labels'] = mlb.fit_transform(train_df['emotion_only']).tolist() # type: ignore\n",
    "test_df['binarized_labels'] = mlb.fit_transform(test_df['emotion_only']).tolist() # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c47be6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset.from_pandas(train_df[['utterance', 'binarized_labels']])\n",
    "test_dataset = Dataset.from_pandas(test_df[['utterance', 'binarized_labels']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a5d23c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "768c27ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Utilisateurs/umushtaq/.conda/envs/er_nb_env/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fa45aa7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples['utterance'], padding=\"max_length\", truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "716c64a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f0252df886c48b6b3c09e5740358f8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5803 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "950b3c19201e42c18d41dfd71734f586",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1326 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
    "test_dataset = test_dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6ef30b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_labels(examples):\n",
    "    examples['labels'] = torch.tensor(examples['binarized_labels'], dtype=torch.float32)\n",
    "    return examples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "881a01c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f7e262f13f047d8a85897ce4d2b8846",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5803 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f3cf5270b5c44d480d399f9414a909b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1326 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_dataset = train_dataset.map(format_labels, batched=True)\n",
    "test_dataset = test_dataset.map(format_labels, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "48e4a8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_datasets = train_dataset.train_test_split(test_size=0.2)\n",
    "\n",
    "train_dataset = split_datasets['train']\n",
    "eval_dataset = split_datasets['test']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "35f7606d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['utterance', 'binarized_labels', 'input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 4642\n",
       "})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d24651ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['utterance', 'binarized_labels', 'input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 1161\n",
       "})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2e13bc81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# global variables\n",
    "NUM_LABELS = len(mlb.classes_)\n",
    "BATCH_SIZE = 128\n",
    "NB_EPOCHS = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "23519ec4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=NUM_LABELS, problem_type=\"multi_label_classification\", device_map='cuda')\n",
    "#model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9fe47db1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fd19f5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "def compute_metrics(p):\n",
    "    # Apply sigmoid to the logits to get probabilities for multilabel classification\n",
    "    preds = torch.sigmoid(torch.tensor(p.predictions)).numpy()\n",
    "\n",
    "    # Convert probabilities to binary predictions with threshold of 0.5\n",
    "    preds = np.where(preds > 0.5, 1, 0)\n",
    "\n",
    "    # Convert labels to numpy format\n",
    "    labels = p.label_ids\n",
    "\n",
    "    # Compute metrics (precision, recall, f1) for multilabel classification\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='macro')\n",
    "    \n",
    "    # Optionally calculate accuracy for multilabel (accuracy in multilabel can be tricky)\n",
    "    # Here, accuracy is the average of how many labels were correctly predicted per sample\n",
    "    accuracy = (preds == labels).mean()\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"f1\": f1,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f3548e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    \n",
    "    # output\n",
    "    output_dir=RESULTS_FOLDER,          \n",
    "    \n",
    "    # params\n",
    "    num_train_epochs=NB_EPOCHS,               # nb of epochs\n",
    "    per_device_train_batch_size=BATCH_SIZE,   # batch size per device during training\n",
    "    per_device_eval_batch_size=BATCH_SIZE,    # cf. paper Sun et al.\n",
    "    learning_rate=1e-5,#2e-5,                 # cf. paper Sun et al.\n",
    "#     warmup_steps=500,                         # number of warmup steps for learning rate scheduler\n",
    "    warmup_ratio=0.1,                         # cf. paper Sun et al.\n",
    "    weight_decay=0.01,                        # strength of weight decay\n",
    "    \n",
    "    # eval\n",
    "    eval_strategy=\"steps\",              # cf. paper Sun et al.\n",
    "    eval_steps=20,                            # cf. paper Sun et al.\n",
    "    \n",
    "    # log\n",
    "    logging_dir=\"emotion_analysis_comics/bert/logs\",  \n",
    "    logging_strategy='steps',\n",
    "    logging_steps=20,\n",
    "    \n",
    "    # save\n",
    "    save_strategy='steps',\n",
    "    save_total_limit=1,\n",
    "    # save_steps=20, # default 500\n",
    "    load_best_model_at_end=True,              # cf. paper Sun et al.\n",
    "    # metric_for_best_model='eval_loss' \n",
    "    metric_for_best_model='f1'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "296331c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics  # Custom metrics function\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e81a6059",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='740' max='740' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [740/740 35:30, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.649500</td>\n",
       "      <td>0.637006</td>\n",
       "      <td>0.633198</td>\n",
       "      <td>0.136773</td>\n",
       "      <td>0.132929</td>\n",
       "      <td>0.285887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.614600</td>\n",
       "      <td>0.579988</td>\n",
       "      <td>0.783930</td>\n",
       "      <td>0.067283</td>\n",
       "      <td>0.324263</td>\n",
       "      <td>0.047860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.540900</td>\n",
       "      <td>0.499175</td>\n",
       "      <td>0.793405</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.482700</td>\n",
       "      <td>0.467149</td>\n",
       "      <td>0.793528</td>\n",
       "      <td>0.000937</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.000470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.460900</td>\n",
       "      <td>0.453364</td>\n",
       "      <td>0.797342</td>\n",
       "      <td>0.037577</td>\n",
       "      <td>0.229592</td>\n",
       "      <td>0.021838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.448000</td>\n",
       "      <td>0.445267</td>\n",
       "      <td>0.804356</td>\n",
       "      <td>0.093359</td>\n",
       "      <td>0.213832</td>\n",
       "      <td>0.063270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.438100</td>\n",
       "      <td>0.437019</td>\n",
       "      <td>0.807678</td>\n",
       "      <td>0.112289</td>\n",
       "      <td>0.351292</td>\n",
       "      <td>0.076765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.425600</td>\n",
       "      <td>0.432352</td>\n",
       "      <td>0.811493</td>\n",
       "      <td>0.151294</td>\n",
       "      <td>0.450360</td>\n",
       "      <td>0.111808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.421600</td>\n",
       "      <td>0.427156</td>\n",
       "      <td>0.815430</td>\n",
       "      <td>0.197648</td>\n",
       "      <td>0.413575</td>\n",
       "      <td>0.144266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.410800</td>\n",
       "      <td>0.423386</td>\n",
       "      <td>0.818629</td>\n",
       "      <td>0.223215</td>\n",
       "      <td>0.393082</td>\n",
       "      <td>0.164793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.396300</td>\n",
       "      <td>0.418661</td>\n",
       "      <td>0.821582</td>\n",
       "      <td>0.241971</td>\n",
       "      <td>0.499866</td>\n",
       "      <td>0.178766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.391700</td>\n",
       "      <td>0.417287</td>\n",
       "      <td>0.818014</td>\n",
       "      <td>0.237121</td>\n",
       "      <td>0.456470</td>\n",
       "      <td>0.175250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.381800</td>\n",
       "      <td>0.414927</td>\n",
       "      <td>0.816907</td>\n",
       "      <td>0.266980</td>\n",
       "      <td>0.439937</td>\n",
       "      <td>0.213528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.372000</td>\n",
       "      <td>0.414803</td>\n",
       "      <td>0.820721</td>\n",
       "      <td>0.287910</td>\n",
       "      <td>0.450059</td>\n",
       "      <td>0.228048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.365000</td>\n",
       "      <td>0.414812</td>\n",
       "      <td>0.816661</td>\n",
       "      <td>0.300306</td>\n",
       "      <td>0.432763</td>\n",
       "      <td>0.248098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.353400</td>\n",
       "      <td>0.413631</td>\n",
       "      <td>0.816784</td>\n",
       "      <td>0.304517</td>\n",
       "      <td>0.424271</td>\n",
       "      <td>0.252048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.350400</td>\n",
       "      <td>0.414178</td>\n",
       "      <td>0.820352</td>\n",
       "      <td>0.330341</td>\n",
       "      <td>0.429543</td>\n",
       "      <td>0.275152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.342100</td>\n",
       "      <td>0.415860</td>\n",
       "      <td>0.816414</td>\n",
       "      <td>0.318870</td>\n",
       "      <td>0.420012</td>\n",
       "      <td>0.267519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>0.341100</td>\n",
       "      <td>0.416571</td>\n",
       "      <td>0.816537</td>\n",
       "      <td>0.330021</td>\n",
       "      <td>0.417931</td>\n",
       "      <td>0.282253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.324000</td>\n",
       "      <td>0.415298</td>\n",
       "      <td>0.818998</td>\n",
       "      <td>0.327634</td>\n",
       "      <td>0.425765</td>\n",
       "      <td>0.275291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.324600</td>\n",
       "      <td>0.418184</td>\n",
       "      <td>0.814077</td>\n",
       "      <td>0.330151</td>\n",
       "      <td>0.409506</td>\n",
       "      <td>0.284533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>0.320300</td>\n",
       "      <td>0.417666</td>\n",
       "      <td>0.816045</td>\n",
       "      <td>0.331928</td>\n",
       "      <td>0.413501</td>\n",
       "      <td>0.282156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>0.307000</td>\n",
       "      <td>0.419350</td>\n",
       "      <td>0.813461</td>\n",
       "      <td>0.335219</td>\n",
       "      <td>0.404868</td>\n",
       "      <td>0.289059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.308700</td>\n",
       "      <td>0.418886</td>\n",
       "      <td>0.814569</td>\n",
       "      <td>0.335615</td>\n",
       "      <td>0.407450</td>\n",
       "      <td>0.289883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.298700</td>\n",
       "      <td>0.419223</td>\n",
       "      <td>0.813953</td>\n",
       "      <td>0.331915</td>\n",
       "      <td>0.405673</td>\n",
       "      <td>0.287064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>0.301500</td>\n",
       "      <td>0.423180</td>\n",
       "      <td>0.815061</td>\n",
       "      <td>0.340310</td>\n",
       "      <td>0.408607</td>\n",
       "      <td>0.296149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.293400</td>\n",
       "      <td>0.422576</td>\n",
       "      <td>0.814323</td>\n",
       "      <td>0.341210</td>\n",
       "      <td>0.404579</td>\n",
       "      <td>0.296999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>0.293200</td>\n",
       "      <td>0.424049</td>\n",
       "      <td>0.814815</td>\n",
       "      <td>0.343771</td>\n",
       "      <td>0.402710</td>\n",
       "      <td>0.304219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>0.283600</td>\n",
       "      <td>0.424454</td>\n",
       "      <td>0.815184</td>\n",
       "      <td>0.343539</td>\n",
       "      <td>0.405666</td>\n",
       "      <td>0.301566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.283600</td>\n",
       "      <td>0.425204</td>\n",
       "      <td>0.814446</td>\n",
       "      <td>0.345629</td>\n",
       "      <td>0.402859</td>\n",
       "      <td>0.305793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>0.283600</td>\n",
       "      <td>0.426046</td>\n",
       "      <td>0.815184</td>\n",
       "      <td>0.345054</td>\n",
       "      <td>0.407026</td>\n",
       "      <td>0.302141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>640</td>\n",
       "      <td>0.279100</td>\n",
       "      <td>0.427820</td>\n",
       "      <td>0.812969</td>\n",
       "      <td>0.345790</td>\n",
       "      <td>0.399242</td>\n",
       "      <td>0.306438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>0.276000</td>\n",
       "      <td>0.427256</td>\n",
       "      <td>0.814569</td>\n",
       "      <td>0.345327</td>\n",
       "      <td>0.405684</td>\n",
       "      <td>0.303792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>680</td>\n",
       "      <td>0.279400</td>\n",
       "      <td>0.427563</td>\n",
       "      <td>0.815184</td>\n",
       "      <td>0.350805</td>\n",
       "      <td>0.405179</td>\n",
       "      <td>0.310849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.273100</td>\n",
       "      <td>0.428107</td>\n",
       "      <td>0.813707</td>\n",
       "      <td>0.346109</td>\n",
       "      <td>0.399640</td>\n",
       "      <td>0.308914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>0.279600</td>\n",
       "      <td>0.427990</td>\n",
       "      <td>0.813584</td>\n",
       "      <td>0.348278</td>\n",
       "      <td>0.400298</td>\n",
       "      <td>0.310300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>740</td>\n",
       "      <td>0.270800</td>\n",
       "      <td>0.428028</td>\n",
       "      <td>0.813830</td>\n",
       "      <td>0.348565</td>\n",
       "      <td>0.400906</td>\n",
       "      <td>0.310364</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Utilisateurs/umushtaq/.conda/envs/er_nb_env/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Utilisateurs/umushtaq/.conda/envs/er_nb_env/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Utilisateurs/umushtaq/.conda/envs/er_nb_env/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Utilisateurs/umushtaq/.conda/envs/er_nb_env/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Utilisateurs/umushtaq/.conda/envs/er_nb_env/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Utilisateurs/umushtaq/.conda/envs/er_nb_env/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Utilisateurs/umushtaq/.conda/envs/er_nb_env/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Utilisateurs/umushtaq/.conda/envs/er_nb_env/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Utilisateurs/umushtaq/.conda/envs/er_nb_env/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Utilisateurs/umushtaq/.conda/envs/er_nb_env/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Utilisateurs/umushtaq/.conda/envs/er_nb_env/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Utilisateurs/umushtaq/.conda/envs/er_nb_env/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Utilisateurs/umushtaq/.conda/envs/er_nb_env/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Utilisateurs/umushtaq/.conda/envs/er_nb_env/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Utilisateurs/umushtaq/.conda/envs/er_nb_env/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Utilisateurs/umushtaq/.conda/envs/er_nb_env/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Utilisateurs/umushtaq/.conda/envs/er_nb_env/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Utilisateurs/umushtaq/.conda/envs/er_nb_env/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Utilisateurs/umushtaq/.conda/envs/er_nb_env/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Utilisateurs/umushtaq/.conda/envs/er_nb_env/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Utilisateurs/umushtaq/.conda/envs/er_nb_env/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Utilisateurs/umushtaq/.conda/envs/er_nb_env/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Utilisateurs/umushtaq/.conda/envs/er_nb_env/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Utilisateurs/umushtaq/.conda/envs/er_nb_env/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Utilisateurs/umushtaq/.conda/envs/er_nb_env/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Utilisateurs/umushtaq/.conda/envs/er_nb_env/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Utilisateurs/umushtaq/.conda/envs/er_nb_env/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Utilisateurs/umushtaq/.conda/envs/er_nb_env/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Utilisateurs/umushtaq/.conda/envs/er_nb_env/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Utilisateurs/umushtaq/.conda/envs/er_nb_env/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Utilisateurs/umushtaq/.conda/envs/er_nb_env/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Utilisateurs/umushtaq/.conda/envs/er_nb_env/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Utilisateurs/umushtaq/.conda/envs/er_nb_env/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Utilisateurs/umushtaq/.conda/envs/er_nb_env/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Utilisateurs/umushtaq/.conda/envs/er_nb_env/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Utilisateurs/umushtaq/.conda/envs/er_nb_env/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Utilisateurs/umushtaq/.conda/envs/er_nb_env/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=740, training_loss=0.363961589014208, metrics={'train_runtime': 2133.1295, 'train_samples_per_second': 43.523, 'train_steps_per_second': 0.347, 'total_flos': 2.4428326990848e+16, 'train_loss': 0.363961589014208, 'epoch': 20.0})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b5e2ad89",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=7, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model_file = os.path.join(\"/notebooks/cascade_bert/saved_models\", 'best-model-with-real-prev-probs')\n",
    "\n",
    "#model = BertForSequenceClassification.from_pretrained(model_file, num_labels=NUM_LABELS)\n",
    "#model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b7a8f3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(model, test_dataset):\n",
    "    predictions, true_labels = [], []\n",
    "\n",
    "    # Assuming test_dataset is already tokenized and has the right format\n",
    "    for batch in test_dataset:\n",
    "        # Check the structure of the batch\n",
    "        #print(batch)  # Debugging line to see the batch content\n",
    "\n",
    "        # Prepare input tensors, ensuring we handle only the necessary fields\n",
    "        input_ids = torch.tensor(batch['input_ids']).unsqueeze(0)  # Add batch dimension\n",
    "        attention_mask = torch.tensor(batch['attention_mask']).unsqueeze(0)  # Add batch dimension\n",
    "        \n",
    "        # If there are any other fields needed, handle them similarly\n",
    "\n",
    "        # Move inputs to the appropriate device (GPU/CPU)\n",
    "        input_ids = input_ids.to(model.device)\n",
    "        attention_mask = attention_mask.to(model.device)\n",
    "\n",
    "        # Run inference\n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "\n",
    "        # Apply sigmoid to get the predicted probabilities for multilabel classification\n",
    "        logits = outputs.logits\n",
    "        probs = torch.sigmoid(logits).cpu().numpy()\n",
    "\n",
    "        # Convert probabilities to binary predictions (threshold = 0.5)\n",
    "        preds = np.where(probs > 0.5, 1, 0)\n",
    "\n",
    "        predictions.append(preds)\n",
    "\n",
    "        # Assuming labels are present in the batch\n",
    "        #true_labels.append(batch['labels'].cpu().numpy())  # Ground truth labels\n",
    "        true_labels.append(batch['labels'])\n",
    "\n",
    "    # Convert to numpy arrays for classification report\n",
    "    predictions = np.vstack(predictions)\n",
    "    true_labels = np.vstack(true_labels)\n",
    "\n",
    "    return predictions, true_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "22cee954",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions, true_labels = get_predictions(model, test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "203c8f19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger      0.531     0.449     0.487       454\n",
      "     disgust      0.000     0.000     0.000        50\n",
      "        fear      0.509     0.388     0.440       299\n",
      "         joy      0.515     0.465     0.488       297\n",
      "     neutral      0.000     0.000     0.000       109\n",
      "     sadness      0.509     0.331     0.401       344\n",
      "    surprise      0.677     0.485     0.565       355\n",
      "\n",
      "   micro avg      0.548     0.390     0.456      1908\n",
      "   macro avg      0.392     0.303     0.340      1908\n",
      "weighted avg      0.504     0.390     0.438      1908\n",
      " samples avg      0.461     0.397     0.409      1908\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Utilisateurs/umushtaq/.conda/envs/er_nb_env/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Utilisateurs/umushtaq/.conda/envs/er_nb_env/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(true_labels, predictions, target_names=mlb.classes_, digits=3)) # type: ignore"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fee04a15",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "precision    recall  f1-score   support\n",
    "\n",
    "    surprise      0.382     0.439     0.409       278\n",
    "         joy      0.448     0.417     0.432       343\n",
    "     neutral      0.216     0.085     0.122       129\n",
    "     disgust      0.000     0.000     0.000        23\n",
    "        fear      0.334     0.427     0.375       281\n",
    "       anger      0.487     0.481     0.484       516\n",
    "     sadness      0.251     0.267     0.259       206\n",
    "\n",
    "    accuracy                          0.394      1776\n",
    "   macro avg      0.303     0.302     0.297      1776\n",
    "weighted avg      0.386     0.394     0.386      1776\n",
    "\n",
    "bert, 100 epochs, smaller dataset (5282), wo class weights"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0103c7cc",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "precision    recall  f1-score   support\n",
    "\n",
    "       anger      0.499     0.592     0.541       321\n",
    "        fear      0.461     0.363     0.406       212\n",
    "     neutral      0.056     0.048     0.051        42\n",
    "    surprise      0.441     0.463     0.452       177\n",
    "         joy      0.421     0.421     0.421       195\n",
    "     disgust      0.000     0.000     0.000        21\n",
    "     sadness      0.348     0.357     0.352       129\n",
    "\n",
    "    accuracy                          0.437      1097\n",
    "   macro avg      0.318     0.320     0.318      1097\n",
    "weighted avg      0.424     0.437     0.428      1097\n",
    "\n",
    "bert, 100 epochs, complete dataset (6736), wo class weights"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9eccacd6",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "\n",
    "precision    recall  f1-score   support\n",
    "\n",
    "     neutral      0.152     0.286     0.198        42\n",
    "        fear      0.456     0.340     0.389       212\n",
    "     sadness      0.295     0.380     0.332       129\n",
    "     disgust      0.000     0.000     0.000        21\n",
    "         joy      0.444     0.405     0.424       195\n",
    "       anger      0.525     0.533     0.529       321\n",
    "    surprise      0.429     0.446     0.438       177\n",
    "\n",
    "    accuracy                          0.421      1097\n",
    "   macro avg      0.329     0.341     0.330      1097\n",
    "weighted avg      0.430     0.421     0.422      1097\n",
    "\n",
    "\n",
    "bert, 100 epochs, complete dataset (6736), w class weights"
   ]
  },
  {
   "cell_type": "raw",
   "id": "966d650a",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "precision    recall  f1-score   support\n",
    "\n",
    "    surprise      0.460     0.455     0.457       200\n",
    "     sadness      0.331     0.406     0.364       217\n",
    "        fear      0.342     0.495     0.404       182\n",
    "       anger      0.512     0.337     0.407       365\n",
    "     neutral      0.347     0.229     0.276       109\n",
    "     disgust      0.000     0.000     0.000        18\n",
    "         joy      0.409     0.481     0.442       235\n",
    "\n",
    "    accuracy                          0.400      1326\n",
    "   macro avg      0.343     0.343     0.336      1326\n",
    "weighted avg      0.413     0.400     0.397      1326\n",
    "\n",
    "bert, epoch 50, complete 35 dataset (7129), w class weights"
   ]
  },
  {
   "cell_type": "raw",
   "id": "be088cae",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "precision    recall  f1-score   support\n",
    "\n",
    "     neutral      0.404     0.193     0.261       109\n",
    "    surprise      0.458     0.385     0.418       200\n",
    "     disgust      0.000     0.000     0.000        18\n",
    "       anger      0.433     0.463     0.448       365\n",
    "         joy      0.416     0.443     0.429       235\n",
    "     sadness      0.350     0.392     0.370       217\n",
    "        fear      0.341     0.418     0.375       182\n",
    "\n",
    "    accuracy                          0.401      1326\n",
    "   macro avg      0.343     0.328     0.329      1326\n",
    "weighted avg      0.399     0.401     0.396      1326\n",
    "\n",
    "\n",
    "bert, epoch 50, complete 35 dataset (7129), wo class weights"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
