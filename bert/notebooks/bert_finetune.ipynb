{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d48c7115",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 3,
     "id": "db736e14-03fb-4438-938d-c705d6786666",
     "kernelId": "5ae81875-6bf9-4a4d-b9d2-28830bffd5f4"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "# import pandas as pd\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import transformers\n",
    "from transformers import Trainer\n",
    "from transformers import BertTokenizer\n",
    "from transformers import BertForSequenceClassification\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers.data.data_collator import DataCollatorWithPadding\n",
    "\n",
    "import datasets\n",
    "from datasets import Dataset\n",
    "from datasets import ClassLabel\n",
    "from datasets import load_metric\n",
    "\n",
    "import evaluate # type: ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b0d459f",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "37286c02-6bf4-41f5-ab70-51515a054e7b",
     "kernelId": "5ae81875-6bf9-4a4d-b9d2-28830bffd5f4"
    }
   },
   "source": [
    "## Global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d2e73f1",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 2,
     "id": "0c699094-439f-4dda-85a9-815e7948540c",
     "kernelId": "5ae81875-6bf9-4a4d-b9d2-28830bffd5f4"
    }
   },
   "outputs": [],
   "source": [
    "# DATA_FOLDER = '/notebooks/Data/bert_sequence_classification'\n",
    "DATA_FILE = 'emotion_analysis_comics/bert/datasets/comics_dataset_35.pt'\n",
    "RESULTS_FOLDER = 'emotion_analysis_comics/bert/outputs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25cd7cc9",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 3,
     "id": "35aada91-232a-421e-a28f-94b359c6d65d",
     "kernelId": "5ae81875-6bf9-4a4d-b9d2-28830bffd5f4"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f26bac23",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 4,
     "id": "dc52e71e-65fa-4946-acdf-e4fffe9d0f79",
     "kernelId": "5ae81875-6bf9-4a4d-b9d2-28830bffd5f4"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fbd7f91",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "013a6d64-65e7-4189-a468-40ecfd8a6736",
     "kernelId": "5ae81875-6bf9-4a4d-b9d2-28830bffd5f4"
    }
   },
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16553ed1",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 5,
     "id": "626737f9-ff56-4992-b72b-60750375e455",
     "kernelId": "5ae81875-6bf9-4a4d-b9d2-28830bffd5f4"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_399529/2065342137.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  dataset = torch.load(DATA_FILE)\n"
     ]
    }
   ],
   "source": [
    "dataset = torch.load(DATA_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65621b2b",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 6,
     "id": "4fbfcc7b-55fb-456e-ab02-2ae975803046",
     "kernelId": "5ae81875-6bf9-4a4d-b9d2-28830bffd5f4"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['file_name', 'page_nr', 'panel_nr', 'balloon_nr', 'utterance', 'raw_annotation', 'raw_emotion', 'raw_speaker_id', 'emotion', 'speaker_id', 'split', 'utterance_emotion', 'unique_emotion'],\n",
       "        num_rows: 5222\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['file_name', 'page_nr', 'panel_nr', 'balloon_nr', 'utterance', 'raw_annotation', 'raw_emotion', 'raw_speaker_id', 'emotion', 'speaker_id', 'split', 'utterance_emotion', 'unique_emotion'],\n",
       "        num_rows: 1326\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['file_name', 'page_nr', 'panel_nr', 'balloon_nr', 'utterance', 'raw_annotation', 'raw_emotion', 'raw_speaker_id', 'emotion', 'speaker_id', 'split', 'utterance_emotion', 'unique_emotion'],\n",
       "        num_rows: 581\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a0ec515d",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = dataset['test']['unique_emotion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae0da8ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1326"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b04a0b4",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 7,
     "id": "57c21a2e-83cd-4f4b-a19a-0bae29eb4794",
     "kernelId": "5ae81875-6bf9-4a4d-b9d2-28830bffd5f4"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"OH, NOW THAT I GET A BETTER LOOK AT YOU, I SEE THAT OLIVE TONE TO YOUR SKIN. YOU'RE BEAUTIFUL.\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train']['utterance'][230]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2254f8d2",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 4,
     "id": "492e0415-2634-47bb-88bf-665c130d032c",
     "kernelId": "5ae81875-6bf9-4a4d-b9d2-28830bffd5f4"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Utilisateurs/umushtaq/.conda/envs/er_nb_env/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3cea7797",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 9,
     "id": "ba2c9132-d013-4b26-be96-146cf024a45e",
     "kernelId": "5ae81875-6bf9-4a4d-b9d2-28830bffd5f4"
    }
   },
   "outputs": [],
   "source": [
    "label_names = list(set(dataset['train']['unique_emotion']))\n",
    "label_nb = len(label_names)\n",
    "labels = ClassLabel(num_classes=label_nb, names=label_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "207db7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_labels = dataset['test']['unique_emotion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "abb7b0c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1326"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a4c6f867",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = Counter(list_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b1f90e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_samples = []\n",
    "\n",
    "for cl in labels.names:\n",
    "    class_samples.append(counter[cl])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d0a4ad62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[109, 200, 18, 365, 235, 217, 182]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "af5da0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels.num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b6457a76",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 11,
     "id": "5438b78c-249c-48ac-98e8-a87a2cc0c86d",
     "kernelId": "5ae81875-6bf9-4a4d-b9d2-28830bffd5f4"
    }
   },
   "outputs": [],
   "source": [
    "def tokenize(batch):\n",
    "    tokens = tokenizer(batch['utterance'], truncation=True, padding=True, max_length=512)\n",
    "    tokens['labels'] = labels.str2int(batch['unique_emotion'])\n",
    "    return tokens\n",
    "\n",
    "# this is just the text. if the results are nice, check transfer with text + topic "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "171237c1",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 12,
     "id": "cb8d8c9a-7539-4d02-9dc5-98bade787549",
     "kernelId": "5ae81875-6bf9-4a4d-b9d2-28830bffd5f4"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d215b094b41e41528b500788ffc4c673",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5222 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12ce004b7fae4534b47b5a444ffb5679",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1326 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9c02579badc4c0084d8bc1b09f949ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/581 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = dataset.map(tokenize, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "02cc5896",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 13,
     "id": "84abf830-f842-4e91-8d5c-7fcd9ea2942e",
     "kernelId": "5ae81875-6bf9-4a4d-b9d2-28830bffd5f4"
    }
   },
   "outputs": [],
   "source": [
    "dataset.set_format('torch', columns=['input_ids', 'attention_mask', 'labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3c4c9e",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 14,
     "id": "c7d70e98-c2e0-4055-9d52-74c67c199c72",
     "kernelId": "5ae81875-6bf9-4a4d-b9d2-28830bffd5f4"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9d61c56a",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 15,
     "id": "e825c71a-23f8-4794-b114-729819def9ab",
     "kernelId": "5ae81875-6bf9-4a4d-b9d2-28830bffd5f4"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset = dataset['train'].shuffle(seed=42)\n",
    "test_dataset = dataset['test'].shuffle(seed=42)\n",
    "val_dataset = dataset['validation'].shuffle(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "989a4b43",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 16,
     "id": "e13433b1-343d-417d-bfbd-8bacb4c57d23",
     "kernelId": "5ae81875-6bf9-4a4d-b9d2-28830bffd5f4"
    }
   },
   "outputs": [],
   "source": [
    "dataset_d = {}\n",
    "dataset_d['train'] = train_dataset\n",
    "dataset_d['test'] = test_dataset\n",
    "dataset_d['val'] = val_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4b64d7b8",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 18,
     "id": "aa1384b3-bd47-41a3-86b1-9cf814d47cdf",
     "kernelId": "5ae81875-6bf9-4a4d-b9d2-28830bffd5f4"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'TRAIN'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sanity check\n",
    "set(dataset_d['train']['split'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8638ed33",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 19,
     "id": "84df366a-6334-4e3a-902b-deb1c99491fb",
     "kernelId": "5ae81875-6bf9-4a4d-b9d2-28830bffd5f4"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'TRAIN'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sanity check\n",
    "set(dataset_d['val']['split'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b68364ce",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 20,
     "id": "406ad783-a570-4c26-8aa6-243e866b6fbf",
     "kernelId": "5ae81875-6bf9-4a4d-b9d2-28830bffd5f4"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'TEST'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sanity check\n",
    "set(dataset_d['test']['split'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2e13bc81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# global variables\n",
    "NUM_LABELS = label_nb\n",
    "BATCH_SIZE = 256\n",
    "NB_EPOCHS = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "23519ec4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=NUM_LABELS, device_map='cuda')\n",
    "#model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9fe47db1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6992c7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_counts = torch.tensor(class_samples, dtype=torch.float32).cuda()\n",
    "class_weights = 1.0 / class_counts\n",
    "class_weights = class_weights / class_weights.sum() * len(class_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "64ea8b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#class_weights.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5fb9670c",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 27,
     "id": "521987db-56d5-4e71-95af-7d1fb4a06e3f",
     "kernelId": "5ae81875-6bf9-4a4d-b9d2-28830bffd5f4"
    }
   },
   "outputs": [],
   "source": [
    "# https://huggingface.co/transformers/main_classes/trainer.html\n",
    "class CustomTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        labels = inputs.get(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.get('logits')\n",
    "        loss_fct = nn.CrossEntropyLoss()#(weight=class_weights)\n",
    "        loss = loss_fct(logits, labels)\n",
    "        return (loss, outputs) if return_outputs else loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b9e622cb",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 28,
     "id": "06697293-0ef4-4d24-95a9-6ca0ed569b51",
     "kernelId": "5ae81875-6bf9-4a4d-b9d2-28830bffd5f4"
    }
   },
   "outputs": [],
   "source": [
    "#metric = load_metric('f1', trust_remote_code=True)\n",
    "metric = evaluate.load(\"f1\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    \n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    \n",
    "    return metric.compute(predictions=predictions, references=labels, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "60f56478",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 29,
     "id": "956f8a45-f8bd-42a5-b829-5e2b0e82cf42",
     "kernelId": "5ae81875-6bf9-4a4d-b9d2-28830bffd5f4"
    }
   },
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    \n",
    "    # output\n",
    "    output_dir=RESULTS_FOLDER,          \n",
    "    \n",
    "    # params\n",
    "    num_train_epochs=NB_EPOCHS,               # nb of epochs\n",
    "    per_device_train_batch_size=BATCH_SIZE,   # batch size per device during training\n",
    "    per_device_eval_batch_size=BATCH_SIZE,    # cf. paper Sun et al.\n",
    "    learning_rate=1e-5,#2e-5,                 # cf. paper Sun et al.\n",
    "#     warmup_steps=500,                         # number of warmup steps for learning rate scheduler\n",
    "    warmup_ratio=0.1,                         # cf. paper Sun et al.\n",
    "    weight_decay=0.01,                        # strength of weight decay\n",
    "    \n",
    "    # eval\n",
    "    eval_strategy=\"steps\",              # cf. paper Sun et al.\n",
    "    eval_steps=20,                            # cf. paper Sun et al.\n",
    "    \n",
    "    # log\n",
    "    logging_dir=\"emotion_analysis_comics/bert/logs\",  \n",
    "    logging_strategy='steps',\n",
    "    logging_steps=20,\n",
    "    \n",
    "    # save\n",
    "    save_strategy='steps',\n",
    "    save_total_limit=1,\n",
    "    # save_steps=20, # default 500\n",
    "    load_best_model_at_end=True,              # cf. paper Sun et al.\n",
    "    # metric_for_best_model='eval_loss' \n",
    "    metric_for_best_model='f1'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8222824c",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 30,
     "id": "219545f7-5aff-4d0c-87e2-4ca28a6e7acc",
     "kernelId": "5ae81875-6bf9-4a4d-b9d2-28830bffd5f4"
    }
   },
   "outputs": [],
   "source": [
    "trainer = CustomTrainer( # Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    tokenizer=tokenizer,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics\n",
    "    # callbacks=[EarlyStoppingCallback(early_stopping_patience=5)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9bfa9966",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 31,
     "id": "b524a80a-ccf0-41f4-a015-e4ba2913fdc4",
     "kernelId": "5ae81875-6bf9-4a4d-b9d2-28830bffd5f4"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1050' max='1050' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1050/1050 32:25, Epoch 50/50]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.912400</td>\n",
       "      <td>1.894216</td>\n",
       "      <td>0.096020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.872800</td>\n",
       "      <td>1.845676</td>\n",
       "      <td>0.101985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1.798900</td>\n",
       "      <td>1.739588</td>\n",
       "      <td>0.165700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1.686200</td>\n",
       "      <td>1.642476</td>\n",
       "      <td>0.219324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.600100</td>\n",
       "      <td>1.578327</td>\n",
       "      <td>0.255111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1.521700</td>\n",
       "      <td>1.517977</td>\n",
       "      <td>0.299006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1.448600</td>\n",
       "      <td>1.472455</td>\n",
       "      <td>0.326045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1.383700</td>\n",
       "      <td>1.458198</td>\n",
       "      <td>0.341179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1.313600</td>\n",
       "      <td>1.440376</td>\n",
       "      <td>0.360589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.259700</td>\n",
       "      <td>1.439553</td>\n",
       "      <td>0.361647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>1.198400</td>\n",
       "      <td>1.461118</td>\n",
       "      <td>0.376174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>1.141300</td>\n",
       "      <td>1.457193</td>\n",
       "      <td>0.388390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>1.103800</td>\n",
       "      <td>1.467078</td>\n",
       "      <td>0.387090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>1.054500</td>\n",
       "      <td>1.478947</td>\n",
       "      <td>0.393737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.984700</td>\n",
       "      <td>1.482419</td>\n",
       "      <td>0.399953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.940300</td>\n",
       "      <td>1.509838</td>\n",
       "      <td>0.400694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.900400</td>\n",
       "      <td>1.522192</td>\n",
       "      <td>0.397922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.858100</td>\n",
       "      <td>1.535065</td>\n",
       "      <td>0.392793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>0.818000</td>\n",
       "      <td>1.558041</td>\n",
       "      <td>0.389624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.778800</td>\n",
       "      <td>1.567279</td>\n",
       "      <td>0.391143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.732300</td>\n",
       "      <td>1.594133</td>\n",
       "      <td>0.395829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>0.696200</td>\n",
       "      <td>1.609079</td>\n",
       "      <td>0.394475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>0.665600</td>\n",
       "      <td>1.648934</td>\n",
       "      <td>0.393124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.644400</td>\n",
       "      <td>1.676736</td>\n",
       "      <td>0.383992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.593300</td>\n",
       "      <td>1.680264</td>\n",
       "      <td>0.388013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>0.571800</td>\n",
       "      <td>1.694661</td>\n",
       "      <td>0.385223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.545100</td>\n",
       "      <td>1.711080</td>\n",
       "      <td>0.383091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>0.522300</td>\n",
       "      <td>1.744368</td>\n",
       "      <td>0.378708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>0.483300</td>\n",
       "      <td>1.774767</td>\n",
       "      <td>0.373868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.478200</td>\n",
       "      <td>1.783983</td>\n",
       "      <td>0.389162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>0.457500</td>\n",
       "      <td>1.815174</td>\n",
       "      <td>0.374063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>640</td>\n",
       "      <td>0.449200</td>\n",
       "      <td>1.836739</td>\n",
       "      <td>0.370097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>0.410700</td>\n",
       "      <td>1.864816</td>\n",
       "      <td>0.356748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>680</td>\n",
       "      <td>0.404100</td>\n",
       "      <td>1.890246</td>\n",
       "      <td>0.358782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.380400</td>\n",
       "      <td>1.899514</td>\n",
       "      <td>0.356867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>0.376000</td>\n",
       "      <td>1.913723</td>\n",
       "      <td>0.362903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>740</td>\n",
       "      <td>0.376600</td>\n",
       "      <td>1.942912</td>\n",
       "      <td>0.357478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>760</td>\n",
       "      <td>0.363100</td>\n",
       "      <td>1.952786</td>\n",
       "      <td>0.363813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>0.347800</td>\n",
       "      <td>1.952422</td>\n",
       "      <td>0.359408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.338500</td>\n",
       "      <td>1.963966</td>\n",
       "      <td>0.360469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>820</td>\n",
       "      <td>0.329300</td>\n",
       "      <td>1.982498</td>\n",
       "      <td>0.358097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>0.320600</td>\n",
       "      <td>1.995798</td>\n",
       "      <td>0.356525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>860</td>\n",
       "      <td>0.310700</td>\n",
       "      <td>2.009136</td>\n",
       "      <td>0.364188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>880</td>\n",
       "      <td>0.309000</td>\n",
       "      <td>2.027051</td>\n",
       "      <td>0.362731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.300500</td>\n",
       "      <td>2.022564</td>\n",
       "      <td>0.359574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>920</td>\n",
       "      <td>0.308400</td>\n",
       "      <td>2.028498</td>\n",
       "      <td>0.364697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>940</td>\n",
       "      <td>0.291000</td>\n",
       "      <td>2.036302</td>\n",
       "      <td>0.362699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>0.281100</td>\n",
       "      <td>2.044103</td>\n",
       "      <td>0.360706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>980</td>\n",
       "      <td>0.317400</td>\n",
       "      <td>2.040959</td>\n",
       "      <td>0.358669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.274900</td>\n",
       "      <td>2.048691</td>\n",
       "      <td>0.361858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1020</td>\n",
       "      <td>0.277300</td>\n",
       "      <td>2.051373</td>\n",
       "      <td>0.361353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1040</td>\n",
       "      <td>0.281200</td>\n",
       "      <td>2.052464</td>\n",
       "      <td>0.362368</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1050, training_loss=0.7460589454287574, metrics={'train_runtime': 1946.8836, 'train_samples_per_second': 134.112, 'train_steps_per_second': 0.539, 'total_flos': 2.871503018349e+16, 'train_loss': 0.7460589454287574, 'epoch': 50.0})"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1ed32b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save best model\n",
    "#trainer.save_model(os.path.join(\"/notebooks/cascade_bert/saved_models\", 'best-model-with-real-prev-probs'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b5e2ad89",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=7, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model_file = os.path.join(\"/notebooks/cascade_bert/saved_models\", 'best-model-with-real-prev-probs')\n",
    "\n",
    "#model = BertForSequenceClassification.from_pretrained(model_file, num_labels=NUM_LABELS)\n",
    "#model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "85ef89d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_trainer = Trainer(model, data_collator=DataCollatorWithPadding(tokenizer))\n",
    "test_raw_preds, test_labels, _ = test_trainer.predict(test_dataset)\n",
    "test_preds = np.argmax(test_raw_preds, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3925efec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1326"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "046c53ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 6, 6, ..., 5, 6, 4])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e0c19919",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 3, 6, ..., 4, 3, 4])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "95c46295",
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels=['fear', 'anger', 'disgust', 'joy', 'sadness', 'surprise', 'neutral']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c6fe8fae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     neutral      0.404     0.193     0.261       109\n",
      "    surprise      0.458     0.385     0.418       200\n",
      "     disgust      0.000     0.000     0.000        18\n",
      "       anger      0.433     0.463     0.448       365\n",
      "         joy      0.416     0.443     0.429       235\n",
      "     sadness      0.350     0.392     0.370       217\n",
      "        fear      0.341     0.418     0.375       182\n",
      "\n",
      "    accuracy                          0.401      1326\n",
      "   macro avg      0.343     0.328     0.329      1326\n",
      "weighted avg      0.399     0.401     0.396      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Utilisateurs/umushtaq/.conda/envs/er_nb_env/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Utilisateurs/umushtaq/.conda/envs/er_nb_env/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Utilisateurs/umushtaq/.conda/envs/er_nb_env/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "target_name = labels.int2str([0,1,2,3,4,5,6])\n",
    "print(classification_report(test_labels, test_preds, target_names=target_name, digits=3)) # type: ignore"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fee04a15",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "precision    recall  f1-score   support\n",
    "\n",
    "    surprise      0.382     0.439     0.409       278\n",
    "         joy      0.448     0.417     0.432       343\n",
    "     neutral      0.216     0.085     0.122       129\n",
    "     disgust      0.000     0.000     0.000        23\n",
    "        fear      0.334     0.427     0.375       281\n",
    "       anger      0.487     0.481     0.484       516\n",
    "     sadness      0.251     0.267     0.259       206\n",
    "\n",
    "    accuracy                          0.394      1776\n",
    "   macro avg      0.303     0.302     0.297      1776\n",
    "weighted avg      0.386     0.394     0.386      1776\n",
    "\n",
    "bert, 100 epochs, smaller dataset (5282), wo class weights"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0103c7cc",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "precision    recall  f1-score   support\n",
    "\n",
    "       anger      0.499     0.592     0.541       321\n",
    "        fear      0.461     0.363     0.406       212\n",
    "     neutral      0.056     0.048     0.051        42\n",
    "    surprise      0.441     0.463     0.452       177\n",
    "         joy      0.421     0.421     0.421       195\n",
    "     disgust      0.000     0.000     0.000        21\n",
    "     sadness      0.348     0.357     0.352       129\n",
    "\n",
    "    accuracy                          0.437      1097\n",
    "   macro avg      0.318     0.320     0.318      1097\n",
    "weighted avg      0.424     0.437     0.428      1097\n",
    "\n",
    "bert, 100 epochs, complete dataset (6736), wo class weights"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9eccacd6",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "\n",
    "precision    recall  f1-score   support\n",
    "\n",
    "     neutral      0.152     0.286     0.198        42\n",
    "        fear      0.456     0.340     0.389       212\n",
    "     sadness      0.295     0.380     0.332       129\n",
    "     disgust      0.000     0.000     0.000        21\n",
    "         joy      0.444     0.405     0.424       195\n",
    "       anger      0.525     0.533     0.529       321\n",
    "    surprise      0.429     0.446     0.438       177\n",
    "\n",
    "    accuracy                          0.421      1097\n",
    "   macro avg      0.329     0.341     0.330      1097\n",
    "weighted avg      0.430     0.421     0.422      1097\n",
    "\n",
    "\n",
    "bert, 100 epochs, complete dataset (6736), w class weights"
   ]
  },
  {
   "cell_type": "raw",
   "id": "966d650a",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "precision    recall  f1-score   support\n",
    "\n",
    "    surprise      0.460     0.455     0.457       200\n",
    "     sadness      0.331     0.406     0.364       217\n",
    "        fear      0.342     0.495     0.404       182\n",
    "       anger      0.512     0.337     0.407       365\n",
    "     neutral      0.347     0.229     0.276       109\n",
    "     disgust      0.000     0.000     0.000        18\n",
    "         joy      0.409     0.481     0.442       235\n",
    "\n",
    "    accuracy                          0.400      1326\n",
    "   macro avg      0.343     0.343     0.336      1326\n",
    "weighted avg      0.413     0.400     0.397      1326\n",
    "\n",
    "bert, epoch 50, complete 35 dataset (7129), w class weights"
   ]
  },
  {
   "cell_type": "raw",
   "id": "be088cae",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "precision    recall  f1-score   support\n",
    "\n",
    "     neutral      0.404     0.193     0.261       109\n",
    "    surprise      0.458     0.385     0.418       200\n",
    "     disgust      0.000     0.000     0.000        18\n",
    "       anger      0.433     0.463     0.448       365\n",
    "         joy      0.416     0.443     0.429       235\n",
    "     sadness      0.350     0.392     0.370       217\n",
    "        fear      0.341     0.418     0.375       182\n",
    "\n",
    "    accuracy                          0.401      1326\n",
    "   macro avg      0.343     0.328     0.329      1326\n",
    "weighted avg      0.399     0.401     0.396      1326\n",
    "\n",
    "\n",
    "bert, epoch 50, complete 35 dataset (7129), wo class weights"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
