{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "bb0e5f83-d32d-4d5e-bb28-cf61e6a4fd47",
     "kernelId": ""
    }
   },
   "source": [
    "# Prepare dataset for BERT fine-tune"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "c41f6822-5637-4efa-9850-ff1b8e2a109a",
     "kernelId": ""
    }
   },
   "source": [
    "- Create dataset from comics dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "190922a4-3897-4417-b2e3-ad2e51dd6b1a",
     "kernelId": ""
    }
   },
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "a705b996-66aa-4aa6-9ce0-1edd956b8866",
     "kernelId": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import datasets\n",
    "import transformers\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from datasets import Dataset\n",
    "from datasets import DatasetDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "a8a8872d-0a98-4bd7-b38a-37810f8cdab3",
     "kernelId": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas:\t\t 2.2.2\n",
      "transformers:\t 4.44.2\n",
      "datasets:\t 2.21.0\n"
     ]
    }
   ],
   "source": [
    "print('pandas:\\t\\t', pd.__version__)\n",
    "print('transformers:\\t', transformers.__version__)\n",
    "print('datasets:\\t', datasets.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "5bf6295b-ee0c-47fa-8aa7-4aa06f0bab27",
     "kernelId": ""
    }
   },
   "source": [
    "### Load and Process dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_file = Path.cwd() / \"emotion_analysis_comics\" / \"dataset_files\" / \"comics_dataset.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_df = pd.read_csv(dataset_file, index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_map = {\n",
    "    'AN': 'anger',\n",
    "    'DI': 'disgust',\n",
    "    'FE': 'fear',\n",
    "    'SA': 'sadness',\n",
    "    'SU': 'surprise',\n",
    "    'JO': 'joy'\n",
    "}\n",
    "\n",
    "def extract_emotions(row):\n",
    "\n",
    "    emotion_str = row.emotion\n",
    "\n",
    "    if emotion_str == 'Neutral':\n",
    "        return ['neutral']\n",
    "\n",
    "    emotions = emotion_str.split('-')\n",
    "    tags = []\n",
    "\n",
    "    for emotion in emotions:\n",
    "        abbrev = emotion[:2]  # Get the abbreviation\n",
    "        value_part = emotion[2:]  # Get the value part\n",
    "        \n",
    "        # Ensure that the value part is a valid integer and abbrev is in the emotion_map\n",
    "        if abbrev in emotion_map and value_part.isdigit():\n",
    "            value = int(value_part)\n",
    "            if value > 0:\n",
    "                tag = emotion_map[abbrev].lower() + \":\" + str(value)\n",
    "                #tags.append(emotion_map[abbrev].lower())\n",
    "                tags.append(tag)\n",
    "        else:\n",
    "            print(f\"Warning: Skipping invalid emotion entry: '{emotion}'\")\n",
    "    return tags  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_df['utterance_emotion'] = dataset_df.apply(lambda row: extract_emotions(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique_emotion(row):\n",
    "    \n",
    "    emotion_vals = []\n",
    "    utterance_emotion = row.utterance_emotion\n",
    "    \n",
    "    for element in utterance_emotion:\n",
    "        if element == 'neutral':\n",
    "            return 'neutral'\n",
    "        else:\n",
    "            emotion_val = element.split(\":\")[1]\n",
    "            emotion_vals.append(emotion_val)\n",
    "    \n",
    "    return utterance_emotion[emotion_vals.index(max(emotion_vals))].split(\":\")[0]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_df['unique_emotion'] = dataset_df.apply(lambda row: get_unique_emotion(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = dataset_df[dataset_df.split=='TRAIN'].reset_index(drop=True)\n",
    "test_df = dataset_df[dataset_df.split=='TEST'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "41d56883-23e9-4722-9298-bc70f438ed0d",
     "kernelId": ""
    }
   },
   "source": [
    "## Prepare Dataset object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = Dataset.from_pandas(train_df)\n",
    "dataset_test = Dataset.from_pandas(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_datasets = dataset_train.train_test_split(train_size=0.9)\n",
    "dataset_train = train_val_datasets['train']\n",
    "dataset_val = train_val_datasets['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "e260bb57-be23-441a-a38f-f0598f773f9c",
     "kernelId": ""
    }
   },
   "outputs": [],
   "source": [
    "dataset = DatasetDict({\"train\": dataset_train, \"test\": dataset_test, \"validation\": dataset_val})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "b8ec2355-2e51-4cf6-ad2b-0ae3e6e52419",
     "kernelId": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['file_name', 'page_nr', 'panel_nr', 'balloon_nr', 'utterance', 'raw_annotation', 'raw_emotion', 'raw_speaker_id', 'emotion', 'speaker_id', 'split', 'utterance_emotion', 'unique_emotion'],\n",
       "        num_rows: 5075\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['file_name', 'page_nr', 'panel_nr', 'balloon_nr', 'utterance', 'raw_annotation', 'raw_emotion', 'raw_speaker_id', 'emotion', 'speaker_id', 'split', 'utterance_emotion', 'unique_emotion'],\n",
       "        num_rows: 1097\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['file_name', 'page_nr', 'panel_nr', 'balloon_nr', 'utterance', 'raw_annotation', 'raw_emotion', 'raw_speaker_id', 'emotion', 'speaker_id', 'split', 'utterance_emotion', 'unique_emotion'],\n",
       "        num_rows: 564\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "b7e61d38-7343-4e99-830c-54f683dde1a2",
     "kernelId": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'TRAIN'}, {'TEST'}, {'TRAIN'})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sanity check\n",
    "set(dataset['train']['split']), set(dataset['test']['split']), set(dataset['validation']['split'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "8ab4f270-c88d-4519-bc7b-83705dd28808",
     "kernelId": ""
    }
   },
   "source": [
    "## Save dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "6dadff8a-16ab-4dbc-bd1a-36e1d65db632",
     "kernelId": ""
    }
   },
   "outputs": [],
   "source": [
    "torch.save(dataset, os.path.join(\"emotion_analysis_comics/bert/datasets/\", 'comics_dataset_complete.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
