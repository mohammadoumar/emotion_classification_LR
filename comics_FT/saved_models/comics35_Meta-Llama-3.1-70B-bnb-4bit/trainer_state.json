{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.9977020298736117,
  "eval_steps": 500,
  "global_step": 1304,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.015319800842589047,
      "grad_norm": NaN,
      "learning_rate": 2.2900763358778625e-06,
      "loss": 2.5391,
      "step": 10
    },
    {
      "epoch": 0.030639601685178094,
      "grad_norm": 1.5662686824798584,
      "learning_rate": 6.106870229007634e-06,
      "loss": 1.4431,
      "step": 20
    },
    {
      "epoch": 0.04595940252776714,
      "grad_norm": 0.6680282950401306,
      "learning_rate": 9.923664122137405e-06,
      "loss": 0.8247,
      "step": 30
    },
    {
      "epoch": 0.06127920337035619,
      "grad_norm": 0.4266512393951416,
      "learning_rate": 1.3740458015267178e-05,
      "loss": 0.8079,
      "step": 40
    },
    {
      "epoch": 0.07659900421294523,
      "grad_norm": 0.7778392434120178,
      "learning_rate": 1.7557251908396945e-05,
      "loss": 0.748,
      "step": 50
    },
    {
      "epoch": 0.09191880505553428,
      "grad_norm": 1.15913987159729,
      "learning_rate": 2.1374045801526718e-05,
      "loss": 0.7248,
      "step": 60
    },
    {
      "epoch": 0.10723860589812333,
      "grad_norm": 0.5873337984085083,
      "learning_rate": 2.5190839694656487e-05,
      "loss": 0.7131,
      "step": 70
    },
    {
      "epoch": 0.12255840674071238,
      "grad_norm": 0.6617868542671204,
      "learning_rate": 2.900763358778626e-05,
      "loss": 0.6774,
      "step": 80
    },
    {
      "epoch": 0.1378782075833014,
      "grad_norm": 0.3886786997318268,
      "learning_rate": 3.282442748091603e-05,
      "loss": 0.7267,
      "step": 90
    },
    {
      "epoch": 0.15319800842589046,
      "grad_norm": 0.5728182196617126,
      "learning_rate": 3.66412213740458e-05,
      "loss": 0.6868,
      "step": 100
    },
    {
      "epoch": 0.1685178092684795,
      "grad_norm": 0.9112205505371094,
      "learning_rate": 4.0458015267175576e-05,
      "loss": 0.7106,
      "step": 110
    },
    {
      "epoch": 0.18383761011106856,
      "grad_norm": 0.9260298609733582,
      "learning_rate": 4.4274809160305345e-05,
      "loss": 0.7171,
      "step": 120
    },
    {
      "epoch": 0.1991574109536576,
      "grad_norm": 1.8138340711593628,
      "learning_rate": 4.809160305343512e-05,
      "loss": 0.71,
      "step": 130
    },
    {
      "epoch": 0.21447721179624665,
      "grad_norm": 1.030337929725647,
      "learning_rate": 4.999775845607947e-05,
      "loss": 0.733,
      "step": 140
    },
    {
      "epoch": 0.2297970126388357,
      "grad_norm": 1.0705028772354126,
      "learning_rate": 4.997982851641236e-05,
      "loss": 0.6942,
      "step": 150
    },
    {
      "epoch": 0.24511681348142475,
      "grad_norm": 0.5049346089363098,
      "learning_rate": 4.994398149754069e-05,
      "loss": 0.6929,
      "step": 160
    },
    {
      "epoch": 0.26043661432401377,
      "grad_norm": 1.4625099897384644,
      "learning_rate": 4.989024311116524e-05,
      "loss": 0.6709,
      "step": 170
    },
    {
      "epoch": 0.2757564151666028,
      "grad_norm": 1.202339768409729,
      "learning_rate": 4.981865190178299e-05,
      "loss": 0.7095,
      "step": 180
    },
    {
      "epoch": 0.29107621600919187,
      "grad_norm": 1.1392478942871094,
      "learning_rate": 4.9729259219040646e-05,
      "loss": 0.6935,
      "step": 190
    },
    {
      "epoch": 0.3063960168517809,
      "grad_norm": 0.6888910531997681,
      "learning_rate": 4.9622129180903476e-05,
      "loss": 0.713,
      "step": 200
    },
    {
      "epoch": 0.32171581769436997,
      "grad_norm": 1.1833884716033936,
      "learning_rate": 4.9497338627665903e-05,
      "loss": 0.7101,
      "step": 210
    },
    {
      "epoch": 0.337035618536959,
      "grad_norm": 0.70183265209198,
      "learning_rate": 4.9354977066836986e-05,
      "loss": 0.7187,
      "step": 220
    },
    {
      "epoch": 0.35235541937954806,
      "grad_norm": 0.8740909099578857,
      "learning_rate": 4.919514660893996e-05,
      "loss": 0.6994,
      "step": 230
    },
    {
      "epoch": 0.3676752202221371,
      "grad_norm": NaN,
      "learning_rate": 4.9054781256066894e-05,
      "loss": 0.7821,
      "step": 240
    },
    {
      "epoch": 0.38299502106472616,
      "grad_norm": 2.612759590148926,
      "learning_rate": 4.888367436949474e-05,
      "loss": 0.7273,
      "step": 250
    },
    {
      "epoch": 0.3983148219073152,
      "grad_norm": 0.9890579581260681,
      "learning_rate": 4.8677285705693473e-05,
      "loss": 0.6945,
      "step": 260
    },
    {
      "epoch": 0.41363462274990426,
      "grad_norm": 0.7154607772827148,
      "learning_rate": 4.845391422701582e-05,
      "loss": 0.7007,
      "step": 270
    },
    {
      "epoch": 0.4289544235924933,
      "grad_norm": 0.5306317806243896,
      "learning_rate": 4.8213720149312464e-05,
      "loss": 0.673,
      "step": 280
    },
    {
      "epoch": 0.44427422443508235,
      "grad_norm": 0.8110902905464172,
      "learning_rate": 4.7956875754643384e-05,
      "loss": 0.6856,
      "step": 290
    },
    {
      "epoch": 0.4595940252776714,
      "grad_norm": 2.2073984146118164,
      "learning_rate": 4.76835652677065e-05,
      "loss": 0.7007,
      "step": 300
    },
    {
      "epoch": 0.47491382612026045,
      "grad_norm": 0.4419251084327698,
      "learning_rate": 4.739398472370031e-05,
      "loss": 0.6899,
      "step": 310
    },
    {
      "epoch": 0.4902336269628495,
      "grad_norm": 1.8830153942108154,
      "learning_rate": 4.7088341827715344e-05,
      "loss": 0.6883,
      "step": 320
    },
    {
      "epoch": 0.5055534278054385,
      "grad_norm": 0.7230990529060364,
      "learning_rate": 4.676685580575516e-05,
      "loss": 0.6904,
      "step": 330
    },
    {
      "epoch": 0.5208732286480275,
      "grad_norm": 0.6276141405105591,
      "learning_rate": 4.642975724749396e-05,
      "loss": 0.6896,
      "step": 340
    },
    {
      "epoch": 0.5361930294906166,
      "grad_norm": 0.6032342910766602,
      "learning_rate": 4.607728794088331e-05,
      "loss": 0.6773,
      "step": 350
    },
    {
      "epoch": 0.5515128303332056,
      "grad_norm": 1.0434377193450928,
      "learning_rate": 4.570970069872695e-05,
      "loss": 0.6874,
      "step": 360
    },
    {
      "epoch": 0.5668326311757947,
      "grad_norm": 1.1769218444824219,
      "learning_rate": 4.532725917734774e-05,
      "loss": 0.6647,
      "step": 370
    },
    {
      "epoch": 0.5821524320183837,
      "grad_norm": 0.7632355093955994,
      "learning_rate": 4.4930237687477026e-05,
      "loss": 0.6848,
      "step": 380
    },
    {
      "epoch": 0.5974722328609728,
      "grad_norm": 0.7999227046966553,
      "learning_rate": 4.4518920997502055e-05,
      "loss": 0.6902,
      "step": 390
    },
    {
      "epoch": 0.6127920337035618,
      "grad_norm": 0.49538350105285645,
      "learning_rate": 4.4093604129212415e-05,
      "loss": 0.6743,
      "step": 400
    },
    {
      "epoch": 0.6281118345461509,
      "grad_norm": 0.9563454985618591,
      "learning_rate": 4.365459214619214e-05,
      "loss": 0.6693,
      "step": 410
    },
    {
      "epoch": 0.6434316353887399,
      "grad_norm": 1.057097315788269,
      "learning_rate": 4.320219993500927e-05,
      "loss": 0.6826,
      "step": 420
    },
    {
      "epoch": 0.658751436231329,
      "grad_norm": 0.5471212863922119,
      "learning_rate": 4.273675197935968e-05,
      "loss": 0.6815,
      "step": 430
    },
    {
      "epoch": 0.674071237073918,
      "grad_norm": 1.3388288021087646,
      "learning_rate": 4.225858212732729e-05,
      "loss": 0.6819,
      "step": 440
    },
    {
      "epoch": 0.6893910379165071,
      "grad_norm": 0.7904536128044128,
      "learning_rate": 4.1768033351927574e-05,
      "loss": 0.6872,
      "step": 450
    },
    {
      "epoch": 0.7047108387590961,
      "grad_norm": 0.48458966612815857,
      "learning_rate": 4.126545750510605e-05,
      "loss": 0.6624,
      "step": 460
    },
    {
      "epoch": 0.7200306396016852,
      "grad_norm": 0.684121310710907,
      "learning_rate": 4.0751215065368336e-05,
      "loss": 0.6722,
      "step": 470
    },
    {
      "epoch": 0.7353504404442742,
      "grad_norm": 1.0266938209533691,
      "learning_rate": 4.02256748792226e-05,
      "loss": 0.6963,
      "step": 480
    },
    {
      "epoch": 0.7506702412868632,
      "grad_norm": 1.5552747249603271,
      "learning_rate": 3.9689213896620047e-05,
      "loss": 0.6752,
      "step": 490
    },
    {
      "epoch": 0.7659900421294523,
      "grad_norm": 0.49828511476516724,
      "learning_rate": 3.9142216900583065e-05,
      "loss": 0.6945,
      "step": 500
    },
    {
      "epoch": 0.7813098429720413,
      "grad_norm": 1.13843834400177,
      "learning_rate": 3.8585076231215057e-05,
      "loss": 0.6831,
      "step": 510
    },
    {
      "epoch": 0.7966296438146304,
      "grad_norm": 0.5412273406982422,
      "learning_rate": 3.801819150428976e-05,
      "loss": 0.6773,
      "step": 520
    },
    {
      "epoch": 0.8119494446572194,
      "grad_norm": 0.6883360147476196,
      "learning_rate": 3.744196932462219e-05,
      "loss": 0.674,
      "step": 530
    },
    {
      "epoch": 0.8272692454998085,
      "grad_norm": 0.602599561214447,
      "learning_rate": 3.685682299442638e-05,
      "loss": 0.6901,
      "step": 540
    },
    {
      "epoch": 0.8425890463423975,
      "grad_norm": 0.5982228517532349,
      "learning_rate": 3.6263172216869524e-05,
      "loss": 0.6865,
      "step": 550
    },
    {
      "epoch": 0.8579088471849866,
      "grad_norm": 0.6308378577232361,
      "learning_rate": 3.566144279503489e-05,
      "loss": 0.6667,
      "step": 560
    },
    {
      "epoch": 0.8732286480275756,
      "grad_norm": 1.1356502771377563,
      "learning_rate": 3.505206632650944e-05,
      "loss": 0.6918,
      "step": 570
    },
    {
      "epoch": 0.8885484488701647,
      "grad_norm": 1.1791049242019653,
      "learning_rate": 3.443547989381536e-05,
      "loss": 0.6566,
      "step": 580
    },
    {
      "epoch": 0.9038682497127537,
      "grad_norm": 1.2085192203521729,
      "learning_rate": 3.381212575090745e-05,
      "loss": 0.6891,
      "step": 590
    },
    {
      "epoch": 0.9191880505553428,
      "grad_norm": 0.6296268701553345,
      "learning_rate": 3.318245100596115e-05,
      "loss": 0.6657,
      "step": 600
    },
    {
      "epoch": 0.9345078513979318,
      "grad_norm": 0.6386196613311768,
      "learning_rate": 3.25469073006789e-05,
      "loss": 0.6628,
      "step": 610
    },
    {
      "epoch": 0.9498276522405209,
      "grad_norm": 0.7663583755493164,
      "learning_rate": 3.1905950486344816e-05,
      "loss": 0.6722,
      "step": 620
    },
    {
      "epoch": 0.9651474530831099,
      "grad_norm": 0.5051196813583374,
      "learning_rate": 3.126004029685984e-05,
      "loss": 0.6726,
      "step": 630
    },
    {
      "epoch": 0.980467253925699,
      "grad_norm": 0.4979647397994995,
      "learning_rate": 3.0609640018992195e-05,
      "loss": 0.6657,
      "step": 640
    },
    {
      "epoch": 0.995787054768288,
      "grad_norm": 0.652968168258667,
      "learning_rate": 2.9955216160079423e-05,
      "loss": 0.6756,
      "step": 650
    },
    {
      "epoch": 1.011106855610877,
      "grad_norm": 0.5357991456985474,
      "learning_rate": 2.9297238113420417e-05,
      "loss": 0.6621,
      "step": 660
    },
    {
      "epoch": 1.026426656453466,
      "grad_norm": 0.538894534111023,
      "learning_rate": 2.863617782159755e-05,
      "loss": 0.6452,
      "step": 670
    },
    {
      "epoch": 1.041746457296055,
      "grad_norm": 0.8652967214584351,
      "learning_rate": 2.7972509437970178e-05,
      "loss": 0.6486,
      "step": 680
    },
    {
      "epoch": 1.0570662581386443,
      "grad_norm": 0.8354670405387878,
      "learning_rate": 2.7306708986582553e-05,
      "loss": 0.6554,
      "step": 690
    },
    {
      "epoch": 1.0723860589812333,
      "grad_norm": 0.6389106512069702,
      "learning_rate": 2.6639254020729896e-05,
      "loss": 0.6258,
      "step": 700
    },
    {
      "epoch": 1.0877058598238223,
      "grad_norm": 0.5358771681785583,
      "learning_rate": 2.5970623280427612e-05,
      "loss": 0.6179,
      "step": 710
    },
    {
      "epoch": 1.1030256606664113,
      "grad_norm": 1.0671592950820923,
      "learning_rate": 2.53012963490293e-05,
      "loss": 0.6358,
      "step": 720
    },
    {
      "epoch": 1.1183454615090005,
      "grad_norm": 0.6379063129425049,
      "learning_rate": 2.4631753309239937e-05,
      "loss": 0.6399,
      "step": 730
    },
    {
      "epoch": 1.1336652623515895,
      "grad_norm": 0.5861248970031738,
      "learning_rate": 2.396247439877078e-05,
      "loss": 0.6383,
      "step": 740
    },
    {
      "epoch": 1.1489850631941785,
      "grad_norm": 0.8066832423210144,
      "learning_rate": 2.329393966588323e-05,
      "loss": 0.651,
      "step": 750
    },
    {
      "epoch": 1.1643048640367675,
      "grad_norm": 0.8677359223365784,
      "learning_rate": 2.2626628625068425e-05,
      "loss": 0.6338,
      "step": 760
    },
    {
      "epoch": 1.1796246648793565,
      "grad_norm": 0.8747865557670593,
      "learning_rate": 2.1961019913109815e-05,
      "loss": 0.6523,
      "step": 770
    },
    {
      "epoch": 1.1949444657219457,
      "grad_norm": 0.4460431933403015,
      "learning_rate": 2.129759094577524e-05,
      "loss": 0.6583,
      "step": 780
    },
    {
      "epoch": 1.2102642665645347,
      "grad_norm": 0.5971298217773438,
      "learning_rate": 2.063681757538477e-05,
      "loss": 0.6375,
      "step": 790
    },
    {
      "epoch": 1.2255840674071237,
      "grad_norm": 0.7283204793930054,
      "learning_rate": 1.9979173749499946e-05,
      "loss": 0.6452,
      "step": 800
    },
    {
      "epoch": 1.2409038682497127,
      "grad_norm": 0.9118220806121826,
      "learning_rate": 1.9325131170979313e-05,
      "loss": 0.6428,
      "step": 810
    },
    {
      "epoch": 1.2562236690923019,
      "grad_norm": 0.7219006419181824,
      "learning_rate": 1.867515895964388e-05,
      "loss": 0.6363,
      "step": 820
    },
    {
      "epoch": 1.2715434699348909,
      "grad_norm": 0.9161598086357117,
      "learning_rate": 1.8029723315795354e-05,
      "loss": 0.6259,
      "step": 830
    },
    {
      "epoch": 1.2868632707774799,
      "grad_norm": 0.682094156742096,
      "learning_rate": 1.738928718582847e-05,
      "loss": 0.6387,
      "step": 840
    },
    {
      "epoch": 1.3021830716200689,
      "grad_norm": 0.6449736952781677,
      "learning_rate": 1.6754309930177113e-05,
      "loss": 0.6512,
      "step": 850
    },
    {
      "epoch": 1.3175028724626578,
      "grad_norm": 0.5195993781089783,
      "learning_rate": 1.6125246993832643e-05,
      "loss": 0.6426,
      "step": 860
    },
    {
      "epoch": 1.332822673305247,
      "grad_norm": 0.6720317006111145,
      "learning_rate": 1.550254957967052e-05,
      "loss": 0.6503,
      "step": 870
    },
    {
      "epoch": 1.348142474147836,
      "grad_norm": 0.5365777611732483,
      "learning_rate": 1.4886664324819682e-05,
      "loss": 0.6299,
      "step": 880
    },
    {
      "epoch": 1.363462274990425,
      "grad_norm": 0.8746711015701294,
      "learning_rate": 1.4278032980306763e-05,
      "loss": 0.6238,
      "step": 890
    },
    {
      "epoch": 1.3787820758330143,
      "grad_norm": 0.7574365735054016,
      "learning_rate": 1.3677092094204885e-05,
      "loss": 0.633,
      "step": 900
    },
    {
      "epoch": 1.3941018766756033,
      "grad_norm": 0.4992647171020508,
      "learning_rate": 1.30842726985144e-05,
      "loss": 0.6334,
      "step": 910
    },
    {
      "epoch": 1.4094216775181923,
      "grad_norm": 0.8683122992515564,
      "learning_rate": 1.2500000000000006e-05,
      "loss": 0.6248,
      "step": 920
    },
    {
      "epoch": 1.4247414783607812,
      "grad_norm": 0.47219154238700867,
      "learning_rate": 1.1924693075206189e-05,
      "loss": 0.625,
      "step": 930
    },
    {
      "epoch": 1.4400612792033702,
      "grad_norm": 0.814340353012085,
      "learning_rate": 1.1358764569869568e-05,
      "loss": 0.6387,
      "step": 940
    },
    {
      "epoch": 1.4553810800459595,
      "grad_norm": 0.7386305928230286,
      "learning_rate": 1.0802620402943794e-05,
      "loss": 0.6673,
      "step": 950
    },
    {
      "epoch": 1.4707008808885484,
      "grad_norm": 0.45496997237205505,
      "learning_rate": 1.025665947544941e-05,
      "loss": 0.635,
      "step": 960
    },
    {
      "epoch": 1.4860206817311374,
      "grad_norm": 0.7919344902038574,
      "learning_rate": 9.721273384357318e-06,
      "loss": 0.6342,
      "step": 970
    },
    {
      "epoch": 1.5013404825737267,
      "grad_norm": 0.48019880056381226,
      "learning_rate": 9.19684614171117e-06,
      "loss": 0.6212,
      "step": 980
    },
    {
      "epoch": 1.5166602834163156,
      "grad_norm": 0.6188994646072388,
      "learning_rate": 8.68375389919022e-06,
      "loss": 0.6383,
      "step": 990
    },
    {
      "epoch": 1.5319800842589046,
      "grad_norm": 0.8983986377716064,
      "learning_rate": 8.182364678309998e-06,
      "loss": 0.6091,
      "step": 1000
    },
    {
      "epoch": 1.5472998851014936,
      "grad_norm": 0.5772743821144104,
      "learning_rate": 7.693038106454541e-06,
      "loss": 0.644,
      "step": 1010
    },
    {
      "epoch": 1.5626196859440826,
      "grad_norm": 0.47346222400665283,
      "learning_rate": 7.216125158929338e-06,
      "loss": 0.6411,
      "step": 1020
    },
    {
      "epoch": 1.5779394867866716,
      "grad_norm": 0.7974011301994324,
      "learning_rate": 6.751967907220142e-06,
      "loss": 0.6149,
      "step": 1030
    },
    {
      "epoch": 1.5932592876292608,
      "grad_norm": 0.794049084186554,
      "learning_rate": 6.300899273638134e-06,
      "loss": 0.5948,
      "step": 1040
    },
    {
      "epoch": 1.6085790884718498,
      "grad_norm": 0.7372562289237976,
      "learning_rate": 5.863242792527385e-06,
      "loss": 0.6078,
      "step": 1050
    },
    {
      "epoch": 1.623898889314439,
      "grad_norm": 0.5929791331291199,
      "learning_rate": 5.439312378206068e-06,
      "loss": 0.6164,
      "step": 1060
    },
    {
      "epoch": 1.639218690157028,
      "grad_norm": 0.6707231998443604,
      "learning_rate": 5.0294120998076235e-06,
      "loss": 0.6351,
      "step": 1070
    },
    {
      "epoch": 1.654538490999617,
      "grad_norm": 0.5936693549156189,
      "learning_rate": 4.633835963183583e-06,
      "loss": 0.656,
      "step": 1080
    },
    {
      "epoch": 1.669858291842206,
      "grad_norm": 0.8362029790878296,
      "learning_rate": 4.252867700024374e-06,
      "loss": 0.6504,
      "step": 1090
    },
    {
      "epoch": 1.685178092684795,
      "grad_norm": 0.5265198945999146,
      "learning_rate": 3.886780564349357e-06,
      "loss": 0.629,
      "step": 1100
    },
    {
      "epoch": 1.700497893527384,
      "grad_norm": 0.5683417916297913,
      "learning_rate": 3.535837136512177e-06,
      "loss": 0.623,
      "step": 1110
    },
    {
      "epoch": 1.7158176943699732,
      "grad_norm": 0.7486534118652344,
      "learning_rate": 3.200289134861853e-06,
      "loss": 0.6284,
      "step": 1120
    },
    {
      "epoch": 1.7311374952125622,
      "grad_norm": 0.743197500705719,
      "learning_rate": 2.8803772351948033e-06,
      "loss": 0.6161,
      "step": 1130
    },
    {
      "epoch": 1.7464572960551514,
      "grad_norm": 0.5831079483032227,
      "learning_rate": 2.576330898127252e-06,
      "loss": 0.6056,
      "step": 1140
    },
    {
      "epoch": 1.7617770968977404,
      "grad_norm": 0.7694847583770752,
      "learning_rate": 2.2883682045119063e-06,
      "loss": 0.6179,
      "step": 1150
    },
    {
      "epoch": 1.7770968977403294,
      "grad_norm": 0.9040511846542358,
      "learning_rate": 2.016695699016838e-06,
      "loss": 0.6388,
      "step": 1160
    },
    {
      "epoch": 1.7924166985829184,
      "grad_norm": 1.0246044397354126,
      "learning_rate": 1.7615082419788708e-06,
      "loss": 0.5969,
      "step": 1170
    },
    {
      "epoch": 1.8077364994255074,
      "grad_norm": 0.8848704099655151,
      "learning_rate": 1.5229888696377036e-06,
      "loss": 0.6089,
      "step": 1180
    },
    {
      "epoch": 1.8230563002680964,
      "grad_norm": 0.9122017025947571,
      "learning_rate": 1.301308662850964e-06,
      "loss": 0.6255,
      "step": 1190
    },
    {
      "epoch": 1.8383761011106856,
      "grad_norm": 0.5437559485435486,
      "learning_rate": 1.0966266243844393e-06,
      "loss": 0.6085,
      "step": 1200
    },
    {
      "epoch": 1.8536959019532746,
      "grad_norm": 1.2419689893722534,
      "learning_rate": 9.090895648654563e-07,
      "loss": 0.6331,
      "step": 1210
    },
    {
      "epoch": 1.8690157027958638,
      "grad_norm": 0.6371358633041382,
      "learning_rate": 7.388319974812096e-07,
      "loss": 0.6138,
      "step": 1220
    },
    {
      "epoch": 1.8843355036384528,
      "grad_norm": 0.5576462745666504,
      "learning_rate": 5.859760414975602e-07,
      "loss": 0.6336,
      "step": 1230
    },
    {
      "epoch": 1.8996553044810418,
      "grad_norm": 0.7960637807846069,
      "learning_rate": 4.5063133466757004e-07,
      "loss": 0.6164,
      "step": 1240
    },
    {
      "epoch": 1.9149751053236308,
      "grad_norm": 1.3410152196884155,
      "learning_rate": 3.32894954592497e-07,
      "loss": 0.6419,
      "step": 1250
    },
    {
      "epoch": 1.9302949061662198,
      "grad_norm": 0.8277632594108582,
      "learning_rate": 2.3285134909173112e-07,
      "loss": 0.6126,
      "step": 1260
    },
    {
      "epoch": 1.9456147070088088,
      "grad_norm": 0.6130069494247437,
      "learning_rate": 1.5057227563160526e-07,
      "loss": 0.6261,
      "step": 1270
    },
    {
      "epoch": 1.9609345078513978,
      "grad_norm": 0.6458188891410828,
      "learning_rate": 8.611674985648522e-08,
      "loss": 0.627,
      "step": 1280
    },
    {
      "epoch": 1.976254308693987,
      "grad_norm": 0.4898168742656708,
      "learning_rate": 3.953100325909953e-08,
      "loss": 0.6171,
      "step": 1290
    },
    {
      "epoch": 1.991574109536576,
      "grad_norm": 0.6599991917610168,
      "learning_rate": 1.08484500204592e-08,
      "loss": 0.6171,
      "step": 1300
    },
    {
      "epoch": 1.9977020298736117,
      "step": 1304,
      "total_flos": 1.0429894528975503e+18,
      "train_loss": 0.6831504945740378,
      "train_runtime": 10881.8008,
      "train_samples_per_second": 0.96,
      "train_steps_per_second": 0.12
    }
  ],
  "logging_steps": 10,
  "max_steps": 1304,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 5000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1.0429894528975503e+18,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
