{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.9977020298736117,
  "eval_steps": 500,
  "global_step": 1304,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.015319800842589047,
      "grad_norm": 6.408298015594482,
      "learning_rate": 3.053435114503817e-06,
      "loss": 0.6469,
      "step": 10
    },
    {
      "epoch": 0.030639601685178094,
      "grad_norm": 1.2479523420333862,
      "learning_rate": 6.870229007633589e-06,
      "loss": 0.2263,
      "step": 20
    },
    {
      "epoch": 0.04595940252776714,
      "grad_norm": 1.4455974102020264,
      "learning_rate": 1.0687022900763359e-05,
      "loss": 0.1786,
      "step": 30
    },
    {
      "epoch": 0.06127920337035619,
      "grad_norm": 1.2058902978897095,
      "learning_rate": 1.450381679389313e-05,
      "loss": 0.173,
      "step": 40
    },
    {
      "epoch": 0.07659900421294523,
      "grad_norm": 0.7444149255752563,
      "learning_rate": 1.83206106870229e-05,
      "loss": 0.165,
      "step": 50
    },
    {
      "epoch": 0.09191880505553428,
      "grad_norm": 0.8722384572029114,
      "learning_rate": 2.2137404580152673e-05,
      "loss": 0.1747,
      "step": 60
    },
    {
      "epoch": 0.10723860589812333,
      "grad_norm": 0.8004484176635742,
      "learning_rate": 2.5954198473282442e-05,
      "loss": 0.1669,
      "step": 70
    },
    {
      "epoch": 0.12255840674071238,
      "grad_norm": 0.9736725091934204,
      "learning_rate": 2.9770992366412214e-05,
      "loss": 0.1585,
      "step": 80
    },
    {
      "epoch": 0.1378782075833014,
      "grad_norm": 0.7120847702026367,
      "learning_rate": 3.358778625954199e-05,
      "loss": 0.185,
      "step": 90
    },
    {
      "epoch": 0.15319800842589046,
      "grad_norm": 0.7231093645095825,
      "learning_rate": 3.7404580152671756e-05,
      "loss": 0.1591,
      "step": 100
    },
    {
      "epoch": 0.1685178092684795,
      "grad_norm": 1.3079663515090942,
      "learning_rate": 4.122137404580153e-05,
      "loss": 0.1729,
      "step": 110
    },
    {
      "epoch": 0.18383761011106856,
      "grad_norm": 1.5310691595077515,
      "learning_rate": 4.5038167938931294e-05,
      "loss": 0.1789,
      "step": 120
    },
    {
      "epoch": 0.1991574109536576,
      "grad_norm": 2.4096219539642334,
      "learning_rate": 4.885496183206107e-05,
      "loss": 0.1763,
      "step": 130
    },
    {
      "epoch": 0.21447721179624665,
      "grad_norm": 1.793763518333435,
      "learning_rate": 4.999560663694411e-05,
      "loss": 0.1721,
      "step": 140
    },
    {
      "epoch": 0.2297970126388357,
      "grad_norm": 1.0154881477355957,
      "learning_rate": 4.9974091841168195e-05,
      "loss": 0.1745,
      "step": 150
    },
    {
      "epoch": 0.24511681348142475,
      "grad_norm": 1.2456187009811401,
      "learning_rate": 4.993466408088629e-05,
      "loss": 0.1791,
      "step": 160
    },
    {
      "epoch": 0.26043661432401377,
      "grad_norm": 1.766223669052124,
      "learning_rate": 4.987735163612856e-05,
      "loss": 0.1799,
      "step": 170
    },
    {
      "epoch": 0.2757564151666028,
      "grad_norm": 1.1216437816619873,
      "learning_rate": 4.980219561492788e-05,
      "loss": 0.1722,
      "step": 180
    },
    {
      "epoch": 0.29107621600919187,
      "grad_norm": 1.6936599016189575,
      "learning_rate": 4.970924992383465e-05,
      "loss": 0.1779,
      "step": 190
    },
    {
      "epoch": 0.3063960168517809,
      "grad_norm": 0.9482419490814209,
      "learning_rate": 4.9598581229251627e-05,
      "loss": 0.1719,
      "step": 200
    },
    {
      "epoch": 0.32171581769436997,
      "grad_norm": 2.0092828273773193,
      "learning_rate": 4.94702689096167e-05,
      "loss": 0.1797,
      "step": 210
    },
    {
      "epoch": 0.337035618536959,
      "grad_norm": 1.0336412191390991,
      "learning_rate": 4.932440499846776e-05,
      "loss": 0.1724,
      "step": 220
    },
    {
      "epoch": 0.35235541937954806,
      "grad_norm": 1.8324247598648071,
      "learning_rate": 4.916109411843049e-05,
      "loss": 0.164,
      "step": 230
    },
    {
      "epoch": 0.3676752202221371,
      "grad_norm": 2.675250768661499,
      "learning_rate": 4.898045340617663e-05,
      "loss": 0.1825,
      "step": 240
    },
    {
      "epoch": 0.38299502106472616,
      "grad_norm": 0.964930534362793,
      "learning_rate": 4.8782612428406235e-05,
      "loss": 0.1972,
      "step": 250
    },
    {
      "epoch": 0.3983148219073152,
      "grad_norm": 1.0041260719299316,
      "learning_rate": 4.856771308891445e-05,
      "loss": 0.1726,
      "step": 260
    },
    {
      "epoch": 0.41363462274990426,
      "grad_norm": 1.6016812324523926,
      "learning_rate": 4.833590952680933e-05,
      "loss": 0.1687,
      "step": 270
    },
    {
      "epoch": 0.4289544235924933,
      "grad_norm": 1.0645697116851807,
      "learning_rate": 4.8087368005953716e-05,
      "loss": 0.1672,
      "step": 280
    },
    {
      "epoch": 0.44427422443508235,
      "grad_norm": 1.067694067955017,
      "learning_rate": 4.7849516776052285e-05,
      "loss": 0.2546,
      "step": 290
    },
    {
      "epoch": 0.4595940252776714,
      "grad_norm": 1.878039002418518,
      "learning_rate": 4.756967408530979e-05,
      "loss": 0.1964,
      "step": 300
    },
    {
      "epoch": 0.47491382612026045,
      "grad_norm": 0.7012358903884888,
      "learning_rate": 4.7273643027303604e-05,
      "loss": 0.1671,
      "step": 310
    },
    {
      "epoch": 0.4902336269628495,
      "grad_norm": 1.4005203247070312,
      "learning_rate": 4.6961635933832164e-05,
      "loss": 0.1559,
      "step": 320
    },
    {
      "epoch": 0.5055534278054385,
      "grad_norm": 1.3226211071014404,
      "learning_rate": 4.6633876595695404e-05,
      "loss": 0.1616,
      "step": 330
    },
    {
      "epoch": 0.5208732286480275,
      "grad_norm": 0.8979308605194092,
      "learning_rate": 4.6290600102178174e-05,
      "loss": 0.1653,
      "step": 340
    },
    {
      "epoch": 0.5361930294906166,
      "grad_norm": 0.6928342580795288,
      "learning_rate": 4.593205267242962e-05,
      "loss": 0.1668,
      "step": 350
    },
    {
      "epoch": 0.5515128303332056,
      "grad_norm": 1.9213021993637085,
      "learning_rate": 4.555849147885961e-05,
      "loss": 0.1657,
      "step": 360
    },
    {
      "epoch": 0.5668326311757947,
      "grad_norm": 1.7668359279632568,
      "learning_rate": 4.517018446267873e-05,
      "loss": 0.1546,
      "step": 370
    },
    {
      "epoch": 0.5821524320183837,
      "grad_norm": 1.6916979551315308,
      "learning_rate": 4.4767410141714265e-05,
      "loss": 0.1607,
      "step": 380
    },
    {
      "epoch": 0.5974722328609728,
      "grad_norm": 1.1502019166946411,
      "learning_rate": 4.435045741064001e-05,
      "loss": 0.1533,
      "step": 390
    },
    {
      "epoch": 0.6127920337035618,
      "grad_norm": 0.740206778049469,
      "learning_rate": 4.391962533376307e-05,
      "loss": 0.1492,
      "step": 400
    },
    {
      "epoch": 0.6281118345461509,
      "grad_norm": 1.3024797439575195,
      "learning_rate": 4.347522293051648e-05,
      "loss": 0.1619,
      "step": 410
    },
    {
      "epoch": 0.6434316353887399,
      "grad_norm": 1.0448600053787231,
      "learning_rate": 4.301756895381131e-05,
      "loss": 0.1669,
      "step": 420
    },
    {
      "epoch": 0.658751436231329,
      "grad_norm": 0.795724093914032,
      "learning_rate": 4.254699166140736e-05,
      "loss": 0.1527,
      "step": 430
    },
    {
      "epoch": 0.674071237073918,
      "grad_norm": 1.7839527130126953,
      "learning_rate": 4.206382858046636e-05,
      "loss": 0.1682,
      "step": 440
    },
    {
      "epoch": 0.6893910379165071,
      "grad_norm": 1.1754008531570435,
      "learning_rate": 4.156842626545662e-05,
      "loss": 0.1768,
      "step": 450
    },
    {
      "epoch": 0.7047108387590961,
      "grad_norm": 1.2899950742721558,
      "learning_rate": 4.106114004958271e-05,
      "loss": 0.1448,
      "step": 460
    },
    {
      "epoch": 0.7200306396016852,
      "grad_norm": 0.9760959148406982,
      "learning_rate": 4.0542333789918474e-05,
      "loss": 0.1574,
      "step": 470
    },
    {
      "epoch": 0.7353504404442742,
      "grad_norm": 1.0134295225143433,
      "learning_rate": 4.001237960642622e-05,
      "loss": 0.174,
      "step": 480
    },
    {
      "epoch": 0.7506702412868632,
      "grad_norm": 1.4056193828582764,
      "learning_rate": 3.9471657615049284e-05,
      "loss": 0.1555,
      "step": 490
    },
    {
      "epoch": 0.7659900421294523,
      "grad_norm": 0.9953039884567261,
      "learning_rate": 3.892055565506929e-05,
      "loss": 0.1596,
      "step": 500
    },
    {
      "epoch": 0.7813098429720413,
      "grad_norm": 1.4691489934921265,
      "learning_rate": 3.8359469010923845e-05,
      "loss": 0.1439,
      "step": 510
    },
    {
      "epoch": 0.7966296438146304,
      "grad_norm": 1.2256163358688354,
      "learning_rate": 3.7788800128684084e-05,
      "loss": 0.1699,
      "step": 520
    },
    {
      "epoch": 0.8119494446572194,
      "grad_norm": 1.2695224285125732,
      "learning_rate": 3.72089583273954e-05,
      "loss": 0.1611,
      "step": 530
    },
    {
      "epoch": 0.8272692454998085,
      "grad_norm": 0.6958436369895935,
      "learning_rate": 3.662035950548852e-05,
      "loss": 0.1704,
      "step": 540
    },
    {
      "epoch": 0.8425890463423975,
      "grad_norm": 0.942311704158783,
      "learning_rate": 3.602342584247141e-05,
      "loss": 0.1549,
      "step": 550
    },
    {
      "epoch": 0.8579088471849866,
      "grad_norm": 0.9393925070762634,
      "learning_rate": 3.541858549611596e-05,
      "loss": 0.143,
      "step": 560
    },
    {
      "epoch": 0.8732286480275756,
      "grad_norm": 1.6388263702392578,
      "learning_rate": 3.480627229535677e-05,
      "loss": 0.1642,
      "step": 570
    },
    {
      "epoch": 0.8885484488701647,
      "grad_norm": 2.7907063961029053,
      "learning_rate": 3.418692542912218e-05,
      "loss": 0.1565,
      "step": 580
    },
    {
      "epoch": 0.9038682497127537,
      "grad_norm": 1.0632511377334595,
      "learning_rate": 3.356098913132077e-05,
      "loss": 0.1699,
      "step": 590
    },
    {
      "epoch": 0.9191880505553428,
      "grad_norm": 0.8736873269081116,
      "learning_rate": 3.292891236220929e-05,
      "loss": 0.1595,
      "step": 600
    },
    {
      "epoch": 0.9345078513979318,
      "grad_norm": 1.2067923545837402,
      "learning_rate": 3.2291148486370626e-05,
      "loss": 0.145,
      "step": 610
    },
    {
      "epoch": 0.9498276522405209,
      "grad_norm": 1.866892695426941,
      "learning_rate": 3.164815494753261e-05,
      "loss": 0.1628,
      "step": 620
    },
    {
      "epoch": 0.9651474530831099,
      "grad_norm": 1.3308513164520264,
      "learning_rate": 3.100039294046107e-05,
      "loss": 0.1507,
      "step": 630
    },
    {
      "epoch": 0.980467253925699,
      "grad_norm": 0.6177799701690674,
      "learning_rate": 3.0348327080162435e-05,
      "loss": 0.1542,
      "step": 640
    },
    {
      "epoch": 0.995787054768288,
      "grad_norm": 0.8189528584480286,
      "learning_rate": 2.9692425068633056e-05,
      "loss": 0.1515,
      "step": 650
    },
    {
      "epoch": 1.011106855610877,
      "grad_norm": 1.3302732706069946,
      "learning_rate": 2.903315735939438e-05,
      "loss": 0.128,
      "step": 660
    },
    {
      "epoch": 1.026426656453466,
      "grad_norm": 1.4243049621582031,
      "learning_rate": 2.8370996820054594e-05,
      "loss": 0.1285,
      "step": 670
    },
    {
      "epoch": 1.041746457296055,
      "grad_norm": 1.4201774597167969,
      "learning_rate": 2.770641839313871e-05,
      "loss": 0.1199,
      "step": 680
    },
    {
      "epoch": 1.0570662581386443,
      "grad_norm": 1.272178053855896,
      "learning_rate": 2.703989875543033e-05,
      "loss": 0.1186,
      "step": 690
    },
    {
      "epoch": 1.0723860589812333,
      "grad_norm": 1.1584429740905762,
      "learning_rate": 2.6371915976069623e-05,
      "loss": 0.1176,
      "step": 700
    },
    {
      "epoch": 1.0877058598238223,
      "grad_norm": 1.2575374841690063,
      "learning_rate": 2.5702949173652513e-05,
      "loss": 0.109,
      "step": 710
    },
    {
      "epoch": 1.1030256606664113,
      "grad_norm": 1.7451833486557007,
      "learning_rate": 2.5033478172577156e-05,
      "loss": 0.1198,
      "step": 720
    },
    {
      "epoch": 1.1183454615090005,
      "grad_norm": 1.5810818672180176,
      "learning_rate": 2.4363983158884207e-05,
      "loss": 0.1334,
      "step": 730
    },
    {
      "epoch": 1.1336652623515895,
      "grad_norm": 0.9455736875534058,
      "learning_rate": 2.3694944335837653e-05,
      "loss": 0.1032,
      "step": 740
    },
    {
      "epoch": 1.1489850631941785,
      "grad_norm": 1.0379432439804077,
      "learning_rate": 2.3026841579493308e-05,
      "loss": 0.1233,
      "step": 750
    },
    {
      "epoch": 1.1643048640367675,
      "grad_norm": 2.2529335021972656,
      "learning_rate": 2.2360154094502016e-05,
      "loss": 0.1022,
      "step": 760
    },
    {
      "epoch": 1.1796246648793565,
      "grad_norm": 2.491673707962036,
      "learning_rate": 2.1695360070394397e-05,
      "loss": 0.1396,
      "step": 770
    },
    {
      "epoch": 1.1949444657219457,
      "grad_norm": 1.8448783159255981,
      "learning_rate": 2.1032936338593718e-05,
      "loss": 0.1121,
      "step": 780
    },
    {
      "epoch": 1.2102642665645347,
      "grad_norm": 1.172118067741394,
      "learning_rate": 2.0373358030402908e-05,
      "loss": 0.1119,
      "step": 790
    },
    {
      "epoch": 1.2255840674071237,
      "grad_norm": 1.138342022895813,
      "learning_rate": 1.9717098236210942e-05,
      "loss": 0.1059,
      "step": 800
    },
    {
      "epoch": 1.2409038682497127,
      "grad_norm": 1.9027926921844482,
      "learning_rate": 1.9064627666163147e-05,
      "loss": 0.1209,
      "step": 810
    },
    {
      "epoch": 1.2562236690923019,
      "grad_norm": 2.3753111362457275,
      "learning_rate": 1.841641431253876e-05,
      "loss": 0.1204,
      "step": 820
    },
    {
      "epoch": 1.2715434699348909,
      "grad_norm": 2.0463998317718506,
      "learning_rate": 1.7772923114077872e-05,
      "loss": 0.1158,
      "step": 830
    },
    {
      "epoch": 1.2868632707774799,
      "grad_norm": 1.3232579231262207,
      "learning_rate": 1.7134615622498622e-05,
      "loss": 0.1241,
      "step": 840
    },
    {
      "epoch": 1.3021830716200689,
      "grad_norm": 1.4730100631713867,
      "learning_rate": 1.6501949671443698e-05,
      "loss": 0.1228,
      "step": 850
    },
    {
      "epoch": 1.3175028724626578,
      "grad_norm": 1.0548632144927979,
      "learning_rate": 1.587537904809372e-05,
      "loss": 0.1191,
      "step": 860
    },
    {
      "epoch": 1.332822673305247,
      "grad_norm": 1.0113825798034668,
      "learning_rate": 1.5255353167683017e-05,
      "loss": 0.1239,
      "step": 870
    },
    {
      "epoch": 1.348142474147836,
      "grad_norm": 1.3957335948944092,
      "learning_rate": 1.4642316751151158e-05,
      "loss": 0.1247,
      "step": 880
    },
    {
      "epoch": 1.363462274990425,
      "grad_norm": 2.285700798034668,
      "learning_rate": 1.4036709506161577e-05,
      "loss": 0.1114,
      "step": 890
    },
    {
      "epoch": 1.3787820758330143,
      "grad_norm": 1.9826772212982178,
      "learning_rate": 1.3438965811716058e-05,
      "loss": 0.1056,
      "step": 900
    },
    {
      "epoch": 1.3941018766756033,
      "grad_norm": 2.5991768836975098,
      "learning_rate": 1.284951440659119e-05,
      "loss": 0.1068,
      "step": 910
    },
    {
      "epoch": 1.4094216775181923,
      "grad_norm": 1.572935700416565,
      "learning_rate": 1.2268778081820362e-05,
      "loss": 0.1342,
      "step": 920
    },
    {
      "epoch": 1.4247414783607812,
      "grad_norm": 0.9431979060173035,
      "learning_rate": 1.1697173377441928e-05,
      "loss": 0.1056,
      "step": 930
    },
    {
      "epoch": 1.4400612792033702,
      "grad_norm": 1.69528067111969,
      "learning_rate": 1.1135110283730857e-05,
      "loss": 0.1224,
      "step": 940
    },
    {
      "epoch": 1.4553810800459595,
      "grad_norm": 2.0429234504699707,
      "learning_rate": 1.0582991947128324e-05,
      "loss": 0.1249,
      "step": 950
    },
    {
      "epoch": 1.4707008808885484,
      "grad_norm": 1.1377930641174316,
      "learning_rate": 1.0041214381080177e-05,
      "loss": 0.1181,
      "step": 960
    },
    {
      "epoch": 1.4860206817311374,
      "grad_norm": 1.9961285591125488,
      "learning_rate": 9.51016618199155e-06,
      "loss": 0.1215,
      "step": 970
    },
    {
      "epoch": 1.5013404825737267,
      "grad_norm": 1.3531043529510498,
      "learning_rate": 8.990228250501445e-06,
      "loss": 0.115,
      "step": 980
    },
    {
      "epoch": 1.5166602834163156,
      "grad_norm": 2.184171199798584,
      "learning_rate": 8.48177351827727e-06,
      "loss": 0.1224,
      "step": 990
    },
    {
      "epoch": 1.5319800842589046,
      "grad_norm": 1.2236934900283813,
      "learning_rate": 7.985166680525133e-06,
      "loss": 0.1027,
      "step": 1000
    },
    {
      "epoch": 1.5472998851014936,
      "grad_norm": 1.3753931522369385,
      "learning_rate": 7.500763934407851e-06,
      "loss": 0.119,
      "step": 1010
    },
    {
      "epoch": 1.5626196859440826,
      "grad_norm": 1.139756202697754,
      "learning_rate": 7.028912723558337e-06,
      "loss": 0.1108,
      "step": 1020
    },
    {
      "epoch": 1.5779394867866716,
      "grad_norm": 2.0436789989471436,
      "learning_rate": 6.569951488871498e-06,
      "loss": 0.1109,
      "step": 1030
    },
    {
      "epoch": 1.5932592876292608,
      "grad_norm": 2.008009672164917,
      "learning_rate": 6.124209425753455e-06,
      "loss": 0.0939,
      "step": 1040
    },
    {
      "epoch": 1.6085790884718498,
      "grad_norm": 1.6877059936523438,
      "learning_rate": 5.692006248002274e-06,
      "loss": 0.1005,
      "step": 1050
    },
    {
      "epoch": 1.623898889314439,
      "grad_norm": 2.632028818130493,
      "learning_rate": 5.2736519584893974e-06,
      "loss": 0.1155,
      "step": 1060
    },
    {
      "epoch": 1.639218690157028,
      "grad_norm": 1.3659001588821411,
      "learning_rate": 4.869446626806404e-06,
      "loss": 0.1177,
      "step": 1070
    },
    {
      "epoch": 1.654538490999617,
      "grad_norm": 1.4211992025375366,
      "learning_rate": 4.4796801740365325e-06,
      "loss": 0.1157,
      "step": 1080
    },
    {
      "epoch": 1.669858291842206,
      "grad_norm": 1.7362433671951294,
      "learning_rate": 4.104632164805344e-06,
      "loss": 0.0993,
      "step": 1090
    },
    {
      "epoch": 1.685178092684795,
      "grad_norm": 1.76005220413208,
      "learning_rate": 3.7445716067596503e-06,
      "loss": 0.1131,
      "step": 1100
    },
    {
      "epoch": 1.700497893527384,
      "grad_norm": 1.457828402519226,
      "learning_rate": 3.399756757618572e-06,
      "loss": 0.1045,
      "step": 1110
    },
    {
      "epoch": 1.7158176943699732,
      "grad_norm": 2.1384546756744385,
      "learning_rate": 3.0704349399351435e-06,
      "loss": 0.1042,
      "step": 1120
    },
    {
      "epoch": 1.7311374952125622,
      "grad_norm": 1.9502437114715576,
      "learning_rate": 2.7568423637012646e-06,
      "loss": 0.1012,
      "step": 1130
    },
    {
      "epoch": 1.7464572960551514,
      "grad_norm": 1.0186189413070679,
      "learning_rate": 2.4592039569232338e-06,
      "loss": 0.1108,
      "step": 1140
    },
    {
      "epoch": 1.7617770968977404,
      "grad_norm": 2.6700751781463623,
      "learning_rate": 2.1777332042895227e-06,
      "loss": 0.103,
      "step": 1150
    },
    {
      "epoch": 1.7770968977403294,
      "grad_norm": 2.4729344844818115,
      "learning_rate": 1.9126319940462932e-06,
      "loss": 0.1302,
      "step": 1160
    },
    {
      "epoch": 1.7924166985829184,
      "grad_norm": 2.2577807903289795,
      "learning_rate": 1.6640904731906715e-06,
      "loss": 0.0866,
      "step": 1170
    },
    {
      "epoch": 1.8077364994255074,
      "grad_norm": 2.123377799987793,
      "learning_rate": 1.4322869110855508e-06,
      "loss": 0.1013,
      "step": 1180
    },
    {
      "epoch": 1.8230563002680964,
      "grad_norm": 1.809842586517334,
      "learning_rate": 1.2173875715937727e-06,
      "loss": 0.103,
      "step": 1190
    },
    {
      "epoch": 1.8383761011106856,
      "grad_norm": 1.5888787508010864,
      "learning_rate": 1.0195465938233756e-06,
      "loss": 0.1102,
      "step": 1200
    },
    {
      "epoch": 1.8536959019532746,
      "grad_norm": 2.0236077308654785,
      "learning_rate": 8.389058815695127e-07,
      "loss": 0.1061,
      "step": 1210
    },
    {
      "epoch": 1.8690157027958638,
      "grad_norm": 1.3156168460845947,
      "learning_rate": 6.755950015322477e-07,
      "loss": 0.1197,
      "step": 1220
    },
    {
      "epoch": 1.8843355036384528,
      "grad_norm": 1.5019893646240234,
      "learning_rate": 5.297310903832981e-07,
      "loss": 0.1117,
      "step": 1230
    },
    {
      "epoch": 1.8996553044810418,
      "grad_norm": 1.4774059057235718,
      "learning_rate": 4.0141877074837684e-07,
      "loss": 0.103,
      "step": 1240
    },
    {
      "epoch": 1.9149751053236308,
      "grad_norm": 2.6503939628601074,
      "learning_rate": 2.907500761653581e-07,
      "loss": 0.1159,
      "step": 1250
    },
    {
      "epoch": 1.9302949061662198,
      "grad_norm": 2.0329129695892334,
      "learning_rate": 1.9780438507212285e-07,
      "loss": 0.1036,
      "step": 1260
    },
    {
      "epoch": 1.9456147070088088,
      "grad_norm": 1.6255367994308472,
      "learning_rate": 1.226483638714443e-07,
      "loss": 0.1034,
      "step": 1270
    },
    {
      "epoch": 1.9609345078513978,
      "grad_norm": 1.2302167415618896,
      "learning_rate": 6.533591911371262e-08,
      "loss": 0.1077,
      "step": 1280
    },
    {
      "epoch": 1.976254308693987,
      "grad_norm": 1.5862869024276733,
      "learning_rate": 2.590815883181108e-08,
      "loss": 0.1154,
      "step": 1290
    },
    {
      "epoch": 1.991574109536576,
      "grad_norm": 0.6642457246780396,
      "learning_rate": 4.393363055896216e-09,
      "loss": 0.0936,
      "step": 1300
    },
    {
      "epoch": 1.9977020298736117,
      "step": 1304,
      "total_flos": 1.2526294562163917e+17,
      "train_loss": 0.14428404131275743,
      "train_runtime": 1987.4694,
      "train_samples_per_second": 5.255,
      "train_steps_per_second": 0.656
    }
  ],
  "logging_steps": 10,
  "max_steps": 1304,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 5000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1.2526294562163917e+17,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
