{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.9977020298736117,
  "eval_steps": 500,
  "global_step": 1304,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.015319800842589047,
      "grad_norm": 0.9341220855712891,
      "learning_rate": 3.816793893129772e-06,
      "loss": 1.1119,
      "step": 10
    },
    {
      "epoch": 0.030639601685178094,
      "grad_norm": 0.7845427989959717,
      "learning_rate": 7.633587786259543e-06,
      "loss": 0.6751,
      "step": 20
    },
    {
      "epoch": 0.04595940252776714,
      "grad_norm": 0.47078341245651245,
      "learning_rate": 1.1450381679389314e-05,
      "loss": 0.2407,
      "step": 30
    },
    {
      "epoch": 0.06127920337035619,
      "grad_norm": 0.32625916600227356,
      "learning_rate": 1.5267175572519086e-05,
      "loss": 0.2239,
      "step": 40
    },
    {
      "epoch": 0.07659900421294523,
      "grad_norm": 0.28080877661705017,
      "learning_rate": 1.9083969465648855e-05,
      "loss": 0.1769,
      "step": 50
    },
    {
      "epoch": 0.09191880505553428,
      "grad_norm": 0.4571634829044342,
      "learning_rate": 2.2900763358778628e-05,
      "loss": 0.1778,
      "step": 60
    },
    {
      "epoch": 0.10723860589812333,
      "grad_norm": 0.2802547216415405,
      "learning_rate": 2.6717557251908397e-05,
      "loss": 0.1736,
      "step": 70
    },
    {
      "epoch": 0.12255840674071238,
      "grad_norm": 0.38628390431404114,
      "learning_rate": 3.053435114503817e-05,
      "loss": 0.161,
      "step": 80
    },
    {
      "epoch": 0.1378782075833014,
      "grad_norm": 0.22268149256706238,
      "learning_rate": 3.435114503816794e-05,
      "loss": 0.1861,
      "step": 90
    },
    {
      "epoch": 0.15319800842589046,
      "grad_norm": 0.22288812696933746,
      "learning_rate": 3.816793893129771e-05,
      "loss": 0.1617,
      "step": 100
    },
    {
      "epoch": 0.1685178092684795,
      "grad_norm": 0.33748844265937805,
      "learning_rate": 4.198473282442748e-05,
      "loss": 0.1599,
      "step": 110
    },
    {
      "epoch": 0.18383761011106856,
      "grad_norm": 0.47911933064460754,
      "learning_rate": 4.5801526717557256e-05,
      "loss": 0.1642,
      "step": 120
    },
    {
      "epoch": 0.1991574109536576,
      "grad_norm": 0.4396366477012634,
      "learning_rate": 4.9618320610687025e-05,
      "loss": 0.173,
      "step": 130
    },
    {
      "epoch": 0.21447721179624665,
      "grad_norm": 0.2947353720664978,
      "learning_rate": 4.999273764080493e-05,
      "loss": 0.1699,
      "step": 140
    },
    {
      "epoch": 0.2297970126388357,
      "grad_norm": 0.3331475853919983,
      "learning_rate": 4.996763860622537e-05,
      "loss": 0.1697,
      "step": 150
    },
    {
      "epoch": 0.24511681348142475,
      "grad_norm": 0.2630494236946106,
      "learning_rate": 4.992463123579936e-05,
      "loss": 0.1601,
      "step": 160
    },
    {
      "epoch": 0.26043661432401377,
      "grad_norm": 0.2866156995296478,
      "learning_rate": 4.986374637707503e-05,
      "loss": 0.1601,
      "step": 170
    },
    {
      "epoch": 0.2757564151666028,
      "grad_norm": 0.6145289540290833,
      "learning_rate": 4.978502770044167e-05,
      "loss": 0.1734,
      "step": 180
    },
    {
      "epoch": 0.29107621600919187,
      "grad_norm": 0.4072108864784241,
      "learning_rate": 4.968853166780668e-05,
      "loss": 0.1652,
      "step": 190
    },
    {
      "epoch": 0.3063960168517809,
      "grad_norm": 0.480544775724411,
      "learning_rate": 4.957432749209755e-05,
      "loss": 0.1644,
      "step": 200
    },
    {
      "epoch": 0.32171581769436997,
      "grad_norm": 0.4030105769634247,
      "learning_rate": 4.944249708761804e-05,
      "loss": 0.1684,
      "step": 210
    },
    {
      "epoch": 0.337035618536959,
      "grad_norm": 0.24336376786231995,
      "learning_rate": 4.929313501129427e-05,
      "loss": 0.1541,
      "step": 220
    },
    {
      "epoch": 0.35235541937954806,
      "grad_norm": 0.25352558493614197,
      "learning_rate": 4.912634839485251e-05,
      "loss": 0.153,
      "step": 230
    },
    {
      "epoch": 0.3676752202221371,
      "grad_norm": 0.4703757166862488,
      "learning_rate": 4.8942256867977775e-05,
      "loss": 0.1527,
      "step": 240
    },
    {
      "epoch": 0.38299502106472616,
      "grad_norm": 0.2738450765609741,
      "learning_rate": 4.874099247250798e-05,
      "loss": 0.1737,
      "step": 250
    },
    {
      "epoch": 0.3983148219073152,
      "grad_norm": 0.20326006412506104,
      "learning_rate": 4.8522699567725364e-05,
      "loss": 0.1517,
      "step": 260
    },
    {
      "epoch": 0.41363462274990426,
      "grad_norm": 0.2435881644487381,
      "learning_rate": 4.828753472681302e-05,
      "loss": 0.1614,
      "step": 270
    },
    {
      "epoch": 0.4289544235924933,
      "grad_norm": 0.27522778511047363,
      "learning_rate": 4.803566662455102e-05,
      "loss": 0.1449,
      "step": 280
    },
    {
      "epoch": 0.44427422443508235,
      "grad_norm": 0.3547927737236023,
      "learning_rate": 4.7767275916332356e-05,
      "loss": 0.1428,
      "step": 290
    },
    {
      "epoch": 0.4595940252776714,
      "grad_norm": 0.6259211897850037,
      "learning_rate": 4.74825551085857e-05,
      "loss": 0.1564,
      "step": 300
    },
    {
      "epoch": 0.47491382612026045,
      "grad_norm": 0.29468613862991333,
      "learning_rate": 4.7181708420697925e-05,
      "loss": 0.1652,
      "step": 310
    },
    {
      "epoch": 0.4902336269628495,
      "grad_norm": 0.32849884033203125,
      "learning_rate": 4.6864951638535285e-05,
      "loss": 0.144,
      "step": 320
    },
    {
      "epoch": 0.5055534278054385,
      "grad_norm": 0.35800299048423767,
      "learning_rate": 4.653251195966843e-05,
      "loss": 0.159,
      "step": 330
    },
    {
      "epoch": 0.5208732286480275,
      "grad_norm": 0.3061497211456299,
      "learning_rate": 4.618462783041231e-05,
      "loss": 0.1523,
      "step": 340
    },
    {
      "epoch": 0.5361930294906166,
      "grad_norm": 0.25552210211753845,
      "learning_rate": 4.582154877479761e-05,
      "loss": 0.1523,
      "step": 350
    },
    {
      "epoch": 0.5515128303332056,
      "grad_norm": 0.49050167202949524,
      "learning_rate": 4.544353521559677e-05,
      "loss": 0.151,
      "step": 360
    },
    {
      "epoch": 0.5668326311757947,
      "grad_norm": 0.315991073846817,
      "learning_rate": 4.505085828753258e-05,
      "loss": 0.1501,
      "step": 370
    },
    {
      "epoch": 0.5821524320183837,
      "grad_norm": 0.3402276635169983,
      "learning_rate": 4.4643799642803646e-05,
      "loss": 0.1472,
      "step": 380
    },
    {
      "epoch": 0.5974722328609728,
      "grad_norm": 0.30481481552124023,
      "learning_rate": 4.422265124906593e-05,
      "loss": 0.1499,
      "step": 390
    },
    {
      "epoch": 0.6127920337035618,
      "grad_norm": 0.33355873823165894,
      "learning_rate": 4.378771518001551e-05,
      "loss": 0.1343,
      "step": 400
    },
    {
      "epoch": 0.6281118345461509,
      "grad_norm": 0.3752823770046234,
      "learning_rate": 4.333930339872264e-05,
      "loss": 0.15,
      "step": 410
    },
    {
      "epoch": 0.6434316353887399,
      "grad_norm": 0.44457370042800903,
      "learning_rate": 4.2877737533872485e-05,
      "loss": 0.1486,
      "step": 420
    },
    {
      "epoch": 0.658751436231329,
      "grad_norm": 0.2837487459182739,
      "learning_rate": 4.2403348649073174e-05,
      "loss": 0.1524,
      "step": 430
    },
    {
      "epoch": 0.674071237073918,
      "grad_norm": 0.45043206214904785,
      "learning_rate": 4.1916477005396414e-05,
      "loss": 0.1529,
      "step": 440
    },
    {
      "epoch": 0.6893910379165071,
      "grad_norm": 0.24350300431251526,
      "learning_rate": 4.141747181732128e-05,
      "loss": 0.1588,
      "step": 450
    },
    {
      "epoch": 0.7047108387590961,
      "grad_norm": 0.21050415933132172,
      "learning_rate": 4.09066910022559e-05,
      "loss": 0.1427,
      "step": 460
    },
    {
      "epoch": 0.7200306396016852,
      "grad_norm": 0.3318917751312256,
      "learning_rate": 4.038450092381697e-05,
      "loss": 0.1508,
      "step": 470
    },
    {
      "epoch": 0.7353504404442742,
      "grad_norm": 0.26478278636932373,
      "learning_rate": 3.985127612905108e-05,
      "loss": 0.1549,
      "step": 480
    },
    {
      "epoch": 0.7506702412868632,
      "grad_norm": 0.3911854028701782,
      "learning_rate": 3.93073990797864e-05,
      "loss": 0.1406,
      "step": 490
    },
    {
      "epoch": 0.7659900421294523,
      "grad_norm": 0.24975541234016418,
      "learning_rate": 3.875325987830736e-05,
      "loss": 0.1502,
      "step": 500
    },
    {
      "epoch": 0.7813098429720413,
      "grad_norm": 0.4537622928619385,
      "learning_rate": 3.818925598754918e-05,
      "loss": 0.1392,
      "step": 510
    },
    {
      "epoch": 0.7966296438146304,
      "grad_norm": 0.2848789095878601,
      "learning_rate": 3.761579194601284e-05,
      "loss": 0.1511,
      "step": 520
    },
    {
      "epoch": 0.8119494446572194,
      "grad_norm": 0.3659457564353943,
      "learning_rate": 3.703327907760499e-05,
      "loss": 0.1457,
      "step": 530
    },
    {
      "epoch": 0.8272692454998085,
      "grad_norm": 0.21618542075157166,
      "learning_rate": 3.644213519661103e-05,
      "loss": 0.155,
      "step": 540
    },
    {
      "epoch": 0.8425890463423975,
      "grad_norm": 0.3251773416996002,
      "learning_rate": 3.5842784308012816e-05,
      "loss": 0.1456,
      "step": 550
    },
    {
      "epoch": 0.8579088471849866,
      "grad_norm": 0.2513447403907776,
      "learning_rate": 3.523565630336607e-05,
      "loss": 0.1388,
      "step": 560
    },
    {
      "epoch": 0.8732286480275756,
      "grad_norm": 0.5134329199790955,
      "learning_rate": 3.4621186652455515e-05,
      "loss": 0.1456,
      "step": 570
    },
    {
      "epoch": 0.8885484488701647,
      "grad_norm": 0.38531777262687683,
      "learning_rate": 3.399981609094902e-05,
      "loss": 0.1385,
      "step": 580
    },
    {
      "epoch": 0.9038682497127537,
      "grad_norm": 0.4675888121128082,
      "learning_rate": 3.3371990304274656e-05,
      "loss": 0.1616,
      "step": 590
    },
    {
      "epoch": 0.9191880505553428,
      "grad_norm": 0.31117871403694153,
      "learning_rate": 3.273815960794757e-05,
      "loss": 0.1485,
      "step": 600
    },
    {
      "epoch": 0.9345078513979318,
      "grad_norm": 0.30350205302238464,
      "learning_rate": 3.20987786245758e-05,
      "loss": 0.1339,
      "step": 610
    },
    {
      "epoch": 0.9498276522405209,
      "grad_norm": 0.36945247650146484,
      "learning_rate": 3.1454305957776794e-05,
      "loss": 0.1437,
      "step": 620
    },
    {
      "epoch": 0.9651474530831099,
      "grad_norm": 0.28993043303489685,
      "learning_rate": 3.0805203863238527e-05,
      "loss": 0.1535,
      "step": 630
    },
    {
      "epoch": 0.980467253925699,
      "grad_norm": 0.25112542510032654,
      "learning_rate": 3.0151937917161088e-05,
      "loss": 0.1451,
      "step": 640
    },
    {
      "epoch": 0.995787054768288,
      "grad_norm": 0.3329163193702698,
      "learning_rate": 2.949497668231663e-05,
      "loss": 0.1417,
      "step": 650
    },
    {
      "epoch": 1.011106855610877,
      "grad_norm": 0.329998642206192,
      "learning_rate": 2.8834791371967142e-05,
      "loss": 0.1285,
      "step": 660
    },
    {
      "epoch": 1.026426656453466,
      "grad_norm": 0.2637293338775635,
      "learning_rate": 2.8171855511881106e-05,
      "loss": 0.1311,
      "step": 670
    },
    {
      "epoch": 1.041746457296055,
      "grad_norm": 0.38303622603416443,
      "learning_rate": 2.7506644600691567e-05,
      "loss": 0.1239,
      "step": 680
    },
    {
      "epoch": 1.0570662581386443,
      "grad_norm": 0.2847003936767578,
      "learning_rate": 2.6839635768839018e-05,
      "loss": 0.1235,
      "step": 690
    },
    {
      "epoch": 1.0723860589812333,
      "grad_norm": 0.38254985213279724,
      "learning_rate": 2.6171307436343917e-05,
      "loss": 0.1234,
      "step": 700
    },
    {
      "epoch": 1.0877058598238223,
      "grad_norm": 0.23154547810554504,
      "learning_rate": 2.550213896965431e-05,
      "loss": 0.1185,
      "step": 710
    },
    {
      "epoch": 1.1030256606664113,
      "grad_norm": 0.36052900552749634,
      "learning_rate": 2.483261033781444e-05,
      "loss": 0.1252,
      "step": 720
    },
    {
      "epoch": 1.1183454615090005,
      "grad_norm": 0.24592888355255127,
      "learning_rate": 2.416320176820132e-05,
      "loss": 0.1276,
      "step": 730
    },
    {
      "epoch": 1.1336652623515895,
      "grad_norm": 0.32704928517341614,
      "learning_rate": 2.3494393402075882e-05,
      "loss": 0.1112,
      "step": 740
    },
    {
      "epoch": 1.1489850631941785,
      "grad_norm": 0.34154894948005676,
      "learning_rate": 2.2826664950195984e-05,
      "loss": 0.1332,
      "step": 750
    },
    {
      "epoch": 1.1643048640367675,
      "grad_norm": 0.29301294684410095,
      "learning_rate": 2.2160495348738123e-05,
      "loss": 0.1138,
      "step": 760
    },
    {
      "epoch": 1.1796246648793565,
      "grad_norm": 0.38142678141593933,
      "learning_rate": 2.1496362415774812e-05,
      "loss": 0.1471,
      "step": 770
    },
    {
      "epoch": 1.1949444657219457,
      "grad_norm": 0.238408163189888,
      "learning_rate": 2.0834742508553825e-05,
      "loss": 0.1247,
      "step": 780
    },
    {
      "epoch": 1.2102642665645347,
      "grad_norm": 0.373796284198761,
      "learning_rate": 2.017611018182533e-05,
      "loss": 0.1225,
      "step": 790
    },
    {
      "epoch": 1.2255840674071237,
      "grad_norm": 0.4135371148586273,
      "learning_rate": 1.9520937847461864e-05,
      "loss": 0.1183,
      "step": 800
    },
    {
      "epoch": 1.2409038682497127,
      "grad_norm": 0.40739715099334717,
      "learning_rate": 1.886969543561525e-05,
      "loss": 0.1255,
      "step": 810
    },
    {
      "epoch": 1.2562236690923019,
      "grad_norm": 0.37600886821746826,
      "learning_rate": 1.8222850057653627e-05,
      "loss": 0.1228,
      "step": 820
    },
    {
      "epoch": 1.2715434699348909,
      "grad_norm": 0.5917083621025085,
      "learning_rate": 1.7580865671120295e-05,
      "loss": 0.121,
      "step": 830
    },
    {
      "epoch": 1.2868632707774799,
      "grad_norm": 0.3385573923587799,
      "learning_rate": 1.6944202746954583e-05,
      "loss": 0.1357,
      "step": 840
    },
    {
      "epoch": 1.3021830716200689,
      "grad_norm": 0.3539119064807892,
      "learning_rate": 1.6313317939213647e-05,
      "loss": 0.1272,
      "step": 850
    },
    {
      "epoch": 1.3175028724626578,
      "grad_norm": 0.3416787087917328,
      "learning_rate": 1.5688663757531878e-05,
      "loss": 0.1214,
      "step": 860
    },
    {
      "epoch": 1.332822673305247,
      "grad_norm": 0.36900702118873596,
      "learning_rate": 1.5070688242553006e-05,
      "loss": 0.1297,
      "step": 870
    },
    {
      "epoch": 1.348142474147836,
      "grad_norm": 0.2817242741584778,
      "learning_rate": 1.445983464456761e-05,
      "loss": 0.1333,
      "step": 880
    },
    {
      "epoch": 1.363462274990425,
      "grad_norm": 0.3381797671318054,
      "learning_rate": 1.3856541105586545e-05,
      "loss": 0.1245,
      "step": 890
    },
    {
      "epoch": 1.3787820758330143,
      "grad_norm": 0.5226531624794006,
      "learning_rate": 1.3261240345078433e-05,
      "loss": 0.1175,
      "step": 900
    },
    {
      "epoch": 1.3941018766756033,
      "grad_norm": 0.24633361399173737,
      "learning_rate": 1.2674359349596421e-05,
      "loss": 0.1158,
      "step": 910
    },
    {
      "epoch": 1.4094216775181923,
      "grad_norm": 0.434631884098053,
      "learning_rate": 1.2096319066517037e-05,
      "loss": 0.1343,
      "step": 920
    },
    {
      "epoch": 1.4247414783607812,
      "grad_norm": 0.2606666088104248,
      "learning_rate": 1.1527534102110612e-05,
      "loss": 0.1065,
      "step": 930
    },
    {
      "epoch": 1.4400612792033702,
      "grad_norm": 0.4128410816192627,
      "learning_rate": 1.0968412424160084e-05,
      "loss": 0.1277,
      "step": 940
    },
    {
      "epoch": 1.4553810800459595,
      "grad_norm": 0.4905949831008911,
      "learning_rate": 1.0419355069341204e-05,
      "loss": 0.1415,
      "step": 950
    },
    {
      "epoch": 1.4707008808885484,
      "grad_norm": 0.3796606957912445,
      "learning_rate": 9.880755855574186e-06,
      "loss": 0.1256,
      "step": 960
    },
    {
      "epoch": 1.4860206817311374,
      "grad_norm": 0.490413635969162,
      "learning_rate": 9.353001099553178e-06,
      "loss": 0.1359,
      "step": 970
    },
    {
      "epoch": 1.5013404825737267,
      "grad_norm": 0.35015448927879333,
      "learning_rate": 8.836469339655978e-06,
      "loss": 0.1229,
      "step": 980
    },
    {
      "epoch": 1.5166602834163156,
      "grad_norm": 0.32921308279037476,
      "learning_rate": 8.331531064432876e-06,
      "loss": 0.1299,
      "step": 990
    },
    {
      "epoch": 1.5319800842589046,
      "grad_norm": 0.3956048786640167,
      "learning_rate": 7.838548446869356e-06,
      "loss": 0.1107,
      "step": 1000
    },
    {
      "epoch": 1.5472998851014936,
      "grad_norm": 0.2523763179779053,
      "learning_rate": 7.357875084613208e-06,
      "loss": 0.1233,
      "step": 1010
    },
    {
      "epoch": 1.5626196859440826,
      "grad_norm": 0.24545352160930634,
      "learning_rate": 6.889855746352375e-06,
      "loss": 0.1165,
      "step": 1020
    },
    {
      "epoch": 1.5779394867866716,
      "grad_norm": 0.4053359627723694,
      "learning_rate": 6.434826124525561e-06,
      "loss": 0.1118,
      "step": 1030
    },
    {
      "epoch": 1.5932592876292608,
      "grad_norm": 0.23606693744659424,
      "learning_rate": 5.993112594542813e-06,
      "loss": 0.111,
      "step": 1040
    },
    {
      "epoch": 1.6085790884718498,
      "grad_norm": 0.4125782549381256,
      "learning_rate": 5.565031980688845e-06,
      "loss": 0.1132,
      "step": 1050
    },
    {
      "epoch": 1.623898889314439,
      "grad_norm": 0.36352911591529846,
      "learning_rate": 5.150891328877103e-06,
      "loss": 0.1204,
      "step": 1060
    },
    {
      "epoch": 1.639218690157028,
      "grad_norm": 0.3463282585144043,
      "learning_rate": 4.750987686417405e-06,
      "loss": 0.1288,
      "step": 1070
    },
    {
      "epoch": 1.654538490999617,
      "grad_norm": 0.2855854332447052,
      "learning_rate": 4.365607888955206e-06,
      "loss": 0.1259,
      "step": 1080
    },
    {
      "epoch": 1.669858291842206,
      "grad_norm": 0.289350688457489,
      "learning_rate": 3.99502835473535e-06,
      "loss": 0.1139,
      "step": 1090
    },
    {
      "epoch": 1.685178092684795,
      "grad_norm": 0.39770013093948364,
      "learning_rate": 3.6395148863377858e-06,
      "loss": 0.1174,
      "step": 1100
    },
    {
      "epoch": 1.700497893527384,
      "grad_norm": 0.45436790585517883,
      "learning_rate": 3.2993224800274974e-06,
      "loss": 0.1209,
      "step": 1110
    },
    {
      "epoch": 1.7158176943699732,
      "grad_norm": 0.34357956051826477,
      "learning_rate": 2.974695142855388e-06,
      "loss": 0.1107,
      "step": 1120
    },
    {
      "epoch": 1.7311374952125622,
      "grad_norm": 0.42854559421539307,
      "learning_rate": 2.665865717641353e-06,
      "loss": 0.1121,
      "step": 1130
    },
    {
      "epoch": 1.7464572960551514,
      "grad_norm": 0.3307943642139435,
      "learning_rate": 2.373055715964978e-06,
      "loss": 0.1211,
      "step": 1140
    },
    {
      "epoch": 1.7617770968977404,
      "grad_norm": 0.3251047432422638,
      "learning_rate": 2.096475159283698e-06,
      "loss": 0.1109,
      "step": 1150
    },
    {
      "epoch": 1.7770968977403294,
      "grad_norm": 0.4222699701786041,
      "learning_rate": 1.8363224282924641e-06,
      "loss": 0.1407,
      "step": 1160
    },
    {
      "epoch": 1.7924166985829184,
      "grad_norm": 0.39863336086273193,
      "learning_rate": 1.5927841206327815e-06,
      "loss": 0.099,
      "step": 1170
    },
    {
      "epoch": 1.8077364994255074,
      "grad_norm": 0.43124979734420776,
      "learning_rate": 1.3660349170533466e-06,
      "loss": 0.116,
      "step": 1180
    },
    {
      "epoch": 1.8230563002680964,
      "grad_norm": 0.3227565586566925,
      "learning_rate": 1.1562374561182144e-06,
      "loss": 0.1086,
      "step": 1190
    },
    {
      "epoch": 1.8383761011106856,
      "grad_norm": 0.30742621421813965,
      "learning_rate": 9.63542217552335e-07,
      "loss": 0.1219,
      "step": 1200
    },
    {
      "epoch": 1.8536959019532746,
      "grad_norm": 0.4963410198688507,
      "learning_rate": 7.88087414308189e-07,
      "loss": 0.1136,
      "step": 1210
    },
    {
      "epoch": 1.8690157027958638,
      "grad_norm": 0.243174210190773,
      "learning_rate": 6.299988934309026e-07,
      "loss": 0.1195,
      "step": 1220
    },
    {
      "epoch": 1.8843355036384528,
      "grad_norm": 0.32412397861480713,
      "learning_rate": 4.893900457929563e-07,
      "loss": 0.1272,
      "step": 1230
    },
    {
      "epoch": 1.8996553044810418,
      "grad_norm": 0.3807825744152069,
      "learning_rate": 3.663617247632339e-07,
      "loss": 0.1163,
      "step": 1240
    },
    {
      "epoch": 1.9149751053236308,
      "grad_norm": 0.41060933470726013,
      "learning_rate": 2.610021738687379e-07,
      "loss": 0.13,
      "step": 1250
    },
    {
      "epoch": 1.9302949061662198,
      "grad_norm": 0.3362877368927002,
      "learning_rate": 1.73386963500885e-07,
      "loss": 0.1108,
      "step": 1260
    },
    {
      "epoch": 1.9456147070088088,
      "grad_norm": 0.31864097714424133,
      "learning_rate": 1.0357893671171792e-07,
      "loss": 0.1182,
      "step": 1270
    },
    {
      "epoch": 1.9609345078513978,
      "grad_norm": 0.3247547447681427,
      "learning_rate": 5.162816413900873e-08,
      "loss": 0.124,
      "step": 1280
    },
    {
      "epoch": 1.976254308693987,
      "grad_norm": 0.307209312915802,
      "learning_rate": 1.7571908092475775e-08,
      "loss": 0.1362,
      "step": 1290
    },
    {
      "epoch": 1.991574109536576,
      "grad_norm": 0.23535676300525665,
      "learning_rate": 1.434595826954599e-09,
      "loss": 0.1055,
      "step": 1300
    },
    {
      "epoch": 1.9977020298736117,
      "step": 1304,
      "total_flos": 1.1365745676885197e+17,
      "train_loss": 0.15078284134345551,
      "train_runtime": 1693.3714,
      "train_samples_per_second": 6.168,
      "train_steps_per_second": 0.77
    }
  ],
  "logging_steps": 10,
  "max_steps": 1304,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 5000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1.1365745676885197e+17,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
