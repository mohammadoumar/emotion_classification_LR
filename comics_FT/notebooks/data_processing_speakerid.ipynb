{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b20aa00d-c84a-4970-bc99-ffd9f8ed9776",
   "metadata": {},
   "source": [
    "# Data Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "640868d0-4cf7-4fb0-bfb3-3ed663372d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc1c6f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "CURRENT_DIR = Path.cwd()\n",
    "#EAC_DIR = CURRENT_DIR.parent.parent\n",
    "EAC_DIR = Path(CURRENT_DIR) / \"emotion_analysis_comics\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb3fd533",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/Utilisateurs/umushtaq')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CURRENT_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0df15c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FILE = Path(EAC_DIR) / \"dataset_files\" / \"comics_dataset.csv\"\n",
    "DATASET_DIR = Path(EAC_DIR) / \"finetuning\" / \"datasets\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f0c44be-8571-45e5-a85e-808d4990a707",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(DATA_FILE, index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0977b469-ed44-4281-ab22-b1a2abcfcd4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique_emotion(row):\n",
    "\n",
    "    utterance_emotions = row.emotion\n",
    "\n",
    "    utterance_emotions_l = []\n",
    "    emotion_class_labels = [\"anger\", \"disgust\", \"fear\", \"sadness\", \"surprise\", \"joy\"]\n",
    "\n",
    "    if utterance_emotions == 'Neutral':\n",
    "        \n",
    "        utterance_emotions_l.append('neutral')\n",
    "    \n",
    "    else:\n",
    "        utterance_emotions = utterance_emotions.split(\"-\")\n",
    "       \n",
    "        #emotion_annotation_l = []\n",
    "\n",
    "        for idx, emotion_annotation in enumerate(utterance_emotions):\n",
    "\n",
    "            if '0' not in emotion_annotation:\n",
    "         \n",
    "                #emotion_annotation_l.append(emotion_class_labels[idx])\n",
    "                #utterance_emotions_l.append(emotion_annotation[:-1])\n",
    "                utterance_emotions_l.append(emotion_class_labels[idx])\n",
    "\n",
    "    return utterance_emotions_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2cb175d1-b9c6-4485-aaf2-0cddf0483938",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['emotion_c'] = df.apply(lambda row: get_unique_emotion(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "221694ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>page_nr</th>\n",
       "      <th>panel_nr</th>\n",
       "      <th>balloon_nr</th>\n",
       "      <th>utterance</th>\n",
       "      <th>raw_annotation</th>\n",
       "      <th>raw_emotion</th>\n",
       "      <th>raw_speaker_id</th>\n",
       "      <th>emotion</th>\n",
       "      <th>speaker_id</th>\n",
       "      <th>split</th>\n",
       "      <th>emotion_c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>QC copy - 1500 - 04 Nightwing 19 _Nightwing 95...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>DID YOU HAVE TO ELECTROCUTE HER SO HARD?</td>\n",
       "      <td>2024-08-27 - aselermekova20\\nFeeling:AN0-DI0-F...</td>\n",
       "      <td>2024-08-27 - aselermekova20\\nFeeling:AN0-DI0-F...</td>\n",
       "      <td>2024-09-05 - aidaraliev12345\\nSpokenBy:ID-1</td>\n",
       "      <td>AN0-DI0-FE3-SA0-SU5-JO0</td>\n",
       "      <td>ID-1</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>[fear, surprise]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>QC copy - 1500 - 04 Nightwing 19 _Nightwing 95...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>IT'S NOT LIKE I HAVE DIFFERENT SETTINGS.</td>\n",
       "      <td>2024-08-27 - aselermekova20\\nFeeling:AN0-DI0-F...</td>\n",
       "      <td>2024-08-27 - aselermekova20\\nFeeling:AN0-DI0-F...</td>\n",
       "      <td>2024-09-05 - aidaraliev12345\\nSpokenBy:ID-2</td>\n",
       "      <td>AN0-DI0-FE0-SA0-SU5-JO0</td>\n",
       "      <td>ID-2</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>[surprise]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>QC copy - 1500 - 04 Nightwing 19 _Nightwing 95...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>YOU'RE ELECTROCUTIONER. IT'S YOUR WHOLE THING....</td>\n",
       "      <td>2024-08-27 - aselermekova20\\nFeeling:AN0-DI0-F...</td>\n",
       "      <td>2024-08-27 - aselermekova20\\nFeeling:AN0-DI0-F...</td>\n",
       "      <td>2024-09-05 - aidaraliev12345\\nSpokenBy:ID-1</td>\n",
       "      <td>AN0-DI0-FE2-SA0-SU0-JO0</td>\n",
       "      <td>ID-1</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>[fear]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>QC copy - 1500 - 04 Nightwing 19 _Nightwing 95...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>OH, HEY. I THINK SHE'S AWAKE.</td>\n",
       "      <td>2024-08-27 - aselermekova20\\nFeeling:AN0-DI0-F...</td>\n",
       "      <td>2024-08-27 - aselermekova20\\nFeeling:AN0-DI0-F...</td>\n",
       "      <td>2024-09-05 - aidaraliev12345\\nSpokenBy:ID-2</td>\n",
       "      <td>AN0-DI0-FE0-SA0-SU4-JO0</td>\n",
       "      <td>ID-2</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>[surprise]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>QC copy - 1500 - 04 Nightwing 19 _Nightwing 95...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>WELCOME BACK, MADAM MAYOR. BLOCKBUSTER IS PRET...</td>\n",
       "      <td>2024-08-27 - aselermekova20\\nFeeling:AN3-DI0-F...</td>\n",
       "      <td>2024-08-27 - aselermekova20\\nFeeling:AN3-DI0-F...</td>\n",
       "      <td>2024-09-05 - aidaraliev12345\\nSpokenBy:ID-1</td>\n",
       "      <td>AN3-DI0-FE0-SA0-SU0-JO0</td>\n",
       "      <td>ID-1</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>[anger]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7124</th>\n",
       "      <td>QC copy - 1737 - 34 The Walking Dead vol 15 - ...</td>\n",
       "      <td>21</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>SHE WOULDN'T DO THAT TO US. WE TALKED FOR A LO...</td>\n",
       "      <td>2024-09-06 - SyimykRasulov\\nFeeling:AN0-DI0-FE...</td>\n",
       "      <td>2024-09-06 - SyimykRasulov\\nFeeling:AN0-DI0-FE...</td>\n",
       "      <td>\\n2024-09-06 - SyimykRasulov\\nSpokenBy:Eugene</td>\n",
       "      <td>AN0-DI0-FE1-SA3-SU0-JO0</td>\n",
       "      <td>Eugene</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>[fear, sadness]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7125</th>\n",
       "      <td>QC copy - 1737 - 34 The Walking Dead vol 15 - ...</td>\n",
       "      <td>21</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>… I KNOW HER.</td>\n",
       "      <td>2024-09-06 - SyimykRasulov\\nFeeling:AN0-DI0-FE...</td>\n",
       "      <td>2024-09-06 - SyimykRasulov\\nFeeling:AN0-DI0-FE...</td>\n",
       "      <td>\\n2024-09-06 - SyimykRasulov\\nSpokenBy:Eugene</td>\n",
       "      <td>AN0-DI0-FE1-SA3-SU0-JO0</td>\n",
       "      <td>Eugene</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>[fear, sadness]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7126</th>\n",
       "      <td>QC copy - 1737 - 34 The Walking Dead vol 15 - ...</td>\n",
       "      <td>21</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>UH, GUYS…</td>\n",
       "      <td>2024-09-06 - SyimykRasulov\\nFeeling:AN0-DI0-FE...</td>\n",
       "      <td>2024-09-06 - SyimykRasulov\\nFeeling:AN0-DI0-FE...</td>\n",
       "      <td>\\n2024-09-06 - SyimykRasulov\\nSpokenBy:JUANITA...</td>\n",
       "      <td>AN0-DI0-FE3-SA0-SU4-JO0</td>\n",
       "      <td>JUANITA SANCHEZ</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>[fear, surprise]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7127</th>\n",
       "      <td>QC copy - 1737 - 34 The Walking Dead vol 15 - ...</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>PUT YOUR WEAPONS DOWN AND PUT YOUR HANDS IN TH...</td>\n",
       "      <td>2024-09-06 - SyimykRasulov\\nFeeling:AN4-DI0-FE...</td>\n",
       "      <td>2024-09-06 - SyimykRasulov\\nFeeling:AN4-DI0-FE...</td>\n",
       "      <td>\\n2024-09-06 - SyimykRasulov\\nSpokenBy:ID- 2</td>\n",
       "      <td>AN4-DI0-FE0-SA0-SU0-JO0</td>\n",
       "      <td>ID- 2</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>[anger]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7128</th>\n",
       "      <td>QC copy - 1737 - 34 The Walking Dead vol 15 - ...</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>SURE DOESN'T SEEM LIKE THEY CAME HERE TO TALK…</td>\n",
       "      <td>2024-09-06 - SyimykRasulov\\nFeeling:AN4-DI0-FE...</td>\n",
       "      <td>2024-09-06 - SyimykRasulov\\nFeeling:AN4-DI0-FE...</td>\n",
       "      <td>\\n2024-09-06 - SyimykRasulov\\nSpokenBy:Michonne</td>\n",
       "      <td>AN4-DI0-FE3-SA2-SU0-JO0</td>\n",
       "      <td>Michonne</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>[anger, fear, sadness]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7129 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              file_name  page_nr  panel_nr  \\\n",
       "0     QC copy - 1500 - 04 Nightwing 19 _Nightwing 95...        1         2   \n",
       "1     QC copy - 1500 - 04 Nightwing 19 _Nightwing 95...        1         2   \n",
       "2     QC copy - 1500 - 04 Nightwing 19 _Nightwing 95...        1         2   \n",
       "3     QC copy - 1500 - 04 Nightwing 19 _Nightwing 95...        1         3   \n",
       "4     QC copy - 1500 - 04 Nightwing 19 _Nightwing 95...        1         4   \n",
       "...                                                 ...      ...       ...   \n",
       "7124  QC copy - 1737 - 34 The Walking Dead vol 15 - ...       21         3   \n",
       "7125  QC copy - 1737 - 34 The Walking Dead vol 15 - ...       21         3   \n",
       "7126  QC copy - 1737 - 34 The Walking Dead vol 15 - ...       21         4   \n",
       "7127  QC copy - 1737 - 34 The Walking Dead vol 15 - ...       22         1   \n",
       "7128  QC copy - 1737 - 34 The Walking Dead vol 15 - ...       22         2   \n",
       "\n",
       "      balloon_nr                                          utterance  \\\n",
       "0              1           DID YOU HAVE TO ELECTROCUTE HER SO HARD?   \n",
       "1              2           IT'S NOT LIKE I HAVE DIFFERENT SETTINGS.   \n",
       "2              3  YOU'RE ELECTROCUTIONER. IT'S YOUR WHOLE THING....   \n",
       "3              1                      OH, HEY. I THINK SHE'S AWAKE.   \n",
       "4              1  WELCOME BACK, MADAM MAYOR. BLOCKBUSTER IS PRET...   \n",
       "...          ...                                                ...   \n",
       "7124           2  SHE WOULDN'T DO THAT TO US. WE TALKED FOR A LO...   \n",
       "7125           3                                      … I KNOW HER.   \n",
       "7126           1                                          UH, GUYS…   \n",
       "7127           1  PUT YOUR WEAPONS DOWN AND PUT YOUR HANDS IN TH...   \n",
       "7128           1     SURE DOESN'T SEEM LIKE THEY CAME HERE TO TALK…   \n",
       "\n",
       "                                         raw_annotation  \\\n",
       "0     2024-08-27 - aselermekova20\\nFeeling:AN0-DI0-F...   \n",
       "1     2024-08-27 - aselermekova20\\nFeeling:AN0-DI0-F...   \n",
       "2     2024-08-27 - aselermekova20\\nFeeling:AN0-DI0-F...   \n",
       "3     2024-08-27 - aselermekova20\\nFeeling:AN0-DI0-F...   \n",
       "4     2024-08-27 - aselermekova20\\nFeeling:AN3-DI0-F...   \n",
       "...                                                 ...   \n",
       "7124  2024-09-06 - SyimykRasulov\\nFeeling:AN0-DI0-FE...   \n",
       "7125  2024-09-06 - SyimykRasulov\\nFeeling:AN0-DI0-FE...   \n",
       "7126  2024-09-06 - SyimykRasulov\\nFeeling:AN0-DI0-FE...   \n",
       "7127  2024-09-06 - SyimykRasulov\\nFeeling:AN4-DI0-FE...   \n",
       "7128  2024-09-06 - SyimykRasulov\\nFeeling:AN4-DI0-FE...   \n",
       "\n",
       "                                            raw_emotion  \\\n",
       "0     2024-08-27 - aselermekova20\\nFeeling:AN0-DI0-F...   \n",
       "1     2024-08-27 - aselermekova20\\nFeeling:AN0-DI0-F...   \n",
       "2     2024-08-27 - aselermekova20\\nFeeling:AN0-DI0-F...   \n",
       "3     2024-08-27 - aselermekova20\\nFeeling:AN0-DI0-F...   \n",
       "4     2024-08-27 - aselermekova20\\nFeeling:AN3-DI0-F...   \n",
       "...                                                 ...   \n",
       "7124  2024-09-06 - SyimykRasulov\\nFeeling:AN0-DI0-FE...   \n",
       "7125  2024-09-06 - SyimykRasulov\\nFeeling:AN0-DI0-FE...   \n",
       "7126  2024-09-06 - SyimykRasulov\\nFeeling:AN0-DI0-FE...   \n",
       "7127  2024-09-06 - SyimykRasulov\\nFeeling:AN4-DI0-FE...   \n",
       "7128  2024-09-06 - SyimykRasulov\\nFeeling:AN4-DI0-FE...   \n",
       "\n",
       "                                         raw_speaker_id  \\\n",
       "0           2024-09-05 - aidaraliev12345\\nSpokenBy:ID-1   \n",
       "1           2024-09-05 - aidaraliev12345\\nSpokenBy:ID-2   \n",
       "2           2024-09-05 - aidaraliev12345\\nSpokenBy:ID-1   \n",
       "3           2024-09-05 - aidaraliev12345\\nSpokenBy:ID-2   \n",
       "4           2024-09-05 - aidaraliev12345\\nSpokenBy:ID-1   \n",
       "...                                                 ...   \n",
       "7124      \\n2024-09-06 - SyimykRasulov\\nSpokenBy:Eugene   \n",
       "7125      \\n2024-09-06 - SyimykRasulov\\nSpokenBy:Eugene   \n",
       "7126  \\n2024-09-06 - SyimykRasulov\\nSpokenBy:JUANITA...   \n",
       "7127       \\n2024-09-06 - SyimykRasulov\\nSpokenBy:ID- 2   \n",
       "7128    \\n2024-09-06 - SyimykRasulov\\nSpokenBy:Michonne   \n",
       "\n",
       "                      emotion       speaker_id  split               emotion_c  \n",
       "0     AN0-DI0-FE3-SA0-SU5-JO0             ID-1  TRAIN        [fear, surprise]  \n",
       "1     AN0-DI0-FE0-SA0-SU5-JO0             ID-2  TRAIN              [surprise]  \n",
       "2     AN0-DI0-FE2-SA0-SU0-JO0             ID-1  TRAIN                  [fear]  \n",
       "3     AN0-DI0-FE0-SA0-SU4-JO0             ID-2  TRAIN              [surprise]  \n",
       "4     AN3-DI0-FE0-SA0-SU0-JO0             ID-1  TRAIN                 [anger]  \n",
       "...                       ...              ...    ...                     ...  \n",
       "7124  AN0-DI0-FE1-SA3-SU0-JO0           Eugene  TRAIN         [fear, sadness]  \n",
       "7125  AN0-DI0-FE1-SA3-SU0-JO0           Eugene  TRAIN         [fear, sadness]  \n",
       "7126  AN0-DI0-FE3-SA0-SU4-JO0  JUANITA SANCHEZ  TRAIN        [fear, surprise]  \n",
       "7127  AN4-DI0-FE0-SA0-SU0-JO0            ID- 2  TRAIN                 [anger]  \n",
       "7128  AN4-DI0-FE3-SA2-SU0-JO0         Michonne  TRAIN  [anger, fear, sadness]  \n",
       "\n",
       "[7129 rows x 12 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9ecb78a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'JACKSON T. WINTERS': 598,\n",
       " 'ID-1': 195,\n",
       " 'OLIVIA': 162,\n",
       " 'CHRISTOPHER': 143,\n",
       " 'Joan Peterson': 141,\n",
       " 'Skinner': 140,\n",
       " 'ANDERSON LAKE': 127,\n",
       " 'ID- 64': 117,\n",
       " 'Felicia Book': 111,\n",
       " 'Robby Trick': 110,\n",
       " 'ID-12': 98,\n",
       " 'Rick': 94,\n",
       " 'Oliver King': 91,\n",
       " 'CALIX': 83,\n",
       " 'Nina': 83,\n",
       " 'AARON': 82,\n",
       " 'MARKUS SCHRECKEN': 75,\n",
       " 'Tom ': 73,\n",
       " 'JESUS': 72,\n",
       " 'JUANITA SANCHEZ': 70,\n",
       " 'Franklin': 69,\n",
       " 'Roger Henry': 66,\n",
       " 'Ms.Jones': 66,\n",
       " 'EL MAESTRO DE LA MUERTE': 66,\n",
       " 'no annotation': 65,\n",
       " 'ID- 36': 65,\n",
       " 'Eugene': 62,\n",
       " 'Agent Bixby': 58,\n",
       " 'Laura': 58,\n",
       " 'ID- 1': 55,\n",
       " 'HAWKGIRL': 55,\n",
       " 'ID-2': 55,\n",
       " 'Edzia Rusnak': 54,\n",
       " 'John': 50,\n",
       " 'Momma': 49,\n",
       " 'Mr.Rider': 49,\n",
       " 'Donatello': 49,\n",
       " 'ID-5': 48,\n",
       " 'Wenona Blood Crow': 47,\n",
       " 'Renny': 47,\n",
       " 'FRANCESCA': 45,\n",
       " 'ID-13': 44,\n",
       " 'Michonne': 43,\n",
       " 'Augustus Paulson': 42,\n",
       " 'Bryn': 41,\n",
       " 'Carl': 41,\n",
       " 'Travis': 40,\n",
       " 'Jennifer': 40,\n",
       " 'VAEA': 39,\n",
       " 'Jay Burns': 39,\n",
       " 'Dwight': 37,\n",
       " 'Lobo': 37,\n",
       " 'ID- 3': 36,\n",
       " 'Raphael': 36,\n",
       " 'Jake': 36,\n",
       " 'Aaron': 36,\n",
       " 'Lady Cop': 35,\n",
       " 'ID- 71': 35,\n",
       " 'Belle the Tinkerer': 35,\n",
       " 'Metamorpho': 35,\n",
       " 'Barb': 34,\n",
       " 'Junior': 34,\n",
       " 'ID-6': 34,\n",
       " 'Conrad Paulson': 34,\n",
       " 'Starman': 34,\n",
       " 'Maggie': 33,\n",
       " 'GALEN': 33,\n",
       " 'Cal': 32,\n",
       " 'ID- 2': 31,\n",
       " 'Joe Burns': 30,\n",
       " 'NIGHTWING': 30,\n",
       " 'Doctor Starline': 30,\n",
       " 'Bob': 29,\n",
       " 'ID-3': 28,\n",
       " 'EL SILBÓN': 28,\n",
       " 'ID-7': 27,\n",
       " 'Siddiq': 27,\n",
       " 'Superboy': 27,\n",
       " 'unknown': 27,\n",
       " 'Tom': 25,\n",
       " 'ID- 33': 25,\n",
       " 'Leonardo': 25,\n",
       " 'DANIEL': 25,\n",
       " 'Jimmy': 23,\n",
       " 'Green Arrow': 23,\n",
       " 'MAGISTER PAVUS': 23,\n",
       " ' Michelangelo': 22,\n",
       " 'BATSAUR': 22,\n",
       " 'Hector': 22,\n",
       " 'UNITY': 22,\n",
       " 'ID- 4': 21,\n",
       " 'FLORIAN': 21,\n",
       " 'BLOCKBUSTER': 21,\n",
       " 'John Wesley Jones': 20,\n",
       " 'TED': 20,\n",
       " 'Jesus': 20,\n",
       " 'ELF': 20,\n",
       " 'ID- 5': 19,\n",
       " 'AQUANYX': 19,\n",
       " 'ID- 21': 19,\n",
       " 'ID- 20': 19,\n",
       " 'Black Mask': 19,\n",
       " 'Flash': 18,\n",
       " 'ID- 30': 18,\n",
       " 'BLACKMANTASAURUS': 17,\n",
       " 'TANYA': 17,\n",
       " 'Diz': 17,\n",
       " 'Dick': 17,\n",
       " 'ID- 6': 17,\n",
       " 'Zavok': 17,\n",
       " 'SUPERSAUR': 17,\n",
       " 'Dolores': 17,\n",
       " 'Good Looks': 16,\n",
       " 'Cole Cash': 16,\n",
       " 'Negan': 16,\n",
       " 'Taylor': 16,\n",
       " 'Emma': 16,\n",
       " 'QUEEN': 15,\n",
       " 'Kid Flash': 15,\n",
       " 'Mera': 15,\n",
       " 'Eleanor': 15,\n",
       " 'STEPHANIE': 15,\n",
       " 'Chloe': 15,\n",
       " 'Jodh': 14,\n",
       " 'Shelly': 14,\n",
       " 'ID-9': 14,\n",
       " 'Linda': 14,\n",
       " 'Non-Fat': 14,\n",
       " 'ICE': 14,\n",
       " 'Natasha': 14,\n",
       " 'ID- 57': 13,\n",
       " 'SLIM': 13,\n",
       " 'Belle': 13,\n",
       " 'Robin': 13,\n",
       " 'MAGGIE': 13,\n",
       " 'MELINDA': 13,\n",
       " 'ID- 7': 13,\n",
       " 'Alejandro': 12,\n",
       " 'ID-4': 12,\n",
       " 'The Commodore': 12,\n",
       " 'KREEGS': 12,\n",
       " 'WONDERDON': 12,\n",
       " 'Irey': 11,\n",
       " 'ID- 14': 11,\n",
       " 'LAURA': 11,\n",
       " 'Krunch': 11,\n",
       " 'Flash 2': 11,\n",
       " 'Sonic': 11,\n",
       " 'Juliet': 11,\n",
       " 'Mr.Allen': 10,\n",
       " 'Celia': 10,\n",
       " 'Chen': 10,\n",
       " 'Victor Jacks': 10,\n",
       " 'Cassie': 10,\n",
       " 'Liam': 10,\n",
       " 'ID-3 ': 10,\n",
       " 'Starfire': 9,\n",
       " 'Vector the Crocodile': 9,\n",
       " 'MACLEAN': 9,\n",
       " 'ID- 25': 9,\n",
       " 'ID-20': 9,\n",
       " 'GREEN TORCH': 9,\n",
       " 'ID- 22': 9,\n",
       " 'Manny': 9,\n",
       " 'Director': 9,\n",
       " 'Bananas': 9,\n",
       " 'Jai': 9,\n",
       " 'BATWOMAN': 8,\n",
       " 'ID-8': 8,\n",
       " 'Liz Cohen': 8,\n",
       " 'ID-14': 8,\n",
       " 'ID- 28': 8,\n",
       " 'FATHER': 8,\n",
       " 'ID- 24': 8,\n",
       " \"Jones's partner\": 8,\n",
       " 'ID- 74': 8,\n",
       " 'ID- 70': 8,\n",
       " 'ID- 72': 8,\n",
       " 'ID-1 ': 8,\n",
       " 'Stargirl': 8,\n",
       " 'Green Lantern': 8,\n",
       " 'Lord Westshire': 8,\n",
       " 'Kara': 7,\n",
       " 'YUMIKO': 7,\n",
       " 'ID- 53': 7,\n",
       " 'ID- 52': 7,\n",
       " 'ID- 54': 7,\n",
       " 'Debbie': 7,\n",
       " 'Holly': 7,\n",
       " 'ID- 66': 7,\n",
       " 'Max': 7,\n",
       " 'Batgirl': 7,\n",
       " 'Britney': 7,\n",
       " 'ID-10': 7,\n",
       " 'Cyborg': 7,\n",
       " 'Dante': 6,\n",
       " 'Jesse': 6,\n",
       " 'ID- 8': 6,\n",
       " 'Loose Cannon': 6,\n",
       " 'ID- 65': 6,\n",
       " 'April': 6,\n",
       " 'Mel': 6,\n",
       " ' Tails': 6,\n",
       " 'Speedy': 6,\n",
       " 'ID- 55': 6,\n",
       " 'ID- 56': 6,\n",
       " 'ID- 42': 6,\n",
       " 'ATROCITAURUS': 6,\n",
       " 'Nuki': 6,\n",
       " 'Paco': 6,\n",
       " 'GIGANTA': 6,\n",
       " 'MAGNA': 6,\n",
       " 'Brianna': 6,\n",
       " 'William': 6,\n",
       " 'Lydia': 6,\n",
       " 'FLASHRAPTOR': 5,\n",
       " 'ID- 23': 5,\n",
       " 'Joey Gangemi': 5,\n",
       " 'ID- 67': 5,\n",
       " 'Sarah': 5,\n",
       " 'Penelope': 5,\n",
       " 'Baxter Stockman': 5,\n",
       " 'Henry': 5,\n",
       " 'Andy': 5,\n",
       " 'Jokergirl': 5,\n",
       " 'Harley Quinn': 5,\n",
       " 'Supergirl': 5,\n",
       " 'Mike': 5,\n",
       " 'Damian': 5,\n",
       " 'Freezing enemy': 5,\n",
       " 'Mrs.Allen': 4,\n",
       " 'Jayna': 4,\n",
       " 'Nathan': 4,\n",
       " 'ID- 27': 4,\n",
       " 'ID- 17': 4,\n",
       " 'ID- 62': 4,\n",
       " 'Match': 4,\n",
       " 'Manhunter': 4,\n",
       " 'Homo Abominus': 4,\n",
       " 'ID- 68': 4,\n",
       " 'AGOSTO': 4,\n",
       " 'ID-11': 4,\n",
       " 'Nancy': 4,\n",
       " 'Doris': 4,\n",
       " 'unknown_speaker': 3,\n",
       " 'ID-18': 3,\n",
       " 'ID- 29': 3,\n",
       " 'ID- 26': 3,\n",
       " 'ID- 18': 3,\n",
       " 'Espio the Chameleon': 3,\n",
       " 'Tiger Claw': 3,\n",
       " 'Charmy Bee': 3,\n",
       " 'ID-15': 3,\n",
       " 'Michelangelo': 3,\n",
       " 'blue serious gnom': 3,\n",
       " 'ID- 63': 3,\n",
       " 'Mr.John': 3,\n",
       " 'blue gnom': 3,\n",
       " 'ID- 9': 3,\n",
       " 'ID- 11': 3,\n",
       " 'Josh': 3,\n",
       " 'ID- 69': 3,\n",
       " 'Alicia': 3,\n",
       " 'ID- 73': 3,\n",
       " 'Jay': 3,\n",
       " 'Lieutenant Bratts': 3,\n",
       " 'Widow Perkins': 3,\n",
       " 'KING': 3,\n",
       " 'TREY': 3,\n",
       " 'Toby': 3,\n",
       " 'Splinter': 3,\n",
       " 'Vanessa': 3,\n",
       " 'Johan Van Der Veldt': 3,\n",
       " 'Trapp': 2,\n",
       " 'COMMISSIONER': 2,\n",
       " 'ID- 16': 2,\n",
       " 'Brun': 2,\n",
       " 'Doctor MacNamara DeSoto': 2,\n",
       " 'ID- 34': 2,\n",
       " 'ID-17': 2,\n",
       " 'REVERSE-SLASH': 2,\n",
       " 'ID- 38': 2,\n",
       " 'Frankenstein': 2,\n",
       " 'Carter': 2,\n",
       " 'Kill': 2,\n",
       " 'ID- 76': 2,\n",
       " 'ID- 10': 2,\n",
       " 'ID-2 ': 2,\n",
       " 'ELLIOT': 2,\n",
       " 'ID- 60': 2,\n",
       " 'Psimon': 2,\n",
       " 'ID- 59': 2,\n",
       " 'ID- 43': 2,\n",
       " 'ID- 50': 2,\n",
       " 'ID- 51': 2,\n",
       " 'Terra': 2,\n",
       " 'Michelangelo\\t': 2,\n",
       " 'ROBIN': 1,\n",
       " 'Annie': 1,\n",
       " 'FLASH': 1,\n",
       " 'STARGIRL': 1,\n",
       " 'BATSAU': 1,\n",
       " 'ID-19': 1,\n",
       " 'Mikey': 1,\n",
       " 'Agent Poole': 1,\n",
       " 'ID-16': 1,\n",
       " 'Master Zik': 1,\n",
       " 'MARONI': 1,\n",
       " 'Zeena': 1,\n",
       " 'Stanley': 1,\n",
       " 'Gladys': 1,\n",
       " ' ID-12': 1,\n",
       " 'Shadow the Hedgehog': 1,\n",
       " 'ID- 46': 1,\n",
       " 'ID- 49': 1,\n",
       " 'ID- 35': 1,\n",
       " 'ID- 37': 1,\n",
       " 'ID- 19': 1,\n",
       " 'Jewel the Beetle': 1,\n",
       " 'ID- 31': 1,\n",
       " 'ID- 32': 1,\n",
       " 'Doctor Eggman': 1,\n",
       " 'Ronnie': 1,\n",
       " 'Zazz': 1,\n",
       " 'red ring': 1,\n",
       " 'ID- 47': 1,\n",
       " 'green ring': 1,\n",
       " 'violet ring': 1,\n",
       " 'ID- 48': 1,\n",
       " 'Bystander': 1,\n",
       " 'ID- 58': 1,\n",
       " 'ID- 45': 1,\n",
       " 'ID- 44': 1,\n",
       " 'ID- 61': 1,\n",
       " 'sky blue ring': 1,\n",
       " 'blue ring': 1,\n",
       " 'Donatello\\t': 1,\n",
       " 'AUTUMN': 1,\n",
       " 'CALIX ': 1,\n",
       " 'Ace': 1,\n",
       " 'Lucia': 1,\n",
       " 'ID- 75': 1,\n",
       " 'BRIGHT REVENANT': 1,\n",
       " 'ID- 12': 1,\n",
       " 'AUDRE': 1}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.speaker_id.value_counts().to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cda7246",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9e406fab-1e50-42c7-9513-25b407d42b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Page level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1d169570-7fef-4bab-834c-8b1709aa1f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df = df.groupby(['file_name', 'page_nr', 'split']).agg({\n",
    "    'utterance': list,\n",
    "    'emotion_c': list,\n",
    "    'speaker_id': list\n",
    "}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c88662c7-4271-4377-9f9d-7d81e013bb53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "split\n",
       "TRAIN    718\n",
       "TEST     156\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_df['split'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6add324c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>page_nr</th>\n",
       "      <th>split</th>\n",
       "      <th>utterance</th>\n",
       "      <th>emotion_c</th>\n",
       "      <th>speaker_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>QC copy - 1499 - 58 ECC Co_mics 50 _The Jurass...</td>\n",
       "      <td>1</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>[THIS VILE THING ATTACKED THE SMALL BEASTS OF ...</td>\n",
       "      <td>[[anger], [anger], [fear], [fear], [fear, sadn...</td>\n",
       "      <td>[AQUANYX, AQUANYX, ID-1, ID-1, AQUANYX, ID-1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>QC copy - 1499 - 58 ECC Co_mics 50 _The Jurass...</td>\n",
       "      <td>2</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>[NO--  #GKKK…#, #CHOMP!, BY THE SKIN OF MATILD...</td>\n",
       "      <td>[[fear], [anger], [surprise], [anger], [joy], ...</td>\n",
       "      <td>[ID-1, BLACKMANTASAURUS, AQUANYX, AQUANYX, BLA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>QC copy - 1499 - 58 ECC Co_mics 50 _The Jurass...</td>\n",
       "      <td>3</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>[COME ON, BEAST!, SHOW YOURSELF!, WHY DO YOU H...</td>\n",
       "      <td>[[joy], [joy], [anger], [anger]]</td>\n",
       "      <td>[AQUANYX, AQUANYX, AQUANYX, AQUANYX]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>QC copy - 1499 - 58 ECC Co_mics 50 _The Jurass...</td>\n",
       "      <td>4</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>[#AARGH! ]</td>\n",
       "      <td>[[fear, surprise]]</td>\n",
       "      <td>[AQUANYX]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>QC copy - 1499 - 58 ECC Co_mics 50 _The Jurass...</td>\n",
       "      <td>5</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>[I, THE GREEN TORCH, HAVE BEEN TASKED WITH PRO...</td>\n",
       "      <td>[[anger], [anger], [fear], [fear, surprise], [...</td>\n",
       "      <td>[GREEN TORCH, GREEN TORCH, ATROCITAURUS, ATROC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>869</th>\n",
       "      <td>QC copy - 2200 - Stillwater 13.xlsx</td>\n",
       "      <td>16</td>\n",
       "      <td>TEST</td>\n",
       "      <td>[WE WERE IN GALEN'S OFFICE. YOU WERE ABOUT TO ...</td>\n",
       "      <td>[[anger], [anger], [anger], [anger], [anger, s...</td>\n",
       "      <td>[LAURA, LAURA, LAURA, DANIEL, DANIEL, DANIEL, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>870</th>\n",
       "      <td>QC copy - 2200 - Stillwater 13.xlsx</td>\n",
       "      <td>17</td>\n",
       "      <td>TEST</td>\n",
       "      <td>[SO WHAT ARE WE GOING TO DO?, THE WAY I SEE IT...</td>\n",
       "      <td>[[sadness, surprise], [anger], [anger], [anger...</td>\n",
       "      <td>[ID-6, GALEN, ID-7, GALEN, GALEN, GALEN, GALEN]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>QC copy - 2200 - Stillwater 13.xlsx</td>\n",
       "      <td>18</td>\n",
       "      <td>TEST</td>\n",
       "      <td>[KIDDIE COUNCIL'S BEEN GOING A LONG TIME... , ...</td>\n",
       "      <td>[[anger, sadness], [anger], [anger], [anger], ...</td>\n",
       "      <td>[TED, KREEGS, ID-8, ID-8, GALEN, GALEN, KREEGS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>872</th>\n",
       "      <td>QC copy - 2200 - Stillwater 13.xlsx</td>\n",
       "      <td>19</td>\n",
       "      <td>TEST</td>\n",
       "      <td>[IT'S BEEN… PEACEFUL. ASIDE FROM SHIT LIKE THI...</td>\n",
       "      <td>[[anger], [joy], [joy], [anger, surprise], [an...</td>\n",
       "      <td>[KREEGS, GALEN, GALEN, KREEGS, GALEN, GALEN, K...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>873</th>\n",
       "      <td>QC copy - 2200 - Stillwater 13.xlsx</td>\n",
       "      <td>20</td>\n",
       "      <td>TEST</td>\n",
       "      <td>[\" AND PAY OUR NEIGHBOURS A VISIT. \"]</td>\n",
       "      <td>[[anger, joy]]</td>\n",
       "      <td>[GALEN]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>874 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             file_name  page_nr  split  \\\n",
       "0    QC copy - 1499 - 58 ECC Co_mics 50 _The Jurass...        1  TRAIN   \n",
       "1    QC copy - 1499 - 58 ECC Co_mics 50 _The Jurass...        2  TRAIN   \n",
       "2    QC copy - 1499 - 58 ECC Co_mics 50 _The Jurass...        3  TRAIN   \n",
       "3    QC copy - 1499 - 58 ECC Co_mics 50 _The Jurass...        4  TRAIN   \n",
       "4    QC copy - 1499 - 58 ECC Co_mics 50 _The Jurass...        5  TRAIN   \n",
       "..                                                 ...      ...    ...   \n",
       "869                QC copy - 2200 - Stillwater 13.xlsx       16   TEST   \n",
       "870                QC copy - 2200 - Stillwater 13.xlsx       17   TEST   \n",
       "871                QC copy - 2200 - Stillwater 13.xlsx       18   TEST   \n",
       "872                QC copy - 2200 - Stillwater 13.xlsx       19   TEST   \n",
       "873                QC copy - 2200 - Stillwater 13.xlsx       20   TEST   \n",
       "\n",
       "                                             utterance  \\\n",
       "0    [THIS VILE THING ATTACKED THE SMALL BEASTS OF ...   \n",
       "1    [NO--  #GKKK…#, #CHOMP!, BY THE SKIN OF MATILD...   \n",
       "2    [COME ON, BEAST!, SHOW YOURSELF!, WHY DO YOU H...   \n",
       "3                                           [#AARGH! ]   \n",
       "4    [I, THE GREEN TORCH, HAVE BEEN TASKED WITH PRO...   \n",
       "..                                                 ...   \n",
       "869  [WE WERE IN GALEN'S OFFICE. YOU WERE ABOUT TO ...   \n",
       "870  [SO WHAT ARE WE GOING TO DO?, THE WAY I SEE IT...   \n",
       "871  [KIDDIE COUNCIL'S BEEN GOING A LONG TIME... , ...   \n",
       "872  [IT'S BEEN… PEACEFUL. ASIDE FROM SHIT LIKE THI...   \n",
       "873              [\" AND PAY OUR NEIGHBOURS A VISIT. \"]   \n",
       "\n",
       "                                             emotion_c  \\\n",
       "0    [[anger], [anger], [fear], [fear], [fear, sadn...   \n",
       "1    [[fear], [anger], [surprise], [anger], [joy], ...   \n",
       "2                     [[joy], [joy], [anger], [anger]]   \n",
       "3                                   [[fear, surprise]]   \n",
       "4    [[anger], [anger], [fear], [fear, surprise], [...   \n",
       "..                                                 ...   \n",
       "869  [[anger], [anger], [anger], [anger], [anger, s...   \n",
       "870  [[sadness, surprise], [anger], [anger], [anger...   \n",
       "871  [[anger, sadness], [anger], [anger], [anger], ...   \n",
       "872  [[anger], [joy], [joy], [anger, surprise], [an...   \n",
       "873                                     [[anger, joy]]   \n",
       "\n",
       "                                            speaker_id  \n",
       "0    [AQUANYX, AQUANYX, ID-1, ID-1, AQUANYX, ID-1, ...  \n",
       "1    [ID-1, BLACKMANTASAURUS, AQUANYX, AQUANYX, BLA...  \n",
       "2                 [AQUANYX, AQUANYX, AQUANYX, AQUANYX]  \n",
       "3                                            [AQUANYX]  \n",
       "4    [GREEN TORCH, GREEN TORCH, ATROCITAURUS, ATROC...  \n",
       "..                                                 ...  \n",
       "869  [LAURA, LAURA, LAURA, DANIEL, DANIEL, DANIEL, ...  \n",
       "870    [ID-6, GALEN, ID-7, GALEN, GALEN, GALEN, GALEN]  \n",
       "871  [TED, KREEGS, ID-8, ID-8, GALEN, GALEN, KREEGS...  \n",
       "872  [KREEGS, GALEN, GALEN, KREEGS, GALEN, GALEN, K...  \n",
       "873                                            [GALEN]  \n",
       "\n",
       "[874 rows x 6 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "543e8f26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'QC copy - 1560 - 36 Fantasmas vol. 1 - Ghosted 3.xlsx'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_df.iloc[450]['file_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1032f549",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AQUANYX',\n",
       " 'AQUANYX',\n",
       " 'ID-1',\n",
       " 'ID-1',\n",
       " 'AQUANYX',\n",
       " 'ID-1',\n",
       " 'AQUANYX',\n",
       " 'AQUANYX',\n",
       " 'AQUANYX',\n",
       " 'ID-1']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_df.iloc[0]['speaker_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3ebb206e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ID-1',\n",
       " 'BLACKMANTASAURUS',\n",
       " 'AQUANYX',\n",
       " 'AQUANYX',\n",
       " 'BLACKMANTASAURUS',\n",
       " 'BLACKMANTASAURUS',\n",
       " 'AQUANYX',\n",
       " 'AQUANYX',\n",
       " 'AQUANYX']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_df.iloc[1]['utterance']\n",
    "grouped_df.iloc[1]['speaker_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3671d8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df['utterance'] = grouped_df['utterance'].apply(json.dumps)\n",
    "grouped_df.to_csv(Path(EAC_DIR) / \"dataset_files\" / \"comics_dataset_pg.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f2fa22-35d5-41aa-abf1-5a9987ee0b08",
   "metadata": {},
   "source": [
    "### Prepare prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3fd57164",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Formatting Fx\n",
    "# Build questoin\n",
    "# Build answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "608f81e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def formatting_fct(instruction=\"\", input=\"\", output=\"\"):\n",
    "    \n",
    "    prompt_d ={\n",
    "            \n",
    "        \"instruction\": f\"\"\"{instruction}\"\"\",\n",
    "        \"input\": f\"\"\"{input}\"\"\",\n",
    "        \"output\": f\"\"\"{output}\"\"\"\n",
    "            \n",
    "        }\n",
    "    \n",
    "    return prompt_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "12ccbb5c-ac0c-4b96-800c-3cbc9b5c8c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_instruction():\n",
    "    emotion_classes = [\"anger\", \"disgust\", \"fear\", \"sadness\", \"surprise\", \"joy\", \"neutral\"]\n",
    "    formatted_classes = \", \".join([f'\"{emotion}\"' for emotion in emotion_classes])\n",
    "    \n",
    "    instruction = f\"\"\"### Emotion Analysis Expert Role\n",
    "\n",
    "You are an advanced emotion analysis expert specializing in comic book dialogue interpretation. Your task is to analyze utterances and identify their emotional content.\n",
    "\n",
    "INPUT:\n",
    "- You will receive a list of utterances from a page in a comic book\n",
    "- The utterance may express one or multiple emotions\n",
    "\n",
    "TASK:\n",
    "1. Carefully analyze the emotional context and tone of each utterance in the page\n",
    "2. Identify applicable emotions from the following classes:\n",
    "   {formatted_classes}\n",
    "3. For each utterance in a comic page, identify all emotions present and return an array of emotion arrays in order.\n",
    "\n",
    "RULES:\n",
    "1. Use ONLY the labels listed above\n",
    "2. Output must be a JSON with single key \"page_utterance_emotions\"\n",
    "3. Value must be an array where:\n",
    "   - Each element is an array of emotions for one utterance\n",
    "   - Order matches the input utterances order\n",
    "   - Multiple emotions are allowed per utterance\n",
    "4. No explanations, only JSON output\n",
    "\n",
    "IMPORTANT:\n",
    "- Each array element corresponds to one utterance\n",
    "- One utterance can have multiple emotions\n",
    "- Maintain exact spelling and case of emotion labels\n",
    "- Keep emotions in arrays even for single emotions\n",
    "\n",
    "\"\"\"\n",
    "    return instruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "44e9dbd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_tagged_text(utterances):\n",
    "\n",
    "    concatenated_utterances = '\\n'.join(f\"{i + 1}. {line}\" for i, line in enumerate(utterances))\n",
    "    \n",
    "    question = f\"\"\"Now analyze these utterances in a page:\\n{concatenated_utterances}\"\"\"\n",
    "\n",
    "    return question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "539b6d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_answer(utterance_emotions):\n",
    "                \n",
    "\n",
    "    return json.dumps({\"page_utterance_emotions\": utterance_emotions})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd67b57",
   "metadata": {},
   "source": [
    "### Build Data Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "85fd7584",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = grouped_df[grouped_df.split == 'TRAIN'].reset_index()\n",
    "\n",
    "data_file_train = []\n",
    "\n",
    "for index, _ in df_train.iterrows():\n",
    "    \n",
    "    i = index\n",
    "\n",
    "    instruction = build_instruction()\n",
    "    question = build_tagged_text(df_train.iloc[i].utterance)\n",
    "    answer = build_answer(df_train.iloc[i].emotion_c)\n",
    "    \n",
    "    data_file_train.append( formatting_fct(instruction, question, answer) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "181fe00c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "718"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_file_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "47f46aa1-f3f0-4fc1-8902-b19947e9edd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Emotion Analysis Expert Role\n",
      "\n",
      "You are an advanced emotion analysis expert specializing in comic book dialogue interpretation. Your task is to analyze utterances and identify their emotional content.\n",
      "\n",
      "INPUT:\n",
      "- You will receive a list of utterances from a page in a comic book\n",
      "- The utterance may express one or multiple emotions\n",
      "\n",
      "TASK:\n",
      "1. Carefully analyze the emotional context and tone of each utterance in the page\n",
      "2. Identify applicable emotions from the following classes:\n",
      "   \"anger\", \"disgust\", \"fear\", \"sadness\", \"surprise\", \"joy\", \"neutral\"\n",
      "3. For each utterance in a comic page, identify all emotions present and return an array of emotion arrays in order.\n",
      "\n",
      "RULES:\n",
      "1. Use ONLY the labels listed above\n",
      "2. Output must be a JSON with single key \"page_utterance_emotions\"\n",
      "3. Value must be an array where:\n",
      "   - Each element is an array of emotions for one utterance\n",
      "   - Order matches the input utterances order\n",
      "   - Multiple emotions are allowed per utterance\n",
      "4. No explanations, only JSON output\n",
      "\n",
      "IMPORTANT:\n",
      "- Each array element corresponds to one utterance\n",
      "- One utterance can have multiple emotions\n",
      "- Maintain exact spelling and case of emotion labels\n",
      "- Keep emotions in arrays even for single emotions\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(data_file_train[0]['instruction'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "973189e0-9cf9-48a3-8ecb-c74f86aaa355",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now analyze these utterances in a page:\n",
      "1. THIS VILE THING ATTACKED THE SMALL BEASTS OF MY SHORES… \n",
      "2. … IT PUNCHED MY BEAUTIFUL MATILDA… AND NOW IT BEGS FOR LIFE.\n",
      "3. MY MASTER!\n",
      "4. PLEASE!\n",
      "5. BUT I HAVE NOT CHASED THIS MONSTER ALL THIS WAY TO LET IT GROVEL!\n",
      "6. HEAL MEEE!\n",
      "7. I HAVE COME TO CONQ--!\n",
      "8. WHAT--\n",
      "9. --IS THAT?!\n",
      "10. NO! NO!\n"
     ]
    }
   ],
   "source": [
    "print(data_file_train[0]['input'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8f133831-3c86-471c-b5d8-bbaa66eb525a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"page_utterance_emotions\": [[\"anger\"], [\"anger\"], [\"fear\"], [\"fear\"], [\"fear\", \"sadness\"], [\"sadness\"], [\"anger\"], [\"surprise\"], [\"surprise\"], [\"fear\", \"surprise\"]]}\n"
     ]
    }
   ],
   "source": [
    "print(data_file_train[0]['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "91becc82",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = grouped_df[grouped_df.split == 'TEST'].reset_index()\n",
    "\n",
    "data_file_test = []\n",
    "\n",
    "for index, _ in df_test.iterrows():\n",
    "    \n",
    "    i = index\n",
    "\n",
    "    instruction = build_instruction()\n",
    "    question = build_tagged_text(df_test.iloc[i].utterance)\n",
    "    answer = build_answer(df_test.iloc[i].emotion_c)\n",
    "    \n",
    "    data_file_test.append( formatting_fct(instruction, question, answer) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "96669b4f-b279-48ba-8b9b-d04f91d49c67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6e2c531d-d86d-4289-8f3d-d00fd56d0051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'instruction': '### Emotion Analysis Expert Role\\n\\nYou are an advanced emotion analysis expert specializing in comic book dialogue interpretation. Your task is to analyze utterances and identify their emotional content.\\n\\nINPUT:\\n- You will receive a list of utterances from a page in a comic book\\n- The utterance may express one or multiple emotions\\n\\nTASK:\\n1. Carefully analyze the emotional context and tone of each utterance in the page\\n2. Identify applicable emotions from the following classes:\\n   \"anger\", \"disgust\", \"fear\", \"sadness\", \"surprise\", \"joy\", \"neutral\"\\n3. For each utterance in a comic page, identify all emotions present and return an array of emotion arrays in order.\\n\\nRULES:\\n1. Use ONLY the labels listed above\\n2. Output must be a JSON with single key \"page_utterance_emotions\"\\n3. Value must be an array where:\\n   - Each element is an array of emotions for one utterance\\n   - Order matches the input utterances order\\n   - Multiple emotions are allowed per utterance\\n4. No explanations, only JSON output\\n\\nIMPORTANT:\\n- Each array element corresponds to one utterance\\n- One utterance can have multiple emotions\\n- Maintain exact spelling and case of emotion labels\\n- Keep emotions in arrays even for single emotions\\n\\n', 'input': \"Now analyze these utterances in a page:\\n1. HOW'S IT GOING?\\n2. HEY.\\n3. CAN I GET YOU ANYTHING?\\n4. JUST A COKE.\\n5. OKAY. COMING UP.\\n6. THANKS.\\n7. HOW IS IT OUT THERE? GETTING HOT?\\n8. IT'S ALL RIGHT.\\n9. ONE COKE. ENJOY.\\n10. @ONCE UPON A TIME…\\n11. @… IN A FAR OFF KINGDOM…\", 'output': '{\"page_utterance_emotions\": [[\"surprise\", \"joy\"], [\"joy\"], [\"surprise\", \"joy\"], [\"joy\"], [\"joy\"], [\"joy\"], [\"surprise\"], [\"joy\"], [\"joy\"], [\"neutral\"], [\"neutral\"]]}'}\n",
      "{'instruction': '### Emotion Analysis Expert Role\\n\\nYou are an advanced emotion analysis expert specializing in comic book dialogue interpretation. Your task is to analyze utterances and identify their emotional content.\\n\\nINPUT:\\n- You will receive a list of utterances from a page in a comic book\\n- The utterance may express one or multiple emotions\\n\\nTASK:\\n1. Carefully analyze the emotional context and tone of each utterance in the page\\n2. Identify applicable emotions from the following classes:\\n   \"anger\", \"disgust\", \"fear\", \"sadness\", \"surprise\", \"joy\", \"neutral\"\\n3. For each utterance in a comic page, identify all emotions present and return an array of emotion arrays in order.\\n\\nRULES:\\n1. Use ONLY the labels listed above\\n2. Output must be a JSON with single key \"page_utterance_emotions\"\\n3. Value must be an array where:\\n   - Each element is an array of emotions for one utterance\\n   - Order matches the input utterances order\\n   - Multiple emotions are allowed per utterance\\n4. No explanations, only JSON output\\n\\nIMPORTANT:\\n- Each array element corresponds to one utterance\\n- One utterance can have multiple emotions\\n- Maintain exact spelling and case of emotion labels\\n- Keep emotions in arrays even for single emotions\\n\\n', 'input': \"Now analyze these utterances in a page:\\n1. … THERE LIVED FOUR STRAPPING YOUNG LADS WHO WERE, AS LADS TEND TO DO, CAUSING A HAIR OF TROUBLE FOR THE CITIZENS OF THE REALM.\\n2. YOU SEE, THEIR CARRIAGE WAS BLOCKING THE MAIN ROAD IN THE TOWNSHIP, AND THE LOCALS COULD NOT GET THEIR WARES TO MARKET.\\n3. # #@# NON-FAT! PULL OVER!\\n4. IT'S THAT % # # # @ LADY COP!\\n5. THE SITUATION WAS BECOMING QUITE UNTENABLE, WHEN ALONG CAME A GRAND AND AUGUST PRINCESS WHO WAS, AS PRINCESSES TEND TO BE, EAGER TO HELP.\\n6. YEAH, THERE THEY ARE NOW. THEY'RE DRIVING RIGHT DOWN DANGER AT FIFTEEN MILES PER HOUR. JESUS. I GOT THEM.\\n7. IF DORIS CALLS AGAIN, TELL HER I'M ALREADY HERE. SHE'LL KEEP WHINING ANYWAY, BUT YOU MIGHT AS WELL TELL HER.\", 'output': '{\"page_utterance_emotions\": [[\"neutral\"], [\"neutral\"], [\"anger\", \"disgust\"], [\"anger\", \"disgust\"], [\"neutral\"], [\"sadness\"], [\"sadness\"]]}'}\n",
      "{'instruction': '### Emotion Analysis Expert Role\\n\\nYou are an advanced emotion analysis expert specializing in comic book dialogue interpretation. Your task is to analyze utterances and identify their emotional content.\\n\\nINPUT:\\n- You will receive a list of utterances from a page in a comic book\\n- The utterance may express one or multiple emotions\\n\\nTASK:\\n1. Carefully analyze the emotional context and tone of each utterance in the page\\n2. Identify applicable emotions from the following classes:\\n   \"anger\", \"disgust\", \"fear\", \"sadness\", \"surprise\", \"joy\", \"neutral\"\\n3. For each utterance in a comic page, identify all emotions present and return an array of emotion arrays in order.\\n\\nRULES:\\n1. Use ONLY the labels listed above\\n2. Output must be a JSON with single key \"page_utterance_emotions\"\\n3. Value must be an array where:\\n   - Each element is an array of emotions for one utterance\\n   - Order matches the input utterances order\\n   - Multiple emotions are allowed per utterance\\n4. No explanations, only JSON output\\n\\nIMPORTANT:\\n- Each array element corresponds to one utterance\\n- One utterance can have multiple emotions\\n- Maintain exact spelling and case of emotion labels\\n- Keep emotions in arrays even for single emotions\\n\\n', 'input': \"Now analyze these utterances in a page:\\n1. IT'S A HUNDRED AND FOUR DEGREES IN THE SHADE, I'M SUPPOSED TO BE INSIDE DOING THE WEEKLY REPORTS, AND I'M DRAGGED AWAY AGAIN BY YOU DINGBATS.\\n2. I JUST WASHED THIS UNIFORM AND NOW IT'S ALREADY SOAKED THROUGH. JESUS.\\n3. I DO NOT HAVE THE PATIENCE FOR THIS TODAY.\\n4. WHAT'D WE DO, WHAT'D WE DO? WE'RE JUST DRIVING. IS IT ILLEGAL TO DRIVE IN CALIFORNIA NOW OR WHAT?\\n5. NON-FAT, HOW OLD ARE YOU?\\n6. KRUNCH IS SIXTEEN.\\n7. YOU GOT A LICENSE, KRUNCH?\\n8. HEY, DON'T BE MEAN TO KRUNCH! HE'S JUST GOT TO PASS THE WRITTEN PART.\\n9. ON HIS SIXTH TEST HE GOT THREE WHOLE QUESTIONS RIGHT. A NEW RECORD!\\n10. #HAHAHAHAHA!\\n11. IT'S NOT FUNNY, BANANAS!\\n12. I DID MORE THAN THREE! I DON'T WANT TO PUNCH YOU BUT I WILL PUNCH YOU IF YOU KEEP SAYING THINGS LIKE THAT.\\n13. FINE! FOUR WHOLE QUESTIONS! HAPPY?!\\n14. LOOK, LADY COP, THIS IS ALL… A LITTLE MISCOMMUNICATION.\\n15. WE'RE JUST GOING OUT TO THE VALLEY TO DO SOME OFF ROADING. IT'S KIDS. IT'S FUN.\\n16. YOU DON'T NEED A LICENSE FOR THAT, DO YOU?\", 'output': '{\"page_utterance_emotions\": [[\"anger\", \"sadness\"], [\"anger\", \"sadness\"], [\"anger\", \"sadness\"], [\"fear\", \"surprise\"], [\"surprise\"], [\"joy\"], [\"anger\", \"surprise\"], [\"joy\"], [\"joy\"], [\"joy\"], [\"anger\"], [\"anger\"], [\"surprise\", \"joy\"], [\"fear\", \"sadness\"], [\"fear\", \"sadness\"], [\"fear\", \"surprise\"]]}'}\n",
      "{'instruction': '### Emotion Analysis Expert Role\\n\\nYou are an advanced emotion analysis expert specializing in comic book dialogue interpretation. Your task is to analyze utterances and identify their emotional content.\\n\\nINPUT:\\n- You will receive a list of utterances from a page in a comic book\\n- The utterance may express one or multiple emotions\\n\\nTASK:\\n1. Carefully analyze the emotional context and tone of each utterance in the page\\n2. Identify applicable emotions from the following classes:\\n   \"anger\", \"disgust\", \"fear\", \"sadness\", \"surprise\", \"joy\", \"neutral\"\\n3. For each utterance in a comic page, identify all emotions present and return an array of emotion arrays in order.\\n\\nRULES:\\n1. Use ONLY the labels listed above\\n2. Output must be a JSON with single key \"page_utterance_emotions\"\\n3. Value must be an array where:\\n   - Each element is an array of emotions for one utterance\\n   - Order matches the input utterances order\\n   - Multiple emotions are allowed per utterance\\n4. No explanations, only JSON output\\n\\nIMPORTANT:\\n- Each array element corresponds to one utterance\\n- One utterance can have multiple emotions\\n- Maintain exact spelling and case of emotion labels\\n- Keep emotions in arrays even for single emotions\\n\\n', 'input': 'Now analyze these utterances in a page:\\n1. DON\\'T TOUCH ME, GOOD LOOKS, AND DON\\'T EVER…\\n2. ...EVER…\\n3. … CALL ME \" LADY COP. \" ZERO TOLERANCE. OKAY?\\n4. BUT OF COURSE, MA\\'AM. MY DEEP APOLOGIES.\\n5. BUT… AM I SO WRONG ABOUT THE LAW HERE? I DON\\'T KNOW THAT I AM.\\n6. YOU DON\\'T NEED A DRIVER\\'S LICENSE TO OFF-ROAD IN THE VALLEY.\\n7. YOU DO NEED A DRIVER\\'S LICENSE AND A PERMIT TO DRIVE THIS… THING ON A PAVED STREET IN THE MIDDLE OF TOWN.\\n8. THAT\\'S A TWO-HUNDRED - DOLLAR TICKET.\\n9. CAN DRIVE IT THERE? CAN\\'T DRIVE IT HERE?\\n10. WHAT\\'RE WE SUPPOSED TO DO, CARRY IT?!\\n11. HEY! KRUNCH COULD PUT IT ON HIS HEAD AND WALK IT OVER, BALANCE IT. HE\\'S GOT NOTHING UP THERE TO DAMAGE.\\n12. I COULD FIND SOMETHING OF YOURS TO DAMAGE!\\n13. LOOK, IT\\'S TOO HOT TO FIGHT.\\n14. AND FRANKLY, I\\'D RATHER HAVE YOU GUYS KNOCKING EACH OTHER AROUND OUT IN THE SAND THAN HERE IN THE TOWN.\\n15. I GET A LITTLE TIRED OF BEING CALLED OUT OF THEA.C. EVERY TIME A DINGBAT DOES SOMETHING STUPID. WHICH IS OFTEN.\\n16. I\\'LL ESCORT YOU TO THE VALLEY. COME BACK IN A BIT TO PICK YOU UP.\\n17. YOU GOT MY CELL. CALL ME WHEN YOU\\'RE READY.\\n18. YOU FOLLOW THE RULES, YOU STAY SAFE, WE FORGET ABOUT THE TICKET. OKAY?\\n19. AH, LADY COP! YOU\\'RE THE BEST!\\n20. GOOD LOOKS, WHAT THE HELL IS WRONG WITH YOU?!\\n21. WHAT\\'D I JUST SAY ABOUT THAT? ARE YOU EVEN LISTENING?!', 'output': '{\"page_utterance_emotions\": [[\"anger\", \"disgust\"], [\"anger\", \"disgust\"], [\"anger\", \"disgust\"], [\"fear\", \"sadness\"], [\"fear\", \"sadness\", \"surprise\"], [\"sadness\"], [\"sadness\"], [\"fear\", \"sadness\"], [\"sadness\", \"surprise\"], [\"sadness\", \"surprise\"], [\"joy\"], [\"anger\"], [\"anger\"], [\"anger\"], [\"anger\", \"disgust\"], [\"joy\"], [\"joy\"], [\"surprise\", \"joy\"], [\"surprise\", \"joy\"], [\"anger\", \"surprise\"], [\"anger\", \"surprise\"]]}'}\n",
      "{'instruction': '### Emotion Analysis Expert Role\\n\\nYou are an advanced emotion analysis expert specializing in comic book dialogue interpretation. Your task is to analyze utterances and identify their emotional content.\\n\\nINPUT:\\n- You will receive a list of utterances from a page in a comic book\\n- The utterance may express one or multiple emotions\\n\\nTASK:\\n1. Carefully analyze the emotional context and tone of each utterance in the page\\n2. Identify applicable emotions from the following classes:\\n   \"anger\", \"disgust\", \"fear\", \"sadness\", \"surprise\", \"joy\", \"neutral\"\\n3. For each utterance in a comic page, identify all emotions present and return an array of emotion arrays in order.\\n\\nRULES:\\n1. Use ONLY the labels listed above\\n2. Output must be a JSON with single key \"page_utterance_emotions\"\\n3. Value must be an array where:\\n   - Each element is an array of emotions for one utterance\\n   - Order matches the input utterances order\\n   - Multiple emotions are allowed per utterance\\n4. No explanations, only JSON output\\n\\nIMPORTANT:\\n- Each array element corresponds to one utterance\\n- One utterance can have multiple emotions\\n- Maintain exact spelling and case of emotion labels\\n- Keep emotions in arrays even for single emotions\\n\\n', 'input': 'Now analyze these utterances in a page:\\n1. AT THAT SAME MOMENT, IN THE FAR EAST, AN OGRE SPIED A MAN DOING EVIL AND JUMPED OFF HIS PERCH TO INTERVENE.\\n2. #HA HA HA HA HA HA HA HA HA HA HA HA HA HA\\n3.   HA HA HA HA HA HA HA HA HA HA HA HA', 'output': '{\"page_utterance_emotions\": [[\"neutral\"], [\"joy\"], [\"joy\"]]}'}\n",
      "{'instruction': '### Emotion Analysis Expert Role\\n\\nYou are an advanced emotion analysis expert specializing in comic book dialogue interpretation. Your task is to analyze utterances and identify their emotional content.\\n\\nINPUT:\\n- You will receive a list of utterances from a page in a comic book\\n- The utterance may express one or multiple emotions\\n\\nTASK:\\n1. Carefully analyze the emotional context and tone of each utterance in the page\\n2. Identify applicable emotions from the following classes:\\n   \"anger\", \"disgust\", \"fear\", \"sadness\", \"surprise\", \"joy\", \"neutral\"\\n3. For each utterance in a comic page, identify all emotions present and return an array of emotion arrays in order.\\n\\nRULES:\\n1. Use ONLY the labels listed above\\n2. Output must be a JSON with single key \"page_utterance_emotions\"\\n3. Value must be an array where:\\n   - Each element is an array of emotions for one utterance\\n   - Order matches the input utterances order\\n   - Multiple emotions are allowed per utterance\\n4. No explanations, only JSON output\\n\\nIMPORTANT:\\n- Each array element corresponds to one utterance\\n- One utterance can have multiple emotions\\n- Maintain exact spelling and case of emotion labels\\n- Keep emotions in arrays even for single emotions\\n\\n', 'input': \"Now analyze these utterances in a page:\\n1. NOW, I GRANT YOU, MOST OGRES ARE NOT KNOWN FOR THEIR HEROIC DEEDS.\\n2. #GAHHH!\\n3. BUT PERHAPS THAT IS NOT THE FAULT OF OGRES.\\n4. I DIDN'T DO IT… IT WAS SEAN… SEAN HAD THE GUN. YOU SEE THAT, MAN… IT WAS… IT WAS…\\n5. #HEE HEE HEE HEE\\n6. NO, I BELIEVE THE FAULT WITH THAT PARTICULAR PRESUMPTION FALLS UPON OUR SHOULDERS.\\n7. SEAN, MAN, I WAS JUST… WE WEREN'T GOING TO SHOOT…\\n8. IT'S NOT FAIR… NOTHING'S FAIR…\\n9. #HAHAHAHAHAHAHA\\n10. YOU SEE, OGRES ARE COMPLICATED CREATURES, AND ONE OGRE IS NOT LIKE ANOTHER.\\n11. PLEASE DON'T… I… WHATEVER YOU WANT… I DIDN'T EVEN DO IT… I'LL JUST DO… WHATEVER…\\n12. #HAHAHAHA\\n13. AND WE SHOULD NOT JUDGE THEM AS A WHOLE…\\n14. #HA HA HA HA HA HA\\n15. #HA HA HA HA\\n16. … BUT INSTEAD TAKE EACH AS THEY COME TO US.\\n17. #HA HA HA HA HA\\n18. @YOU SHOULDN'T FEEL BAD ABOUT THESE GUYS PASSING. THIS IS SMALL-TIME, LOCAL STUFF. I TOLD YOU THAT WHEN YOU AUDITIONED.\\n19. @IT'S BELOW YOU ANYWAY.\\n20. @I ACTUALLY HAVE SOMETHING BETTER I WANT TO TALK ABOUT.\", 'output': '{\"page_utterance_emotions\": [[\"neutral\"], [\"fear\"], [\"neutral\"], [\"anger\", \"fear\", \"sadness\"], [\"joy\"], [\"sadness\"], [\"fear\", \"surprise\"], [\"anger\", \"fear\", \"sadness\"], [\"joy\"], [\"neutral\"], [\"fear\"], [\"joy\"], [\"neutral\"], [\"joy\"], [\"joy\"], [\"neutral\"], [\"joy\"], [\"anger\"], [\"anger\"], [\"surprise\", \"joy\"]]}'}\n",
      "{'instruction': '### Emotion Analysis Expert Role\\n\\nYou are an advanced emotion analysis expert specializing in comic book dialogue interpretation. Your task is to analyze utterances and identify their emotional content.\\n\\nINPUT:\\n- You will receive a list of utterances from a page in a comic book\\n- The utterance may express one or multiple emotions\\n\\nTASK:\\n1. Carefully analyze the emotional context and tone of each utterance in the page\\n2. Identify applicable emotions from the following classes:\\n   \"anger\", \"disgust\", \"fear\", \"sadness\", \"surprise\", \"joy\", \"neutral\"\\n3. For each utterance in a comic page, identify all emotions present and return an array of emotion arrays in order.\\n\\nRULES:\\n1. Use ONLY the labels listed above\\n2. Output must be a JSON with single key \"page_utterance_emotions\"\\n3. Value must be an array where:\\n   - Each element is an array of emotions for one utterance\\n   - Order matches the input utterances order\\n   - Multiple emotions are allowed per utterance\\n4. No explanations, only JSON output\\n\\nIMPORTANT:\\n- Each array element corresponds to one utterance\\n- One utterance can have multiple emotions\\n- Maintain exact spelling and case of emotion labels\\n- Keep emotions in arrays even for single emotions\\n\\n', 'input': 'Now analyze these utterances in a page:\\n1. YOU TOLD ME IT WAS BELOW ME SO I\\'D GET A BIGGER OFFER.\\n2. I\\'M TIRED OF THIS.\\n3. @I\\'M NOT HERE ARGUING WITH YOU, JACK. I\\'M JUST SAYING WHAT WE BOTH KNOW. IT\\'S A BLESSING THAT IT DIDN\\'T WORK OUT.\\n4. @WHO NEEDS TO HEAR YOU IN TENNESSEE? EVERYONE IN TENNESSEE ALREADY BELIEVES IN WHAT YOU DO.\\n5. @LET SOME OTHER JACK RYDER COPYCAT TELL THOSE HICKS HOW SMART THEY ARE.\\n6. @THIS NEW THING IS MEGA-BIG, A CHANCE TO REACH EVERYONE. IT\\'S A NEW SMALLER CABLE NETWORK, GTN, BUT THEY\\'RE ON ALL THE PROVIDERS.\\n7. @THEY GOT BIG BACKING. THEY\\'RE GOING TO GROW. THIS IS GETTING IN ON THE GROUND FLOOR OF THE NEXT BIG THING.\\n8. @AND THEY REACHED OUT ABOUT YOU, SPECIFICALLY.\\n9. BECAUSE I\\'LL GET THEM HEADLINES THEY\\'LL GET EYES ON, AND THEY DON\\'T CARE WHAT THE HEADLINES ARE FOR.\\n10. \" WHO\\'D HIRE RYDER AFTER HIS INFAMOUS ON-AIR WHACKO RANT GOT HIM FIRED FROM NBS?!\\n11. \" TUNE IN AT ELEVEN! \"\\n12. @THEY\\'RE BASED IN NEW YORK. THEY WANT TO SEE YOU TODAY. IT\\'S A TRAIN RIDE. YOU GO IN, YOU MEET WITH THEM, WHAT\\'S THE HARM?\\n13. @IT\\'S REAL MONEY AND REAL EXPOSURE.\\n14. @I MEAN THIS AS A FRIEND, JACK, BUT YOU GOT TO TRUST ME ON THIS. I\\'M LOOKING OUT FOR YOU. I WANT YOU TO BE HAPPY.\\n15. @HAPPY AND { € A $ # RICH.', 'output': '{\"page_utterance_emotions\": [[\"anger\", \"sadness\"], [\"anger\"], [\"sadness\"], [\"surprise\"], [\"anger\"], [\"neutral\"], [\"joy\"], [\"joy\"], [\"joy\"], [\"anger\", \"surprise\"], [\"anger\", \"surprise\"], [\"anger\", \"surprise\"], [\"joy\"], [\"joy\"], [\"joy\"]]}'}\n",
      "{'instruction': '### Emotion Analysis Expert Role\\n\\nYou are an advanced emotion analysis expert specializing in comic book dialogue interpretation. Your task is to analyze utterances and identify their emotional content.\\n\\nINPUT:\\n- You will receive a list of utterances from a page in a comic book\\n- The utterance may express one or multiple emotions\\n\\nTASK:\\n1. Carefully analyze the emotional context and tone of each utterance in the page\\n2. Identify applicable emotions from the following classes:\\n   \"anger\", \"disgust\", \"fear\", \"sadness\", \"surprise\", \"joy\", \"neutral\"\\n3. For each utterance in a comic page, identify all emotions present and return an array of emotion arrays in order.\\n\\nRULES:\\n1. Use ONLY the labels listed above\\n2. Output must be a JSON with single key \"page_utterance_emotions\"\\n3. Value must be an array where:\\n   - Each element is an array of emotions for one utterance\\n   - Order matches the input utterances order\\n   - Multiple emotions are allowed per utterance\\n4. No explanations, only JSON output\\n\\nIMPORTANT:\\n- Each array element corresponds to one utterance\\n- One utterance can have multiple emotions\\n- Maintain exact spelling and case of emotion labels\\n- Keep emotions in arrays even for single emotions\\n\\n', 'input': \"Now analyze these utterances in a page:\\n1. BUT ENOUGH TALK OF OGRES, FOR I MUST INTRODUCE YOU TO TWO PRINCES WHO WERE THAT DAY GATHERED TO EAT.\\n2. I'M NERVOUS.\\n3. DON'T START.\\n4. WHO WERE THAT DAY WAITING FOR YET ANOTHER PRINCE TO ARRIVE.\\n5. THIS IS A BIG DEAL TO ME.\\n6. I'M AWARE. BUT YOU HAVING ANOTHER ONE OF YOUR PANIC ATTACKS RIGHT NOW ISN'T GOING TO HELP ANYTHING.\\n7. THIS GUY'S A PROFESSIONAL. SO ARE WE. THAT'S ALL IT IS.\\n8. THE LOFTY WARLORD IS LECTURING ME ABOUT PROFESSIONALISM?\\n9. HIDING BEHIND A BEARD AND A SWORD ISN'T A CAREER, IT'S A GAME.\\n10. WE'RE BOTH SUPERHEROES. I DON'T NEED YOU OF ALL PEOPLE JUDGING ME.\\n11. WHO'S JUDGING YOU?\\n12. I'M JUST SAYING, CALM DOWN AND LOOK NORMAL.\\n13. LET'S JUST TRY TO BE NORMAL, OKAY?\\n14. YOU AND ALL THE NORMAL.\\n15. WHAT'S NORMAL?\\n16. BEATS ME, FELLOWS.\", 'output': '{\"page_utterance_emotions\": [[\"neutral\"], [\"fear\"], [\"anger\"], [\"neutral\"], [\"fear\"], [\"anger\"], [\"anger\", \"surprise\"], [\"anger\", \"surprise\"], [\"anger\"], [\"anger\", \"disgust\"], [\"anger\", \"surprise\"], [\"anger\"], [\"anger\", \"surprise\"], [\"anger\"], [\"anger\", \"surprise\"], [\"neutral\"]]}'}\n",
      "{'instruction': '### Emotion Analysis Expert Role\\n\\nYou are an advanced emotion analysis expert specializing in comic book dialogue interpretation. Your task is to analyze utterances and identify their emotional content.\\n\\nINPUT:\\n- You will receive a list of utterances from a page in a comic book\\n- The utterance may express one or multiple emotions\\n\\nTASK:\\n1. Carefully analyze the emotional context and tone of each utterance in the page\\n2. Identify applicable emotions from the following classes:\\n   \"anger\", \"disgust\", \"fear\", \"sadness\", \"surprise\", \"joy\", \"neutral\"\\n3. For each utterance in a comic page, identify all emotions present and return an array of emotion arrays in order.\\n\\nRULES:\\n1. Use ONLY the labels listed above\\n2. Output must be a JSON with single key \"page_utterance_emotions\"\\n3. Value must be an array where:\\n   - Each element is an array of emotions for one utterance\\n   - Order matches the input utterances order\\n   - Multiple emotions are allowed per utterance\\n4. No explanations, only JSON output\\n\\nIMPORTANT:\\n- Each array element corresponds to one utterance\\n- One utterance can have multiple emotions\\n- Maintain exact spelling and case of emotion labels\\n- Keep emotions in arrays even for single emotions\\n\\n', 'input': \"Now analyze these utterances in a page:\\n1. AND THEN, FINALLY, THE THREE GLORIOUS PRINCES OF THE REALM WERE UNITED!\\n2. GUESS WHO MADE THE TRADE AND GOT THE THING?!\\n3. EH, YOU'LL NEVER GUESS, IT WAS ME!\\n4. METAMORPHO!\\n5. WONDERFUL. THE WAITRESS IS COMING OVER. YOU COULDN'T PUT ON A COAT, COME IN THE DOOR?\\n6. YOU HAVE IT HERE? CAN I SEE IT?\\n7. I'M GAS. I CAN'T CARRY THINGS.\\n8. IT'S IN THE CAR.\\n9. YOU LEFT IT IN THE CAR?! WHERE'S YOUR CAR?\\n10. OUTSIDE. I GOT A SPOT ON THE STREET.\\n11. YOU GUYS ORDER? ANYTHING LOOK GOOD?\\n12. DOES IT HURT?\", 'output': '{\"page_utterance_emotions\": [[\"joy\"], [\"joy\"], [\"joy\"], [\"joy\"], [\"surprise\", \"joy\"], [\"surprise\", \"joy\"], [\"sadness\"], [\"sadness\"], [\"fear\", \"surprise\"], [\"neutral\"], [\"surprise\"], [\"fear\", \"surprise\"]]}'}\n",
      "{'instruction': '### Emotion Analysis Expert Role\\n\\nYou are an advanced emotion analysis expert specializing in comic book dialogue interpretation. Your task is to analyze utterances and identify their emotional content.\\n\\nINPUT:\\n- You will receive a list of utterances from a page in a comic book\\n- The utterance may express one or multiple emotions\\n\\nTASK:\\n1. Carefully analyze the emotional context and tone of each utterance in the page\\n2. Identify applicable emotions from the following classes:\\n   \"anger\", \"disgust\", \"fear\", \"sadness\", \"surprise\", \"joy\", \"neutral\"\\n3. For each utterance in a comic page, identify all emotions present and return an array of emotion arrays in order.\\n\\nRULES:\\n1. Use ONLY the labels listed above\\n2. Output must be a JSON with single key \"page_utterance_emotions\"\\n3. Value must be an array where:\\n   - Each element is an array of emotions for one utterance\\n   - Order matches the input utterances order\\n   - Multiple emotions are allowed per utterance\\n4. No explanations, only JSON output\\n\\nIMPORTANT:\\n- Each array element corresponds to one utterance\\n- One utterance can have multiple emotions\\n- Maintain exact spelling and case of emotion labels\\n- Keep emotions in arrays even for single emotions\\n\\n', 'input': \"Now analyze these utterances in a page:\\n1. C'MON, WE'RE GOING.\\n2. WHAT'S WITH YOU?\\n3. HE JUST GOT HERE! LOOK WHAT HE'S BEEN THROUGH! LET HIM EAT.\\n4. I COULD EAT LATER.\\n5. IT'S NO TROUBLE.\\n6. IT'S IN HIS CAR.\\n7. WE'RE LEAVING. HURRY UP.\\n8. ALL RIGHT, I'M COMING!\\n9. GOD, EVERYTHING'S AN ORDER TO YOU. YOU'RE NOT IN THE MILITARY ANYMORE, TRAVIS. I'M NOT YOUR PRIVATE. YES, SIR! NO, SIR!\\n10. DON'T GET RUFFLED. I PARKED RIGHT OUTSIDE, NOT IN THE LOT.\\n11. I'M SURE IT'S FINE.\", 'output': '{\"page_utterance_emotions\": [[\"anger\"], [\"fear\", \"surprise\"], [\"fear\"], [\"joy\"], [\"joy\"], [\"anger\"], [\"anger\"], [\"anger\"], [\"anger\", \"disgust\"], [\"joy\"], [\"joy\"]]}'}\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(data_file_test[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb35781",
   "metadata": {},
   "source": [
    "### Create and save JSON files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "01306b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = Path(DATASET_DIR) / \"comics35_utterance_pg_train.json\"\n",
    "\n",
    "with open(file_path, 'w') as file:\n",
    "    \n",
    "    json.dump(data_file_train, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9b6f5885",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = Path(DATASET_DIR) / \"comics35_utterance_pg_test.json\"\n",
    "\n",
    "with open(file_path, 'w') as file:\n",
    "    \n",
    "    json.dump(data_file_test, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a1d9bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
